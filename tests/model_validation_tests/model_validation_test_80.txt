import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add46512 = tf.keras.layers.Input(shape=([2, 2]))
in1Add46512 = tf.keras.layers.Input(shape=([2, 2]))
in0Min40189 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))
in1Min40189 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))

Add46512 = keras.layers.Add(name = 'Add46512', )([in0Add46512,in1Add46512])
Con1000 = keras.layers.Conv1D(2, (1),strides=(1), padding='same', dilation_rate=(1), name = 'Con1000', )(Add46512)
Zer45531 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer45531', )(Con1000)
Min40189 = keras.layers.Minimum(name = 'Min40189', )([in0Min40189,in1Min40189])
Res32803 = keras.layers.Reshape((2, 1, 2), name = 'Res32803', )(Min40189)
Res72735 = keras.layers.Reshape((2, 2), name = 'Res72735', )(Res32803)
Fla31606 = keras.layers.Flatten(name = 'Fla31606', )(Res72735)
Emb43591 = keras.layers.Embedding(1, 4, name = 'Emb43591', )(Fla31606)
Ave54764 = keras.layers.Average(name = 'Ave54764', )([Zer45531,Emb43591])
model = tf.keras.models.Model(inputs=[in0Add46512,in1Add46512,in0Min40189,in1Min40189], outputs=Ave54764)
w = model.get_layer('Con1000').get_weights() 
w[0] = np.array([[[0.1324, 0.8705], [0.5861, 0.5159]]])
w[1] = np.array([0, 0])
model.get_layer('Con1000').set_weights(w) 
w = model.get_layer('Emb43591').get_weights() 
w[0] =  np.array([[0.7986, 0.7927, 0.736, 0.3042]])
model.get_layer('Emb43591').set_weights(w) 
in0Add46512 = tf.constant([[[0.6352, 0.262], [0.1098, 0.954]]])
in1Add46512 = tf.constant([[[0.8323, 0.4041], [0.3762, 0.8859]]])
in0Min40189 = tf.constant([[[[[0.2171, 0.8424]]], [[[0.7548, 0.7641]]]]])
in1Min40189 = tf.constant([[[[[0.4332, 0.6752]]], [[[0.4131, 0.9748]]]]])
print (np.array2string(model.predict([in0Add46512,in1Add46512,in0Min40189,in1Min40189],steps=1), separator=', '))


LAdd46512 = add_layer([[[[0.6352, 0.262], [0.1098, 0.954]]], [[[0.8323, 0.4041], [0.3762, 0.8859]]]], Add46512), 
LCon1000 = conv1D_layer(Add46512, 1,[[[0.1324, 0.8705], [0.5861, 0.5159]]],[0, 0], 1, true, 1, Con1000), 
LZer45531 = zero_padding1D_layer(Con1000, 2, 0, Zer45531), 
LMin40189 = minimum_layer([[[[[[0.2171, 0.8424]]], [[[0.7548, 0.7641]]]]], [[[[[0.4332, 0.6752]]], [[[0.4131, 0.9748]]]]]], Min40189), 
LRes32803 = reshape_layer(Min40189, [2, 1, 2], Res32803), 
LRes72735 = reshape_layer(Res32803, [2, 2], Res72735), 
LFla31606 = flatten_layer(Res72735, Fla31606), 
LEmb43591 = embedding_layer(Fla31606, [[0.7986, 0.7927, 0.736, 0.3042]], Emb43591), 
LAve54764 = average_layer([Zer45531,Emb43591], Ave54764), 
exec_layers([LAdd46512,LCon1000,LZer45531,LMin40189,LRes32803,LRes72735,LFla31606,LEmb43591,LAve54764],["Add46512","Con1000","Zer45531","Min40189","Res32803","Res72735","Fla31606","Emb43591","Ave54764"],Ave54764,"Ave54764")

Actual (Unparsed): 
 ValueError(ValueError: Operands could not be broadcast together with shapes (4, 2) (4, 4)

Expected (Unparsed): 
Ave54764: Inconsistent Input Shapes, Input Shape [1,4,2]

Actual:   

Expected: 