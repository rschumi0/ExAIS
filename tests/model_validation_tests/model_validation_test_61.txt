import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0LST5309 = tf.keras.layers.Input(shape=([3, 2]))
in0Con39387 = tf.keras.layers.Input(shape=([2, 1, 3, 1]))
in0Add51493 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in1Add51493 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Min29818 = tf.keras.layers.Input(shape=([2, 2, 1]))
in1Min29818 = tf.keras.layers.Input(shape=([2, 2, 1]))

LST5309 = keras.layers.RNN(keras.layers.LSTMCell(2,recurrent_activation='sigmoid', ), name = 'LST5309', input_shape=(3, 2))(in0LST5309)
Res88977 = keras.layers.Reshape((2, 1), name = 'Res88977', )(LST5309)
Res57861 = keras.layers.Reshape((2, 1, 1), name = 'Res57861', )(Res88977)
Res12876 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res12876', )(Res57861)
Zer73234 = keras.layers.ZeroPadding3D(padding=((0, 0), (0, 0), (2, 0)), name = 'Zer73234', )(Res12876)
Con39387 = keras.layers.Concatenate(axis=4, name = 'Con39387', )([Zer73234,in0Con39387])
Add51493 = keras.layers.Add(name = 'Add51493', )([in0Add51493,in1Add51493])
Zer49569 = keras.layers.ZeroPadding3D(padding=((1, 0), (0, 0), (1, 0)), name = 'Zer49569', )(Add51493)
Ave75527 = keras.layers.Average(name = 'Ave75527', )([Con39387,Zer49569])
Res28240 = keras.layers.Reshape((2, 1, 6), name = 'Res28240', )(Ave75527)
Res14562 = keras.layers.Reshape((2, 6), name = 'Res14562', )(Res28240)
Fla27757 = keras.layers.Flatten(name = 'Fla27757', )(Res14562)
Min29818 = keras.layers.Minimum(name = 'Min29818', )([in0Min29818,in1Min29818])
Res52125 = keras.layers.Reshape((2, 2), name = 'Res52125', )(Min29818)
Glo57019 = keras.layers.GlobalMaxPool1D(name = 'Glo57019', )(Res52125)
Sub81892 = keras.layers.Subtract(name = 'Sub81892', )([Fla27757,Glo57019])
model = tf.keras.models.Model(inputs=[in0LST5309,in0Con39387,in0Add51493,in1Add51493,in0Min29818,in1Min29818], outputs=Sub81892)
w = model.get_layer('LST5309').get_weights() 
w[0] = np.array([[6, 10, 5, 9, 7, 6, 3, 1], [6, 6, 6, 10, 1, 3, 10, 3]])
w[1] = np.array([[10, 8, 5, 6, 7, 2, 5, 4], [10, 10, 3, 6, 6, 8, 3, 4]])
w[2] = np.array([7, 1, 10, 7, 9, 10, 1, 8])
model.get_layer('LST5309').set_weights(w) 
in0LST5309 = tf.constant([[[3, 1], [10, 9], [4, 8]]])
in0Con39387 = tf.constant([[[[[0.6717], [0.5562], [0.994]]], [[[0.8726], [0.001], [0.7585]]]]])
in0Add51493 = tf.constant([[[[[0.4362, 0.7064], [0.8362, 0.7004]]]]])
in1Add51493 = tf.constant([[[[[0.5371, 0.9191], [0.0715, 0.8914]]]]])
in0Min29818 = tf.constant([[[[0.7448], [0.4558]], [[0.0697], [0.5466]]]])
in1Min29818 = tf.constant([[[[0.534], [0.823]], [[0.8861], [0.3671]]]])
print (np.array2string(model.predict([in0LST5309,in0Con39387,in0Add51493,in1Add51493,in0Min29818,in1Min29818],steps=1), separator=', '))


LLST5309 = lstmcell_layer([[[3, 1], [10, 9], [4, 8]]],[[6, 10, 5, 9, 7, 6, 3, 1], [6, 6, 6, 10, 1, 3, 10, 3]],[[10, 8, 5, 6, 7, 2, 5, 4], [10, 10, 3, 6, 6, 8, 3, 4]],[7, 1, 10, 7, 9, 10, 1, 8], LST5309), 
LRes88977 = reshape_layer(LST5309, [2, 1], Res88977), 
LRes57861 = reshape_layer(Res88977, [2, 1, 1], Res57861), 
LRes12876 = reshape_layer(Res57861, [2, 1, 1, 1], Res12876), 
LZer73234 = zero_padding3D_layer(Res12876, 0, 0, 0, 0, 2, 0, Zer73234), 
LCon39387 = concatenate_layer([Zer73234,[[[[[0.6717], [0.5562], [0.994]]], [[[0.8726], [0.001], [0.7585]]]]]], 4, Con39387), 
LAdd51493 = add_layer([[[[[[0.4362, 0.7064], [0.8362, 0.7004]]]]], [[[[[0.5371, 0.9191], [0.0715, 0.8914]]]]]], Add51493), 
LZer49569 = zero_padding3D_layer(Add51493, 1, 0, 0, 0, 1, 0, Zer49569), 
LAve75527 = average_layer([Con39387,Zer49569], Ave75527), 
LRes28240 = reshape_layer(Ave75527, [2, 1, 6], Res28240), 
LRes14562 = reshape_layer(Res28240, [2, 6], Res14562), 
LFla27757 = flatten_layer(Res14562, Fla27757), 
LMin29818 = minimum_layer([[[[[0.7448], [0.4558]], [[0.0697], [0.5466]]]], [[[[0.534], [0.823]], [[0.8861], [0.3671]]]]], Min29818), 
LRes52125 = reshape_layer(Min29818, [2, 2], Res52125), 
LGlo57019 = global_max_pool1D_layer(Res52125, Glo57019), 
LSub81892 = subtract_layer(Fla27757,Glo57019, Sub81892), 
exec_layers([LLST5309,LRes88977,LRes57861,LRes12876,LZer73234,LCon39387,LAdd51493,LZer49569,LAve75527,LRes28240,LRes14562,LFla27757,LMin29818,LRes52125,LGlo57019,LSub81892],["LST5309","Res88977","Res57861","Res12876","Zer73234","Con39387","Add51493","Zer49569","Ave75527","Res28240","Res14562","Fla27757","Min29818","Res52125","Glo57019","Sub81892"],Sub81892,"Sub81892")

Actual (Unparsed): 
 ValueError(ValueError: Operands could not be broadcast together with shapes (12,) (2,)

Expected (Unparsed): 
Sub81892: Inconsistent Input Shapes, Input Shape [1,12]

Actual:   

Expected: 