import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave409 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Ave409 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Mul50792 = tf.keras.layers.Input(shape=([1, 1]))
in1Mul50792 = tf.keras.layers.Input(shape=([1, 1]))
in0Con52315 = tf.keras.layers.Input(shape=([3]))
in0Min74663 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in1Min74663 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in0Con91176 = tf.keras.layers.Input(shape=([12]))
in0Min24755 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in1Min24755 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))

Ave409 = keras.layers.Average(name = 'Ave409', )([in0Ave409,in1Ave409])
Res19313 = keras.layers.Reshape((2, 2, 4), name = 'Res19313', )(Ave409)
Res69770 = keras.layers.Reshape((2, 8), name = 'Res69770', )(Res19313)
Fla47163 = keras.layers.Flatten(name = 'Fla47163', )(Res69770)
Mul50792 = keras.layers.Multiply(name = 'Mul50792', )([in0Mul50792,in1Mul50792])
Fla57471 = keras.layers.Flatten(name = 'Fla57471', )(Mul50792)
Con52315 = keras.layers.Concatenate(axis=1, name = 'Con52315', )([Fla57471,in0Con52315])
Min74663 = keras.layers.Minimum(name = 'Min74663', )([in0Min74663,in1Min74663])
Fla29663 = keras.layers.Flatten(name = 'Fla29663', )(Min74663)
Sub87941 = keras.layers.Subtract(name = 'Sub87941', )([Con52315,Fla29663])
Con91176 = keras.layers.Concatenate(axis=1, name = 'Con91176', )([Sub87941,in0Con91176])
Sub54391 = keras.layers.Subtract(name = 'Sub54391', )([Fla47163,Con91176])
Min24755 = keras.layers.Minimum(name = 'Min24755', )([in0Min24755,in1Min24755])
Res28269 = keras.layers.Reshape((1, 2, 4), name = 'Res28269', )(Min24755)
Res59433 = keras.layers.Reshape((1, 8), name = 'Res59433', )(Res28269)
Glo76771 = keras.layers.GlobalAveragePooling1D(name = 'Glo76771', )(Res59433)
Add56990 = keras.layers.Add(name = 'Add56990', )([Sub54391,Glo76771])
model = tf.keras.models.Model(inputs=[in0Ave409,in1Ave409,in0Mul50792,in1Mul50792,in0Con52315,in0Min74663,in1Min74663,in0Con91176,in0Min24755,in1Min24755], outputs=Add56990)
in0Ave409 = tf.constant([[[[[0.1639, 0.7805], [0.8224, 0.3028]], [[0.5382, 0.9371], [0.2117, 0.1575]]], [[[0.7108, 0.4975], [0.3814, 0.2562]], [[0.8529, 0.7927], [0.9572, 0.6773]]]]])
in1Ave409 = tf.constant([[[[[0.9309, 0.3796], [0.0433, 0.4424]], [[0.8912, 0.0723], [0.8791, 0.3601]]], [[[0.7666, 0.4491], [0.5845, 0.6294]], [[0.9893, 0.736], [0.1434, 0.258]]]]])
in0Mul50792 = tf.constant([[[0.157]]])
in1Mul50792 = tf.constant([[[0.0619]]])
in0Con52315 = tf.constant([[0.8818, 0.7787, 0.1357]])
in0Min74663 = tf.constant([[[[[0.8173], [0.6414]], [[0.8616], [0.825]]]]])
in1Min74663 = tf.constant([[[[[0.1171], [0.1013]], [[0.9585], [0.3137]]]]])
in0Con91176 = tf.constant([[0.8501, 0.6696, 0.901, 0.6992, 0.2442, 0.3677, 0.1962, 0.4464, 0.9051, 0.1948, 0.058, 0.3475]])
in0Min24755 = tf.constant([[[[[0.3162, 0.7865], [0.8351, 0.7864]], [[0.2369, 0.1036], [0.8165, 0.9282]]]]])
in1Min24755 = tf.constant([[[[[0.7078, 0.7625], [0.8384, 0.9762]], [[0.6549, 0.5982], [0.9108, 0.8331]]]]])
print (np.array2string(model.predict([in0Ave409,in1Ave409,in0Mul50792,in1Mul50792,in0Con52315,in0Min74663,in1Min74663,in0Con91176,in0Min24755,in1Min24755],steps=1), separator=', '))


LAve409 = average_layer([[[[[[0.1639, 0.7805], [0.8224, 0.3028]], [[0.5382, 0.9371], [0.2117, 0.1575]]], [[[0.7108, 0.4975], [0.3814, 0.2562]], [[0.8529, 0.7927], [0.9572, 0.6773]]]]], [[[[[0.9309, 0.3796], [0.0433, 0.4424]], [[0.8912, 0.0723], [0.8791, 0.3601]]], [[[0.7666, 0.4491], [0.5845, 0.6294]], [[0.9893, 0.736], [0.1434, 0.258]]]]]], Ave409), 
LRes19313 = reshape_layer(Ave409, [2, 2, 4], Res19313), 
LRes69770 = reshape_layer(Res19313, [2, 8], Res69770), 
LFla47163 = flatten_layer(Res69770, Fla47163), 
LMul50792 = multiply_layer([[[[0.157]]], [[[0.0619]]]], Mul50792), 
LFla57471 = flatten_layer(Mul50792, Fla57471), 
LCon52315 = concatenate_layer([Fla57471,[[0.8818, 0.7787, 0.1357]]], 1, Con52315), 
LMin74663 = minimum_layer([[[[[[0.8173], [0.6414]], [[0.8616], [0.825]]]]], [[[[[0.1171], [0.1013]], [[0.9585], [0.3137]]]]]], Min74663), 
LFla29663 = flatten_layer(Min74663, Fla29663), 
LSub87941 = subtract_layer(Con52315,Fla29663, Sub87941), 
LCon91176 = concatenate_layer([Sub87941,[[0.8501, 0.6696, 0.901, 0.6992, 0.2442, 0.3677, 0.1962, 0.4464, 0.9051, 0.1948, 0.058, 0.3475]]], 1, Con91176), 
LSub54391 = subtract_layer(Fla47163,Con91176, Sub54391), 
LMin24755 = minimum_layer([[[[[[0.3162, 0.7865], [0.8351, 0.7864]], [[0.2369, 0.1036], [0.8165, 0.9282]]]]], [[[[[0.7078, 0.7625], [0.8384, 0.9762]], [[0.6549, 0.5982], [0.9108, 0.8331]]]]]], Min24755), 
LRes28269 = reshape_layer(Min24755, [1, 2, 4], Res28269), 
LRes59433 = reshape_layer(Res28269, [1, 8], Res59433), 
LGlo76771 = global_average_pooling1D_layer(Res59433, Glo76771), 
LAdd56990 = add_layer([Sub54391,Glo76771], Add56990), 
exec_layers([LAve409,LRes19313,LRes69770,LFla47163,LMul50792,LFla57471,LCon52315,LMin74663,LFla29663,LSub87941,LCon91176,LSub54391,LMin24755,LRes28269,LRes59433,LGlo76771,LAdd56990],["Ave409","Res19313","Res69770","Fla47163","Mul50792","Fla57471","Con52315","Min74663","Fla29663","Sub87941","Con91176","Sub54391","Min24755","Res28269","Res59433","Glo76771","Add56990"],Add56990,"Add56990")

Actual (Unparsed): 
 ValueError(ValueError: Operands could not be broadcast together with shapes (16,) (8,)

Expected (Unparsed): 
Add56990: Inconsistent Input Shapes, Input Shape [1,16]

Actual:   

Expected: 