import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul39378 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Mul39378 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con94585 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in0ReL80180 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in0Dep66057 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con71801 = tf.keras.layers.Input(shape=([2, 2, 3]))
in0Dot80014 = tf.keras.layers.Input(shape=([2, 3]))
in1Dot80014 = tf.keras.layers.Input(shape=([2, 3]))

Mul39378 = keras.layers.Multiply(name = 'Mul39378', )([in0Mul39378,in1Mul39378])
Res43076 = keras.layers.Reshape((2, 2, 2, 1), name = 'Res43076', )(Mul39378)
Con94585 = keras.layers.Concatenate(axis=4, name = 'Con94585', )([Res43076,in0Con94585])
ReL80180 = keras.layers.ReLU(max_value=5.541726379910661, negative_slope=9.87279638656418, threshold=1.5919839571067829, name = 'ReL80180', input_shape=(1, 2, 2, 2))(in0ReL80180)
Zer98144 = keras.layers.ZeroPadding3D(padding=((1, 0), (0, 0), (0, 0)), name = 'Zer98144', )(ReL80180)
Sub97939 = keras.layers.Subtract(name = 'Sub97939', )([Con94585,Zer98144])
Res18712 = keras.layers.Reshape((2, 2, 4), name = 'Res18712', )(Sub97939)
Dep66057 = keras.layers.DepthwiseConv2D((1, 1),strides=(1, 1), padding='same', name = 'Dep66057', )(in0Dep66057)
Zer28904 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer28904', )(Dep66057)
Con71801 = keras.layers.Concatenate(axis=3, name = 'Con71801', )([Zer28904,in0Con71801])
Add70901 = keras.layers.Add(name = 'Add70901', )([Res18712,Con71801])
Res29901 = keras.layers.Reshape((2, 8), name = 'Res29901', )(Add70901)
Dot80014 = keras.layers.Dot(axes=(2, 2), name = 'Dot80014', )([in0Dot80014,in1Dot80014])
Max15334 = keras.layers.Maximum(name = 'Max15334', )([Res29901,Dot80014])
model = tf.keras.models.Model(inputs=[in0Mul39378,in1Mul39378,in0Con94585,in0ReL80180,in0Dep66057,in0Con71801,in0Dot80014,in1Dot80014], outputs=Max15334)
w = model.get_layer('Dep66057').get_weights() 
w[0] = np.array([[[[0.3508]]]])
w[1] = np.array([0])
model.get_layer('Dep66057').set_weights(w) 
in0Mul39378 = tf.constant([[[[0.9037, 0.5804], [0.9433, 0.5309]], [[0.9599, 0.0692], [0.2315, 0.8146]]]])
in1Mul39378 = tf.constant([[[[0.8206, 0.9673], [0.6715, 0.4104]], [[0.0181, 0.1655], [0.3214, 0.0369]]]])
in0Con94585 = tf.constant([[[[[0.2835], [0.2641]], [[0.7679], [0.0549]]], [[[0.2169], [0.1767]], [[0.7498], [0.0723]]]]])
in0ReL80180 = tf.constant([[[[[0.4918, 0.9692], [0.7956, 0.1846]], [[0.3728, 0.5546], [0.4762, 0.5234]]]]])
in0Dep66057 = tf.constant([[[[0.4351], [0.7749]]]])
in0Con71801 = tf.constant([[[[0.9309, 0.6886, 0.8107], [0.6226, 0.8985, 0.3973]], [[0.6036, 0.2477, 0.6118], [0.433, 0.0379, 0.0906]]]])
in0Dot80014 = tf.constant([[[0.5129, 0.3672, 0.5909], [0.3266, 0.3222, 0.3711]]])
in1Dot80014 = tf.constant([[[0.6676, 0.1252, 0.6692], [0.6147, 0.844, 0.104]]])
print (np.array2string(model.predict([in0Mul39378,in1Mul39378,in0Con94585,in0ReL80180,in0Dep66057,in0Con71801,in0Dot80014,in1Dot80014],steps=1), separator=', '))


LMul39378 = multiply_layer([[[[[0.9037, 0.5804], [0.9433, 0.5309]], [[0.9599, 0.0692], [0.2315, 0.8146]]]], [[[[0.8206, 0.9673], [0.6715, 0.4104]], [[0.0181, 0.1655], [0.3214, 0.0369]]]]], Mul39378), 
LRes43076 = reshape_layer(Mul39378, [2, 2, 2, 1], Res43076), 
LCon94585 = concatenate_layer([Res43076,[[[[[0.2835], [0.2641]], [[0.7679], [0.0549]]], [[[0.2169], [0.1767]], [[0.7498], [0.0723]]]]]], 4, Con94585), 
LReL80180 = relu_layer([[[[[0.4918, 0.9692], [0.7956, 0.1846]], [[0.3728, 0.5546], [0.4762, 0.5234]]]]], 5.541726379910661, 9.87279638656418, 1.5919839571067829, ReL80180), 
LZer98144 = zero_padding3D_layer(ReL80180, 1, 0, 0, 0, 0, 0, Zer98144), 
LSub97939 = subtract_layer(Con94585,Zer98144, Sub97939), 
LRes18712 = reshape_layer(Sub97939, [2, 2, 4], Res18712), 
LDep66057 = depthwise_conv2D_layer([[[[0.4351], [0.7749]]]], 1, 1,[[[[0.3508]]]],[0], 1, 1, true, Dep66057), 
LZer28904 = zero_padding2D_layer(Dep66057, 1, 0, 0, 0, Zer28904), 
LCon71801 = concatenate_layer([Zer28904,[[[[0.9309, 0.6886, 0.8107], [0.6226, 0.8985, 0.3973]], [[0.6036, 0.2477, 0.6118], [0.433, 0.0379, 0.0906]]]]], 3, Con71801), 
LAdd70901 = add_layer([Res18712,Con71801], Add70901), 
LRes29901 = reshape_layer(Add70901, [2, 8], Res29901), 
LDot80014 = dot_layer([[[0.5129, 0.3672, 0.5909], [0.3266, 0.3222, 0.3711]]], [[[0.6676, 0.1252, 0.6692], [0.6147, 0.844, 0.104]]], 2, 2, Dot80014), 
LMax15334 = maximum_layer([Res29901,Dot80014], Max15334), 
exec_layers([LMul39378,LRes43076,LCon94585,LReL80180,LZer98144,LSub97939,LRes18712,LDep66057,LZer28904,LCon71801,LAdd70901,LRes29901,LDot80014,LMax15334],["Mul39378","Res43076","Con94585","ReL80180","Zer98144","Sub97939","Res18712","Dep66057","Zer28904","Con71801","Add70901","Res29901","Dot80014","Max15334"],Max15334,"Max15334")

Actual (Unparsed): 
 ValueError(ValueError: Operands could not be broadcast together with shapes (2, 8) (2, 2)

Expected (Unparsed): 
Max15334: Inconsistent Input Shapes, Input Shape [1,2,8]

Actual:   

Expected: 