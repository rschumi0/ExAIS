import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo83003 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Add17226 = tf.keras.layers.Input(shape=([1, 1]))
in1Add17226 = tf.keras.layers.Input(shape=([1, 1]))
in0Con11236 = tf.keras.layers.Input(shape=([2, 1]))
in0Min57366 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in1Min57366 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in0Add24414 = tf.keras.layers.Input(shape=([2, 2]))
in1Add24414 = tf.keras.layers.Input(shape=([2, 2]))

Glo83003 = keras.layers.GlobalAveragePooling2D(name = 'Glo83003', )(in0Glo83003)
ReL14489 = keras.layers.ReLU(max_value=1.935296227930376, negative_slope=8.177506808284818, threshold=2.7155542585712733, name = 'ReL14489', )(Glo83003)
Res6524 = keras.layers.Reshape((2, 1), name = 'Res6524', )(ReL14489)
Add17226 = keras.layers.Add(name = 'Add17226', )([in0Add17226,in1Add17226])
Lay93607 = keras.layers.LayerNormalization(axis=1, epsilon=1.4423564235357564, name = 'Lay93607', )(Add17226)
Zer84369 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer84369', )(Lay93607)
Con11236 = keras.layers.Concatenate(axis=2, name = 'Con11236', )([Zer84369,in0Con11236])
Min57366 = keras.layers.Minimum(name = 'Min57366', )([in0Min57366,in1Min57366])
Res60079 = keras.layers.Reshape((2, 2, 1), name = 'Res60079', )(Min57366)
Res82307 = keras.layers.Reshape((2, 2), name = 'Res82307', )(Res60079)
Add24414 = keras.layers.Add(name = 'Add24414', )([in0Add24414,in1Add24414])
Sub80120 = keras.layers.Subtract(name = 'Sub80120', )([Res82307,Add24414])
Dot12053 = keras.layers.Dot(axes=(2, 1), name = 'Dot12053', )([Con11236,Sub80120])
Dot37315 = keras.layers.Dot(axes=(1, 1), name = 'Dot37315', )([Res6524,Dot12053])
model = tf.keras.models.Model(inputs=[in0Glo83003,in0Add17226,in1Add17226,in0Con11236,in0Min57366,in1Min57366,in0Add24414,in1Add24414], outputs=Dot37315)
in0Glo83003 = tf.constant([[[[1.5491, 1.1378], [1.591, 1.8033]], [[1.8498, 1.8687], [1.3584, 1.4531]]]])
in0Add17226 = tf.constant([[[0.9826]]])
in1Add17226 = tf.constant([[[0.8682]]])
in0Con11236 = tf.constant([[[0.0776], [0.222]]])
in0Min57366 = tf.constant([[[[[0.4318]], [[0.1139]]], [[[0.8466]], [[0.1169]]]]])
in1Min57366 = tf.constant([[[[[0.5163]], [[0.1416]]], [[[0.4233]], [[0.9208]]]]])
in0Add24414 = tf.constant([[[0.4031, 0.5474], [0.179, 0.166]]])
in1Add24414 = tf.constant([[[0.522, 0.9585], [0.3845, 0.8681]]])
print (np.array2string(model.predict([in0Glo83003,in0Add17226,in1Add17226,in0Con11236,in0Min57366,in1Min57366,in0Add24414,in1Add24414],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot37315.png')

LGlo83003 = global_average_pooling2D_layer([[[[1.5491, 1.1378], [1.591, 1.8033]], [[1.8498, 1.8687], [1.3584, 1.4531]]]], Glo83003), 
LReL14489 = relu_layer(Glo83003, 1.935296227930376, 8.177506808284818, 2.7155542585712733, ReL14489), 
LRes6524 = reshape_layer(ReL14489, [2, 1], Res6524), 
LAdd17226 = add_layer([[[[0.9826]]], [[[0.8682]]]], Add17226), 
LLay93607 = layer_normalization_layer(Add17226, 1, 1.4423564235357564, Lay93607), 
LZer84369 = zero_padding1D_layer(Lay93607, 1, 0, Zer84369), 
LCon11236 = concatenate_layer([Zer84369,[[[0.0776], [0.222]]]], 2, Con11236), 
LMin57366 = minimum_layer([[[[[[0.4318]], [[0.1139]]], [[[0.8466]], [[0.1169]]]]], [[[[[0.5163]], [[0.1416]]], [[[0.4233]], [[0.9208]]]]]], Min57366), 
LRes60079 = reshape_layer(Min57366, [2, 2, 1], Res60079), 
LRes82307 = reshape_layer(Res60079, [2, 2], Res82307), 
LAdd24414 = add_layer([[[[0.4031, 0.5474], [0.179, 0.166]]], [[[0.522, 0.9585], [0.3845, 0.8681]]]], Add24414), 
LSub80120 = subtract_layer(Res82307,Add24414, Sub80120), 
LDot12053 = dot_layer(Con11236,Sub80120, 2, 1, Dot12053), 
LDot37315 = dot_layer(Res6524,Dot12053, 1, 1, Dot37315), 
exec_layers([LGlo83003,LReL14489,LRes6524,LAdd17226,LLay93607,LZer84369,LCon11236,LMin57366,LRes60079,LRes82307,LAdd24414,LSub80120,LDot12053,LDot37315],["Glo83003","ReL14489","Res6524","Add17226","Lay93607","Zer84369","Con11236","Min57366","Res60079","Res82307","Add24414","Sub80120","Dot12053","Dot37315"],Dot37315,"Dot37315")

Actual (Unparsed): [[[0.3930524, 2.5713810]]]

Expected (Unparsed): [[[0.39305234262297123,2.571380946175387]]]

Actual:   [[[0.3931, 2.5714]]]

Expected: [[[0.3931, 2.5714]]]