import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot97125 = tf.keras.layers.Input(shape=([2, 2]))
in1Dot97125 = tf.keras.layers.Input(shape=([2, 2]))
in0Con80769 = tf.keras.layers.Input(shape=([2, 10]))
in0Sub83863 = tf.keras.layers.Input(shape=([2, 2, 2, 3]))
in1Sub83863 = tf.keras.layers.Input(shape=([2, 2, 2, 3]))

Dot97125 = keras.layers.Dot(axes=(2, 1), name = 'Dot97125', )([in0Dot97125,in1Dot97125])
Con80769 = keras.layers.Concatenate(axis=2, name = 'Con80769', )([Dot97125,in0Con80769])
Sub83863 = keras.layers.Subtract(name = 'Sub83863', )([in0Sub83863,in1Sub83863])
Res52340 = keras.layers.Reshape((2, 2, 6), name = 'Res52340', )(Sub83863)
Res80146 = keras.layers.Reshape((2, 12), name = 'Res80146', )(Res52340)
Dot91342 = keras.layers.Dot(axes=(1, 1), name = 'Dot91342', )([Con80769,Res80146])
model = tf.keras.models.Model(inputs=[in0Dot97125,in1Dot97125,in0Con80769,in0Sub83863,in1Sub83863], outputs=Dot91342)
in0Dot97125 = tf.constant([[[0.3821, 0.1083], [0.3304, 0.6695]]])
in1Dot97125 = tf.constant([[[0.711, 0.945], [0.4066, 0.9882]]])
in0Con80769 = tf.constant([[[0.6129, 0.8631, 0.9897, 0.4798, 0.6686, 0.1136, 0.5127, 0.6424, 0.6413, 0.8296], [0.4957, 0.5211, 0.7166, 0.2665, 0.6658, 0.4886, 0.0374, 0.7663, 0.7695, 0.4301]]])
in0Sub83863 = tf.constant([[[[[0.8518, 0.0617, 0.269], [0.2891, 0.9774, 0.7102]], [[0.1977, 0.7997, 0.8912], [0.7323, 0.3556, 0.6963]]], [[[0.877, 0.2054, 0.8432], [0.4043, 0.5961, 0.7942]], [[0.4717, 0.0544, 0.0987], [0.8404, 0.0391, 0.6901]]]]])
in1Sub83863 = tf.constant([[[[[0.3016, 0.7632, 0.5079], [0.8177, 0.4785, 0.0449]], [[0.5013, 0.5453, 0.4068], [0.9319, 0.9665, 0.8639]]], [[[0.8185, 0.995, 0.6813], [0.5932, 0.7173, 0.8603]], [[0.5226, 0.1331, 0.9365], [0.7487, 0.0608, 0.4432]]]]])
print (np.array2string(model.predict([in0Dot97125,in1Dot97125,in0Con80769,in0Sub83863,in1Sub83863],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot91342.png')

LDot97125 = dot_layer([[[0.3821, 0.1083], [0.3304, 0.6695]]], [[[0.711, 0.945], [0.4066, 0.9882]]], 2, 1, Dot97125), 
LCon80769 = concatenate_layer([Dot97125,[[[0.6129, 0.8631, 0.9897, 0.4798, 0.6686, 0.1136, 0.5127, 0.6424, 0.6413, 0.8296], [0.4957, 0.5211, 0.7166, 0.2665, 0.6658, 0.4886, 0.0374, 0.7663, 0.7695, 0.4301]]]], 2, Con80769), 
LSub83863 = subtract_layer([[[[[0.8518, 0.0617, 0.269], [0.2891, 0.9774, 0.7102]], [[0.1977, 0.7997, 0.8912], [0.7323, 0.3556, 0.6963]]], [[[0.877, 0.2054, 0.8432], [0.4043, 0.5961, 0.7942]], [[0.4717, 0.0544, 0.0987], [0.8404, 0.0391, 0.6901]]]]], [[[[[0.3016, 0.7632, 0.5079], [0.8177, 0.4785, 0.0449]], [[0.5013, 0.5453, 0.4068], [0.9319, 0.9665, 0.8639]]], [[[0.8185, 0.995, 0.6813], [0.5932, 0.7173, 0.8603]], [[0.5226, 0.1331, 0.9365], [0.7487, 0.0608, 0.4432]]]]], Sub83863), 
LRes52340 = reshape_layer(Sub83863, [2, 2, 6], Res52340), 
LRes80146 = reshape_layer(Res52340, [2, 12], Res80146), 
LDot91342 = dot_layer(Con80769,Res80146, 1, 1, Dot91342), 
exec_layers([LDot97125,LCon80769,LSub83863,LRes52340,LRes80146,LDot91342],["Dot97125","Con80769","Sub83863","Res52340","Res80146","Dot91342"],Dot91342,"Dot91342")

Actual (Unparsed): [[[0.2033698, -0.6219014, 0.0066823, -0.2626807, 0.0960421, 0.1765190, -0.1216620, 0.0404047, -0.2719472, -0.0165112, -0.2038707, 0.0722985], [0.3145212, -1.0973112, 0.0458321, -0.4313972, 0.1155104, 0.2470613, -0.1916850, 0.0424461, -0.5891222, -0.0041341, -0.3070983, 0.1619835], [0.3662160, -0.8213541, -0.0661680, -0.4176167, 0.2456970, 0.3749966, -0.2113076, 0.1169102, -0.1184087, -0.0768792, -0.3851773, 0.0196663], [0.5053620, -1.0169252, -0.1218285, -0.5546705, 0.3674433, 0.5397757, -0.2885611, 0.1785621, -0.0184919, -0.1244899, -0.5385756, -0.0159959], [0.5864541, -1.2601019, -0.1204218, -0.6585212, 0.4069094, 0.6110802, -0.3369478, 0.1953833, -0.1209568, -0.1318320, -0.6201579, 0.0110549], [0.2795762, -0.5470081, -0.0714779, -0.3039641, 0.2070724, 0.3015953, -0.1592321, 0.1010876, 0.0091414, -0.0713301, -0.2988929, -0.0146156], [0.4068130, -0.9947386, -0.0519355, -0.4791916, 0.2528696, 0.4008102, -0.2368762, 0.1176934, -0.2339374, -0.0723988, -0.4228956, 0.0523287], [0.0910858, -0.4654889, 0.0519653, -0.1523455, -0.0025433, 0.0432816, -0.0593587, -0.0095530, -0.3543212, 0.0221300, -0.0800009, 0.1015960], [0.2842755, -0.3891901, -0.1164290, -0.2780781, 0.2512532, 0.3386272, -0.1575594, 0.1274875, 0.2170182, -0.0989054, -0.3140200, -0.0766945], [0.3982770, -1.0557141, -0.0294054, -0.4843268, 0.2276178, 0.3767363, -0.2340373, 0.1031188, -0.3308276, -0.0579534, -0.4090709, 0.0815333], [0.3978590, -1.0574692, -0.0286245, -0.4843498, 0.2266812, 0.3757930, -0.2338662, 0.1025871, -0.3340414, -0.0574404, -0.4084683, 0.0825077], [0.4816068, -0.9215713, -0.1285582, -0.5197725, 0.3617593, 0.5235033, -0.2737586, 0.1772014, 0.0415205, -0.1261480, -0.5161358, -0.0328492]]]

Expected (Unparsed): [[[0.20336976192599998,-0.62190137358,0.006682236357999971,-0.26268062795799996,0.09604212961199998,0.17651895465400003,-0.12166198715799996,0.04040470970199998,-0.27194721410800005,-0.016511187578,-0.203870732162,0.07229852170200006],[0.314521161462,-1.0973112616799998,0.04583207982599993,-0.4313972179259999,0.11551042130399994,0.24706127017800006,-0.1916849917259999,0.04244605313399999,-0.5891221969559999,-0.004134050946000001,-0.307098362934,0.16198344905400003],[0.36621603,-0.8213540699999999,-0.06616798000000006,-0.41761666999999997,0.24569697000000001,0.3749966,-0.21130756999999994,0.11691016999999998,-0.11840869999999998,-0.07687915000000001,-0.3851773,0.019666290000000045],[0.50536197,-1.0169252100000001,-0.12182850000000002,-0.5546704499999999,0.36744327,0.5397757200000001,-0.28856115,0.17856206999999996,-0.01849194000000004,-0.12448988999999999,-0.53857566,-0.015995969999999915],[0.5864540400000001,-1.26010191,-0.12042179000000004,-0.6585211599999999,0.40690940999999997,0.6110801500000002,-0.33694785999999993,0.19538325999999995,-0.12095679999999992,-0.1318319,-0.62015795,0.011054820000000076],[0.27957621,-0.5470081,-0.07147787000000001,-0.30396413,0.20707242,0.30159529,-0.15923212999999997,0.10108756999999999,0.009141419999999983,-0.07133003,-0.29889287000000003,-0.014615629999999963],[0.40681301999999997,-0.9947385799999999,-0.051935520000000054,-0.47919157999999995,0.25286958,0.40081020000000006,-0.23687617999999994,0.11769337999999997,-0.23393739999999996,-0.07239870000000001,-0.4228956,0.05232866000000004],[0.09108582000000001,-0.46548895999999995,0.051965299999999964,-0.15234549999999997,-0.0025432800000000297,0.04328162000000004,-0.05935869999999997,-0.009552979999999996,-0.35432124,0.022130060000000003,-0.08000086,0.10159598000000003],[0.28427544000000005,-0.38919009000000004,-0.11642897,-0.27807808,0.25125315000000004,0.33862717000000003,-0.15755938,0.1274875,0.21701816000000002,-0.09890534000000001,-0.31402001,-0.07669445999999999],[0.39827703000000003,-1.05571408,-0.02940539000000006,-0.48432670999999994,0.22761779999999993,0.37673629000000003,-0.23403730999999994,0.10311874999999998,-0.33082758,-0.05795332999999998,-0.40907087,0.08153323000000005],[0.39785901,-1.05746915,-0.028624520000000042,-0.4843497299999999,0.22668117,0.3757929400000001,-0.23386622999999995,0.10258706999999997,-0.33404137999999994,-0.05744033,-0.40846832,0.08250767000000006],[0.48160677,-0.92157136,-0.12855825000000004,-0.5197724499999999,0.36175932,0.52350327,-0.27375864999999994,0.17720136999999997,0.04152045999999998,-0.12614799000000002,-0.51613581,-0.032849269999999944]]]

Actual:   [[[0.2034, -0.6219, 0.0067, -0.2626, 0.0961, 0.1766, -0.1216, 0.0405, -0.2719, -0.0165, -0.2038, 0.0723], [0.3146, -1.0973, 0.0459, -0.4313, 0.1156, 0.2471, -0.1916, 0.0425, -0.5891, -0.0041, -0.307, 0.162], [0.3663, -0.8213, -0.0661, -0.4176, 0.2457, 0.375, -0.2113, 0.117, -0.1184, -0.0768, -0.3851, 0.0197], [0.5054, -1.0169, -0.1218, -0.5546, 0.3675, 0.5398, -0.2885, 0.1786, -0.0184, -0.1244, -0.5385, -0.0159], [0.5865, -1.2601, -0.1204, -0.6585, 0.407, 0.6111, -0.3369, 0.1954, -0.1209, -0.1318, -0.6201, 0.0111], [0.2796, -0.547, -0.0714, -0.3039, 0.2071, 0.3016, -0.1592, 0.1011, 0.0092, -0.0713, -0.2988, -0.0146], [0.4069, -0.9947, -0.0519, -0.4791, 0.2529, 0.4009, -0.2368, 0.1177, -0.2339, -0.0723, -0.4228, 0.0524], [0.0911, -0.4654, 0.052, -0.1523, -0.0025, 0.0433, -0.0593, -0.0095, -0.3543, 0.0222, -0.08, 0.1016], [0.2843, -0.3891, -0.1164, -0.278, 0.2513, 0.3387, -0.1575, 0.1275, 0.2171, -0.0989, -0.314, -0.0766], [0.3983, -1.0557, -0.0294, -0.4843, 0.2277, 0.3768, -0.234, 0.1032, -0.3308, -0.0579, -0.409, 0.0816], [0.3979, -1.0574, -0.0286, -0.4843, 0.2267, 0.3758, -0.2338, 0.1026, -0.334, -0.0574, -0.4084, 0.0826], [0.4817, -0.9215, -0.1285, -0.5197, 0.3618, 0.5236, -0.2737, 0.1773, 0.0416, -0.1261, -0.5161, -0.0328]]]

Expected: [[[0.2034, -0.6219, 0.0067, -0.2626, 0.0961, 0.1766, -0.1216, 0.0405, -0.2719, -0.0165, -0.2038, 0.0723], [0.3146, -1.0973, 0.0459, -0.4313, 0.1156, 0.2471, -0.1916, 0.0425, -0.5891, -0.0041, -0.307, 0.162], [0.3663, -0.8213, -0.0661, -0.4176, 0.2457, 0.375, -0.2113, 0.117, -0.1184, -0.0768, -0.3851, 0.0197], [0.5054, -1.0169, -0.1218, -0.5546, 0.3675, 0.5398, -0.2885, 0.1786, -0.0184, -0.1244, -0.5385, -0.0159], [0.5865, -1.2601, -0.1204, -0.6585, 0.407, 0.6111, -0.3369, 0.1954, -0.1209, -0.1318, -0.6201, 0.0111], [0.2796, -0.547, -0.0714, -0.3039, 0.2071, 0.3016, -0.1592, 0.1011, 0.0092, -0.0713, -0.2988, -0.0146], [0.4069, -0.9947, -0.0519, -0.4791, 0.2529, 0.4009, -0.2368, 0.1177, -0.2339, -0.0723, -0.4228, 0.0524], [0.0911, -0.4654, 0.052, -0.1523, -0.0025, 0.0433, -0.0593, -0.0095, -0.3543, 0.0222, -0.08, 0.1016], [0.2843, -0.3891, -0.1164, -0.278, 0.2513, 0.3387, -0.1575, 0.1275, 0.2171, -0.0989, -0.314, -0.0766], [0.3983, -1.0557, -0.0294, -0.4843, 0.2277, 0.3768, -0.234, 0.1032, -0.3308, -0.0579, -0.409, 0.0816], [0.3979, -1.0574, -0.0286, -0.4843, 0.2267, 0.3758, -0.2338, 0.1026, -0.334, -0.0574, -0.4084, 0.0826], [0.4817, -0.9215, -0.1285, -0.5197, 0.3618, 0.5236, -0.2737, 0.1773, 0.0416, -0.1261, -0.5161, -0.0328]]]