import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sof93407 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con90976 = tf.keras.layers.Input(shape=([1, 2]))
in0Bat31596 = tf.keras.layers.Input(shape=([3, 1, 3]))

Sof93407 = keras.layers.Softmax(axis=1, name = 'Sof93407', input_shape=(1, 1, 1))(in0Sof93407)
Res68356 = keras.layers.Reshape((1, 1), name = 'Res68356', )(Sof93407)
Con90976 = keras.layers.Concatenate(axis=2, name = 'Con90976', )([Res68356,in0Con90976])
Bat31596 = keras.layers.BatchNormalization(axis=3, epsilon=0.800230176021712,  name = 'Bat31596', )(in0Bat31596)
Res12089 = keras.layers.Reshape((3, 3), name = 'Res12089', )(Bat31596)
Zer71952 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer71952', )(Res12089)
Dot89157 = keras.layers.Dot(axes=(2, 2), name = 'Dot89157', )([Con90976,Zer71952])
Res41883 = keras.layers.Reshape((1, 5, 1), name = 'Res41883', )(Dot89157)
Glo78176 = keras.layers.GlobalAveragePooling2D(name = 'Glo78176', )(Res41883)
model = tf.keras.models.Model(inputs=[in0Sof93407,in0Con90976,in0Bat31596], outputs=Glo78176)
w = model.get_layer('Bat31596').get_weights() 
w[0] = np.array([0.9205, 0.0677, 0.8049])
w[1] = np.array([0.355, 0.6189, 0.7727])
w[2] = np.array([0.9335, 0.2338, 0.9833])
w[3] = np.array([0.3776, 0.3096, 0.7359])
model.get_layer('Bat31596').set_weights(w) 
in0Sof93407 = tf.constant([[[[0.6537]]]])
in0Con90976 = tf.constant([[[0.2659, 0.0043]]])
in0Bat31596 = tf.constant([[[[1.3965, 1.7542, 1.3974]], [[1.2985, 1.8877, 1.2018]], [[1.6256, 1.3215, 1.0484]]]])
print (np.array2string(model.predict([in0Sof93407,in0Con90976,in0Bat31596],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Glo78176.png')

LSof93407 = softmax_layer([[[[0.6537]]]], 1, Sof93407), 
LRes68356 = reshape_layer(Sof93407, [1, 1], Res68356), 
LCon90976 = concatenate_layer([Res68356,[[[0.2659, 0.0043]]]], 2, Con90976), 
LBat31596 = batch_normalization_layer([[[[1.3965, 1.7542, 1.3974]], [[1.2985, 1.8877, 1.2018]], [[1.6256, 1.3215, 1.0484]]]], 3, 0.800230176021712, [0.9205, 0.0677, 0.8049], [0.355, 0.6189, 0.7727], [0.9335, 0.2338, 0.9833], [0.3776, 0.3096, 0.7359], Bat31596), 
LRes12089 = reshape_layer(Bat31596, [3, 3], Res12089), 
LZer71952 = zero_padding1D_layer(Res12089, 2, 0, Zer71952), 
LDot89157 = dot_layer(Con90976,Zer71952, 2, 2, Dot89157), 
LRes41883 = reshape_layer(Dot89157, [1, 5, 1], Res41883), 
LGlo78176 = global_average_pooling2D_layer(Res41883, Glo78176), 
exec_layers([LSof93407,LRes68356,LCon90976,LBat31596,LRes12089,LZer71952,LDot89157,LRes41883,LGlo78176],["Sof93407","Res68356","Con90976","Bat31596","Res12089","Zer71952","Dot89157","Res41883","Glo78176"],Glo78176,"Glo78176")

Actual (Unparsed): [[0.5865483]]

Expected (Unparsed): [[0.5865483070275779]]

Actual:   [[0.5866]]

Expected: [[0.5866]]