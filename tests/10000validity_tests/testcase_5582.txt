import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave17055 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in1Ave17055 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0Con4680 = tf.keras.layers.Input(shape=([2, 3, 3, 1]))
in0Con56817 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))

Ave17055 = keras.layers.Average(name = 'Ave17055', )([in0Ave17055,in1Ave17055])
Zer14098 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (2, 0)), name = 'Zer14098', )(Ave17055)
Con4680 = keras.layers.Concatenate(axis=4, name = 'Con4680', )([Zer14098,in0Con4680])
Con56817 = keras.layers.Conv3DTranspose(2, (1, 1, 2),strides=(1, 1, 1), padding='valid', name = 'Con56817', )(in0Con56817)
Bat80855 = keras.layers.BatchNormalization(axis=3, epsilon=0.8865766483279401,  name = 'Bat80855', )(Con56817)
Zer8080 = keras.layers.ZeroPadding3D(padding=((0, 0), (2, 0), (0, 0)), name = 'Zer8080', )(Bat80855)
Ave18359 = keras.layers.Average(name = 'Ave18359', )([Con4680,Zer8080])
Res55213 = keras.layers.Reshape((2, 3, 6), name = 'Res55213', )(Ave18359)
Res9400 = keras.layers.Reshape((2, 18), name = 'Res9400', )(Res55213)
Up_86558 = keras.layers.UpSampling1D(size=(2), name = 'Up_86558', )(Res9400)
model = tf.keras.models.Model(inputs=[in0Ave17055,in1Ave17055,in0Con4680,in0Con56817], outputs=Up_86558)
w = model.get_layer('Con56817').get_weights() 
w[0] = np.array([[[[[0.0048], [0.3549]], [[0.6139], [0.0703]]]]])
w[1] = np.array([0, 0])
model.get_layer('Con56817').set_weights(w) 
w = model.get_layer('Bat80855').get_weights() 
w[0] = np.array([0.3403, 0.9062, 0.4063])
w[1] = np.array([0.5836, 0.2273, 0.3312])
w[2] = np.array([0.5272, 0.9364, 0.2779])
w[3] = np.array([0.2908, 0.8527, 0.2718])
model.get_layer('Bat80855').set_weights(w) 
in0Ave17055 = tf.constant([[[[[0.261]], [[0.6423]]]]])
in1Ave17055 = tf.constant([[[[[0.2319]], [[0.9575]]]]])
in0Con4680 = tf.constant([[[[[0.1596], [0.6115], [0.4568]], [[0.353], [0.3683], [0.7488]], [[0.7958], [0.2216], [0.3124]]], [[[0.8604], [0.1681], [0.9256]], [[0.5626], [0.1965], [0.3208]], [[0.7282], [0.2328], [0.5497]]]]])
in0Con56817 = tf.constant([[[[[0.2716], [0.9078]]], [[[0.3056], [0.3302]]]]])
print (np.array2string(model.predict([in0Ave17055,in1Ave17055,in0Con4680,in0Con56817],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Up_86558.png')

LAve17055 = average_layer([[[[[[0.261]], [[0.6423]]]]], [[[[[0.2319]], [[0.9575]]]]]], Ave17055), 
LZer14098 = zero_padding3D_layer(Ave17055, 1, 0, 1, 0, 2, 0, Zer14098), 
LCon4680 = concatenate_layer([Zer14098,[[[[[0.1596], [0.6115], [0.4568]], [[0.353], [0.3683], [0.7488]], [[0.7958], [0.2216], [0.3124]]], [[[0.8604], [0.1681], [0.9256]], [[0.5626], [0.1965], [0.3208]], [[0.7282], [0.2328], [0.5497]]]]]], 4, Con4680), 
LCon56817 = conv3D_transpose_layer([[[[[0.2716], [0.9078]]], [[[0.3056], [0.3302]]]]], 1, 1, 2,[[[[[0.0048], [0.3549]], [[0.6139], [0.0703]]]]],[0, 0], 1, 1, 1, false, Con56817), 
LBat80855 = batch_normalization_layer(Con56817, 3, 0.8865766483279401, [0.3403, 0.9062, 0.4063], [0.5836, 0.2273, 0.3312], [0.5272, 0.9364, 0.2779], [0.2908, 0.8527, 0.2718], Bat80855), 
LZer8080 = zero_padding3D_layer(Bat80855, 0, 0, 2, 0, 0, 0, Zer8080), 
LAve18359 = average_layer([Con4680,Zer8080], Ave18359), 
LRes55213 = reshape_layer(Ave18359, [2, 3, 6], Res55213), 
LRes9400 = reshape_layer(Res55213, [2, 18], Res9400), 
LUp_86558 = up_sampling1D_layer(Res9400, 2, Up_86558), 
exec_layers([LAve17055,LZer14098,LCon4680,LCon56817,LBat80855,LZer8080,LAve18359,LRes55213,LRes9400,LUp_86558],["Ave17055","Zer14098","Con4680","Con56817","Bat80855","Zer8080","Ave18359","Res55213","Res9400","Up_86558"],Up_86558,"Up_86558")

Actual (Unparsed): [[[0.0000000, 0.0798000, 0.0000000, 0.3057500, 0.0000000, 0.2284000, 0.0000000, 0.1765000, 0.0000000, 0.1841500, 0.0000000, 0.3744000, 0.2093341, 0.6221447, -0.1492833, 0.0199844, 0.2183371, 0.2813916], [0.0000000, 0.0798000, 0.0000000, 0.3057500, 0.0000000, 0.2284000, 0.0000000, 0.1765000, 0.0000000, 0.1841500, 0.0000000, 0.3744000, 0.2093341, 0.6221447, -0.1492833, 0.0199844, 0.2183371, 0.2813916], [0.0000000, 0.4302000, 0.0000000, 0.0840500, 0.0000000, 0.4628000, 0.0000000, 0.2813000, 0.0000000, 0.0982500, 0.1232250, 0.1604000, 0.2093597, 0.5902369, -0.1430647, -0.0440220, 0.5513577, 0.3923773], [0.0000000, 0.4302000, 0.0000000, 0.0840500, 0.0000000, 0.4628000, 0.0000000, 0.2813000, 0.0000000, 0.0982500, 0.1232250, 0.1604000, 0.2093597, 0.5902369, -0.1430647, -0.0440220, 0.5513577, 0.3923773]]]

Expected (Unparsed): [[[0,0.0798,0,0.30575,0,0.2284,0,0.1765,0,0.18415,0,0.3744,0.20933410508279948,0.6221447394537245,-0.14928330256949726,0.019984362102311318,0.21833705520791227,0.28139162431046855],[0,0.0798,0,0.30575,0,0.2284,0,0.1765,0,0.18415,0,0.3744,0.20933410508279948,0.6221447394537245,-0.14928330256949726,0.019984362102311318,0.21833705520791227,0.28139162431046855],[0,0.4302,0,0.08405,0,0.4628,0,0.2813,0,0.09825,0.123225,0.1604,0.2093596965036531,0.5902369051330887,-0.1430647231777515,-0.04402205119831179,0.5513576835823372,0.392377290012899],[0,0.4302,0,0.08405,0,0.4628,0,0.2813,0,0.09825,0.123225,0.1604,0.2093596965036531,0.5902369051330887,-0.1430647231777515,-0.04402205119831179,0.5513576835823372,0.392377290012899]]]

Actual:   [[[0, 0.0798, 0, 0.3058, 0, 0.2284, 0, 0.1765, 0, 0.1842, 0, 0.3744, 0.2094, 0.6222, -0.1492, 0.02, 0.2184, 0.2814], [0, 0.0798, 0, 0.3058, 0, 0.2284, 0, 0.1765, 0, 0.1842, 0, 0.3744, 0.2094, 0.6222, -0.1492, 0.02, 0.2184, 0.2814], [0, 0.4302, 0, 0.0841, 0, 0.4628, 0, 0.2813, 0, 0.0983, 0.1233, 0.1604, 0.2094, 0.5903, -0.143, -0.044, 0.5514, 0.3924], [0, 0.4302, 0, 0.0841, 0, 0.4628, 0, 0.2813, 0, 0.0983, 0.1233, 0.1604, 0.2094, 0.5903, -0.143, -0.044, 0.5514, 0.3924]]]

Expected: [[[0, 0.0798, 0, 0.3058, 0, 0.2284, 0, 0.1765, 0, 0.1842, 0, 0.3744, 0.2094, 0.6222, -0.1492, 0.02, 0.2184, 0.2814], [0, 0.0798, 0, 0.3058, 0, 0.2284, 0, 0.1765, 0, 0.1842, 0, 0.3744, 0.2094, 0.6222, -0.1492, 0.02, 0.2184, 0.2814], [0, 0.4302, 0, 0.0841, 0, 0.4628, 0, 0.2813, 0, 0.0983, 0.1233, 0.1604, 0.2094, 0.5903, -0.143, -0.044, 0.5514, 0.3924], [0, 0.4302, 0, 0.0841, 0, 0.4628, 0, 0.2813, 0, 0.0983, 0.1233, 0.1604, 0.2094, 0.5903, -0.143, -0.044, 0.5514, 0.3924]]]