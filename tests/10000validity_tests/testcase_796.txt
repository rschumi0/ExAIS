import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot92062 = tf.keras.layers.Input(shape=([2, 2]))
in1Dot92062 = tf.keras.layers.Input(shape=([2, 2]))
in0Con48711 = tf.keras.layers.Input(shape=([2, 4, 1]))
in0Mul33268 = tf.keras.layers.Input(shape=([1, 1, 1]))
in1Mul33268 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con23072 = tf.keras.layers.Input(shape=([1, 3, 1]))
in0Lay93103 = tf.keras.layers.Input(shape=([1, 3, 2]))
in0Con38286 = tf.keras.layers.Input(shape=([2, 4]))
in0Add93137 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in1Add93137 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))

Dot92062 = keras.layers.Dot(axes=(2, 2), name = 'Dot92062', )([in0Dot92062,in1Dot92062])
Res44938 = keras.layers.Reshape((2, 2, 1), name = 'Res44938', )(Dot92062)
Zer35668 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer35668', )(Res44938)
Con48711 = keras.layers.Concatenate(axis=3, name = 'Con48711', )([Zer35668,in0Con48711])
Mul33268 = keras.layers.Multiply(name = 'Mul33268', )([in0Mul33268,in1Mul33268])
Zer8791 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer8791', )(Mul33268)
Con23072 = keras.layers.Concatenate(axis=3, name = 'Con23072', )([Zer8791,in0Con23072])
Lay93103 = keras.layers.LayerNormalization(axis=1, epsilon=1.9171072056355172, name = 'Lay93103', )(in0Lay93103)
Add5838 = keras.layers.Add(name = 'Add5838', )([Con23072,Lay93103])
Zer59825 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer59825', )(Add5838)
Max46546 = keras.layers.Maximum(name = 'Max46546', )([Con48711,Zer59825])
Res48756 = keras.layers.Reshape((2, 8), name = 'Res48756', )(Max46546)
Con38286 = keras.layers.Concatenate(axis=2, name = 'Con38286', )([Res48756,in0Con38286])
Add93137 = keras.layers.Add(name = 'Add93137', )([in0Add93137,in1Add93137])
Res691 = keras.layers.Reshape((2, 2, 2), name = 'Res691', )(Add93137)
Res62176 = keras.layers.Reshape((2, 4), name = 'Res62176', )(Res691)
Dot48467 = keras.layers.Dot(axes=(1, 1), name = 'Dot48467', )([Con38286,Res62176])
model = tf.keras.models.Model(inputs=[in0Dot92062,in1Dot92062,in0Con48711,in0Mul33268,in1Mul33268,in0Con23072,in0Lay93103,in0Con38286,in0Add93137,in1Add93137], outputs=Dot48467)
in0Dot92062 = tf.constant([[[0.8628, 0.0694], [0.8695, 0.9033]]])
in1Dot92062 = tf.constant([[[0.5026, 0.6102], [0.9076, 0.9829]]])
in0Con48711 = tf.constant([[[[0.3264], [0.0191], [0.4532], [0.0519]], [[0.876], [0.4015], [0.2889], [0.6482]]]])
in0Mul33268 = tf.constant([[[[0.4726]]]])
in1Mul33268 = tf.constant([[[[0.6858]]]])
in0Con23072 = tf.constant([[[[0.8492], [0.7053], [0.8407]]]])
in0Lay93103 = tf.constant([[[[1.6032, 1.872], [1.4248, 1.4748], [1.5691, 1.1668]]]])
in0Con38286 = tf.constant([[[0.9358, 0.263, 0.6479, 0.6598], [0.8741, 0.3197, 0.9126, 0.937]]])
in0Add93137 = tf.constant([[[[[0.8455, 0.3074]], [[0.4293, 0.3403]]], [[[0.3695, 0.0139]], [[0.8006, 0.5219]]]]])
in1Add93137 = tf.constant([[[[[0.5517, 0.5544]], [[0.6077, 0.2631]]], [[[0.5583, 0.0371]], [[0.1649, 0.6228]]]]])
print (np.array2string(model.predict([in0Dot92062,in1Dot92062,in0Con48711,in0Mul33268,in1Mul33268,in0Con23072,in0Lay93103,in0Con38286,in0Add93137,in1Add93137],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot48467.png')

LDot92062 = dot_layer([[[0.8628, 0.0694], [0.8695, 0.9033]]], [[[0.5026, 0.6102], [0.9076, 0.9829]]], 2, 2, Dot92062), 
LRes44938 = reshape_layer(Dot92062, [2, 2, 1], Res44938), 
LZer35668 = zero_padding2D_layer(Res44938, 0, 0, 2, 0, Zer35668), 
LCon48711 = concatenate_layer([Zer35668,[[[[0.3264], [0.0191], [0.4532], [0.0519]], [[0.876], [0.4015], [0.2889], [0.6482]]]]], 3, Con48711), 
LMul33268 = multiply_layer([[[[[0.4726]]]], [[[[0.6858]]]]], Mul33268), 
LZer8791 = zero_padding2D_layer(Mul33268, 0, 0, 2, 0, Zer8791), 
LCon23072 = concatenate_layer([Zer8791,[[[[0.8492], [0.7053], [0.8407]]]]], 3, Con23072), 
LLay93103 = layer_normalization_layer([[[[1.6032, 1.872], [1.4248, 1.4748], [1.5691, 1.1668]]]], 1, 1.9171072056355172, Lay93103), 
LAdd5838 = add_layer([Con23072,Lay93103], Add5838), 
LZer59825 = zero_padding2D_layer(Add5838, 1, 0, 1, 0, Zer59825), 
LMax46546 = maximum_layer([Con48711,Zer59825], Max46546), 
LRes48756 = reshape_layer(Max46546, [2, 8], Res48756), 
LCon38286 = concatenate_layer([Res48756,[[[0.9358, 0.263, 0.6479, 0.6598], [0.8741, 0.3197, 0.9126, 0.937]]]], 2, Con38286), 
LAdd93137 = add_layer([[[[[[0.8455, 0.3074]], [[0.4293, 0.3403]]], [[[0.3695, 0.0139]], [[0.8006, 0.5219]]]]], [[[[[0.5517, 0.5544]], [[0.6077, 0.2631]]], [[[0.5583, 0.0371]], [[0.1649, 0.6228]]]]]], Add93137), 
LRes691 = reshape_layer(Add93137, [2, 2, 2], Res691), 
LRes62176 = reshape_layer(Res691, [2, 4], Res62176), 
LDot48467 = dot_layer(Con38286,Res62176, 1, 1, Dot48467), 
exec_layers([LDot92062,LRes44938,LZer35668,LCon48711,LMul33268,LZer8791,LCon23072,LLay93103,LAdd5838,LZer59825,LMax46546,LRes48756,LCon38286,LAdd93137,LRes691,LRes62176,LDot48467],["Dot92062","Res44938","Zer35668","Con48711","Mul33268","Zer8791","Con23072","Lay93103","Add5838","Zer59825","Max46546","Res48756","Con38286","Add93137","Res691","Res62176","Dot48467"],Dot48467,"Dot48467")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.0000000, 0.0000000], [1.2687989, 0.3259675, 1.1842548, 1.1997069], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.8145743, 0.0597696, 0.8397093, 0.9836042], [1.5819109, 0.4606076, 1.4477141, 1.4184106], [1.2875884, 0.4265381, 1.1509355, 1.0808178], [2.7453547, 0.8191698, 2.5019431, 2.4333440], [0.8525161, 0.0876031, 0.8655161, 0.9936657], [2.1184898, 0.8510516, 1.8143682, 1.5652440], [0.6640813, 0.2429581, 0.5814014, 0.5246548], [1.7519561, 0.6049028, 1.5529876, 1.4355960], [1.7912211, 0.6164026, 1.5888861, 1.4707072]]]

Expected (Unparsed): [[[0.0,0.0,0.0,0.0],[1.2687988799999999,0.32596752,1.1842548000000002,1.19970696],[0.0,0.0,0.0,0.0],[0.81457428,0.05976958,0.8397092999999999,0.98360418],[1.58191085396,0.46060760404800005,1.4477141425,1.4184105968360001],[1.2875883799999999,0.42653806,1.15093555,1.08081779],[2.745354662694,0.8191697876419999,2.5019431539149997,2.4333440849550003],[0.8525161399999999,0.08760312,0.86551615,0.99366575],[2.1184897400000002,0.8510515399999999,1.81436815,1.56524399],[0.6640812599999999,0.2429581,0.5814013499999999,0.5246547899999999],[1.75195616,0.6049028200000001,1.5529876,1.43559608],[1.79122116,0.6164026400000001,1.5888861,1.4707072200000002]]]

Actual:   [[[0, 0, 0, 0], [1.2688, 0.326, 1.1843, 1.1998], [0, 0, 0, 0], [0.8146, 0.0598, 0.8398, 0.9837], [1.582, 0.4607, 1.4478, 1.4185], [1.2876, 0.4266, 1.151, 1.0809], [2.7454, 0.8192, 2.502, 2.4334], [0.8526, 0.0877, 0.8656, 0.9937], [2.1185, 0.8511, 1.8144, 1.5653], [0.6641, 0.243, 0.5815, 0.5247], [1.752, 0.605, 1.553, 1.4356], [1.7913, 0.6165, 1.5889, 1.4708]]]

Expected: [[[0, 0, 0, 0], [1.2688, 0.326, 1.1843, 1.1998], [0, 0, 0, 0], [0.8146, 0.0598, 0.8398, 0.9837], [1.582, 0.4607, 1.4478, 1.4185], [1.2876, 0.4266, 1.151, 1.0809], [2.7454, 0.8192, 2.502, 2.4334], [0.8526, 0.0877, 0.8656, 0.9937], [2.1185, 0.8511, 1.8144, 1.5653], [0.6641, 0.243, 0.5815, 0.5247], [1.752, 0.605, 1.553, 1.4356], [1.7913, 0.6165, 1.5889, 1.4708]]]