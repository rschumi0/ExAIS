import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con74440 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con13480 = tf.keras.layers.Input(shape=([1, 1]))
in0Cro67471 = tf.keras.layers.Input(shape=([4, 1, 3]))
in0Add72853 = tf.keras.layers.Input(shape=([1, 2]))
in1Add72853 = tf.keras.layers.Input(shape=([1, 2]))
in0Con77210 = tf.keras.layers.Input(shape=([2, 4, 2, 3]))
in0Con5265 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))
in0Max78936 = tf.keras.layers.Input(shape=([1, 1, 2, 1]))
in1Max78936 = tf.keras.layers.Input(shape=([1, 1, 2, 1]))
in0Con21918 = tf.keras.layers.Input(shape=([1, 1, 2, 3]))

Con74440 = keras.layers.Conv2DTranspose(2, (1, 1),strides=(1, 1), padding='same', name = 'Con74440', )(in0Con74440)
Res53248 = keras.layers.Reshape((1, 2), name = 'Res53248', )(Con74440)
Con13480 = keras.layers.Concatenate(axis=2, name = 'Con13480', )([Res53248,in0Con13480])
Cro67471 = keras.layers.Cropping2D(cropping=((1, 2), (0, 0)), name = 'Cro67471', )(in0Cro67471)
Bat48494 = keras.layers.BatchNormalization(axis=1, epsilon=0.48432945376047465,  name = 'Bat48494', )(Cro67471)
Res64564 = keras.layers.Reshape((1, 3), name = 'Res64564', )(Bat48494)
Per88131 = keras.layers.Permute((1,2), name = 'Per88131',)(Res64564)
Max27157 = keras.layers.Maximum(name = 'Max27157', )([Con13480,Per88131])
Res31003 = keras.layers.Reshape((1, 3, 1), name = 'Res31003', )(Max27157)
Res72179 = keras.layers.Reshape((1, 3, 1, 1), name = 'Res72179', )(Res31003)
Zer18881 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (1, 0)), name = 'Zer18881', )(Res72179)
Add72853 = keras.layers.Add(name = 'Add72853', )([in0Add72853,in1Add72853])
Res1147 = keras.layers.Reshape((1, 2, 1), name = 'Res1147', )(Add72853)
Res10549 = keras.layers.Reshape((1, 2, 1, 1), name = 'Res10549', )(Res1147)
Up_94075 = keras.layers.UpSampling3D(size=(2, 2, 2), name = 'Up_94075', )(Res10549)
Thr58498 = keras.layers.ThresholdedReLU(theta=0.9663797928272304, name = 'Thr58498', )(Up_94075)
Ave34512 = keras.layers.Average(name = 'Ave34512', )([Zer18881,Thr58498])
Con77210 = keras.layers.Concatenate(axis=4, name = 'Con77210', )([Ave34512,in0Con77210])
Con5265 = keras.layers.Conv3D(4, (1, 1, 1),strides=(1, 2, 1), padding='valid', dilation_rate=(1, 1, 1), name = 'Con5265', )(in0Con5265)
Zer19163 = keras.layers.ZeroPadding3D(padding=((0, 0), (0, 0), (1, 0)), name = 'Zer19163', )(Con5265)
Max78936 = keras.layers.Maximum(name = 'Max78936', )([in0Max78936,in1Max78936])
Con21918 = keras.layers.Concatenate(axis=4, name = 'Con21918', )([Max78936,in0Con21918])
Ave23892 = keras.layers.Average(name = 'Ave23892', )([Zer19163,Con21918])
Zer78080 = keras.layers.ZeroPadding3D(padding=((1, 0), (3, 0), (0, 0)), name = 'Zer78080', )(Ave23892)
Add2105 = keras.layers.Add(name = 'Add2105', )([Con77210,Zer78080])
model = tf.keras.models.Model(inputs=[in0Con74440,in0Con13480,in0Cro67471,in0Add72853,in1Add72853,in0Con77210,in0Con5265,in0Max78936,in1Max78936,in0Con21918], outputs=Add2105)
w = model.get_layer('Con74440').get_weights() 
w[0] = np.array([[[[0.3383, 0.1477], [0.353, 0.0492]]]])
w[1] = np.array([0, 0])
model.get_layer('Con74440').set_weights(w) 
w = model.get_layer('Bat48494').get_weights() 
w[0] = np.array([0.5146])
w[1] = np.array([0.1931])
w[2] = np.array([0.6259])
w[3] = np.array([0.1131])
model.get_layer('Bat48494').set_weights(w) 
w = model.get_layer('Con5265').get_weights() 
w[0] = np.array([[[[[0.152, 0.5894, 0.5285, 0.7122]]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con5265').set_weights(w) 
in0Con74440 = tf.constant([[[[0.416, 0.055]]]])
in0Con13480 = tf.constant([[[0.1887]]])
in0Cro67471 = tf.constant([[[[1.4868, 1.0447, 1.3476]], [[1.2127, 1.9537, 1.9079]], [[1.7724, 1.9065, 1.4525]], [[1.1617, 1.8696, 1.463]]]])
in0Add72853 = tf.constant([[[0.9952, 0.471]]])
in1Add72853 = tf.constant([[[0.1921, 0.6755]]])
in0Con77210 = tf.constant([[[[[0.7559, 0.969, 0.2745], [0.0897, 0.551, 0.5371]], [[0.4108, 0.1433, 0.2444], [0.8267, 0.8124, 0.8626]], [[0.7392, 0.9869, 0.0475], [0.9137, 0.1791, 0.1445]], [[0.0404, 0.2205, 0.4925], [0.4396, 0.4198, 0.0639]]], [[[0.6185, 0.8397, 0.5848], [0.2945, 0.1862, 0.4696]], [[0.7877, 0.0669, 0.7955], [0.172, 0.6765, 0.877]], [[0.2038, 0.0246, 0.1593], [0.5769, 0.6624, 0.5761]], [[0.1599, 0.4778, 0.3657], [0.6374, 0.8176, 0.6111]]]]])
in0Con5265 = tf.constant([[[[[0.16]]]]])
in0Max78936 = tf.constant([[[[[0.6334], [0.8877]]]]])
in1Max78936 = tf.constant([[[[[0.5], [0.1151]]]]])
in0Con21918 = tf.constant([[[[[0.0968, 0.7884, 0.968], [0.4718, 0.0107, 0.7208]]]]])
print (np.array2string(model.predict([in0Con74440,in0Con13480,in0Cro67471,in0Add72853,in1Add72853,in0Con77210,in0Con5265,in0Max78936,in1Max78936,in0Con21918],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add2105.png')

LCon74440 = conv2D_transpose_layer([[[[0.416, 0.055]]]], 1, 1,[[[[0.3383, 0.1477], [0.353, 0.0492]]]],[0, 0], 1, 1, true, Con74440), 
LRes53248 = reshape_layer(Con74440, [1, 2], Res53248), 
LCon13480 = concatenate_layer([Res53248,[[[0.1887]]]], 2, Con13480), 
LCro67471 = cropping2D_layer([[[[1.4868, 1.0447, 1.3476]], [[1.2127, 1.9537, 1.9079]], [[1.7724, 1.9065, 1.4525]], [[1.1617, 1.8696, 1.463]]]], 1, 2, 0, 0, Cro67471), 
LBat48494 = batch_normalization_layer(Cro67471, 1, 0.48432945376047465, [0.5146], [0.1931], [0.6259], [0.1131], Bat48494), 
LRes64564 = reshape_layer(Bat48494, [1, 3], Res64564), 
LPer88131 = permute_layer(Res64564, 1,2, Per88131), 
LMax27157 = maximum_layer([Con13480,Per88131], Max27157), 
LRes31003 = reshape_layer(Max27157, [1, 3, 1], Res31003), 
LRes72179 = reshape_layer(Res31003, [1, 3, 1, 1], Res72179), 
LZer18881 = zero_padding3D_layer(Res72179, 1, 0, 1, 0, 1, 0, Zer18881), 
LAdd72853 = add_layer([[[[0.9952, 0.471]]], [[[0.1921, 0.6755]]]], Add72853), 
LRes1147 = reshape_layer(Add72853, [1, 2, 1], Res1147), 
LRes10549 = reshape_layer(Res1147, [1, 2, 1, 1], Res10549), 
LUp_94075 = up_sampling3D_layer(Res10549, 2, 2, 2, Up_94075), 
LThr58498 = thresholded_relu_layer(Up_94075, 0.9663797928272304, Thr58498), 
LAve34512 = average_layer([Zer18881,Thr58498], Ave34512), 
LCon77210 = concatenate_layer([Ave34512,[[[[[0.7559, 0.969, 0.2745], [0.0897, 0.551, 0.5371]], [[0.4108, 0.1433, 0.2444], [0.8267, 0.8124, 0.8626]], [[0.7392, 0.9869, 0.0475], [0.9137, 0.1791, 0.1445]], [[0.0404, 0.2205, 0.4925], [0.4396, 0.4198, 0.0639]]], [[[0.6185, 0.8397, 0.5848], [0.2945, 0.1862, 0.4696]], [[0.7877, 0.0669, 0.7955], [0.172, 0.6765, 0.877]], [[0.2038, 0.0246, 0.1593], [0.5769, 0.6624, 0.5761]], [[0.1599, 0.4778, 0.3657], [0.6374, 0.8176, 0.6111]]]]]], 4, Con77210), 
LCon5265 = conv3D_layer([[[[[0.16]]]]], 1, 1, 1,[[[[[0.152, 0.5894, 0.5285, 0.7122]]]]],[0, 0, 0, 0], 1, 2, 1, false, 1, 1, 1, Con5265), 
LZer19163 = zero_padding3D_layer(Con5265, 0, 0, 0, 0, 1, 0, Zer19163), 
LMax78936 = maximum_layer([[[[[[0.6334], [0.8877]]]]], [[[[[0.5], [0.1151]]]]]], Max78936), 
LCon21918 = concatenate_layer([Max78936,[[[[[0.0968, 0.7884, 0.968], [0.4718, 0.0107, 0.7208]]]]]], 4, Con21918), 
LAve23892 = average_layer([Zer19163,Con21918], Ave23892), 
LZer78080 = zero_padding3D_layer(Ave23892, 1, 0, 3, 0, 0, 0, Zer78080), 
LAdd2105 = add_layer([Con77210,Zer78080], Add2105), 
exec_layers([LCon74440,LRes53248,LCon13480,LCro67471,LBat48494,LRes64564,LPer88131,LMax27157,LRes31003,LRes72179,LZer18881,LAdd72853,LRes1147,LRes10549,LUp_94075,LThr58498,LAve34512,LCon77210,LCon5265,LZer19163,LMax78936,LCon21918,LAve23892,LZer78080,LAdd2105],["Con74440","Res53248","Con13480","Cro67471","Bat48494","Res64564","Per88131","Max27157","Res31003","Res72179","Zer18881","Add72853","Res1147","Res10549","Up_94075","Thr58498","Ave34512","Con77210","Con5265","Zer19163","Max78936","Con21918","Ave23892","Zer78080","Add2105"],Add2105,"Add2105")

Actual (Unparsed): [[[[[0.5936500, 0.7559000, 0.9690000, 0.2745000], [0.5936500, 0.0897000, 0.5510000, 0.5371000]], [[0.5936500, 0.4108000, 0.1433000, 0.2444000], [0.5936500, 0.8267000, 0.8124000, 0.8626000]], [[0.5732500, 0.7392000, 0.9869000, 0.0475000], [0.5732500, 0.9137000, 0.1791000, 0.1445000]], [[0.5732500, 0.0404000, 0.2205000, 0.4925000], [0.5732500, 0.4396000, 0.4198000, 0.0639000]]], [[[0.5936500, 0.6185000, 0.8397000, 0.5848000], [0.5936500, 0.2945000, 0.1862000, 0.4696000]], [[0.5936500, 0.7877000, 0.0669000, 0.7955000], [0.8855379, 0.1720000, 0.6765000, 0.8770000]], [[0.5732500, 0.2038000, 0.0246000, 0.1593000], [1.1118070, 0.5769000, 0.6624000, 0.5761000]], [[0.8899500, 0.2083000, 0.8720000, 0.8497000], [1.5525708, 0.9204520, 0.8652300, 1.0284760]]]]]

Expected (Unparsed): [[[[[0.59365,0.7559,0.969,0.2745],[0.59365,0.0897,0.551,0.5371]],[[0.59365,0.4108,0.1433,0.2444],[0.59365,0.8267,0.8124,0.8626]],[[0.57325,0.7392,0.9869,0.0475],[0.57325,0.9137,0.1791,0.1445]],[[0.57325,0.0404,0.2205,0.4925],[0.57325,0.4396,0.4198,0.0639]]],[[[0.59365,0.6185,0.8397,0.5848],[0.59365,0.2945,0.1862,0.4696]],[[0.59365,0.7877,0.0669,0.7955],[0.8855379278713648,0.172,0.6765,0.877]],[[0.57325,0.2038,0.0246,0.1593],[1.1118069881179244,0.5769,0.6624,0.5761]],[[0.88995,0.20829999999999999,0.872,0.8497],[1.5525707762970171,0.920452,0.8652299999999999,1.028476]]]]]

Actual:   [[[[[0.5937, 0.7559, 0.969, 0.2745], [0.5937, 0.0897, 0.551, 0.5371]], [[0.5937, 0.4108, 0.1433, 0.2444], [0.5937, 0.8267, 0.8124, 0.8626]], [[0.5733, 0.7392, 0.9869, 0.0475], [0.5733, 0.9137, 0.1791, 0.1445]], [[0.5733, 0.0404, 0.2205, 0.4925], [0.5733, 0.4396, 0.4198, 0.0639]]], [[[0.5937, 0.6185, 0.8397, 0.5848], [0.5937, 0.2945, 0.1862, 0.4696]], [[0.5937, 0.7877, 0.0669, 0.7955], [0.8856, 0.172, 0.6765, 0.877]], [[0.5733, 0.2038, 0.0246, 0.1593], [1.1119, 0.5769, 0.6624, 0.5761]], [[0.89, 0.2083, 0.872, 0.8497], [1.5526, 0.9205, 0.8653, 1.0285]]]]]

Expected: [[[[[0.5937, 0.7559, 0.969, 0.2745], [0.5937, 0.0897, 0.551, 0.5371]], [[0.5937, 0.4108, 0.1433, 0.2444], [0.5937, 0.8267, 0.8124, 0.8626]], [[0.5733, 0.7392, 0.9869, 0.0475], [0.5733, 0.9137, 0.1791, 0.1445]], [[0.5733, 0.0404, 0.2205, 0.4925], [0.5733, 0.4396, 0.4198, 0.0639]]], [[[0.5937, 0.6185, 0.8397, 0.5848], [0.5937, 0.2945, 0.1862, 0.4696]], [[0.5937, 0.7877, 0.0669, 0.7955], [0.8856, 0.172, 0.6765, 0.877]], [[0.5733, 0.2038, 0.0246, 0.1593], [1.1119, 0.5769, 0.6624, 0.5761]], [[0.89, 0.2083, 0.872, 0.8497], [1.5526, 0.9205, 0.8653, 1.0285]]]]]