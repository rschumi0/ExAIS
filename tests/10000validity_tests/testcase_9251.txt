import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min58001 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in1Min58001 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in0Sub80600 = tf.keras.layers.Input(shape=([3, 2]))
in1Sub80600 = tf.keras.layers.Input(shape=([3, 2]))
in0Bat27664 = tf.keras.layers.Input(shape=([4, 1]))
in0Con45823 = tf.keras.layers.Input(shape=([4, 1]))
in0Con52097 = tf.keras.layers.Input(shape=([4, 2]))

Min58001 = keras.layers.Minimum(name = 'Min58001', )([in0Min58001,in1Min58001])
Res34553 = keras.layers.Reshape((1, 2, 2), name = 'Res34553', )(Min58001)
Res60383 = keras.layers.Reshape((1, 4), name = 'Res60383', )(Res34553)
Zer32128 = keras.layers.ZeroPadding1D(padding=((3, 0)), name = 'Zer32128', )(Res60383)
Sub80600 = keras.layers.Subtract(name = 'Sub80600', )([in0Sub80600,in1Sub80600])
Zer98522 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer98522', )(Sub80600)
Bat27664 = keras.layers.BatchNormalization(axis=1, epsilon=0.1690522976916205,  name = 'Bat27664', )(in0Bat27664)
Con45823 = keras.layers.Concatenate(axis=2, name = 'Con45823', )([Bat27664,in0Con45823])
Ave82561 = keras.layers.Average(name = 'Ave82561', )([Zer98522,Con45823])
Con52097 = keras.layers.Concatenate(axis=2, name = 'Con52097', )([Ave82561,in0Con52097])
Sub69200 = keras.layers.Subtract(name = 'Sub69200', )([Zer32128,Con52097])
model = tf.keras.models.Model(inputs=[in0Min58001,in1Min58001,in0Sub80600,in1Sub80600,in0Bat27664,in0Con45823,in0Con52097], outputs=Sub69200)
w = model.get_layer('Bat27664').get_weights() 
w[0] = np.array([0.8445, 0.114, 0.0475, 0.5484])
w[1] = np.array([0.8159, 0.2229, 0.3736, 0.0752])
w[2] = np.array([0.222, 0.7051, 0.3362, 0.7262])
w[3] = np.array([0.4637, 0.6642, 0.8993, 0.0862])
model.get_layer('Bat27664').set_weights(w) 
in0Min58001 = tf.constant([[[[[0.4394], [0.8096]], [[0.1805], [0.1447]]]]])
in1Min58001 = tf.constant([[[[[0.1774], [0.7775]], [[0.9153], [0.1703]]]]])
in0Sub80600 = tf.constant([[[0.6325, 0.6235], [0.3983, 0.5781], [0.1434, 0.912]]])
in1Sub80600 = tf.constant([[[0.3962, 0.0065], [0.7068, 0.3219], [0.4925, 0.9634]]])
in0Bat27664 = tf.constant([[[1.95], [1.8958], [1.2105], [1.6479]]])
in0Con45823 = tf.constant([[[0.2415], [0.6861], [0.3917], [0.8539]]])
in0Con52097 = tf.constant([[[0.7467, 0.8187], [0.2997, 0.8514], [0.9164, 0.2859], [0.725, 0.2514]]])
print (np.array2string(model.predict([in0Min58001,in1Min58001,in0Sub80600,in1Sub80600,in0Bat27664,in0Con45823,in0Con52097],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub69200.png')

LMin58001 = minimum_layer([[[[[[0.4394], [0.8096]], [[0.1805], [0.1447]]]]], [[[[[0.1774], [0.7775]], [[0.9153], [0.1703]]]]]], Min58001), 
LRes34553 = reshape_layer(Min58001, [1, 2, 2], Res34553), 
LRes60383 = reshape_layer(Res34553, [1, 4], Res60383), 
LZer32128 = zero_padding1D_layer(Res60383, 3, 0, Zer32128), 
LSub80600 = subtract_layer([[[0.6325, 0.6235], [0.3983, 0.5781], [0.1434, 0.912]]], [[[0.3962, 0.0065], [0.7068, 0.3219], [0.4925, 0.9634]]], Sub80600), 
LZer98522 = zero_padding1D_layer(Sub80600, 1, 0, Zer98522), 
LBat27664 = batch_normalization_layer([[[1.95], [1.8958], [1.2105], [1.6479]]], 1, 0.1690522976916205, [0.8445, 0.114, 0.0475, 0.5484], [0.8159, 0.2229, 0.3736, 0.0752], [0.222, 0.7051, 0.3362, 0.7262], [0.4637, 0.6642, 0.8993, 0.0862], Bat27664), 
LCon45823 = concatenate_layer([Bat27664,[[[0.2415], [0.6861], [0.3917], [0.8539]]]], 2, Con45823), 
LAve82561 = average_layer([Zer98522,Con45823], Ave82561), 
LCon52097 = concatenate_layer([Ave82561,[[[0.7467, 0.8187], [0.2997, 0.8514], [0.9164, 0.2859], [0.725, 0.2514]]]], 2, Con52097), 
LSub69200 = subtract_layer(Zer32128,Con52097, Sub69200), 
exec_layers([LMin58001,LRes34553,LRes60383,LZer32128,LSub80600,LZer98522,LBat27664,LCon45823,LAve82561,LCon52097,LSub69200],["Min58001","Res34553","Res60383","Zer32128","Sub80600","Zer98522","Bat27664","Con45823","Ave82561","Con52097","Sub69200"],Sub69200,"Sub69200")

Actual (Unparsed): [[[-1.3252186, -0.1207500, -0.7467000, -0.8187000], [-0.3039514, -0.6515500, -0.2997000, -0.8514000], [-0.0526394, -0.3239500, -0.9164000, -0.2859000], [-0.1858828, 0.3762500, -0.5445000, -0.1067000]]]

Expected (Unparsed): [[[-1.3252186084181887,-0.12075,-0.7467,-0.8187],[-0.3039513655655013,-0.6515500000000001,-0.2997,-0.8514],[-0.052639394544946955,-0.32394999999999996,-0.9164,-0.2859],[-0.18588284962580492,0.37625,-0.5445,-0.10670000000000002]]]

Actual:   [[[-1.3252, -0.1207, -0.7467, -0.8187], [-0.3039, -0.6515, -0.2997, -0.8514], [-0.0526, -0.3239, -0.9164, -0.2859], [-0.1858, 0.3763, -0.5445, -0.1067]]]

Expected: [[[-1.3252, -0.1207, -0.7467, -0.8187], [-0.3039, -0.6515, -0.2997, -0.8514], [-0.0526, -0.3239, -0.9164, -0.2859], [-0.1858, 0.3763, -0.5445, -0.1067]]]