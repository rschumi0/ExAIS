import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub48929 = tf.keras.layers.Input(shape=([3, 3]))
in1Sub48929 = tf.keras.layers.Input(shape=([3, 3]))
in0Dot65396 = tf.keras.layers.Input(shape=([3]))
in1Dot65396 = tf.keras.layers.Input(shape=([3]))
in0Max44652 = tf.keras.layers.Input(shape=([2, 1]))
in1Max44652 = tf.keras.layers.Input(shape=([2, 1]))
in0Con23529 = tf.keras.layers.Input(shape=([2, 2]))

Sub48929 = keras.layers.Subtract(name = 'Sub48929', )([in0Sub48929,in1Sub48929])
Dot65396 = keras.layers.Dot(axes=(1, 1), name = 'Dot65396', )([in0Dot65396,in1Dot65396])
Fla98001 = keras.layers.Flatten(name = 'Fla98001', )(Dot65396)
Res27829 = keras.layers.Reshape((1, 1), name = 'Res27829', )(Fla98001)
Res93983 = keras.layers.Reshape((1, 1, 1), name = 'Res93983', )(Res27829)
Con56349 = keras.layers.Conv2DTranspose(3, (1, 1),strides=(1, 1), padding='same', name = 'Con56349', )(Res93983)
Res92996 = keras.layers.Reshape((1, 3), name = 'Res92996', )(Con56349)
Zer13316 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer13316', )(Res92996)
Max44652 = keras.layers.Maximum(name = 'Max44652', )([in0Max44652,in1Max44652])
Con23529 = keras.layers.Concatenate(axis=2, name = 'Con23529', )([Max44652,in0Con23529])
Add74653 = keras.layers.Add(name = 'Add74653', )([Zer13316,Con23529])
Zer34507 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer34507', )(Add74653)
Max19816 = keras.layers.Maximum(name = 'Max19816', )([Sub48929,Zer34507])
model = tf.keras.models.Model(inputs=[in0Sub48929,in1Sub48929,in0Dot65396,in1Dot65396,in0Max44652,in1Max44652,in0Con23529], outputs=Max19816)
w = model.get_layer('Con56349').get_weights() 
w[0] = np.array([[[[0.0268], [0.1957], [0.2806]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con56349').set_weights(w) 
in0Sub48929 = tf.constant([[[0.2829, 0.0044, 0.6888], [0.9449, 0.4822, 0.8548], [0.6951, 0.781, 0.1738]]])
in1Sub48929 = tf.constant([[[0.8886, 0.6139, 0.3468], [0.1906, 0.461, 0.0887], [0.5959, 0.0768, 0.5067]]])
in0Dot65396 = tf.constant([[0.1693, 0.847, 0.7652]])
in1Dot65396 = tf.constant([[0.4345, 0.5082, 0.7152]])
in0Max44652 = tf.constant([[[0.5137], [0.2501]]])
in1Max44652 = tf.constant([[[0.7802], [0.7584]]])
in0Con23529 = tf.constant([[[0.3585, 0.3478], [0.7436, 0.1052]]])
print (np.array2string(model.predict([in0Sub48929,in1Sub48929,in0Dot65396,in1Dot65396,in0Max44652,in1Max44652,in0Con23529],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max19816.png')

LSub48929 = subtract_layer([[[0.2829, 0.0044, 0.6888], [0.9449, 0.4822, 0.8548], [0.6951, 0.781, 0.1738]]], [[[0.8886, 0.6139, 0.3468], [0.1906, 0.461, 0.0887], [0.5959, 0.0768, 0.5067]]], Sub48929), 
LDot65396 = dot_layer([[0.1693, 0.847, 0.7652]], [[0.4345, 0.5082, 0.7152]], 1, 1, Dot65396), 
LFla98001 = flatten_layer(Dot65396, Fla98001), 
LRes27829 = reshape_layer(Fla98001, [1, 1], Res27829), 
LRes93983 = reshape_layer(Res27829, [1, 1, 1], Res93983), 
LCon56349 = conv2D_transpose_layer(Res93983, 1, 1,[[[[0.0268], [0.1957], [0.2806]]]],[0, 0, 0], 1, 1, true, Con56349), 
LRes92996 = reshape_layer(Con56349, [1, 3], Res92996), 
LZer13316 = zero_padding1D_layer(Res92996, 1, 0, Zer13316), 
LMax44652 = maximum_layer([[[[0.5137], [0.2501]]], [[[0.7802], [0.7584]]]], Max44652), 
LCon23529 = concatenate_layer([Max44652,[[[0.3585, 0.3478], [0.7436, 0.1052]]]], 2, Con23529), 
LAdd74653 = add_layer([Zer13316,Con23529], Add74653), 
LZer34507 = zero_padding1D_layer(Add74653, 1, 0, Zer34507), 
LMax19816 = maximum_layer([Sub48929,Zer34507], Max19816), 
exec_layers([LSub48929,LDot65396,LFla98001,LRes27829,LRes93983,LCon56349,LRes92996,LZer13316,LMax44652,LCon23529,LAdd74653,LZer34507,LMax19816],["Sub48929","Dot65396","Fla98001","Res27829","Res93983","Con56349","Res92996","Zer13316","Max44652","Con23529","Add74653","Zer34507","Max19816"],Max19816,"Max19816")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.3420000], [0.7802000, 0.3585000, 0.7661000], [0.7865743, 0.9493350, 0.4001884]]]

Expected (Unparsed): [[[0,0,0.34199999999999997],[0.7802,0.3585,0.7661],[0.786574231372,0.949334965653,0.400188407574]]]

Actual:   [[[0, 0, 0.342], [0.7802, 0.3585, 0.7661], [0.7866, 0.9494, 0.4002]]]

Expected: [[[0, 0, 0.342], [0.7802, 0.3585, 0.7661], [0.7866, 0.9494, 0.4002]]]