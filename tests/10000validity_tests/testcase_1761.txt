import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con52539 = tf.keras.layers.Input(shape=([1, 1, 2, 1]))
in0Glo24730 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Con40525 = tf.keras.layers.Input(shape=([15]))
in0GRU81183 = tf.keras.layers.Input(shape=([3, 2]))
in0Con82392 = tf.keras.layers.Input(shape=([15]))

Con52539 = keras.layers.Conv3DTranspose(4, (1, 1, 1),strides=(1, 1, 2), padding='same', name = 'Con52539', )(in0Con52539)
Res24821 = keras.layers.Reshape((1, 1, 16), name = 'Res24821', )(Con52539)
Res35649 = keras.layers.Reshape((1, 16), name = 'Res35649', )(Res24821)
Fla32986 = keras.layers.Flatten(name = 'Fla32986', )(Res35649)
Glo24730 = keras.layers.GlobalAveragePooling2D(name = 'Glo24730', )(in0Glo24730)
Con40525 = keras.layers.Concatenate(axis=1, name = 'Con40525', )([Glo24730,in0Con40525])
Mul13793 = keras.layers.Multiply(name = 'Mul13793', )([Fla32986,Con40525])
GRU81183 = keras.layers.GRU(1,reset_after=True, recurrent_activation='sigmoid', name = 'GRU81183', )(in0GRU81183)
Res97358 = keras.layers.Reshape((1, 1), name = 'Res97358', )(GRU81183)
GRU95927 = keras.layers.GRU(1,reset_after=False, recurrent_activation='sigmoid', name = 'GRU95927', )(Res97358)
Con82392 = keras.layers.Concatenate(axis=1, name = 'Con82392', )([GRU95927,in0Con82392])
Sub85130 = keras.layers.Subtract(name = 'Sub85130', )([Mul13793,Con82392])
Res46908 = keras.layers.Reshape((16, 1), name = 'Res46908', )(Sub85130)
Res17659 = keras.layers.Reshape((16, 1, 1), name = 'Res17659', )(Res46908)
Con25027 = keras.layers.Conv2DTranspose(4, (15, 1),strides=(1, 1), padding='valid', name = 'Con25027', )(Res17659)
model = tf.keras.models.Model(inputs=[in0Con52539,in0Glo24730,in0Con40525,in0GRU81183,in0Con82392], outputs=Con25027)
w = model.get_layer('Con52539').get_weights() 
w[0] = np.array([[[[[0.5691], [0.2291], [0.4903], [0.6665]]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con52539').set_weights(w) 
w = model.get_layer('GRU81183').get_weights() 
w[0] = np.array([[4, 3, 2], [1, 5, 6]])
w[1] = np.array([[10, 6, 8]])
w[2] = np.array([[1, 3, 10], [5, 5, 2]])
model.get_layer('GRU81183').set_weights(w) 
w = model.get_layer('GRU95927').get_weights() 
w[0] = np.array([[2, 1, 7]])
w[1] = np.array([[4, 5, 5]])
w[2] = np.array([1, 4, 3])
model.get_layer('GRU95927').set_weights(w) 
w = model.get_layer('Con25027').get_weights() 
w[0] = np.array([[[[0.1531], [0.8545], [0.0438], [0.3988]]], [[[0.2403], [0.4945], [0.392], [0.6618]]], [[[0.4784], [0.5041], [0.4899], [0.9087]]], [[[0.8045], [0.3677], [0.4816], [0.2505]]], [[[0.2274], [0.2296], [0.2689], [0.205]]], [[[0.4636], [0.7202], [0.8049], [0.3432]]], [[[0.8722], [0.9318], [0.507], [0.3492]]], [[[0.0479], [0.588], [0.2628], [0.5283]]], [[[0.8232], [0.6613], [0.8422], [0.0869]]], [[[0.9708], [0.3032], [0.5264], [0.6961]]], [[[0.5993], [0.9777], [0.4184], [0.9532]]], [[[0.0922], [0.1101], [0.2073], [0.358]]], [[[0.4513], [0.3991], [0.1275], [0.3326]]], [[[0.0758], [0.1795], [0.4726], [0.6316]]], [[[0.3331], [0.8668], [0.3049], [0.2111]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con25027').set_weights(w) 
in0Con52539 = tf.constant([[[[[0.7721], [0.4581]]]]])
in0Glo24730 = tf.constant([[[[1.3799], [1.3931]], [[1.0643], [1.5577]]]])
in0Con40525 = tf.constant([[0.5101, 0.66, 0.6006, 0.1429, 0.7581, 0.5207, 0.2058, 0.376, 0.8387, 0.7675, 0.1244, 0.0567, 0.8033, 0.19, 0.9987]])
in0GRU81183 = tf.constant([[[9, 9], [2, 8], [4, 6]]])
in0Con82392 = tf.constant([[0.206, 0.6422, 0.1161, 0.6418, 0.8628, 0.4059, 0.8083, 0.7309, 0.8805, 0.8678, 0.3972, 0.8604, 0.79, 0.3922, 0.4808]])
print (np.array2string(model.predict([in0Con52539,in0Glo24730,in0Con40525,in0GRU81183,in0Con82392],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Con25027.png')

LCon52539 = conv3D_transpose_layer([[[[[0.7721], [0.4581]]]]], 1, 1, 1,[[[[[0.5691], [0.2291], [0.4903], [0.6665]]]]],[0, 0, 0, 0], 1, 1, 2, true, Con52539), 
LRes24821 = reshape_layer(Con52539, [1, 1, 16], Res24821), 
LRes35649 = reshape_layer(Res24821, [1, 16], Res35649), 
LFla32986 = flatten_layer(Res35649, Fla32986), 
LGlo24730 = global_average_pooling2D_layer([[[[1.3799], [1.3931]], [[1.0643], [1.5577]]]], Glo24730), 
LCon40525 = concatenate_layer([Glo24730,[[0.5101, 0.66, 0.6006, 0.1429, 0.7581, 0.5207, 0.2058, 0.376, 0.8387, 0.7675, 0.1244, 0.0567, 0.8033, 0.19, 0.9987]]], 1, Con40525), 
LMul13793 = multiply_layer([Fla32986,Con40525], Mul13793), 
LGRU81183 = gru_layer([[[9, 9], [2, 8], [4, 6]]],[[4, 3, 2], [1, 5, 6]],[[10, 6, 8]],[[1, 3, 10], [5, 5, 2]], true, GRU81183), 
LRes97358 = reshape_layer(GRU81183, [1, 1], Res97358), 
LGRU95927 = gru_layer(Res97358,[[2, 1, 7]],[[4, 5, 5]],[1, 4, 3], false, GRU95927), 
LCon82392 = concatenate_layer([GRU95927,[[0.206, 0.6422, 0.1161, 0.6418, 0.8628, 0.4059, 0.8083, 0.7309, 0.8805, 0.8678, 0.3972, 0.8604, 0.79, 0.3922, 0.4808]]], 1, Con82392), 
LSub85130 = subtract_layer(Mul13793,Con82392, Sub85130), 
LRes46908 = reshape_layer(Sub85130, [16, 1], Res46908), 
LRes17659 = reshape_layer(Res46908, [16, 1, 1], Res17659), 
LCon25027 = conv2D_transpose_layer(Res17659, 15, 1,[[[[0.1531], [0.8545], [0.0438], [0.3988]]], [[[0.2403], [0.4945], [0.392], [0.6618]]], [[[0.4784], [0.5041], [0.4899], [0.9087]]], [[[0.8045], [0.3677], [0.4816], [0.2505]]], [[[0.2274], [0.2296], [0.2689], [0.205]]], [[[0.4636], [0.7202], [0.8049], [0.3432]]], [[[0.8722], [0.9318], [0.507], [0.3492]]], [[[0.0479], [0.588], [0.2628], [0.5283]]], [[[0.8232], [0.6613], [0.8422], [0.0869]]], [[[0.9708], [0.3032], [0.5264], [0.6961]]], [[[0.5993], [0.9777], [0.4184], [0.9532]]], [[[0.0922], [0.1101], [0.2073], [0.358]]], [[[0.4513], [0.3991], [0.1275], [0.3326]]], [[[0.0758], [0.1795], [0.4726], [0.6316]]], [[[0.3331], [0.8668], [0.3049], [0.2111]]]],[0, 0, 0, 0], 1, 1, false, Con25027), 
exec_layers([LCon52539,LRes24821,LRes35649,LFla32986,LGlo24730,LCon40525,LMul13793,LGRU81183,LRes97358,LGRU95927,LCon82392,LSub85130,LRes46908,LRes17659,LCon25027],["Con52539","Res24821","Res35649","Fla32986","Glo24730","Con40525","Mul13793","GRU81183","Res97358","GRU95927","Con82392","Sub85130","Res46908","Res17659","Con25027"],Con25027,"Con25027")

Actual (Unparsed): [[[[0.0497624, 0.2777400, 0.0142364, 0.1296228]], [[0.0603809, 0.0618035, 0.1223419, 0.1689374]], [[0.0676072, -0.2286623, 0.0966667, 0.0622714]], [[0.1413665, 0.0320321, -0.0455290, -0.2064792]], [[-0.2588129, -0.6187183, -0.1130316, -0.4471383]], [[-0.3852882, -0.8941153, -0.1533072, -0.6039400]], [[-0.2806637, -0.8966676, -0.6113731, -1.2744008]], [[-1.3737968, -1.7173565, -1.1634820, -1.4995795]], [[-1.3161031, -1.6894613, -0.9318092, -1.6075617]], [[-1.1106286, -2.2360652, -1.5545339, -1.8918951]], [[-2.5333552, -2.7782798, -2.3741119, -1.8857197]], [[-2.5270846, -3.0110307, -2.1566003, -2.6778358]], [[-2.5423951, -3.8003272, -2.7398161, -2.6447749]], [[-3.5385186, -3.7744542, -3.0479872, -2.5729130]], [[-3.6828866, -4.1188989, -3.3097068, -3.9271731]], [[-3.9804833, -4.6788501, -3.7852053, -3.9211297]], [[-3.9796036, -4.0131998, -3.2598528, -3.3214986]], [[-3.6330394, -3.7744468, -3.4716635, -3.5620010]], [[-3.8678578, -4.1298303, -3.5939025, -3.2823299]], [[-3.2084603, -4.0711035, -2.7609335, -3.1681817]], [[-2.6317459, -3.3708045, -2.7488696, -2.7974223]], [[-2.8780028, -3.0202091, -2.4061328, -2.4679690]], [[-2.2463001, -2.6307290, -1.9631323, -2.6521649]], [[-1.8081200, -2.2590917, -1.7363605, -2.1018349]], [[-1.4218139, -1.6268621, -1.0724558, -1.6512029]], [[-0.8657050, -1.2943601, -0.8993453, -1.4807197]], [[-0.5678109, -1.0970628, -0.7853653, -0.9831666]], [[-0.5098628, -0.9470592, -0.4875267, -0.5743966]], [[-0.1670865, -0.4262626, -0.3468079, -0.3864667]], [[-0.1601545, -0.4167574, -0.1465959, -0.1014969]]]]

Expected (Unparsed): [[[[0.04976242310951111,0.27773997744661816,0.014236408440212844,0.1296228238802941]],[[0.060380935801343204,0.06180347021214018,0.12234190658944508,0.16893745416731185]],[[0.06760722009645914,-0.2286623075554951,0.09666672896446415,0.062271374178130945]],[[0.14136654412446745,0.032032106513220804,-0.045528970239191675,-0.20647924031388692]],[[-0.25881289825205767,-0.6187183103443321,-0.11303163281485291,-0.44713833345121756]],[[-0.38528823972934156,-0.8941153190762465,-0.15330723113970735,-0.6039399869177878]],[[-0.28066365786797165,-0.8966675872320342,-0.6113731177590458,-1.2744008133833502]],[[-1.373796850242793,-1.7173564259806713,-1.1634820142661948,-1.4995794439323578]],[[-1.3161030634000621,-1.6894613229504936,-0.9318091852683338,-1.6075616756346753]],[[-1.1106286049731888,-2.2360651515484022,-1.5545339300304837,-1.8918950818248603]],[[-2.5333551663867584,-2.778279796505581,-2.374111835291283,-1.885719624623953]],[[-2.5270845590292548,-3.0110306915111145,-2.156600304446449,-2.677835733030412]],[[-2.5423950201975263,-3.800327161291985,-2.7398160610218607,-2.6447748620974787]],[[-3.5385185960195873,-3.774454176769228,-3.047987178586384,-2.5729129186033384]],[[-3.682886557093589,-4.118898909035751,-3.3097067942122163,-3.927173101823892]],[[-3.9804832573233218,-4.678850090041625,-3.7852052273671473,-3.9211297010244373]],[[-3.9796035653345974,-4.013199815430523,-3.259852781728389,-3.321498595316311]],[[-3.6330393901465863,-3.774446794540908,-3.471663436098266,-3.562000945940264]],[[-3.867857801047346,-4.1298302385624694,-3.59390241502782,-3.2823298384229185]],[[-3.20846023845356,-4.071103450599083,-2.7609334574723223,-3.1681816971357275]],[[-2.6317459161914423,-3.370804482540812,-2.748869583572874,-2.7974222619221423]],[[-2.8780027794160987,-3.0202090594539945,-2.4061327941369006,-2.467968949832472]],[[-2.246300041020353,-2.630729013194967,-1.9631322574221404,-2.652164856566276]],[[-1.8081199575025382,-2.259091624923403,-1.7363604382650975,-2.101834870800359]],[[-1.4218139161290244,-1.62686206888056,-1.0724558038113214,-1.6512028979491264]],[[-0.8657050285078141,-1.2943601152463922,-0.8993453082979062,-1.4807196644791343]],[[-0.56781086,-1.09706282,-0.7853653000000002,-0.9831665600000001]],[[-0.5098628000000001,-0.94705918,-0.48752672,-0.5743966]],[[-0.16708646,-0.42626255999999996,-0.34680786,-0.38646670000000005]],[[-0.16015448000000002,-0.41675744000000003,-0.14659592,-0.10149688000000001]]]]

Actual:   [[[[0.0498, 0.2778, 0.0143, 0.1297]], [[0.0604, 0.0619, 0.1224, 0.169]], [[0.0677, -0.2286, 0.0967, 0.0623]], [[0.1414, 0.0321, -0.0455, -0.2064]], [[-0.2588, -0.6187, -0.113, -0.4471]], [[-0.3852, -0.8941, -0.1533, -0.6039]], [[-0.2806, -0.8966, -0.6113, -1.2744]], [[-1.3737, -1.7173, -1.1634, -1.4995]], [[-1.3161, -1.6894, -0.9318, -1.6075]], [[-1.1106, -2.236, -1.5545, -1.8918]], [[-2.5333, -2.7782, -2.3741, -1.8857]], [[-2.527, -3.011, -2.1566, -2.6778]], [[-2.5423, -3.8003, -2.7398, -2.6447]], [[-3.5385, -3.7744, -3.0479, -2.5729]], [[-3.6828, -4.1188, -3.3097, -3.9271]], [[-3.9804, -4.6788, -3.7852, -3.9211]], [[-3.9796, -4.0131, -3.2598, -3.3214]], [[-3.633, -3.7744, -3.4716, -3.562]], [[-3.8678, -4.1298, -3.5939, -3.2823]], [[-3.2084, -4.0711, -2.7609, -3.1681]], [[-2.6317, -3.3708, -2.7488, -2.7974]], [[-2.878, -3.0202, -2.4061, -2.4679]], [[-2.2463, -2.6307, -1.9631, -2.6521]], [[-1.8081, -2.259, -1.7363, -2.1018]], [[-1.4218, -1.6268, -1.0724, -1.6512]], [[-0.8657, -1.2943, -0.8993, -1.4807]], [[-0.5678, -1.097, -0.7853, -0.9831]], [[-0.5098, -0.947, -0.4875, -0.5743]], [[-0.167, -0.4262, -0.3468, -0.3864]], [[-0.1601, -0.4167, -0.1465, -0.1014]]]]

Expected: [[[[0.0498, 0.2778, 0.0143, 0.1297]], [[0.0604, 0.0619, 0.1224, 0.169]], [[0.0677, -0.2286, 0.0967, 0.0623]], [[0.1414, 0.0321, -0.0455, -0.2064]], [[-0.2588, -0.6187, -0.113, -0.4471]], [[-0.3852, -0.8941, -0.1533, -0.6039]], [[-0.2806, -0.8966, -0.6113, -1.2744]], [[-1.3737, -1.7173, -1.1634, -1.4995]], [[-1.3161, -1.6894, -0.9318, -1.6075]], [[-1.1106, -2.236, -1.5545, -1.8918]], [[-2.5333, -2.7782, -2.3741, -1.8857]], [[-2.527, -3.011, -2.1566, -2.6778]], [[-2.5423, -3.8003, -2.7398, -2.6447]], [[-3.5385, -3.7744, -3.0479, -2.5729]], [[-3.6828, -4.1188, -3.3097, -3.9271]], [[-3.9804, -4.6788, -3.7852, -3.9211]], [[-3.9796, -4.0131, -3.2598, -3.3214]], [[-3.633, -3.7744, -3.4716, -3.562]], [[-3.8678, -4.1298, -3.5939, -3.2823]], [[-3.2084, -4.0711, -2.7609, -3.1681]], [[-2.6317, -3.3708, -2.7488, -2.7974]], [[-2.878, -3.0202, -2.4061, -2.4679]], [[-2.2463, -2.6307, -1.9631, -2.6521]], [[-1.8081, -2.259, -1.7363, -2.1018]], [[-1.4218, -1.6268, -1.0724, -1.6512]], [[-0.8657, -1.2943, -0.8993, -1.4807]], [[-0.5678, -1.097, -0.7853, -0.9831]], [[-0.5098, -0.947, -0.4875, -0.5743]], [[-0.167, -0.4262, -0.3468, -0.3864]], [[-0.1601, -0.4167, -0.1465, -0.1014]]]]