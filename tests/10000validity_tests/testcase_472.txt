import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave90914 = tf.keras.layers.Input(shape=([2, 2, 1]))
in1Ave90914 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Con15027 = tf.keras.layers.Input(shape=([4, 2, 2]))
in0Sub27943 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Sub27943 = tf.keras.layers.Input(shape=([2, 2, 2]))

Ave90914 = keras.layers.Average(name = 'Ave90914', )([in0Ave90914,in1Ave90914])
Cro46785 = keras.layers.Cropping2D(cropping=((1, 0), (1, 0)), name = 'Cro46785', )(Ave90914)
Bat82290 = keras.layers.BatchNormalization(axis=1, epsilon=0.526092979103021,  name = 'Bat82290', )(Cro46785)
Zer83117 = keras.layers.ZeroPadding2D(padding=((3, 0), (1, 0)), name = 'Zer83117', )(Bat82290)
Con15027 = keras.layers.Concatenate(axis=3, name = 'Con15027', )([Zer83117,in0Con15027])
Sub27943 = keras.layers.Subtract(name = 'Sub27943', )([in0Sub27943,in1Sub27943])
Con67135 = keras.layers.Conv2DTranspose(3, (2, 2),strides=(2, 1), padding='same', name = 'Con67135', )(Sub27943)
Max53889 = keras.layers.Maximum(name = 'Max53889', )([Con15027,Con67135])
model = tf.keras.models.Model(inputs=[in0Ave90914,in1Ave90914,in0Con15027,in0Sub27943,in1Sub27943], outputs=Max53889)
w = model.get_layer('Bat82290').get_weights() 
w[0] = np.array([0.0975])
w[1] = np.array([0.7801])
w[2] = np.array([0.4804])
w[3] = np.array([0.6036])
model.get_layer('Bat82290').set_weights(w) 
w = model.get_layer('Con67135').get_weights() 
w[0] = np.array([[[[0.2135, 0.811], [0.7505, 0.2977], [0.1071, 0.1635]], [[0.0545, 0.7181], [0.0116, 0.8259], [0.9256, 0.8209]]], [[[0.6345, 0.7743], [0.3898, 0.0751], [0.0417, 0.6326]], [[0.9923, 0.7905], [0.4305, 0.5273], [0.945, 0.4763]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con67135').set_weights(w) 
in0Ave90914 = tf.constant([[[[0.5724], [0.1062]], [[0.8671], [0.0123]]]])
in1Ave90914 = tf.constant([[[[0.2248], [0.1828]], [[0.6759], [0.0285]]]])
in0Con15027 = tf.constant([[[[0.6658, 0.8595], [0.3528, 0.2001]], [[0.5997, 0.5084], [0.5813, 0.7039]], [[0.3987, 0.6747], [0.0318, 0.4078]], [[0.267, 0.9586], [0.2342, 0.6153]]]])
in0Sub27943 = tf.constant([[[[0.4359, 0.6357], [0.7973, 0.4499]], [[0.453, 0.0547], [0.0319, 0.0984]]]])
in1Sub27943 = tf.constant([[[[0.9086, 0.7057], [0.066, 0.2304]], [[0.1193, 0.8281], [0.4429, 0.7798]]]])
print (np.array2string(model.predict([in0Ave90914,in1Ave90914,in0Con15027,in0Sub27943,in1Sub27943],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max53889.png')

LAve90914 = average_layer([[[[[0.5724], [0.1062]], [[0.8671], [0.0123]]]], [[[[0.2248], [0.1828]], [[0.6759], [0.0285]]]]], Ave90914), 
LCro46785 = cropping2D_layer(Ave90914, 1, 0, 1, 0, Cro46785), 
LBat82290 = batch_normalization_layer(Cro46785, 1, 0.526092979103021, [0.0975], [0.7801], [0.4804], [0.6036], Bat82290), 
LZer83117 = zero_padding2D_layer(Bat82290, 3, 0, 1, 0, Zer83117), 
LCon15027 = concatenate_layer([Zer83117,[[[[0.6658, 0.8595], [0.3528, 0.2001]], [[0.5997, 0.5084], [0.5813, 0.7039]], [[0.3987, 0.6747], [0.0318, 0.4078]], [[0.267, 0.9586], [0.2342, 0.6153]]]]], 3, Con15027), 
LSub27943 = subtract_layer([[[[0.4359, 0.6357], [0.7973, 0.4499]], [[0.453, 0.0547], [0.0319, 0.0984]]]], [[[[0.9086, 0.7057], [0.066, 0.2304]], [[0.1193, 0.8281], [0.4429, 0.7798]]]], Sub27943), 
LCon67135 = conv2D_transpose_layer(Sub27943, 2, 2,[[[[0.2135, 0.811], [0.7505, 0.2977], [0.1071, 0.1635]], [[0.0545, 0.7181], [0.0116, 0.8259], [0.9256, 0.8209]]], [[[0.6345, 0.7743], [0.3898, 0.0751], [0.0417, 0.6326]], [[0.9923, 0.7905], [0.4305, 0.5273], [0.945, 0.4763]]]],[0, 0, 0], 2, 1, true, Con67135), 
LMax53889 = maximum_layer([Con15027,Con67135], Max53889), 
exec_layers([LAve90914,LCro46785,LBat82290,LZer83117,LCon15027,LSub27943,LCon67135,LMax53889],["Ave90914","Cro46785","Bat82290","Zer83117","Con15027","Sub27943","Con67135","Max53889"],Max53889,"Max53889")

Actual (Unparsed): [[[[0.0000000, 0.6658000, 0.8595000], [0.2581179, 0.5508895, 0.2001000]], [[0.0000000, 0.5997000, 0.5084000], [0.1095735, 0.5813000, 0.7039000]], [[0.0000000, 0.3987000, 0.6747000], [0.0000000, 0.0318000, 0.4078000]], [[0.0000000, 0.2670000, 0.9586000], [0.7379029, 0.2342000, 0.6153000]]]]

Expected (Unparsed): [[[[0,0.6658,0.8595],[0.2581179000000001,0.5508894800000002,0.2001]],[[0,0.5997,0.5084],[0.10957349000000013,0.5813,0.7039]],[[0,0.3987,0.6747],[0,0.0318,0.4078]],[[0,0.267,0.9586],[0.7379029361943705,0.2342,0.6153]]]]

Actual:   [[[[0, 0.6658, 0.8595], [0.2582, 0.5509, 0.2001]], [[0, 0.5997, 0.5084], [0.1096, 0.5813, 0.7039]], [[0, 0.3987, 0.6747], [0, 0.0318, 0.4078]], [[0, 0.267, 0.9586], [0.738, 0.2342, 0.6153]]]]

Expected: [[[[0, 0.6658, 0.8595], [0.2582, 0.5509, 0.2001]], [[0, 0.5997, 0.5084], [0.1096, 0.5813, 0.7039]], [[0, 0.3987, 0.6747], [0, 0.0318, 0.4078]], [[0, 0.267, 0.9586], [0.738, 0.2342, 0.6153]]]]