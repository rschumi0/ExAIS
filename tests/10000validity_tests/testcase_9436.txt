import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub86725 = tf.keras.layers.Input(shape=([3, 3, 2, 2]))
in1Sub86725 = tf.keras.layers.Input(shape=([3, 3, 2, 2]))
in0Dot14592 = tf.keras.layers.Input(shape=([2]))
in1Dot14592 = tf.keras.layers.Input(shape=([2]))
in0Dep24160 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con39663 = tf.keras.layers.Input(shape=([3, 3, 3]))

Sub86725 = keras.layers.Subtract(name = 'Sub86725', )([in0Sub86725,in1Sub86725])
Res51420 = keras.layers.Reshape((3, 3, 4), name = 'Res51420', )(Sub86725)
Dot14592 = keras.layers.Dot(axes=(1, 1), name = 'Dot14592', )([in0Dot14592,in1Dot14592])
Res13699 = keras.layers.Reshape((1, 1), name = 'Res13699', )(Dot14592)
Res17483 = keras.layers.Reshape((1, 1, 1), name = 'Res17483', )(Res13699)
Zer3824 = keras.layers.ZeroPadding2D(padding=((0, 0), (1, 0)), name = 'Zer3824', )(Res17483)
Dep24160 = keras.layers.DepthwiseConv2D((1, 2),strides=(1, 1), padding='same', name = 'Dep24160', )(in0Dep24160)
Max58428 = keras.layers.Maximum(name = 'Max58428', )([Zer3824,Dep24160])
Zer26491 = keras.layers.ZeroPadding2D(padding=((2, 0), (1, 0)), name = 'Zer26491', )(Max58428)
Con39663 = keras.layers.Concatenate(axis=3, name = 'Con39663', )([Zer26491,in0Con39663])
Add76375 = keras.layers.Add(name = 'Add76375', )([Res51420,Con39663])
Res72761 = keras.layers.Reshape((3, 3, 4, 1), name = 'Res72761', )(Add76375)
Up_17598 = keras.layers.UpSampling3D(size=(2, 2, 1), name = 'Up_17598', )(Res72761)
model = tf.keras.models.Model(inputs=[in0Sub86725,in1Sub86725,in0Dot14592,in1Dot14592,in0Dep24160,in0Con39663], outputs=Up_17598)
w = model.get_layer('Dep24160').get_weights() 
w[0] = np.array([[[[0.7052]], [[0.5155]]]])
w[1] = np.array([0])
model.get_layer('Dep24160').set_weights(w) 
in0Sub86725 = tf.constant([[[[[0.8267, 0.33], [0.9016, 0.3052]], [[0.7609, 0.701], [0.8749, 0.4623]], [[0.9352, 0.5731], [0.7386, 0.1592]]], [[[0.251, 0.8679], [0.5588, 0.391]], [[0.0471, 0.5857], [0.2698, 0.8592]], [[0.5798, 0.9249], [0.4519, 0.6979]]], [[[0.3243, 0.6108], [0.7658, 0.5251]], [[0.3985, 0.3502], [0.6099, 0.5155]], [[0.0076, 0.2747], [0.4234, 0.033]]]]])
in1Sub86725 = tf.constant([[[[[0.181, 0.2128], [0.2018, 0.7233]], [[0.2312, 0.6399], [0.2145, 0.8715]], [[0.3047, 0.1967], [0.6167, 0.2572]]], [[[0.1111, 0.7335], [0.6347, 0.7022]], [[0.4215, 0.9474], [0.2696, 1]], [[0.2059, 0.8056], [0.0125, 0.9399]]], [[[0.3453, 0.1189], [0.8922, 0.6935]], [[0.6981, 0.8225], [0.2897, 0.92]], [[0.9258, 0.7502], [0.3422, 0.5641]]]]])
in0Dot14592 = tf.constant([[0.8916, 0.9466]])
in1Dot14592 = tf.constant([[0.4327, 0.468]])
in0Dep24160 = tf.constant([[[[0.6323], [0.8507]]]])
in0Con39663 = tf.constant([[[[0.4725, 0.2907, 0.2535], [0.9429, 0.1355, 0.8572], [0.2556, 0.3523, 0.0477]], [[0.9589, 0.8057, 0.4651], [0.7885, 0.9523, 0.2843], [0.722, 0.1064, 0.2866]], [[0.3601, 0.6022, 0.6155], [0.6411, 0.8951, 0.9836], [0.9035, 0.9452, 0.4097]]]])
print (np.array2string(model.predict([in0Sub86725,in1Sub86725,in0Dot14592,in1Dot14592,in0Dep24160,in0Con39663],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Up_17598.png')

LSub86725 = subtract_layer([[[[[0.8267, 0.33], [0.9016, 0.3052]], [[0.7609, 0.701], [0.8749, 0.4623]], [[0.9352, 0.5731], [0.7386, 0.1592]]], [[[0.251, 0.8679], [0.5588, 0.391]], [[0.0471, 0.5857], [0.2698, 0.8592]], [[0.5798, 0.9249], [0.4519, 0.6979]]], [[[0.3243, 0.6108], [0.7658, 0.5251]], [[0.3985, 0.3502], [0.6099, 0.5155]], [[0.0076, 0.2747], [0.4234, 0.033]]]]], [[[[[0.181, 0.2128], [0.2018, 0.7233]], [[0.2312, 0.6399], [0.2145, 0.8715]], [[0.3047, 0.1967], [0.6167, 0.2572]]], [[[0.1111, 0.7335], [0.6347, 0.7022]], [[0.4215, 0.9474], [0.2696, 1]], [[0.2059, 0.8056], [0.0125, 0.9399]]], [[[0.3453, 0.1189], [0.8922, 0.6935]], [[0.6981, 0.8225], [0.2897, 0.92]], [[0.9258, 0.7502], [0.3422, 0.5641]]]]], Sub86725), 
LRes51420 = reshape_layer(Sub86725, [3, 3, 4], Res51420), 
LDot14592 = dot_layer([[0.8916, 0.9466]], [[0.4327, 0.468]], 1, 1, Dot14592), 
LRes13699 = reshape_layer(Dot14592, [1, 1], Res13699), 
LRes17483 = reshape_layer(Res13699, [1, 1, 1], Res17483), 
LZer3824 = zero_padding2D_layer(Res17483, 0, 0, 1, 0, Zer3824), 
LDep24160 = depthwise_conv2D_layer([[[[0.6323], [0.8507]]]], 1, 2,[[[[0.7052]], [[0.5155]]]],[0], 1, 1, true, Dep24160), 
LMax58428 = maximum_layer([Zer3824,Dep24160], Max58428), 
LZer26491 = zero_padding2D_layer(Max58428, 2, 0, 1, 0, Zer26491), 
LCon39663 = concatenate_layer([Zer26491,[[[[0.4725, 0.2907, 0.2535], [0.9429, 0.1355, 0.8572], [0.2556, 0.3523, 0.0477]], [[0.9589, 0.8057, 0.4651], [0.7885, 0.9523, 0.2843], [0.722, 0.1064, 0.2866]], [[0.3601, 0.6022, 0.6155], [0.6411, 0.8951, 0.9836], [0.9035, 0.9452, 0.4097]]]]], 3, Con39663), 
LAdd76375 = add_layer([Res51420,Con39663], Add76375), 
LRes72761 = reshape_layer(Add76375, [3, 3, 4, 1], Res72761), 
LUp_17598 = up_sampling3D_layer(Res72761, 2, 2, 1, Up_17598), 
exec_layers([LSub86725,LRes51420,LDot14592,LRes13699,LRes17483,LZer3824,LDep24160,LMax58428,LZer26491,LCon39663,LAdd76375,LRes72761,LUp_17598],["Sub86725","Res51420","Dot14592","Res13699","Res17483","Zer3824","Dep24160","Max58428","Zer26491","Con39663","Add76375","Res72761","Up_17598"],Up_17598,"Up_17598")

Actual (Unparsed): [[[[[0.6457000], [0.5897000], [0.9905000], [-0.1646000]], [[0.6457000], [0.5897000], [0.9905000], [-0.1646000]], [[0.5297000], [1.0039999], [0.7959000], [0.4480000]], [[0.5297000], [1.0039999], [0.7959000], [0.4480000]], [[0.6305000], [0.6320000], [0.4742000], [-0.0503000]], [[0.6305000], [0.6320000], [0.4742000], [-0.0503000]]], [[[0.6457000], [0.5897000], [0.9905000], [-0.1646000]], [[0.6457000], [0.5897000], [0.9905000], [-0.1646000]], [[0.5297000], [1.0039999], [0.7959000], [0.4480000]], [[0.5297000], [1.0039999], [0.7959000], [0.4480000]], [[0.6305000], [0.6320000], [0.4742000], [-0.0503000]], [[0.6305000], [0.6320000], [0.4742000], [-0.0503000]]], [[[0.1399000], [1.0933000], [0.7298000], [0.1539000]], [[0.1399000], [1.0933000], [0.7298000], [0.1539000]], [[-0.3744000], [0.4268000], [0.9525000], [0.1435000]], [[-0.3744000], [0.4268000], [0.9525000], [0.1435000]], [[0.3739000], [0.8413000], [0.5458000], [0.0446000]], [[0.3739000], [0.8413000], [0.5458000], [0.0446000]]], [[[0.1399000], [1.0933000], [0.7298000], [0.1539000]], [[0.1399000], [1.0933000], [0.7298000], [0.1539000]], [[-0.3744000], [0.4268000], [0.9525000], [0.1435000]], [[-0.3744000], [0.4268000], [0.9525000], [0.1435000]], [[0.3739000], [0.8413000], [0.5458000], [0.0446000]], [[0.3739000], [0.8413000], [0.5458000], [0.0446000]]], [[[-0.0210000], [0.8520000], [0.4758000], [0.4471000]], [[-0.0210000], [0.8520000], [0.4758000], [0.4471000]], [[0.5848339], [0.1688000], [1.2153000], [0.5791000]], [[0.5848339], [0.1688000], [1.2153000], [0.5791000]], [[-0.0893959], [0.4280000], [1.0264000], [-0.1214000]], [[-0.0893959], [0.4280000], [1.0264000], [-0.1214000]]], [[[-0.0210000], [0.8520000], [0.4758000], [0.4471000]], [[-0.0210000], [0.8520000], [0.4758000], [0.4471000]], [[0.5848339], [0.1688000], [1.2153000], [0.5791000]], [[0.5848339], [0.1688000], [1.2153000], [0.5791000]], [[-0.0893959], [0.4280000], [1.0264000], [-0.1214000]], [[-0.0893959], [0.4280000], [1.0264000], [-0.1214000]]]]]

Expected (Unparsed): [[[[[0.6456999999999999],[0.5897],[0.9904999999999999],[-0.16460000000000002]],[[0.6456999999999999],[0.5897],[0.9904999999999999],[-0.16460000000000002]],[[0.5297000000000001],[1.004],[0.7959],[0.4479999999999999]],[[0.5297000000000001],[1.004],[0.7959],[0.4479999999999999]],[[0.6305000000000001],[0.6320000000000001],[0.4742],[-0.05029999999999998]],[[0.6305000000000001],[0.6320000000000001],[0.4742],[-0.05029999999999998]]],[[[0.6456999999999999],[0.5897],[0.9904999999999999],[-0.16460000000000002]],[[0.6456999999999999],[0.5897],[0.9904999999999999],[-0.16460000000000002]],[[0.5297000000000001],[1.004],[0.7959],[0.4479999999999999]],[[0.5297000000000001],[1.004],[0.7959],[0.4479999999999999]],[[0.6305000000000001],[0.6320000000000001],[0.4742],[-0.05029999999999998]],[[0.6305000000000001],[0.6320000000000001],[0.4742],[-0.05029999999999998]]],[[[0.1399],[1.0933],[0.7297999999999999],[0.15389999999999998]],[[0.1399],[1.0933],[0.7297999999999999],[0.15389999999999998]],[[-0.37439999999999996],[0.42679999999999996],[0.9525],[0.14349999999999996]],[[-0.37439999999999996],[0.42679999999999996],[0.9525],[0.14349999999999996]],[[0.3739],[0.8413],[0.5458000000000001],[0.04460000000000003]],[[0.3739],[0.8413],[0.5458000000000001],[0.04460000000000003]]],[[[0.1399],[1.0933],[0.7297999999999999],[0.15389999999999998]],[[0.1399],[1.0933],[0.7297999999999999],[0.15389999999999998]],[[-0.37439999999999996],[0.42679999999999996],[0.9525],[0.14349999999999996]],[[-0.37439999999999996],[0.42679999999999996],[0.9525],[0.14349999999999996]],[[0.3739],[0.8413],[0.5458000000000001],[0.04460000000000003]],[[0.3739],[0.8413],[0.5458000000000001],[0.04460000000000003]]],[[[-0.02100000000000002],[0.852],[0.4758],[0.44710000000000005]],[[-0.02100000000000002],[0.852],[0.4758],[0.44710000000000005]],[[0.5848338099999999],[0.1688],[1.2153],[0.5791]],[[0.5848338099999999],[0.1688],[1.2153],[0.5791]],[[-0.08939587999999987],[0.428],[1.0264],[-0.12140000000000001]],[[-0.08939587999999987],[0.428],[1.0264],[-0.12140000000000001]]],[[[-0.02100000000000002],[0.852],[0.4758],[0.44710000000000005]],[[-0.02100000000000002],[0.852],[0.4758],[0.44710000000000005]],[[0.5848338099999999],[0.1688],[1.2153],[0.5791]],[[0.5848338099999999],[0.1688],[1.2153],[0.5791]],[[-0.08939587999999987],[0.428],[1.0264],[-0.12140000000000001]],[[-0.08939587999999987],[0.428],[1.0264],[-0.12140000000000001]]]]]

Actual:   [[[[[0.6457], [0.5897], [0.9905], [-0.1646]], [[0.6457], [0.5897], [0.9905], [-0.1646]], [[0.5297], [1.004], [0.7959], [0.448]], [[0.5297], [1.004], [0.7959], [0.448]], [[0.6305], [0.632], [0.4742], [-0.0503]], [[0.6305], [0.632], [0.4742], [-0.0503]]], [[[0.6457], [0.5897], [0.9905], [-0.1646]], [[0.6457], [0.5897], [0.9905], [-0.1646]], [[0.5297], [1.004], [0.7959], [0.448]], [[0.5297], [1.004], [0.7959], [0.448]], [[0.6305], [0.632], [0.4742], [-0.0503]], [[0.6305], [0.632], [0.4742], [-0.0503]]], [[[0.1399], [1.0933], [0.7298], [0.1539]], [[0.1399], [1.0933], [0.7298], [0.1539]], [[-0.3744], [0.4268], [0.9525], [0.1435]], [[-0.3744], [0.4268], [0.9525], [0.1435]], [[0.3739], [0.8413], [0.5458], [0.0446]], [[0.3739], [0.8413], [0.5458], [0.0446]]], [[[0.1399], [1.0933], [0.7298], [0.1539]], [[0.1399], [1.0933], [0.7298], [0.1539]], [[-0.3744], [0.4268], [0.9525], [0.1435]], [[-0.3744], [0.4268], [0.9525], [0.1435]], [[0.3739], [0.8413], [0.5458], [0.0446]], [[0.3739], [0.8413], [0.5458], [0.0446]]], [[[-0.021], [0.852], [0.4758], [0.4471]], [[-0.021], [0.852], [0.4758], [0.4471]], [[0.5849], [0.1688], [1.2153], [0.5791]], [[0.5849], [0.1688], [1.2153], [0.5791]], [[-0.0893], [0.428], [1.0264], [-0.1214]], [[-0.0893], [0.428], [1.0264], [-0.1214]]], [[[-0.021], [0.852], [0.4758], [0.4471]], [[-0.021], [0.852], [0.4758], [0.4471]], [[0.5849], [0.1688], [1.2153], [0.5791]], [[0.5849], [0.1688], [1.2153], [0.5791]], [[-0.0893], [0.428], [1.0264], [-0.1214]], [[-0.0893], [0.428], [1.0264], [-0.1214]]]]]

Expected: [[[[[0.6457], [0.5897], [0.9905], [-0.1646]], [[0.6457], [0.5897], [0.9905], [-0.1646]], [[0.5298], [1.004], [0.7959], [0.448]], [[0.5298], [1.004], [0.7959], [0.448]], [[0.6306], [0.6321], [0.4742], [-0.0502]], [[0.6306], [0.6321], [0.4742], [-0.0502]]], [[[0.6457], [0.5897], [0.9905], [-0.1646]], [[0.6457], [0.5897], [0.9905], [-0.1646]], [[0.5298], [1.004], [0.7959], [0.448]], [[0.5298], [1.004], [0.7959], [0.448]], [[0.6306], [0.6321], [0.4742], [-0.0502]], [[0.6306], [0.6321], [0.4742], [-0.0502]]], [[[0.1399], [1.0933], [0.7298], [0.1539]], [[0.1399], [1.0933], [0.7298], [0.1539]], [[-0.3743], [0.4268], [0.9525], [0.1435]], [[-0.3743], [0.4268], [0.9525], [0.1435]], [[0.3739], [0.8413], [0.5459], [0.0447]], [[0.3739], [0.8413], [0.5459], [0.0447]]], [[[0.1399], [1.0933], [0.7298], [0.1539]], [[0.1399], [1.0933], [0.7298], [0.1539]], [[-0.3743], [0.4268], [0.9525], [0.1435]], [[-0.3743], [0.4268], [0.9525], [0.1435]], [[0.3739], [0.8413], [0.5459], [0.0447]], [[0.3739], [0.8413], [0.5459], [0.0447]]], [[[-0.021], [0.852], [0.4758], [0.4472]], [[-0.021], [0.852], [0.4758], [0.4472]], [[0.5849], [0.1688], [1.2153], [0.5791]], [[0.5849], [0.1688], [1.2153], [0.5791]], [[-0.0893], [0.428], [1.0264], [-0.1214]], [[-0.0893], [0.428], [1.0264], [-0.1214]]], [[[-0.021], [0.852], [0.4758], [0.4472]], [[-0.021], [0.852], [0.4758], [0.4472]], [[0.5849], [0.1688], [1.2153], [0.5791]], [[0.5849], [0.1688], [1.2153], [0.5791]], [[-0.0893], [0.428], [1.0264], [-0.1214]], [[-0.0893], [0.428], [1.0264], [-0.1214]]]]]