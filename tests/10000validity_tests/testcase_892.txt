import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot43244 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot43244 = tf.keras.layers.Input(shape=([3, 3]))
in0Con82873 = tf.keras.layers.Input(shape=([3, 3, 2]))
in0Sof5448 = tf.keras.layers.Input(shape=([2, 1]))

Dot43244 = keras.layers.Dot(axes=(1, 2), name = 'Dot43244', )([in0Dot43244,in1Dot43244])
Res59322 = keras.layers.Reshape((3, 3, 1), name = 'Res59322', )(Dot43244)
Con82873 = keras.layers.Concatenate(axis=3, name = 'Con82873', )([Res59322,in0Con82873])
Sof5448 = keras.layers.Softmax(axis=1, name = 'Sof5448', input_shape=(2, 1))(in0Sof5448)
Res86886 = keras.layers.Reshape((2, 1, 1), name = 'Res86886', )(Sof5448)
Con51880 = keras.layers.Conv2DTranspose(3, (1, 1),strides=(1, 1), padding='same', name = 'Con51880', )(Res86886)
Con4677 = keras.layers.Conv2DTranspose(3, (1, 1),strides=(1, 1), padding='valid', name = 'Con4677', )(Con51880)
Zer4497 = keras.layers.ZeroPadding2D(padding=((1, 0), (2, 0)), name = 'Zer4497', )(Con4677)
Ave58152 = keras.layers.Average(name = 'Ave58152', )([Con82873,Zer4497])
model = tf.keras.models.Model(inputs=[in0Dot43244,in1Dot43244,in0Con82873,in0Sof5448], outputs=Ave58152)
w = model.get_layer('Con51880').get_weights() 
w[0] = np.array([[[[0.7957], [0.6791], [0.6488]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con51880').set_weights(w) 
w = model.get_layer('Con4677').get_weights() 
w[0] = np.array([[[[0.8171, 0.9554, 0.3589], [0.4797, 0.5647, 0.5268], [0.8689, 0.0026, 0.2262]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con4677').set_weights(w) 
in0Dot43244 = tf.constant([[[0.1374, 0.7422, 0.9371], [0.7293, 0.7175, 0.3568], [0.1891, 0.5465, 0.5521]]])
in1Dot43244 = tf.constant([[[0.3455, 0.9953, 0.7581], [0.1448, 0.997, 0.0778], [0.0328, 0.4162, 0.2767]]])
in0Con82873 = tf.constant([[[[0.2037, 0.5667], [0.8451, 0.8649], [0.1218, 0.6204]], [[0.3, 0.8577], [0.2321, 0.997], [0.2458, 0.7797]], [[0.0692, 0.2846], [0.6946, 0.8916], [0.9122, 0.691]]]])
in0Sof5448 = tf.constant([[[0.076], [0.3456]]])
print (np.array2string(model.predict([in0Dot43244,in1Dot43244,in0Con82873,in0Sof5448],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave58152.png')

LDot43244 = dot_layer([[[0.1374, 0.7422, 0.9371], [0.7293, 0.7175, 0.3568], [0.1891, 0.5465, 0.5521]]], [[[0.3455, 0.9953, 0.7581], [0.1448, 0.997, 0.0778], [0.0328, 0.4162, 0.2767]]], 1, 2, Dot43244), 
LRes59322 = reshape_layer(Dot43244, [3, 3, 1], Res59322), 
LCon82873 = concatenate_layer([Res59322,[[[[0.2037, 0.5667], [0.8451, 0.8649], [0.1218, 0.6204]], [[0.3, 0.8577], [0.2321, 0.997], [0.2458, 0.7797]], [[0.0692, 0.2846], [0.6946, 0.8916], [0.9122, 0.691]]]]], 3, Con82873), 
LSof5448 = softmax_layer([[[0.076], [0.3456]]], 1, Sof5448), 
LRes86886 = reshape_layer(Sof5448, [2, 1, 1], Res86886), 
LCon51880 = conv2D_transpose_layer(Res86886, 1, 1,[[[[0.7957], [0.6791], [0.6488]]]],[0, 0, 0], 1, 1, true, Con51880), 
LCon4677 = conv2D_transpose_layer(Con51880, 1, 1,[[[[0.8171, 0.9554, 0.3589], [0.4797, 0.5647, 0.5268], [0.8689, 0.0026, 0.2262]]]],[0, 0, 0], 1, 1, false, Con4677), 
LZer4497 = zero_padding2D_layer(Con4677, 1, 0, 2, 0, Zer4497), 
LAve58152 = average_layer([Con82873,Zer4497], Ave58152), 
exec_layers([LDot43244,LRes59322,LCon82873,LSof5448,LRes86886,LCon51880,LCon4677,LZer4497,LAve58152],["Dot43244","Res59322","Con82873","Sof5448","Res86886","Con51880","Con4677","Zer4497","Ave58152"],Ave58152,"Ave58152")

Actual (Unparsed): [[[[0.4583504, 0.1018500, 0.2833500], [0.3808598, 0.4225500, 0.4324500], [0.1801827, 0.0609000, 0.3102000]], [[0.6924297, 0.1500000, 0.4288500], [0.4326679, 0.1160500, 0.4985000], [0.5687380, 0.3625626, 0.5716923]], [[0.5487190, 0.0346000, 0.1423000], [0.2671875, 0.3473000, 0.4458000], [0.6002721, 0.7699239, 0.5836117]]]]

Expected (Unparsed): [[[[0.45835035,0.10185,0.28335],[0.38085979999999997,0.42255,0.43245],[0.18018267500000001,0.0609,0.3102]],[[0.69242975,0.15,0.42885],[0.43266788,0.11605,0.4985],[0.5687379914700332,0.362562564715072,0.5716922957071292]],[[0.54871905,0.0346,0.1423],[0.26718753,0.3473,0.4458],[0.6002721335299669,0.769923885284928,0.5836116792928707]]]]

Actual:   [[[[0.4584, 0.1019, 0.2834], [0.3809, 0.4226, 0.4325], [0.1802, 0.0609, 0.3102]], [[0.6925, 0.15, 0.4289], [0.4327, 0.1161, 0.4985], [0.5688, 0.3626, 0.5717]], [[0.5488, 0.0346, 0.1423], [0.2672, 0.3473, 0.4458], [0.6003, 0.77, 0.5837]]]]

Expected: [[[[0.4584, 0.1019, 0.2834], [0.3809, 0.4226, 0.4325], [0.1802, 0.0609, 0.3102]], [[0.6925, 0.15, 0.4289], [0.4327, 0.1161, 0.4985], [0.5688, 0.3626, 0.5717]], [[0.5488, 0.0346, 0.1423], [0.2672, 0.3473, 0.4458], [0.6003, 0.77, 0.5837]]]]