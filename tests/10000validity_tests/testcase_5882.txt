import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave15763 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in1Ave15763 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0Con10791 = tf.keras.layers.Input(shape=([4, 4, 5, 1]))
in0Zer97490 = tf.keras.layers.Input(shape=([2, 2, 3, 2]))
in0Mul14439 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in1Mul14439 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in0Con29956 = tf.keras.layers.Input(shape=([4, 37]))
in0Min82323 = tf.keras.layers.Input(shape=([1, 1]))
in1Min82323 = tf.keras.layers.Input(shape=([1, 1]))
in0Con75449 = tf.keras.layers.Input(shape=([4, 39]))

Ave15763 = keras.layers.Average(name = 'Ave15763', )([in0Ave15763,in1Ave15763])
Zer51590 = keras.layers.ZeroPadding3D(padding=((3, 0), (2, 0), (4, 0)), name = 'Zer51590', )(Ave15763)
Con10791 = keras.layers.Concatenate(axis=4, name = 'Con10791', )([Zer51590,in0Con10791])
Zer97490 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer97490', )(in0Zer97490)
Add44527 = keras.layers.Add(name = 'Add44527', )([Con10791,Zer97490])
Res58782 = keras.layers.Reshape((4, 4, 10), name = 'Res58782', )(Add44527)
Res74121 = keras.layers.Reshape((4, 40), name = 'Res74121', )(Res58782)
Mul14439 = keras.layers.Multiply(name = 'Mul14439', )([in0Mul14439,in1Mul14439])
Res82052 = keras.layers.Reshape((2, 2, 1), name = 'Res82052', )(Mul14439)
Res16655 = keras.layers.Reshape((2, 2), name = 'Res16655', )(Res82052)
Up_85452 = keras.layers.UpSampling1D(size=(2), name = 'Up_85452', )(Res16655)
Con62041 = keras.layers.Conv1D(3, (1),strides=(1), padding='same', dilation_rate=(1), name = 'Con62041', )(Up_85452)
Con29956 = keras.layers.Concatenate(axis=2, name = 'Con29956', )([Con62041,in0Con29956])
Ave53254 = keras.layers.Average(name = 'Ave53254', )([Res74121,Con29956])
Min82323 = keras.layers.Minimum(name = 'Min82323', )([in0Min82323,in1Min82323])
Zer80113 = keras.layers.ZeroPadding1D(padding=((3, 0)), name = 'Zer80113', )(Min82323)
Con75449 = keras.layers.Concatenate(axis=2, name = 'Con75449', )([Zer80113,in0Con75449])
Max15382 = keras.layers.Maximum(name = 'Max15382', )([Ave53254,Con75449])
model = tf.keras.models.Model(inputs=[in0Ave15763,in1Ave15763,in0Con10791,in0Zer97490,in0Mul14439,in1Mul14439,in0Con29956,in0Min82323,in1Min82323,in0Con75449], outputs=Max15382)
w = model.get_layer('Con62041').get_weights() 
w[0] = np.array([[[0.2045, 0.0665, 0.9952], [0.6791, 0.9818, 0.3902]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con62041').set_weights(w) 
in0Ave15763 = tf.constant([[[[[0.1773]], [[0.7565]]]]])
in1Ave15763 = tf.constant([[[[[0.2389]], [[0.1016]]]]])
in0Con10791 = tf.constant([[[[[0.5068], [0.616], [0.3819], [0.3139], [0.1736]], [[0.0695], [0.9277], [0.9028], [0.1191], [0.5054]], [[0.5257], [0.0689], [0.6515], [0.8316], [0.167]], [[0.1368], [0.3523], [0.602], [0.7177], [0.8345]]], [[[0.6214], [0.4826], [0.3334], [0.6273], [0.0676]], [[0.0048], [0.6925], [0.0457], [0.2534], [0.5358]], [[0.9245], [0.997], [0.3337], [0.875], [0.3479]], [[0.8577], [0.8105], [0.2587], [0.5131], [0.3497]]], [[[0.9673], [0.8479], [0.5953], [0.8147], [0.5435]], [[0.9605], [0.8787], [0.5284], [0.864], [0.4124]], [[0.933], [0.1151], [0.9465], [0.3345], [0.0916]], [[0.9626], [0.0759], [0.7439], [0.0151], [0.7731]]], [[[0.9583], [0.9668], [0.4448], [0.0318], [0.8431]], [[0.7303], [0.7331], [0.2283], [0.9386], [0.3762]], [[0.3783], [0.1212], [0.0359], [0.1787], [0.5802]], [[0.2034], [0.5032], [0.1978], [0.7887], [0.7942]]]]])
in0Zer97490 = tf.constant([[[[[1.2719, 1.8142], [1.8577, 1.4975], [1.2473, 1.7039]], [[1.2618, 1.6812], [1.7882, 1.2133], [1.5848, 1.0184]]], [[[1.8287, 1.9952], [1.2055, 1.492], [1.523, 1.7232]], [[1.2388, 1.372], [1.8722, 1.3357], [1.7252, 1.9238]]]]])
in0Mul14439 = tf.constant([[[[[0.3857]], [[0.6799]]], [[[0.1117]], [[0.3252]]]]])
in1Mul14439 = tf.constant([[[[[0.9048]], [[0.2207]]], [[[0.1329]], [[0.7098]]]]])
in0Con29956 = tf.constant([[[0.3465, 0.4355, 0.1691, 0.8205, 0.8438, 0.5412, 0.5702, 0.8863, 0.5561, 0.8888, 0.957, 0.6011, 0.5214, 0.1103, 0.1455, 0.9009, 0.9234, 0.2219, 0.5548, 0.4874, 0.9753, 0.0323, 0.9934, 0.8188, 0.3035, 0.7108, 0.0767, 0.4108, 0.0753, 0.0185, 0.8813, 0.7781, 0.9389, 0.0238, 0.0867, 0.6247, 0.5615], [0.6121, 0.9073, 0.8267, 0.1854, 0.7302, 0.5751, 0.341, 0.1563, 0.1066, 0.998, 0.4209, 0.82, 0.1331, 0.4896, 0.4232, 0.5338, 0.7042, 0.1421, 0.0508, 0.7929, 0.0708, 0.4976, 0.0903, 0.6331, 0.184, 0.6623, 0.5761, 0.5382, 0.5816, 0.9043, 0.8418, 0.0562, 0.5989, 0.0745, 0.1033, 0.2047, 0.5755], [0.9038, 0.0584, 0.5362, 0.7716, 0.3366, 0.4871, 0.4222, 0.909, 0.5884, 0.9865, 0.7168, 0.6083, 0.5367, 0.7875, 0.4649, 0.5054, 0.3907, 0.0634, 0.7284, 0.5006, 0.3221, 0.2645, 0.9262, 0.4179, 0.8871, 0.7901, 0.3019, 0.3344, 0.6197, 0.7436, 0.2679, 0.9767, 0.1353, 0.609, 0.4068, 0.8752, 0.4478], [0.432, 0.8565, 0.4178, 0.9735, 0.493, 0.6517, 0.5506, 0.8718, 0.52, 0.3508, 0.6361, 0.9571, 0.2035, 0.9373, 0.8978, 0.4029, 0.1479, 0.5538, 0.9573, 0.8577, 0.4244, 0.098, 0.1968, 0.3913, 0.5708, 0.0919, 0.0748, 0.9005, 0.2287, 0.5214, 0.0584, 0.2148, 0.6035, 0.5342, 0.544, 0.1667, 0.5849]]])
in0Min82323 = tf.constant([[[0.2477]]])
in1Min82323 = tf.constant([[[0.8621]]])
in0Con75449 = tf.constant([[[0.5757, 0.9612, 0.9689, 0.8623, 0.3221, 0.829, 0.4236, 0.5931, 0.6563, 0.2728, 0.4144, 0.9179, 0.8239, 0.3092, 0.3563, 0.4991, 0.3562, 0.7653, 0.7849, 0.3803, 0.0564, 0.0684, 0.1796, 0.0378, 0.2644, 0.7623, 0.0418, 0.0879, 0.4069, 0.0012, 0.1616, 0.4086, 0.3891, 0.2951, 0.0701, 0.5999, 0.2127, 0.34, 0.5198], [0.9044, 0.3142, 0.8492, 0.4609, 0.9345, 0.5106, 0.9227, 0.3893, 0.8156, 0.1125, 0.6397, 0.1286, 0.6401, 0.716, 0.2413, 0.0818, 0.4514, 0.4251, 0.4805, 0.7354, 0.3296, 0.767, 0.4613, 0.7327, 0.5313, 0.3664, 0.5637, 0.1476, 0.0558, 0.5187, 0.8534, 0.6826, 0.4513, 0.1662, 0.7174, 0.3928, 0.1568, 0.4222, 0.3299], [0.1928, 0.1791, 0.7077, 0.9555, 0.8446, 0.4511, 0.775, 0.026, 0.3411, 0.7807, 0.3726, 0.3886, 0.6045, 0.9104, 0.0757, 0.1186, 0.1962, 0.8343, 0.8529, 0.8108, 0.3051, 0.1897, 0.27, 0.3228, 0.6177, 0.2335, 0.8399, 0.5287, 0.8072, 0.6426, 0.9229, 0.7585, 0.2804, 0.1355, 0.7502, 0.251, 0.5125, 0.7028, 0.6012], [0.1274, 0.7694, 0.0564, 0.8988, 0.1019, 0.2659, 0.7575, 0.0026, 0.394, 0.8446, 0.3693, 0.7805, 0.0775, 0.0689, 0.8951, 0.6157, 0.4084, 0.2219, 0.7075, 0.3677, 0.5106, 0.0777, 0.1534, 0.9471, 0.1665, 0.4681, 0.0277, 0.5872, 0.3597, 0.6076, 0.1483, 0.5996, 0.6455, 0.8583, 0.337, 0.3845, 0.3898, 0.1176, 0.2126]]])
print (np.array2string(model.predict([in0Ave15763,in1Ave15763,in0Con10791,in0Zer97490,in0Mul14439,in1Mul14439,in0Con29956,in0Min82323,in1Min82323,in0Con75449],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max15382.png')

LAve15763 = average_layer([[[[[[0.1773]], [[0.7565]]]]], [[[[[0.2389]], [[0.1016]]]]]], Ave15763), 
LZer51590 = zero_padding3D_layer(Ave15763, 3, 0, 2, 0, 4, 0, Zer51590), 
LCon10791 = concatenate_layer([Zer51590,[[[[[0.5068], [0.616], [0.3819], [0.3139], [0.1736]], [[0.0695], [0.9277], [0.9028], [0.1191], [0.5054]], [[0.5257], [0.0689], [0.6515], [0.8316], [0.167]], [[0.1368], [0.3523], [0.602], [0.7177], [0.8345]]], [[[0.6214], [0.4826], [0.3334], [0.6273], [0.0676]], [[0.0048], [0.6925], [0.0457], [0.2534], [0.5358]], [[0.9245], [0.997], [0.3337], [0.875], [0.3479]], [[0.8577], [0.8105], [0.2587], [0.5131], [0.3497]]], [[[0.9673], [0.8479], [0.5953], [0.8147], [0.5435]], [[0.9605], [0.8787], [0.5284], [0.864], [0.4124]], [[0.933], [0.1151], [0.9465], [0.3345], [0.0916]], [[0.9626], [0.0759], [0.7439], [0.0151], [0.7731]]], [[[0.9583], [0.9668], [0.4448], [0.0318], [0.8431]], [[0.7303], [0.7331], [0.2283], [0.9386], [0.3762]], [[0.3783], [0.1212], [0.0359], [0.1787], [0.5802]], [[0.2034], [0.5032], [0.1978], [0.7887], [0.7942]]]]]], 4, Con10791), 
LZer97490 = zero_padding3D_layer([[[[[1.2719, 1.8142], [1.8577, 1.4975], [1.2473, 1.7039]], [[1.2618, 1.6812], [1.7882, 1.2133], [1.5848, 1.0184]]], [[[1.8287, 1.9952], [1.2055, 1.492], [1.523, 1.7232]], [[1.2388, 1.372], [1.8722, 1.3357], [1.7252, 1.9238]]]]], 1, 1, 1, 1, 1, 1, Zer97490), 
LAdd44527 = add_layer([Con10791,Zer97490], Add44527), 
LRes58782 = reshape_layer(Add44527, [4, 4, 10], Res58782), 
LRes74121 = reshape_layer(Res58782, [4, 40], Res74121), 
LMul14439 = multiply_layer([[[[[[0.3857]], [[0.6799]]], [[[0.1117]], [[0.3252]]]]], [[[[[0.9048]], [[0.2207]]], [[[0.1329]], [[0.7098]]]]]], Mul14439), 
LRes82052 = reshape_layer(Mul14439, [2, 2, 1], Res82052), 
LRes16655 = reshape_layer(Res82052, [2, 2], Res16655), 
LUp_85452 = up_sampling1D_layer(Res16655, 2, Up_85452), 
LCon62041 = conv1D_layer(Up_85452, 1,[[[0.2045, 0.0665, 0.9952], [0.6791, 0.9818, 0.3902]]],[0, 0, 0], 1, true, 1, Con62041), 
LCon29956 = concatenate_layer([Con62041,[[[0.3465, 0.4355, 0.1691, 0.8205, 0.8438, 0.5412, 0.5702, 0.8863, 0.5561, 0.8888, 0.957, 0.6011, 0.5214, 0.1103, 0.1455, 0.9009, 0.9234, 0.2219, 0.5548, 0.4874, 0.9753, 0.0323, 0.9934, 0.8188, 0.3035, 0.7108, 0.0767, 0.4108, 0.0753, 0.0185, 0.8813, 0.7781, 0.9389, 0.0238, 0.0867, 0.6247, 0.5615], [0.6121, 0.9073, 0.8267, 0.1854, 0.7302, 0.5751, 0.341, 0.1563, 0.1066, 0.998, 0.4209, 0.82, 0.1331, 0.4896, 0.4232, 0.5338, 0.7042, 0.1421, 0.0508, 0.7929, 0.0708, 0.4976, 0.0903, 0.6331, 0.184, 0.6623, 0.5761, 0.5382, 0.5816, 0.9043, 0.8418, 0.0562, 0.5989, 0.0745, 0.1033, 0.2047, 0.5755], [0.9038, 0.0584, 0.5362, 0.7716, 0.3366, 0.4871, 0.4222, 0.909, 0.5884, 0.9865, 0.7168, 0.6083, 0.5367, 0.7875, 0.4649, 0.5054, 0.3907, 0.0634, 0.7284, 0.5006, 0.3221, 0.2645, 0.9262, 0.4179, 0.8871, 0.7901, 0.3019, 0.3344, 0.6197, 0.7436, 0.2679, 0.9767, 0.1353, 0.609, 0.4068, 0.8752, 0.4478], [0.432, 0.8565, 0.4178, 0.9735, 0.493, 0.6517, 0.5506, 0.8718, 0.52, 0.3508, 0.6361, 0.9571, 0.2035, 0.9373, 0.8978, 0.4029, 0.1479, 0.5538, 0.9573, 0.8577, 0.4244, 0.098, 0.1968, 0.3913, 0.5708, 0.0919, 0.0748, 0.9005, 0.2287, 0.5214, 0.0584, 0.2148, 0.6035, 0.5342, 0.544, 0.1667, 0.5849]]]], 2, Con29956), 
LAve53254 = average_layer([Res74121,Con29956], Ave53254), 
LMin82323 = minimum_layer([[[[0.2477]]], [[[0.8621]]]], Min82323), 
LZer80113 = zero_padding1D_layer(Min82323, 3, 0, Zer80113), 
LCon75449 = concatenate_layer([Zer80113,[[[0.5757, 0.9612, 0.9689, 0.8623, 0.3221, 0.829, 0.4236, 0.5931, 0.6563, 0.2728, 0.4144, 0.9179, 0.8239, 0.3092, 0.3563, 0.4991, 0.3562, 0.7653, 0.7849, 0.3803, 0.0564, 0.0684, 0.1796, 0.0378, 0.2644, 0.7623, 0.0418, 0.0879, 0.4069, 0.0012, 0.1616, 0.4086, 0.3891, 0.2951, 0.0701, 0.5999, 0.2127, 0.34, 0.5198], [0.9044, 0.3142, 0.8492, 0.4609, 0.9345, 0.5106, 0.9227, 0.3893, 0.8156, 0.1125, 0.6397, 0.1286, 0.6401, 0.716, 0.2413, 0.0818, 0.4514, 0.4251, 0.4805, 0.7354, 0.3296, 0.767, 0.4613, 0.7327, 0.5313, 0.3664, 0.5637, 0.1476, 0.0558, 0.5187, 0.8534, 0.6826, 0.4513, 0.1662, 0.7174, 0.3928, 0.1568, 0.4222, 0.3299], [0.1928, 0.1791, 0.7077, 0.9555, 0.8446, 0.4511, 0.775, 0.026, 0.3411, 0.7807, 0.3726, 0.3886, 0.6045, 0.9104, 0.0757, 0.1186, 0.1962, 0.8343, 0.8529, 0.8108, 0.3051, 0.1897, 0.27, 0.3228, 0.6177, 0.2335, 0.8399, 0.5287, 0.8072, 0.6426, 0.9229, 0.7585, 0.2804, 0.1355, 0.7502, 0.251, 0.5125, 0.7028, 0.6012], [0.1274, 0.7694, 0.0564, 0.8988, 0.1019, 0.2659, 0.7575, 0.0026, 0.394, 0.8446, 0.3693, 0.7805, 0.0775, 0.0689, 0.8951, 0.6157, 0.4084, 0.2219, 0.7075, 0.3677, 0.5106, 0.0777, 0.1534, 0.9471, 0.1665, 0.4681, 0.0277, 0.5872, 0.3597, 0.6076, 0.1483, 0.5996, 0.6455, 0.8583, 0.337, 0.3845, 0.3898, 0.1176, 0.2126]]]], 2, Con75449), 
LMax15382 = maximum_layer([Ave53254,Con75449], Max15382), 
exec_layers([LAve15763,LZer51590,LCon10791,LZer97490,LAdd44527,LRes58782,LRes74121,LMul14439,LRes82052,LRes16655,LUp_85452,LCon62041,LCon29956,LAve53254,LMin82323,LZer80113,LCon75449,LMax15382],["Ave15763","Zer51590","Con10791","Zer97490","Add44527","Res58782","Res74121","Mul14439","Res82052","Res16655","Up_85452","Con62041","Con29956","Ave53254","Min82323","Zer80113","Con75449","Max15382"],Max15382,"Max15382")

Actual (Unparsed): [[[0.0866342, 0.5757000, 0.9612000, 0.9689000, 0.8623000, 0.3221000, 0.8290000, 0.5788500, 0.5931000, 0.6563000, 0.4431500, 0.4144000, 0.9179000, 0.9423500, 0.3092000, 0.7121000, 0.4991000, 0.3562000, 0.7653000, 0.7849000, 0.3803000, 0.5402500, 0.2437000, 0.5221000, 0.0378000, 0.8224500, 0.7623000, 0.5675500, 0.3554000, 0.4069000, 0.2054000, 0.1616000, 0.4086000, 0.6168000, 0.3890500, 0.7704500, 0.5999000, 0.4022000, 0.3400000, 0.6980000], [0.0866342, 0.9044000, 0.3142000, 0.8492000, 0.4609000, 0.9345000, 0.5106000, 0.9227000, 0.3893000, 0.8156000, 0.1125000, 0.6397000, 1.1349500, 1.4638000, 1.3388500, 0.8381500, 0.8684500, 1.1902500, 0.4251000, 0.6200000, 0.7354000, 0.4876500, 1.0273500, 1.3745000, 1.1429000, 0.8186500, 1.1089500, 1.0387000, 0.3311500, 0.4620000, 0.5187000, 0.8534000, 0.6826000, 0.8261500, 0.1662000, 0.7174000, 0.3928000, 0.3082000, 0.4222000, 0.4626000], [0.0798952, 0.5974565, 0.1791000, 0.8758500, 0.9555000, 0.8446000, 0.4511000, 0.7750000, 0.2435500, 0.4828500, 0.7807000, 0.7744500, 1.4076000, 1.7953500, 0.9104000, 1.2785500, 1.1552500, 1.5260500, 0.8343000, 0.8529000, 0.8108000, 0.8307000, 0.8697000, 0.9046000, 1.0683500, 1.6042000, 1.0715500, 1.5727000, 0.5287000, 0.8072000, 0.6426000, 0.9229000, 0.7585000, 0.2804000, 0.4883500, 0.7502000, 0.3045000, 0.5125000, 0.7028000, 0.6104500], [0.2477000, 0.5929565, 0.7694000, 0.6994000, 0.8988000, 0.4313000, 0.4867500, 0.7575000, 0.3258500, 0.6968500, 0.8446000, 0.6251500, 0.7805000, 0.6846000, 0.4785500, 0.8951000, 0.6157000, 0.9182000, 0.2219000, 0.7075000, 0.3677000, 0.6678000, 0.4288500, 0.2728000, 0.9471000, 0.1665000, 0.4681000, 0.3747500, 0.5872000, 0.3597000, 0.6076000, 0.2160500, 0.5996000, 0.6455000, 0.8583000, 0.4006500, 0.3845000, 0.6663500, 0.2978750, 0.6895500]]]

Expected (Unparsed): [[[0.0866341559915,0.5757,0.9612,0.9689,0.8623,0.3221,0.829,0.57885,0.5931,0.6563,0.44315,0.4144,0.9179,0.94235,0.3092,0.7121,0.4991,0.3562,0.7653,0.7849,0.3803,0.5402499999999999,0.2437,0.5221,0.0378,0.8224499999999999,0.7623,0.56755,0.3554,0.4069,0.2054,0.1616,0.4086,0.6168,0.38905,0.77045,0.5999,0.4022,0.34,0.698],[0.0866341559915,0.9044,0.3142,0.8492,0.4609,0.9345,0.5106,0.9227,0.3893,0.8156,0.1125,0.6397,1.13495,1.4638,1.3388499999999999,0.8381500000000001,0.86845,1.19025,0.4251,0.6200000000000001,0.7354,0.48765,1.02735,1.3745,1.1429,0.8186500000000001,1.10895,1.0387,0.33115,0.46199999999999997,0.5187,0.8534,0.6826,0.8261499999999999,0.1662,0.7174,0.3928,0.30820000000000003,0.4222,0.4626],[0.0798951883605,0.5974565485865,0.1791,0.87585,0.9555,0.8446,0.4511,0.775,0.24355,0.48285,0.7807,0.7744500000000001,1.4076,1.79535,0.9104,1.27855,1.1552499999999999,1.5260500000000001,0.8343,0.8529,0.8108,0.8307,0.8696999999999999,0.9046000000000001,1.0683500000000001,1.6042,1.07155,1.5727000000000002,0.5287,0.8072,0.6426,0.9229,0.7585,0.2804,0.48835,0.7502,0.3045,0.5125,0.7028,0.6104499999999999],[0.2477,0.5929565485865,0.7694,0.6994,0.8988,0.4313,0.48675,0.7575,0.32585,0.69685,0.8446,0.62515,0.7805,0.6846,0.47855,0.8951,0.6157,0.9182,0.2219,0.7075,0.3677,0.6678000000000001,0.42885,0.2728,0.9471,0.1665,0.4681,0.37474999999999997,0.5872,0.3597,0.6076,0.21605,0.5996,0.6455,0.8583,0.40065,0.3845,0.66635,0.297875,0.68955]]]

Actual:   [[[0.0867, 0.5757, 0.9612, 0.9689, 0.8623, 0.3221, 0.829, 0.5789, 0.5931, 0.6563, 0.4432, 0.4144, 0.9179, 0.9424, 0.3092, 0.7121, 0.4991, 0.3562, 0.7653, 0.7849, 0.3803, 0.5403, 0.2437, 0.5221, 0.0378, 0.8225, 0.7623, 0.5676, 0.3554, 0.4069, 0.2054, 0.1616, 0.4086, 0.6168, 0.3891, 0.7705, 0.5999, 0.4022, 0.34, 0.698], [0.0867, 0.9044, 0.3142, 0.8492, 0.4609, 0.9345, 0.5106, 0.9227, 0.3893, 0.8156, 0.1125, 0.6397, 1.135, 1.4638, 1.3389, 0.8382, 0.8685, 1.1903, 0.4251, 0.62, 0.7354, 0.4877, 1.0274, 1.3745, 1.1429, 0.8187, 1.109, 1.0387, 0.3312, 0.462, 0.5187, 0.8534, 0.6826, 0.8262, 0.1662, 0.7174, 0.3928, 0.3082, 0.4222, 0.4626], [0.0799, 0.5975, 0.1791, 0.8759, 0.9555, 0.8446, 0.4511, 0.775, 0.2436, 0.4829, 0.7807, 0.7745, 1.4076, 1.7954, 0.9104, 1.2786, 1.1553, 1.5261, 0.8343, 0.8529, 0.8108, 0.8307, 0.8697, 0.9046, 1.0684, 1.6042, 1.0716, 1.5727, 0.5287, 0.8072, 0.6426, 0.9229, 0.7585, 0.2804, 0.4884, 0.7502, 0.3045, 0.5125, 0.7028, 0.6105], [0.2477, 0.593, 0.7694, 0.6994, 0.8988, 0.4313, 0.4868, 0.7575, 0.3259, 0.6969, 0.8446, 0.6252, 0.7805, 0.6846, 0.4786, 0.8951, 0.6157, 0.9182, 0.2219, 0.7075, 0.3677, 0.6678, 0.4289, 0.2728, 0.9471, 0.1665, 0.4681, 0.3748, 0.5872, 0.3597, 0.6076, 0.2161, 0.5996, 0.6455, 0.8583, 0.4007, 0.3845, 0.6664, 0.2979, 0.6896]]]

Expected: [[[0.0867, 0.5757, 0.9612, 0.9689, 0.8623, 0.3221, 0.829, 0.5789, 0.5931, 0.6563, 0.4432, 0.4144, 0.9179, 0.9424, 0.3092, 0.7121, 0.4991, 0.3562, 0.7653, 0.7849, 0.3803, 0.5403, 0.2437, 0.5221, 0.0378, 0.8225, 0.7623, 0.5676, 0.3554, 0.4069, 0.2054, 0.1616, 0.4086, 0.6168, 0.3891, 0.7705, 0.5999, 0.4022, 0.34, 0.698], [0.0867, 0.9044, 0.3142, 0.8492, 0.4609, 0.9345, 0.5106, 0.9227, 0.3893, 0.8156, 0.1125, 0.6397, 1.135, 1.4638, 1.3389, 0.8382, 0.8685, 1.1903, 0.4251, 0.6201, 0.7354, 0.4877, 1.0274, 1.3745, 1.1429, 0.8187, 1.109, 1.0387, 0.3312, 0.462, 0.5187, 0.8534, 0.6826, 0.8262, 0.1662, 0.7174, 0.3928, 0.3083, 0.4222, 0.4626], [0.0799, 0.5975, 0.1791, 0.8759, 0.9555, 0.8446, 0.4511, 0.775, 0.2436, 0.4829, 0.7807, 0.7745, 1.4076, 1.7954, 0.9104, 1.2786, 1.1553, 1.5261, 0.8343, 0.8529, 0.8108, 0.8307, 0.8697, 0.9047, 1.0684, 1.6042, 1.0716, 1.5728, 0.5287, 0.8072, 0.6426, 0.9229, 0.7585, 0.2804, 0.4884, 0.7502, 0.3045, 0.5125, 0.7028, 0.6105], [0.2477, 0.593, 0.7694, 0.6994, 0.8988, 0.4313, 0.4868, 0.7575, 0.3259, 0.6969, 0.8446, 0.6252, 0.7805, 0.6846, 0.4786, 0.8951, 0.6157, 0.9182, 0.2219, 0.7075, 0.3677, 0.6679, 0.4289, 0.2728, 0.9471, 0.1665, 0.4681, 0.3748, 0.5872, 0.3597, 0.6076, 0.2161, 0.5996, 0.6455, 0.8583, 0.4007, 0.3845, 0.6664, 0.2979, 0.6896]]]