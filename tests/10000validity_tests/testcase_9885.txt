import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sep47114 = tf.keras.layers.Input(shape=([2, 1]))
in0Ave30131 = tf.keras.layers.Input(shape=([1, 1]))
in1Ave30131 = tf.keras.layers.Input(shape=([1, 1]))
in0Dot33926 = tf.keras.layers.Input(shape=([3]))
in1Dot33926 = tf.keras.layers.Input(shape=([3]))
in0Con75575 = tf.keras.layers.Input(shape=([59]))

Sep47114 = keras.layers.SeparableConv1D(3, (1),strides=(1), padding='same', name = 'Sep47114', )(in0Sep47114)
Res90912 = keras.layers.Reshape((2, 3, 1), name = 'Res90912', )(Sep47114)
Res57663 = keras.layers.Reshape((2, 3, 1, 1), name = 'Res57663', )(Res90912)
Zer38704 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer38704', )(Res57663)
Res25045 = keras.layers.Reshape((4, 5, 3), name = 'Res25045', )(Zer38704)
Res78946 = keras.layers.Reshape((4, 15), name = 'Res78946', )(Res25045)
Fla40893 = keras.layers.Flatten(name = 'Fla40893', )(Res78946)
Ave30131 = keras.layers.Average(name = 'Ave30131', )([in0Ave30131,in1Ave30131])
ReL83638 = keras.layers.ReLU(max_value=2.383072258361028, negative_slope=5.479390797542532, threshold=4.183393925378741, name = 'ReL83638', )(Ave30131)
Fla47748 = keras.layers.Flatten(name = 'Fla47748', )(ReL83638)
Dot33926 = keras.layers.Dot(axes=(1, 1), name = 'Dot33926', )([in0Dot33926,in1Dot33926])
Min52110 = keras.layers.Minimum(name = 'Min52110', )([Fla47748,Dot33926])
Con75575 = keras.layers.Concatenate(axis=1, name = 'Con75575', )([Min52110,in0Con75575])
Mul22501 = keras.layers.Multiply(name = 'Mul22501', )([Fla40893,Con75575])
model = tf.keras.models.Model(inputs=[in0Sep47114,in0Ave30131,in1Ave30131,in0Dot33926,in1Dot33926,in0Con75575], outputs=Mul22501)
w = model.get_layer('Sep47114').get_weights() 
w[0] = np.array([[[0.7015]]])
w[1] = np.array([[[0.1099, 0.3942, 0.0163]]])
w[2] = np.array([0, 0, 0])
model.get_layer('Sep47114').set_weights(w) 
in0Sep47114 = tf.constant([[[0.5993], [0.6924]]])
in0Ave30131 = tf.constant([[[0.8579]]])
in1Ave30131 = tf.constant([[[0.9011]]])
in0Dot33926 = tf.constant([[0.7396, 0.4192, 0.9358]])
in1Dot33926 = tf.constant([[0.7159, 0.8627, 0.1826]])
in0Con75575 = tf.constant([[0.5457, 0.0831, 0.2335, 0.8939, 0.4434, 0.3578, 0.1719, 0.8713, 0.4439, 0.2564, 0.4795, 0.3675, 0.2134, 0.7642, 0.6249, 0.107, 0.7948, 0.1218, 0.1626, 0.2167, 0.6043, 0.933, 0.3993, 0.0938, 0.1793, 0.6203, 0.5467, 0.7707, 0.2685, 0.8935, 0.0716, 0.4606, 0.9173, 0.0625, 0.7853, 0.5181, 0.0472, 0.2201, 0.3224, 0.1424, 0.6525, 0.551, 0.0516, 0.7627, 0.1475, 0.2778, 0.1359, 0.1992, 0.5829, 0.0496, 0.4093, 0.3721, 0.4215, 0.8962, 0.9774, 0.5419, 0.3136, 0.2261, 0.9619]])
print (np.array2string(model.predict([in0Sep47114,in0Ave30131,in1Ave30131,in0Dot33926,in1Dot33926,in0Con75575],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul22501.png')

LSep47114 = separable_conv1D_layer([[[0.5993], [0.6924]]], 1,[[[[0.7015]]],[[[0.1099, 0.3942, 0.0163]]]],[0, 0, 0], 1, true, Sep47114), 
LRes90912 = reshape_layer(Sep47114, [2, 3, 1], Res90912), 
LRes57663 = reshape_layer(Res90912, [2, 3, 1, 1], Res57663), 
LZer38704 = zero_padding3D_layer(Res57663, 1, 1, 1, 1, 1, 1, Zer38704), 
LRes25045 = reshape_layer(Zer38704, [4, 5, 3], Res25045), 
LRes78946 = reshape_layer(Res25045, [4, 15], Res78946), 
LFla40893 = flatten_layer(Res78946, Fla40893), 
LAve30131 = average_layer([[[[0.8579]]], [[[0.9011]]]], Ave30131), 
LReL83638 = relu_layer(Ave30131, 2.383072258361028, 5.479390797542532, 4.183393925378741, ReL83638), 
LFla47748 = flatten_layer(ReL83638, Fla47748), 
LDot33926 = dot_layer([[0.7396, 0.4192, 0.9358]], [[0.7159, 0.8627, 0.1826]], 1, 1, Dot33926), 
LMin52110 = minimum_layer([Fla47748,Dot33926], Min52110), 
LCon75575 = concatenate_layer([Min52110,[[0.5457, 0.0831, 0.2335, 0.8939, 0.4434, 0.3578, 0.1719, 0.8713, 0.4439, 0.2564, 0.4795, 0.3675, 0.2134, 0.7642, 0.6249, 0.107, 0.7948, 0.1218, 0.1626, 0.2167, 0.6043, 0.933, 0.3993, 0.0938, 0.1793, 0.6203, 0.5467, 0.7707, 0.2685, 0.8935, 0.0716, 0.4606, 0.9173, 0.0625, 0.7853, 0.5181, 0.0472, 0.2201, 0.3224, 0.1424, 0.6525, 0.551, 0.0516, 0.7627, 0.1475, 0.2778, 0.1359, 0.1992, 0.5829, 0.0496, 0.4093, 0.3721, 0.4215, 0.8962, 0.9774, 0.5419, 0.3136, 0.2261, 0.9619]]], 1, Con75575), 
LMul22501 = multiply_layer([Fla40893,Con75575], Mul22501), 
exec_layers([LSep47114,LRes90912,LRes57663,LZer38704,LRes25045,LRes78946,LFla40893,LAve30131,LReL83638,LFla47748,LDot33926,LMin52110,LCon75575,LMul22501],["Sep47114","Res90912","Res57663","Zer38704","Res25045","Res78946","Fla40893","Ave30131","ReL83638","Fla47748","Dot33926","Min52110","Con75575","Mul22501"],Mul22501,"Mul22501")

Actual (Unparsed): [[-0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0075126, 0.0000000, 0.0000000, 0.1546216, 0.0000000, 0.0000000, 0.0012287, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0033363, 0.0000000, 0.0000000, 0.0090374, 0.0000000, 0.0000000, 0.0011274, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000]]

Expected (Unparsed): [[-0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007512598630173,0.0,0.0,0.15462161914797004,0.0,0.0,0.0012286829931805,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00333627963375,0.0,0.0,0.009037396844064,0.0,0.0,0.001127411156832,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]

Actual:   [[-0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0076, 0, 0, 0.1547, 0, 0, 0.0013, 0, 0, 0, 0, 0, 0, 0, 0, 0.0034, 0, 0, 0.0091, 0, 0, 0.0012, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]

Expected: [[-0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0076, 0, 0, 0.1547, 0, 0, 0.0013, 0, 0, 0, 0, 0, 0, 0, 0, 0.0034, 0, 0, 0.0091, 0, 0, 0.0012, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]