import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add37043 = tf.keras.layers.Input(shape=([2, 1, 2]))
in1Add37043 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Sub81746 = tf.keras.layers.Input(shape=([3]))
in1Sub81746 = tf.keras.layers.Input(shape=([3]))
in0Con75544 = tf.keras.layers.Input(shape=([1]))
in0Con9070 = tf.keras.layers.Input(shape=([6, 1]))
in0Min44009 = tf.keras.layers.Input(shape=([2, 1, 2]))
in1Min44009 = tf.keras.layers.Input(shape=([2, 1, 2]))

Add37043 = keras.layers.Add(name = 'Add37043', )([in0Add37043,in1Add37043])
Res50524 = keras.layers.Reshape((2, 2), name = 'Res50524', )(Add37043)
Fla92946 = keras.layers.Flatten(name = 'Fla92946', )(Res50524)
Sub81746 = keras.layers.Subtract(name = 'Sub81746', )([in0Sub81746,in1Sub81746])
ELU29190 = keras.layers.ELU(alpha=-9.941269082025253, name = 'ELU29190', )(Sub81746)
Con75544 = keras.layers.Concatenate(axis=1, name = 'Con75544', )([ELU29190,in0Con75544])
Mul14404 = keras.layers.Multiply(name = 'Mul14404', )([Fla92946,Con75544])
Res97943 = keras.layers.Reshape((4, 1), name = 'Res97943', )(Mul14404)
Zer39417 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer39417', )(Res97943)
Con9070 = keras.layers.Concatenate(axis=2, name = 'Con9070', )([Zer39417,in0Con9070])
Min44009 = keras.layers.Minimum(name = 'Min44009', )([in0Min44009,in1Min44009])
Res50684 = keras.layers.Reshape((2, 2), name = 'Res50684', )(Min44009)
Dot97552 = keras.layers.Dot(axes=(2, 2), name = 'Dot97552', )([Con9070,Res50684])
model = tf.keras.models.Model(inputs=[in0Add37043,in1Add37043,in0Sub81746,in1Sub81746,in0Con75544,in0Con9070,in0Min44009,in1Min44009], outputs=Dot97552)
in0Add37043 = tf.constant([[[[0.0414, 0.2373]], [[0.0116, 0.6358]]]])
in1Add37043 = tf.constant([[[[0.881, 0.51]], [[0.8989, 0.8558]]]])
in0Sub81746 = tf.constant([[0.8971, 0.3679, 0.3936]])
in1Sub81746 = tf.constant([[0.5515, 0.1791, 0.4419]])
in0Con75544 = tf.constant([[0.2762]])
in0Con9070 = tf.constant([[[0.8217], [0.2766], [0.8263], [0.6451], [0.9578], [0.2574]]])
in0Min44009 = tf.constant([[[[0.9801, 0.8038]], [[0.5243, 0.367]]]])
in1Min44009 = tf.constant([[[[0.0776, 0.9977]], [[0.4987, 0.0453]]]])
print (np.array2string(model.predict([in0Add37043,in1Add37043,in0Sub81746,in1Sub81746,in0Con75544,in0Con9070,in0Min44009,in1Min44009],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot97552.png')

LAdd37043 = add_layer([[[[[0.0414, 0.2373]], [[0.0116, 0.6358]]]], [[[[0.881, 0.51]], [[0.8989, 0.8558]]]]], Add37043), 
LRes50524 = reshape_layer(Add37043, [2, 2], Res50524), 
LFla92946 = flatten_layer(Res50524, Fla92946), 
LSub81746 = subtract_layer([[0.8971, 0.3679, 0.3936]], [[0.5515, 0.1791, 0.4419]], Sub81746), 
LELU29190 = elu_layer(Sub81746, -9.941269082025253, ELU29190), 
LCon75544 = concatenate_layer([ELU29190,[[0.2762]]], 1, Con75544), 
LMul14404 = multiply_layer([Fla92946,Con75544], Mul14404), 
LRes97943 = reshape_layer(Mul14404, [4, 1], Res97943), 
LZer39417 = zero_padding1D_layer(Res97943, 2, 0, Zer39417), 
LCon9070 = concatenate_layer([Zer39417,[[[0.8217], [0.2766], [0.8263], [0.6451], [0.9578], [0.2574]]]], 2, Con9070), 
LMin44009 = minimum_layer([[[[[0.9801, 0.8038]], [[0.5243, 0.367]]]], [[[[0.0776, 0.9977]], [[0.4987, 0.0453]]]]], Min44009), 
LRes50684 = reshape_layer(Min44009, [2, 2], Res50684), 
LDot97552 = dot_layer(Con9070,Res50684, 2, 2, Dot97552), 
exec_layers([LAdd37043,LRes50524,LFla92946,LSub81746,LELU29190,LCon75544,LMul14404,LRes97943,LZer39417,LCon9070,LMin44009,LRes50684,LDot97552],["Add37043","Res50524","Fla92946","Sub81746","ELU29190","Con75544","Mul14404","Res97943","Zer39417","Con9070","Min44009","Res50684","Dot97552"],Dot97552,"Dot97552")

Actual (Unparsed): [[[0.6604824, 0.0372230], [0.2223311, 0.0125300], [0.6889174, 0.1964077], [0.5294800, 0.0995847], [0.8029992, 0.2562329], [0.2388678, 0.2171146]]]

Expected (Unparsed): [[[0.66048246,0.03722301],[0.22233108,0.012529980000000001],[0.688917379744,0.19640769412800002],[0.529479982624,0.099584732688],[0.8029992057387466,0.25623276569475417],[0.23886776179199998,0.217114606104]]]

Actual:   [[[0.6605, 0.0373], [0.2224, 0.0126], [0.689, 0.1965], [0.5295, 0.0996], [0.803, 0.2563], [0.2389, 0.2172]]]

Expected: [[[0.6605, 0.0373], [0.2224, 0.0126], [0.689, 0.1965], [0.5295, 0.0996], [0.803, 0.2563], [0.2389, 0.2172]]]