import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add22279 = tf.keras.layers.Input(shape=([1, 2, 2]))
in1Add22279 = tf.keras.layers.Input(shape=([1, 2, 2]))
in0Con60124 = tf.keras.layers.Input(shape=([3, 3, 1]))
in0Sub39465 = tf.keras.layers.Input(shape=([3, 3, 3]))
in1Sub39465 = tf.keras.layers.Input(shape=([3, 3, 3]))

Add22279 = keras.layers.Add(name = 'Add22279', )([in0Add22279,in1Add22279])
Zer99407 = keras.layers.ZeroPadding2D(padding=((2, 0), (1, 0)), name = 'Zer99407', )(Add22279)
Con60124 = keras.layers.Concatenate(axis=3, name = 'Con60124', )([Zer99407,in0Con60124])
Sub39465 = keras.layers.Subtract(name = 'Sub39465', )([in0Sub39465,in1Sub39465])
Thr36323 = keras.layers.ThresholdedReLU(theta=4.921576143489559, name = 'Thr36323', )(Sub39465)
Sub69485 = keras.layers.Subtract(name = 'Sub69485', )([Con60124,Thr36323])
model = tf.keras.models.Model(inputs=[in0Add22279,in1Add22279,in0Con60124,in0Sub39465,in1Sub39465], outputs=Sub69485)
in0Add22279 = tf.constant([[[[0.304, 0.2084], [0.8849, 0.4951]]]])
in1Add22279 = tf.constant([[[[0.4144, 0.7154], [0.4478, 0.5294]]]])
in0Con60124 = tf.constant([[[[0.4417], [0.8294], [0.1888]], [[0.3995], [0.8593], [0.9703]], [[0.3532], [0.8964], [0.7947]]]])
in0Sub39465 = tf.constant([[[[0.8452, 0.3516, 0.2653], [0.2059, 0.8932, 0.6334], [0.2419, 0.3322, 0.9683]], [[0.5555, 0.8152, 0.0432], [0.1201, 0.6273, 0.975], [0.0516, 0.5721, 0.8579]], [[0.593, 0.9806, 0.5949], [0.4988, 0.1773, 0.5383], [0.5969, 0.7941, 0.2995]]]])
in1Sub39465 = tf.constant([[[[0.4316, 0.2723, 0.0715], [0.9773, 0.2089, 0.0094], [0.2609, 0.2363, 0.6752]], [[0.5329, 0.3272, 0.9254], [0.1251, 0.9293, 0.1638], [0.6152, 0.4058, 0.7912]], [[0.2109, 0.0672, 0.7383], [0.2, 0.4316, 0.3322], [0.3022, 0.6673, 0.3116]]]])
print (np.array2string(model.predict([in0Add22279,in1Add22279,in0Con60124,in0Sub39465,in1Sub39465],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub69485.png')

LAdd22279 = add_layer([[[[[0.304, 0.2084], [0.8849, 0.4951]]]], [[[[0.4144, 0.7154], [0.4478, 0.5294]]]]], Add22279), 
LZer99407 = zero_padding2D_layer(Add22279, 2, 0, 1, 0, Zer99407), 
LCon60124 = concatenate_layer([Zer99407,[[[[0.4417], [0.8294], [0.1888]], [[0.3995], [0.8593], [0.9703]], [[0.3532], [0.8964], [0.7947]]]]], 3, Con60124), 
LSub39465 = subtract_layer([[[[0.8452, 0.3516, 0.2653], [0.2059, 0.8932, 0.6334], [0.2419, 0.3322, 0.9683]], [[0.5555, 0.8152, 0.0432], [0.1201, 0.6273, 0.975], [0.0516, 0.5721, 0.8579]], [[0.593, 0.9806, 0.5949], [0.4988, 0.1773, 0.5383], [0.5969, 0.7941, 0.2995]]]], [[[[0.4316, 0.2723, 0.0715], [0.9773, 0.2089, 0.0094], [0.2609, 0.2363, 0.6752]], [[0.5329, 0.3272, 0.9254], [0.1251, 0.9293, 0.1638], [0.6152, 0.4058, 0.7912]], [[0.2109, 0.0672, 0.7383], [0.2, 0.4316, 0.3322], [0.3022, 0.6673, 0.3116]]]], Sub39465), 
LThr36323 = thresholded_relu_layer(Sub39465, 4.921576143489559, Thr36323), 
LSub69485 = subtract_layer(Con60124,Thr36323, Sub69485), 
exec_layers([LAdd22279,LZer99407,LCon60124,LSub39465,LThr36323,LSub69485],["Add22279","Zer99407","Con60124","Sub39465","Thr36323","Sub69485"],Sub69485,"Sub69485")

Actual (Unparsed): [[[[0.0000000, 0.0000000, 0.4417000], [0.0000000, 0.0000000, 0.8294000], [0.0000000, 0.0000000, 0.1888000]], [[0.0000000, 0.0000000, 0.3995000], [0.0000000, 0.0000000, 0.8593000], [0.0000000, 0.0000000, 0.9703000]], [[0.0000000, 0.0000000, 0.3532000], [0.7184000, 0.9238000, 0.8964000], [1.3327000, 1.0245000, 0.7947000]]]]

Expected (Unparsed): [[[[0,0,0.4417],[0,0,0.8294],[0,0,0.1888]],[[0,0,0.3995],[0,0,0.8593],[0,0,0.9703]],[[0,0,0.3532],[0.7183999999999999,0.9238000000000001,0.8964],[1.3327,1.0245,0.7947]]]]

Actual:   [[[[0, 0, 0.4417], [0, 0, 0.8294], [0, 0, 0.1888]], [[0, 0, 0.3995], [0, 0, 0.8593], [0, 0, 0.9703]], [[0, 0, 0.3532], [0.7184, 0.9238, 0.8964], [1.3327, 1.0245, 0.7947]]]]

Expected: [[[[0, 0, 0.4417], [0, 0, 0.8294], [0, 0, 0.1888]], [[0, 0, 0.3995], [0, 0, 0.8593], [0, 0, 0.9703]], [[0, 0, 0.3532], [0.7184, 0.9239, 0.8964], [1.3327, 1.0245, 0.7947]]]]