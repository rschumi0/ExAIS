import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave81206 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))
in1Ave81206 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))
in0Con19265 = tf.keras.layers.Input(shape=([199]))
in0Zer4304 = tf.keras.layers.Input(shape=([3, 2, 3, 2]))
in0Glo72842 = tf.keras.layers.Input(shape=([1, 2, 2]))
in0Dot70695 = tf.keras.layers.Input(shape=([3]))
in1Dot70695 = tf.keras.layers.Input(shape=([3]))
in0Con62719 = tf.keras.layers.Input(shape=([1]))
in0Con97879 = tf.keras.layers.Input(shape=([198]))

Ave81206 = keras.layers.Average(name = 'Ave81206', )([in0Ave81206,in1Ave81206])
Res90258 = keras.layers.Reshape((1, 1, 1), name = 'Res90258', )(Ave81206)
Res87884 = keras.layers.Reshape((1, 1), name = 'Res87884', )(Res90258)
Glo8712 = keras.layers.GlobalMaxPool1D(name = 'Glo8712', )(Res87884)
Lea60628 = keras.layers.LeakyReLU(alpha=3.7833501168238457, name = 'Lea60628', )(Glo8712)
Con19265 = keras.layers.Concatenate(axis=1, name = 'Con19265', )([Lea60628,in0Con19265])
Zer4304 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer4304', )(in0Zer4304)
Res65094 = keras.layers.Reshape((5, 4, 10), name = 'Res65094', )(Zer4304)
Res96929 = keras.layers.Reshape((5, 40), name = 'Res96929', )(Res65094)
Fla45300 = keras.layers.Flatten(name = 'Fla45300', )(Res96929)
Glo72842 = keras.layers.GlobalAveragePooling2D(name = 'Glo72842', )(in0Glo72842)
Dot70695 = keras.layers.Dot(axes=(1, 1), name = 'Dot70695', )([in0Dot70695,in1Dot70695])
ReL49884 = keras.layers.ReLU(max_value=5.798888633118751, negative_slope=7.514856570268887, threshold=8.69130750424608, name = 'ReL49884', )(Dot70695)
Res85414 = keras.layers.Reshape((1, 1), name = 'Res85414', )(ReL49884)
Sim84053 = keras.layers.SimpleRNN(1,name = 'Sim84053', )(Res85414)
Con62719 = keras.layers.Concatenate(axis=1, name = 'Con62719', )([Sim84053,in0Con62719])
Add59858 = keras.layers.Add(name = 'Add59858', )([Glo72842,Con62719])
Con97879 = keras.layers.Concatenate(axis=1, name = 'Con97879', )([Add59858,in0Con97879])
Add379 = keras.layers.Add(name = 'Add379', )([Fla45300,Con97879])
Sub90912 = keras.layers.Subtract(name = 'Sub90912', )([Con19265,Add379])
model = tf.keras.models.Model(inputs=[in0Ave81206,in1Ave81206,in0Con19265,in0Zer4304,in0Glo72842,in0Dot70695,in1Dot70695,in0Con62719,in0Con97879], outputs=Sub90912)
w = model.get_layer('Sim84053').get_weights() 
w[0] = np.array([[9]])
w[1] = np.array([[9]])
w[2] = np.array([9])
model.get_layer('Sim84053').set_weights(w) 
in0Ave81206 = tf.constant([[[[[0.3523]]]]])
in1Ave81206 = tf.constant([[[[[0.7672]]]]])
in0Con19265 = tf.constant([[0.612, 0.223, 0.805, 0.6925, 0.0215, 0.1958, 0.2982, 0.4447, 0.7188, 0.8002, 0.4301, 0.079, 0.4553, 0.6157, 0.5322, 0.5496, 0.3231, 0.452, 0.7834, 0.1137, 0.8078, 0.8473, 0.7569, 0.0946, 0.3149, 0.6343, 0.7671, 0.7422, 0.0767, 0.3439, 0.6702, 0.3967, 0.1271, 0.4364, 0.7522, 0.7101, 0.4662, 0.4821, 0.4775, 0.6401, 0.6248, 0.45, 0.163, 0.2935, 0.5907, 0.2033, 0.0944, 0.4688, 0.4563, 0.1507, 0.2083, 0.9219, 0.2122, 0.7575, 0.2237, 0.9653, 0.8227, 0.2807, 0.0287, 0.9953, 0.094, 0.6599, 0.202, 0.9435, 0.8736, 0.9708, 0.7787, 0.4452, 0.8026, 0.2255, 0.7608, 0.7285, 0.1857, 0.5915, 0.4141, 0.8413, 0.5391, 0.2949, 0.0947, 0.8524, 0.0304, 0.5684, 0.2037, 0.094, 0.3335, 0.0132, 0.8835, 0.339, 0.3895, 0.6533, 0.2349, 0.0537, 0.1826, 0.777, 0.162, 0.5049, 0.9238, 0.3878, 0.4329, 0.5575, 0.964, 0.7114, 0.1805, 0.4527, 0.3536, 0.7474, 0.8631, 0.7247, 0.2093, 0.2913, 0.6537, 0.681, 0.9559, 0.2054, 0.3352, 0.5509, 0.0658, 0.9695, 0.0385, 0.488, 0.1383, 0.7039, 0.581, 0.1025, 0.0325, 0.9255, 0.7397, 0.0945, 0.2932, 0.2706, 0.5216, 0.8615, 0.2985, 0.2977, 0.3837, 0.6607, 0.3923, 0.2705, 0.3981, 0.0219, 0.7694, 0.5131, 0.5587, 0.6252, 0.0267, 0.5286, 0.7812, 0.7886, 0.1107, 0.5763, 0.6624, 0.0386, 0.8504, 0.8145, 0.7316, 0.9792, 0.3928, 0.4334, 0.7548, 0.8208, 0.6333, 0.4254, 0.6308, 0.4791, 0.1672, 0.7715, 0.5588, 0.1154, 0.3826, 0.8563, 0.4498, 0.3522, 0.0584, 0.8691, 0.0029, 0.1682, 0.2373, 0.7956, 0.4778, 0.6561, 0.2013, 0.3593, 0.9524, 0.405, 0.0943, 0.9349, 0.7789, 0.264, 0.1078, 0.0203, 0.0216, 0.6347, 0.1734, 0.3307, 0.8961, 0.2434, 0.7934, 0.9553, 0.6125]])
in0Zer4304 = tf.constant([[[[[1.0091, 1.768], [1.4295, 1.1744], [1.7577, 1.794]], [[1.6378, 1.1081], [1.8721, 1.4583], [1.7592, 1.7701]]], [[[1.9761, 1.4469], [1.218, 1.5546], [1.7221, 1.1484]], [[1.6019, 1.9718], [1.6708, 1.5983], [1.2492, 1.8303]]], [[[1.6716, 1.1548], [1.7304, 1.7625], [1.7416, 1.9271]], [[1.9582, 1.9335], [1.6095, 1.6254], [1.3487, 1.5652]]]]])
in0Glo72842 = tf.constant([[[[1.5495, 1.6844], [1.9283, 1.7282]]]])
in0Dot70695 = tf.constant([[0.2388, 0.0537, 0.7699]])
in1Dot70695 = tf.constant([[0.6537, 0.1422, 0.9897]])
in0Con62719 = tf.constant([[0.2765]])
in0Con97879 = tf.constant([[0.6955, 0.7125, 0.2388, 0.221, 0.9205, 0.964, 0.6613, 0.9633, 0.0222, 0.6924, 0.2148, 0.1073, 0.9985, 0.0111, 0.704, 0.9317, 0.0001, 0.1646, 0.2623, 0.8492, 0.7941, 0.2775, 0.4445, 0.0142, 0.8105, 0.6155, 0.6083, 0.6066, 0.5572, 0.1108, 0.295, 0.8474, 0.204, 0.7365, 0.2871, 0.713, 0.3029, 0.5538, 0.6409, 0.1301, 0.9388, 0.9027, 0.2719, 0.1603, 0.0865, 0.2561, 0.6052, 0.3099, 0.5848, 0.7182, 0.3922, 0.6395, 0.9367, 0.0097, 0.0454, 0.7881, 0.0905, 0.0546, 0.7429, 0.3762, 0.4663, 0.959, 0.1155, 0.5073, 0.7545, 0.257, 0.5453, 0.2479, 0.4294, 0.7849, 0.976, 0.0336, 0.4995, 0.4445, 0.6638, 0.9226, 0.7461, 0.4148, 0.4826, 0.4982, 0.589, 0.0804, 0.2372, 0.0064, 0.7627, 0.0601, 0.9365, 0.0106, 0.1864, 0.2382, 0.1309, 0.4385, 0.7681, 0.6292, 0.2281, 0.4076, 0.3956, 0.2383, 0.1675, 0.6215, 0.0347, 0.82, 0.9558, 0.4499, 0.6827, 0.5831, 0.3425, 0.0264, 0.9047, 0.4408, 0.3527, 0.8313, 0.819, 0.3641, 0.4815, 0.2588, 0.6904, 0.7602, 0.1025, 0.6131, 0.7433, 0.5677, 0.0482, 0.8267, 0.4084, 0.9383, 0.3766, 0.9462, 0.9854, 0.9565, 0.0568, 0.0961, 0.6166, 0.8387, 0.6756, 0.1952, 0.5473, 0.4494, 0.2993, 0.1746, 0.8753, 0.7718, 0.3052, 0.8281, 0.3851, 0.1796, 0.3419, 0.7091, 0.5992, 0.9723, 0.5709, 0.6828, 0.8872, 0.6528, 0.9996, 0.8387, 0.3224, 0.8585, 0.021, 0.4767, 0.9931, 0.6838, 0.2447, 0.7879, 0.6443, 0.3773, 0.3228, 0.67, 0.8465, 0.037, 0.757, 0.8416, 0.3769, 0.9835, 0.6011, 0.0475, 0.1285, 0.9449, 0.5722, 0.6867, 0.6623, 0.0549, 0.323, 0.6317, 0.4648, 0.9329, 0.5362, 0.3627, 0.0804, 0.7947, 0.0606, 0.7904, 0.5513, 0.6237, 0.5212, 0.3049, 0.0159, 0.9207]])
print (np.array2string(model.predict([in0Ave81206,in1Ave81206,in0Con19265,in0Zer4304,in0Glo72842,in0Dot70695,in1Dot70695,in0Con62719,in0Con97879],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub90912.png')

LAve81206 = average_layer([[[[[[0.3523]]]]], [[[[[0.7672]]]]]], Ave81206), 
LRes90258 = reshape_layer(Ave81206, [1, 1, 1], Res90258), 
LRes87884 = reshape_layer(Res90258, [1, 1], Res87884), 
LGlo8712 = global_max_pool1D_layer(Res87884, Glo8712), 
LLea60628 = leaky_relu_layer(Glo8712, 3.7833501168238457, Lea60628), 
LCon19265 = concatenate_layer([Lea60628,[[0.612, 0.223, 0.805, 0.6925, 0.0215, 0.1958, 0.2982, 0.4447, 0.7188, 0.8002, 0.4301, 0.079, 0.4553, 0.6157, 0.5322, 0.5496, 0.3231, 0.452, 0.7834, 0.1137, 0.8078, 0.8473, 0.7569, 0.0946, 0.3149, 0.6343, 0.7671, 0.7422, 0.0767, 0.3439, 0.6702, 0.3967, 0.1271, 0.4364, 0.7522, 0.7101, 0.4662, 0.4821, 0.4775, 0.6401, 0.6248, 0.45, 0.163, 0.2935, 0.5907, 0.2033, 0.0944, 0.4688, 0.4563, 0.1507, 0.2083, 0.9219, 0.2122, 0.7575, 0.2237, 0.9653, 0.8227, 0.2807, 0.0287, 0.9953, 0.094, 0.6599, 0.202, 0.9435, 0.8736, 0.9708, 0.7787, 0.4452, 0.8026, 0.2255, 0.7608, 0.7285, 0.1857, 0.5915, 0.4141, 0.8413, 0.5391, 0.2949, 0.0947, 0.8524, 0.0304, 0.5684, 0.2037, 0.094, 0.3335, 0.0132, 0.8835, 0.339, 0.3895, 0.6533, 0.2349, 0.0537, 0.1826, 0.777, 0.162, 0.5049, 0.9238, 0.3878, 0.4329, 0.5575, 0.964, 0.7114, 0.1805, 0.4527, 0.3536, 0.7474, 0.8631, 0.7247, 0.2093, 0.2913, 0.6537, 0.681, 0.9559, 0.2054, 0.3352, 0.5509, 0.0658, 0.9695, 0.0385, 0.488, 0.1383, 0.7039, 0.581, 0.1025, 0.0325, 0.9255, 0.7397, 0.0945, 0.2932, 0.2706, 0.5216, 0.8615, 0.2985, 0.2977, 0.3837, 0.6607, 0.3923, 0.2705, 0.3981, 0.0219, 0.7694, 0.5131, 0.5587, 0.6252, 0.0267, 0.5286, 0.7812, 0.7886, 0.1107, 0.5763, 0.6624, 0.0386, 0.8504, 0.8145, 0.7316, 0.9792, 0.3928, 0.4334, 0.7548, 0.8208, 0.6333, 0.4254, 0.6308, 0.4791, 0.1672, 0.7715, 0.5588, 0.1154, 0.3826, 0.8563, 0.4498, 0.3522, 0.0584, 0.8691, 0.0029, 0.1682, 0.2373, 0.7956, 0.4778, 0.6561, 0.2013, 0.3593, 0.9524, 0.405, 0.0943, 0.9349, 0.7789, 0.264, 0.1078, 0.0203, 0.0216, 0.6347, 0.1734, 0.3307, 0.8961, 0.2434, 0.7934, 0.9553, 0.6125]]], 1, Con19265), 
LZer4304 = zero_padding3D_layer([[[[[1.0091, 1.768], [1.4295, 1.1744], [1.7577, 1.794]], [[1.6378, 1.1081], [1.8721, 1.4583], [1.7592, 1.7701]]], [[[1.9761, 1.4469], [1.218, 1.5546], [1.7221, 1.1484]], [[1.6019, 1.9718], [1.6708, 1.5983], [1.2492, 1.8303]]], [[[1.6716, 1.1548], [1.7304, 1.7625], [1.7416, 1.9271]], [[1.9582, 1.9335], [1.6095, 1.6254], [1.3487, 1.5652]]]]], 1, 1, 1, 1, 1, 1, Zer4304), 
LRes65094 = reshape_layer(Zer4304, [5, 4, 10], Res65094), 
LRes96929 = reshape_layer(Res65094, [5, 40], Res96929), 
LFla45300 = flatten_layer(Res96929, Fla45300), 
LGlo72842 = global_average_pooling2D_layer([[[[1.5495, 1.6844], [1.9283, 1.7282]]]], Glo72842), 
LDot70695 = dot_layer([[0.2388, 0.0537, 0.7699]], [[0.6537, 0.1422, 0.9897]], 1, 1, Dot70695), 
LReL49884 = relu_layer(Dot70695, 5.798888633118751, 7.514856570268887, 8.69130750424608, ReL49884), 
LRes85414 = reshape_layer(ReL49884, [1, 1], Res85414), 
LSim84053 = simple_rnn_layer(Res85414,[[9]],[[9]],[9], Sim84053), 
LCon62719 = concatenate_layer([Sim84053,[[0.2765]]], 1, Con62719), 
LAdd59858 = add_layer([Glo72842,Con62719], Add59858), 
LCon97879 = concatenate_layer([Add59858,[[0.6955, 0.7125, 0.2388, 0.221, 0.9205, 0.964, 0.6613, 0.9633, 0.0222, 0.6924, 0.2148, 0.1073, 0.9985, 0.0111, 0.704, 0.9317, 0.0001, 0.1646, 0.2623, 0.8492, 0.7941, 0.2775, 0.4445, 0.0142, 0.8105, 0.6155, 0.6083, 0.6066, 0.5572, 0.1108, 0.295, 0.8474, 0.204, 0.7365, 0.2871, 0.713, 0.3029, 0.5538, 0.6409, 0.1301, 0.9388, 0.9027, 0.2719, 0.1603, 0.0865, 0.2561, 0.6052, 0.3099, 0.5848, 0.7182, 0.3922, 0.6395, 0.9367, 0.0097, 0.0454, 0.7881, 0.0905, 0.0546, 0.7429, 0.3762, 0.4663, 0.959, 0.1155, 0.5073, 0.7545, 0.257, 0.5453, 0.2479, 0.4294, 0.7849, 0.976, 0.0336, 0.4995, 0.4445, 0.6638, 0.9226, 0.7461, 0.4148, 0.4826, 0.4982, 0.589, 0.0804, 0.2372, 0.0064, 0.7627, 0.0601, 0.9365, 0.0106, 0.1864, 0.2382, 0.1309, 0.4385, 0.7681, 0.6292, 0.2281, 0.4076, 0.3956, 0.2383, 0.1675, 0.6215, 0.0347, 0.82, 0.9558, 0.4499, 0.6827, 0.5831, 0.3425, 0.0264, 0.9047, 0.4408, 0.3527, 0.8313, 0.819, 0.3641, 0.4815, 0.2588, 0.6904, 0.7602, 0.1025, 0.6131, 0.7433, 0.5677, 0.0482, 0.8267, 0.4084, 0.9383, 0.3766, 0.9462, 0.9854, 0.9565, 0.0568, 0.0961, 0.6166, 0.8387, 0.6756, 0.1952, 0.5473, 0.4494, 0.2993, 0.1746, 0.8753, 0.7718, 0.3052, 0.8281, 0.3851, 0.1796, 0.3419, 0.7091, 0.5992, 0.9723, 0.5709, 0.6828, 0.8872, 0.6528, 0.9996, 0.8387, 0.3224, 0.8585, 0.021, 0.4767, 0.9931, 0.6838, 0.2447, 0.7879, 0.6443, 0.3773, 0.3228, 0.67, 0.8465, 0.037, 0.757, 0.8416, 0.3769, 0.9835, 0.6011, 0.0475, 0.1285, 0.9449, 0.5722, 0.6867, 0.6623, 0.0549, 0.323, 0.6317, 0.4648, 0.9329, 0.5362, 0.3627, 0.0804, 0.7947, 0.0606, 0.7904, 0.5513, 0.6237, 0.5212, 0.3049, 0.0159, 0.9207]]], 1, Con97879), 
LAdd379 = add_layer([Fla45300,Con97879], Add379), 
LSub90912 = subtract_layer(Con19265,Add379, Sub90912), 
exec_layers([LAve81206,LRes90258,LRes87884,LGlo8712,LLea60628,LCon19265,LZer4304,LRes65094,LRes96929,LFla45300,LGlo72842,LDot70695,LReL49884,LRes85414,LSim84053,LCon62719,LAdd59858,LCon97879,LAdd379,LSub90912],["Ave81206","Res90258","Res87884","Glo8712","Lea60628","Con19265","Zer4304","Res65094","Res96929","Fla45300","Glo72842","Dot70695","ReL49884","Res85414","Sim84053","Con62719","Add59858","Con97879","Add379","Sub90912"],Sub90912,"Sub90912")

Actual (Unparsed): [[-0.1791500, -1.3708000, -0.4725000, 0.0925000, 0.4537000, -0.1995000, -0.7247000, -0.6658000, -0.2166000, -0.2445000, 0.7780000, -0.2623000, -0.1358000, 0.3480000, -0.3828000, 0.5211000, -0.1544000, -0.6086000, 0.4519000, 0.6188000, -0.1486000, -0.0414000, 0.0532000, 0.4794000, -0.3499000, 0.3007000, -0.1762000, 0.1516000, 0.1339000, -0.5299000, -0.2133000, 0.5594000, 0.1017000, -0.7203000, 0.2324000, 0.0157000, 0.4230000, -0.2468000, 0.1792000, -0.0763000, -0.0008000, 0.4947000, -0.4888000, -0.7397000, 0.0216000, 0.4304000, 0.1168000, -0.1617000, -0.1364000, 0.1464000, -0.4341000, -0.5099000, -0.4794000, -2.1953000, -1.6087000, -0.9604000, -0.8377999, -1.7594000, 0.1902000, -0.0259000, 0.2524000, -0.2822000, -1.4442000, -1.8651000, -1.0441000, -1.0920000, -1.5429000, -1.2484000, -0.1001000, 0.5547000, -0.2039000, -0.0241000, -0.2475000, 0.1521000, 0.0920000, -0.0304000, 0.1775000, -0.3835000, -0.4512000, -0.3201000, 0.3698000, -0.4678000, -0.0206000, 0.1233000, -0.1432000, 0.3271000, -0.7495000, 0.8234000, -0.5975000, 0.3789000, 0.4669000, -0.0033000, -2.0533000, -1.7028000, -1.2091001, -2.0218000, -1.4453000, -0.6321999, -0.0078000, 0.1946000, 0.3900000, 0.3425000, -0.9252000, -2.6113000, -2.1739000, -1.6946000, -1.1845000, -1.5503000, 0.3822000, 0.1829000, -0.6134000, 0.2129000, 0.3283000, 0.1246000, -0.6136000, -0.0289000, 0.0694000, -0.1930000, 0.2791000, -0.7217000, 0.3855000, -0.4748000, -0.0394000, 0.0132999, 0.0543000, -0.7942000, 0.5171000, -0.1986000, -0.2821000, -0.6530000, -0.7148000, -0.4349000, -0.8669000, -0.9524001, -2.0493000, -2.2175000, -1.7565000, -1.7299999, -0.2768000, -0.0513000, -0.2774000, 0.5948000, -2.3203999, -2.1466000, -1.2895001, -2.4268000, -1.2052001, -0.9636000, 0.4467000, -0.5984000, -0.0229000, -0.3099000, -0.5323000, 0.1676000, -0.0727000, 0.0788000, -0.0204000, -0.4459000, 0.1110000, -0.1037000, 0.7998000, 0.1566000, -0.5677000, -0.0530000, 0.2344000, -0.6207000, 0.1272000, 0.1815000, -0.2074000, -0.2874000, 0.0098000, 0.4128000, -0.4048000, -0.7832000, 0.4922000, -0.9806000, -0.4329000, 0.1898000, 0.6671000, -0.4671000, 0.0839000, -0.4854000, -0.3030000, 0.8975000, 0.0820000, -0.5374000, 0.4701000, -0.1540000, -0.2722000, -0.2549000, -0.0601000, -0.7731000, 0.5741000, -0.6170000, -0.2206000, 0.2724000, -0.2778000, 0.4885000, 0.9394000, -0.3082000]]

Expected (Unparsed): [[-0.17915000000000014,-1.3708,-0.47250000000000003,0.09250000000000003,0.4537,-0.1995,-0.7247,-0.6658,-0.21660000000000001,-0.24450000000000005,0.778,-0.26230000000000003,-0.13579999999999998,0.348,-0.38280000000000003,0.5211,-0.15439999999999998,-0.6086,0.4519,0.6188,-0.14859999999999998,-0.04139999999999999,0.053200000000000025,0.4794,-0.3499,0.3007,-0.17620000000000002,0.15159999999999996,0.13390000000000002,-0.5299,-0.21330000000000005,0.5594,0.10170000000000001,-0.7203,0.23240000000000002,0.015699999999999936,0.42299999999999993,-0.24679999999999996,0.17919999999999997,-0.07629999999999998,-0.0008000000000000229,0.49470000000000003,-0.48879999999999996,-0.7396999999999999,0.021600000000000008,0.4304,0.11680000000000001,-0.1617,-0.13639999999999997,0.14639999999999997,-0.4341,-0.5098999999999999,-0.47939999999999994,-2.1952999999999996,-1.6087000000000002,-0.9604000000000001,-0.8378000000000001,-1.7594,0.1902,-0.025900000000000003,0.25239999999999996,-0.2822,-1.4442,-1.8651,-1.0441,-1.0919999999999996,-1.5429,-1.2484,-0.10010000000000002,0.5547,-0.2039,-0.02410000000000001,-0.24749999999999994,0.1521,0.09200000000000003,-0.030399999999999983,0.1775000000000001,-0.38349999999999995,-0.4512,-0.3201,0.3698000000000001,-0.4678,-0.02059999999999995,0.12329999999999999,-0.1432,0.3271,-0.7495,0.8233999999999999,-0.5974999999999999,0.3789,0.4669,-0.0032999999999999974,-2.0532999999999997,-1.7028,-1.2090999999999998,-2.0218,-1.4453,-0.6322000000000001,-0.007800000000000029,0.1946,0.39,0.3424999999999999,-0.9252,-2.6113,-2.1738999999999997,-1.6945999999999999,-1.1845000000000003,-1.5503000000000002,0.3822,0.1829,-0.6134,0.21289999999999992,0.32830000000000004,0.12459999999999993,-0.6135999999999999,-0.02889999999999998,0.06939999999999996,-0.19299999999999998,0.2791,-0.7217,0.3855,-0.4748,-0.03939999999999999,0.013299999999999979,0.054299999999999994,-0.7942,0.5171,-0.1986,-0.2821,-0.653,-0.7148000000000001,-0.43490000000000006,-0.8668999999999999,-0.9524000000000001,-2.0493,-2.2175,-1.7565000000000004,-1.73,-0.2768,-0.05130000000000001,-0.27740000000000004,0.5948,-2.3204,-2.1466000000000003,-1.2894999999999999,-2.4268,-1.2052,-0.9635999999999999,0.4467,-0.5983999999999999,-0.02289999999999992,-0.30990000000000006,-0.5323,0.16760000000000008,-0.07269999999999999,0.07879999999999998,-0.020400000000000085,-0.4459,0.11099999999999999,-0.10370000000000001,0.7998,0.15659999999999996,-0.5677,-0.052999999999999936,0.23440000000000003,-0.6207,0.12719999999999998,0.18149999999999994,-0.20739999999999997,-0.28740000000000004,0.00979999999999992,0.4128,-0.4048,-0.7832,0.49219999999999997,-0.9806,-0.43289999999999995,0.18980000000000002,0.6671,-0.46709999999999996,0.08389999999999997,-0.48539999999999994,-0.303,0.8975000000000001,0.08200000000000002,-0.5374000000000001,0.47009999999999996,-0.15399999999999991,-0.2722,-0.2549,-0.0601,-0.7731,0.5741,-0.617,-0.22060000000000002,0.2724,-0.2778,0.4885,0.9394,-0.3081999999999999]]

Actual:   [[-0.1791, -1.3708, -0.4725, 0.0925, 0.4537, -0.1995, -0.7247, -0.6658, -0.2166, -0.2445, 0.778, -0.2623, -0.1358, 0.348, -0.3828, 0.5211, -0.1544, -0.6086, 0.4519, 0.6188, -0.1486, -0.0414, 0.0532, 0.4794, -0.3499, 0.3007, -0.1762, 0.1516, 0.1339, -0.5299, -0.2133, 0.5594, 0.1017, -0.7203, 0.2324, 0.0157, 0.423, -0.2468, 0.1792, -0.0763, -0.0008, 0.4947, -0.4888, -0.7397, 0.0216, 0.4304, 0.1168, -0.1617, -0.1364, 0.1464, -0.4341, -0.5099, -0.4794, -2.1953, -1.6087, -0.9604, -0.8377, -1.7594, 0.1902, -0.0259, 0.2524, -0.2822, -1.4442, -1.8651, -1.0441, -1.092, -1.5429, -1.2484, -0.1001, 0.5547, -0.2039, -0.0241, -0.2475, 0.1521, 0.092, -0.0304, 0.1775, -0.3835, -0.4512, -0.3201, 0.3698, -0.4678, -0.0206, 0.1233, -0.1432, 0.3271, -0.7495, 0.8234, -0.5975, 0.3789, 0.4669, -0.0033, -2.0533, -1.7028, -1.2091, -2.0218, -1.4453, -0.6321, -0.0078, 0.1946, 0.39, 0.3425, -0.9252, -2.6113, -2.1739, -1.6946, -1.1845, -1.5503, 0.3822, 0.1829, -0.6134, 0.2129, 0.3283, 0.1246, -0.6136, -0.0289, 0.0694, -0.193, 0.2791, -0.7217, 0.3855, -0.4748, -0.0394, 0.0133, 0.0543, -0.7942, 0.5171, -0.1986, -0.2821, -0.653, -0.7148, -0.4349, -0.8669, -0.9524, -2.0493, -2.2175, -1.7565, -1.7299, -0.2768, -0.0513, -0.2774, 0.5948, -2.3203, -2.1466, -1.2895, -2.4268, -1.2052, -0.9636, 0.4467, -0.5984, -0.0229, -0.3099, -0.5323, 0.1676, -0.0727, 0.0788, -0.0204, -0.4459, 0.111, -0.1037, 0.7998, 0.1566, -0.5677, -0.053, 0.2344, -0.6207, 0.1272, 0.1815, -0.2074, -0.2874, 0.0098, 0.4128, -0.4048, -0.7832, 0.4922, -0.9806, -0.4329, 0.1898, 0.6671, -0.4671, 0.0839, -0.4854, -0.303, 0.8975, 0.082, -0.5374, 0.4701, -0.154, -0.2722, -0.2549, -0.0601, -0.7731, 0.5741, -0.617, -0.2206, 0.2724, -0.2778, 0.4885, 0.9394, -0.3082]]

Expected: [[-0.1791, -1.3708, -0.4725, 0.0926, 0.4537, -0.1995, -0.7247, -0.6658, -0.2166, -0.2445, 0.778, -0.2623, -0.1357, 0.348, -0.3828, 0.5211, -0.1543, -0.6086, 0.4519, 0.6188, -0.1485, -0.0413, 0.0533, 0.4794, -0.3499, 0.3007, -0.1762, 0.1516, 0.134, -0.5299, -0.2133, 0.5594, 0.1018, -0.7203, 0.2325, 0.0157, 0.423, -0.2467, 0.1792, -0.0762, -0.0008, 0.4948, -0.4887, -0.7396, 0.0217, 0.4304, 0.1169, -0.1617, -0.1363, 0.1464, -0.4341, -0.5098, -0.4793, -2.1952, -1.6087, -0.9604, -0.8378, -1.7594, 0.1902, -0.0259, 0.2524, -0.2822, -1.4442, -1.8651, -1.0441, -1.0919, -1.5429, -1.2484, -0.1001, 0.5547, -0.2039, -0.0241, -0.2474, 0.1521, 0.0921, -0.0303, 0.1776, -0.3834, -0.4512, -0.3201, 0.3699, -0.4678, -0.0205, 0.1233, -0.1432, 0.3271, -0.7495, 0.8234, -0.5974, 0.3789, 0.4669, -0.0032, -2.0532, -1.7028, -1.209, -2.0218, -1.4453, -0.6322, -0.0078, 0.1946, 0.39, 0.3425, -0.9252, -2.6113, -2.1738, -1.6945, -1.1845, -1.5503, 0.3822, 0.1829, -0.6134, 0.2129, 0.3284, 0.1246, -0.6135, -0.0288, 0.0694, -0.1929, 0.2791, -0.7217, 0.3855, -0.4748, -0.0393, 0.0133, 0.0543, -0.7942, 0.5171, -0.1986, -0.2821, -0.653, -0.7148, -0.4349, -0.8668, -0.9524, -2.0493, -2.2175, -1.7565, -1.73, -0.2768, -0.0513, -0.2774, 0.5948, -2.3204, -2.1466, -1.2894, -2.4268, -1.2052, -0.9635, 0.4467, -0.5983, -0.0228, -0.3099, -0.5323, 0.1677, -0.0726, 0.0788, -0.0204, -0.4459, 0.111, -0.1037, 0.7998, 0.1566, -0.5677, -0.0529, 0.2345, -0.6207, 0.1272, 0.1815, -0.2073, -0.2874, 0.0098, 0.4128, -0.4048, -0.7832, 0.4922, -0.9806, -0.4328, 0.1899, 0.6671, -0.467, 0.0839, -0.4853, -0.303, 0.8976, 0.0821, -0.5374, 0.4701, -0.1539, -0.2722, -0.2549, -0.0601, -0.7731, 0.5741, -0.617, -0.2206, 0.2724, -0.2778, 0.4885, 0.9394, -0.3081]]