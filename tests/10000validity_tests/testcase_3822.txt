import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer4469 = tf.keras.layers.Input(shape=([3, 4, 4]))
in0PRe66928 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con96137 = tf.keras.layers.Input(shape=([2]))
in0Dot91853 = tf.keras.layers.Input(shape=([2, 3]))
in1Dot91853 = tf.keras.layers.Input(shape=([2, 3]))
in0Con66806 = tf.keras.layers.Input(shape=([117]))

Zer4469 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer4469', )(in0Zer4469)
Res71526 = keras.layers.Reshape((5, 24), name = 'Res71526', )(Zer4469)
Fla16085 = keras.layers.Flatten(name = 'Fla16085', )(Res71526)
PRe66928 = keras.layers.PReLU(name = 'PRe66928', input_shape=(1, 1, 1))(in0PRe66928)
Res7237 = keras.layers.Reshape((1, 1), name = 'Res7237', )(PRe66928)
Fla92118 = keras.layers.Flatten(name = 'Fla92118', )(Res7237)
Con96137 = keras.layers.Concatenate(axis=1, name = 'Con96137', )([Fla92118,in0Con96137])
Dot91853 = keras.layers.Dot(axes=(1, 1), name = 'Dot91853', )([in0Dot91853,in1Dot91853])
Glo67650 = keras.layers.GlobalAveragePooling1D(name = 'Glo67650', )(Dot91853)
Max28510 = keras.layers.Maximum(name = 'Max28510', )([Con96137,Glo67650])
Con66806 = keras.layers.Concatenate(axis=1, name = 'Con66806', )([Max28510,in0Con66806])
Sub20611 = keras.layers.Subtract(name = 'Sub20611', )([Fla16085,Con66806])
Res91732 = keras.layers.Reshape((120, 1), name = 'Res91732', )(Sub20611)
Ave13355 = keras.layers.AveragePooling1D(pool_size=(63), strides=(2), padding='valid', name = 'Ave13355', )(Res91732)
model = tf.keras.models.Model(inputs=[in0Zer4469,in0PRe66928,in0Con96137,in0Dot91853,in1Dot91853,in0Con66806], outputs=Ave13355)
w = model.get_layer('PRe66928').get_weights() 
w[0] = np.array([[[0.7337]]])
model.get_layer('PRe66928').set_weights(w) 
in0Zer4469 = tf.constant([[[[1.3851, 1.7098, 1.2793, 1.0109], [1.5052, 1.8933, 1.1684, 1.4018], [1.1724, 1.4307, 1.6468, 1.3028], [1.5573, 1.1897, 1.6344, 1.4865]], [[1.3106, 1.2254, 1.6369, 1.9617], [1.4176, 1.0184, 1.5536, 1.5796], [1.7432, 1.5106, 1.9048, 1.4145], [1.5307, 1.8407, 1.4725, 1.6122]], [[1.6217, 1.3701, 1.551, 1.9244], [1.3116, 1.1912, 1.3608, 1.0688], [1.5683, 1.8127, 1.6886, 1.3936], [1.8078, 1.1302, 1.4904, 1.0576]]]])
in0PRe66928 = tf.constant([[[[0.5388]]]])
in0Con96137 = tf.constant([[0.9466, 0.3851]])
in0Dot91853 = tf.constant([[[0.1043, 0.0141, 0.0893], [0.9719, 0.7962, 0.9843]]])
in1Dot91853 = tf.constant([[[0.2349, 0.1186, 0.5367], [0.5268, 0.4665, 0.0004]]])
in0Con66806 = tf.constant([[0.4189, 0.8123, 0.0105, 0.9732, 0.2553, 0.7571, 0.393, 0.8201, 0.4526, 0.273, 0.6105, 0.5971, 0.6294, 0.2733, 0.5017, 0.575, 0.1538, 0.2978, 0.2724, 0.4873, 0.2359, 0.2752, 0.4498, 0.1245, 0.4854, 0.3304, 0.6469, 0.8009, 0.4844, 0.5741, 0.3323, 0.4037, 0.8765, 0.0829, 0.7002, 0.0808, 0.5788, 0.9537, 0.2991, 0.8827, 0.9868, 0.4015, 0.2886, 0.8296, 0.4612, 0.3566, 0.0725, 0.9485, 0.9595, 0.9133, 0.5765, 0.7915, 0.4093, 0.2856, 0.6313, 0.8339, 0.3056, 0.6307, 0.7567, 0.9308, 0.0577, 0.218, 0.1432, 0.7057, 0.8166, 0.9393, 0.7788, 0.3455, 0.8619, 0.0851, 0.479, 0.7753, 0.1484, 0.6436, 0.044, 0.6042, 0.2756, 0.1169, 0.8891, 0.546, 0.9711, 0.9987, 0.2717, 0.2438, 0.1599, 0.6036, 0.6749, 0.559, 0.8298, 0.9019, 0.9962, 0.4174, 0.1946, 0.3738, 0.9378, 0.2526, 0.1114, 0.6699, 0.4001, 0.9303, 0.3102, 0.0405, 0.736, 0.7968, 0.7598, 0.0792, 0.4419, 0.1519, 0.4112, 0.3165, 0.2338, 0.0173, 0.6365, 0.5935, 0.4832, 0.5425, 0.91]])
print (np.array2string(model.predict([in0Zer4469,in0PRe66928,in0Con96137,in0Dot91853,in1Dot91853,in0Con66806],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave13355.png')

LZer4469 = zero_padding2D_layer([[[[1.3851, 1.7098, 1.2793, 1.0109], [1.5052, 1.8933, 1.1684, 1.4018], [1.1724, 1.4307, 1.6468, 1.3028], [1.5573, 1.1897, 1.6344, 1.4865]], [[1.3106, 1.2254, 1.6369, 1.9617], [1.4176, 1.0184, 1.5536, 1.5796], [1.7432, 1.5106, 1.9048, 1.4145], [1.5307, 1.8407, 1.4725, 1.6122]], [[1.6217, 1.3701, 1.551, 1.9244], [1.3116, 1.1912, 1.3608, 1.0688], [1.5683, 1.8127, 1.6886, 1.3936], [1.8078, 1.1302, 1.4904, 1.0576]]]], 1, 1, 1, 1, Zer4469), 
LRes71526 = reshape_layer(Zer4469, [5, 24], Res71526), 
LFla16085 = flatten_layer(Res71526, Fla16085), 
LPRe66928 = prelu_layer([[[[0.5388]]]], [[[0.7337]]], PRe66928), 
LRes7237 = reshape_layer(PRe66928, [1, 1], Res7237), 
LFla92118 = flatten_layer(Res7237, Fla92118), 
LCon96137 = concatenate_layer([Fla92118,[[0.9466, 0.3851]]], 1, Con96137), 
LDot91853 = dot_layer([[[0.1043, 0.0141, 0.0893], [0.9719, 0.7962, 0.9843]]], [[[0.2349, 0.1186, 0.5367], [0.5268, 0.4665, 0.0004]]], 1, 1, Dot91853), 
LGlo67650 = global_average_pooling1D_layer(Dot91853, Glo67650), 
LMax28510 = maximum_layer([Con96137,Glo67650], Max28510), 
LCon66806 = concatenate_layer([Max28510,[[0.4189, 0.8123, 0.0105, 0.9732, 0.2553, 0.7571, 0.393, 0.8201, 0.4526, 0.273, 0.6105, 0.5971, 0.6294, 0.2733, 0.5017, 0.575, 0.1538, 0.2978, 0.2724, 0.4873, 0.2359, 0.2752, 0.4498, 0.1245, 0.4854, 0.3304, 0.6469, 0.8009, 0.4844, 0.5741, 0.3323, 0.4037, 0.8765, 0.0829, 0.7002, 0.0808, 0.5788, 0.9537, 0.2991, 0.8827, 0.9868, 0.4015, 0.2886, 0.8296, 0.4612, 0.3566, 0.0725, 0.9485, 0.9595, 0.9133, 0.5765, 0.7915, 0.4093, 0.2856, 0.6313, 0.8339, 0.3056, 0.6307, 0.7567, 0.9308, 0.0577, 0.218, 0.1432, 0.7057, 0.8166, 0.9393, 0.7788, 0.3455, 0.8619, 0.0851, 0.479, 0.7753, 0.1484, 0.6436, 0.044, 0.6042, 0.2756, 0.1169, 0.8891, 0.546, 0.9711, 0.9987, 0.2717, 0.2438, 0.1599, 0.6036, 0.6749, 0.559, 0.8298, 0.9019, 0.9962, 0.4174, 0.1946, 0.3738, 0.9378, 0.2526, 0.1114, 0.6699, 0.4001, 0.9303, 0.3102, 0.0405, 0.736, 0.7968, 0.7598, 0.0792, 0.4419, 0.1519, 0.4112, 0.3165, 0.2338, 0.0173, 0.6365, 0.5935, 0.4832, 0.5425, 0.91]]], 1, Con66806), 
LSub20611 = subtract_layer(Fla16085,Con66806, Sub20611), 
LRes91732 = reshape_layer(Sub20611, [120, 1], Res91732), 
LAve13355 = average_pooling1D_layer(Res91732, 63, 2, false, Ave13355), 
exec_layers([LZer4469,LRes71526,LFla16085,LPRe66928,LRes7237,LFla92118,LCon96137,LDot91853,LGlo67650,LMax28510,LCon66806,LSub20611,LRes91732,LAve13355],["Zer4469","Res71526","Fla16085","PRe66928","Res7237","Fla92118","Con96137","Dot91853","Glo67650","Max28510","Con66806","Sub20611","Res91732","Ave13355"],Ave13355,"Ave13355")

Actual (Unparsed): [[[0.0989492], [0.1649000], [0.2167778], [0.2275571], [0.2292111], [0.2324349], [0.2327270], [0.2599206], [0.3154667], [0.3729032], [0.4022000], [0.4218429], [0.4807159], [0.5309206], [0.5626127], [0.5183000], [0.4799111], [0.4313317], [0.3919603], [0.3506698], [0.2932032], [0.2639190], [0.2197254], [0.2173619], [0.2284254], [0.2236857], [0.2499857], [0.2138556], [0.1595143]]]

Expected (Unparsed): [[[0.09894920634920641],[0.16490000000000007],[0.21677777777777782],[0.22755714285714285],[0.2292111111111111],[0.23243492063492063],[0.2327269841269841],[0.25992063492063505],[0.31546666666666673],[0.37290317460317474],[0.4022000000000001],[0.42184285714285724],[0.48071587301587315],[0.530920634920635],[0.5626126984126986],[0.5183000000000002],[0.47991111111111123],[0.4313317460317461],[0.39196031746031745],[0.3506698412698413],[0.2932031746031747],[0.2639190476190476],[0.21972539682539682],[0.2173619047619048],[0.22842539682539684],[0.22368571428571435],[0.2499857142857143],[0.21385555555555558],[0.15951428571428578]]]

Actual:   [[[0.099], [0.1649], [0.2168], [0.2276], [0.2293], [0.2325], [0.2328], [0.26], [0.3155], [0.373], [0.4022], [0.4219], [0.4808], [0.531], [0.5627], [0.5183], [0.48], [0.4314], [0.392], [0.3507], [0.2933], [0.264], [0.2198], [0.2174], [0.2285], [0.2237], [0.25], [0.2139], [0.1596]]]

Expected: [[[0.099], [0.165], [0.2168], [0.2276], [0.2293], [0.2325], [0.2328], [0.26], [0.3155], [0.373], [0.4023], [0.4219], [0.4808], [0.531], [0.5627], [0.5184], [0.48], [0.4314], [0.392], [0.3507], [0.2933], [0.264], [0.2198], [0.2174], [0.2285], [0.2237], [0.25], [0.2139], [0.1596]]]