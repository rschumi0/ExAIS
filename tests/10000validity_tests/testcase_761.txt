import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min88890 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Min88890 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Glo90787 = tf.keras.layers.Input(shape=([1, 2, 2]))
in0Con16143 = tf.keras.layers.Input(shape=([6]))
in0Glo93282 = tf.keras.layers.Input(shape=([2, 1, 1, 1]))
in0Con69510 = tf.keras.layers.Input(shape=([63]))

Min88890 = keras.layers.Minimum(name = 'Min88890', )([in0Min88890,in1Min88890])
Res38750 = keras.layers.Reshape((2, 4), name = 'Res38750', )(Min88890)
Fla97827 = keras.layers.Flatten(name = 'Fla97827', )(Res38750)
Glo90787 = keras.layers.GlobalAveragePooling2D(name = 'Glo90787', )(in0Glo90787)
Con16143 = keras.layers.Concatenate(axis=1, name = 'Con16143', )([Glo90787,in0Con16143])
Min43269 = keras.layers.Minimum(name = 'Min43269', )([Fla97827,Con16143])
Res29830 = keras.layers.Reshape((8, 1), name = 'Res29830', )(Min43269)
Res90104 = keras.layers.Reshape((8, 1, 1), name = 'Res90104', )(Res29830)
Res46956 = keras.layers.Reshape((8, 1, 1, 1), name = 'Res46956', )(Res90104)
Up_51677 = keras.layers.UpSampling3D(size=(2, 2, 2), name = 'Up_51677', )(Res46956)
Res70665 = keras.layers.Reshape((16, 2, 2), name = 'Res70665', )(Up_51677)
Res87933 = keras.layers.Reshape((16, 4), name = 'Res87933', )(Res70665)
Fla297 = keras.layers.Flatten(name = 'Fla297', )(Res87933)
Glo93282 = keras.layers.GlobalAveragePooling3D(name = 'Glo93282', )(in0Glo93282)
Con69510 = keras.layers.Concatenate(axis=1, name = 'Con69510', )([Glo93282,in0Con69510])
Min58692 = keras.layers.Minimum(name = 'Min58692', )([Fla297,Con69510])
model = tf.keras.models.Model(inputs=[in0Min88890,in1Min88890,in0Glo90787,in0Con16143,in0Glo93282,in0Con69510], outputs=Min58692)
in0Min88890 = tf.constant([[[[0.5558, 0.8394], [0.534, 0.877]], [[0.0793, 0.6096], [0.1566, 0.7041]]]])
in1Min88890 = tf.constant([[[[0.0586, 0.5696], [0.2887, 0.5994]], [[0.8171, 0.5009], [0.3674, 0.1028]]]])
in0Glo90787 = tf.constant([[[[1.8146, 1.754], [1.9117, 1.7131]]]])
in0Con16143 = tf.constant([[0.3648, 0.2319, 0.6906, 0.9301, 0.3301, 0.3453]])
in0Glo93282 = tf.constant([[[[[1.5587]]], [[[1.3651]]]]])
in0Con69510 = tf.constant([[0.6158, 0.7129, 0.0324, 0.3487, 0.4731, 0.4131, 0.8145, 0.8026, 0.8086, 0.8539, 0.3737, 0.0429, 0.2214, 0.6773, 0.3297, 0.8961, 0.2367, 0.1098, 0.9288, 0.0308, 0.3846, 0.2281, 0.9655, 0.6442, 0.6309, 0.2204, 0.9094, 0.0386, 0.1392, 0.6005, 0.3819, 0.7791, 0.7197, 0.9027, 0.2088, 0.519, 0.346, 0.8536, 0.5014, 0.3821, 0.8068, 0.4042, 0.6106, 0.9977, 0.8989, 0.2832, 0.3382, 0.8997, 0.5674, 0.9341, 0.4937, 0.0211, 0.0501, 0.7878, 0.7391, 0.442, 0.393, 0.8363, 0.6769, 0.3818, 0.6711, 0.3767, 0.3066]])
print (np.array2string(model.predict([in0Min88890,in1Min88890,in0Glo90787,in0Con16143,in0Glo93282,in0Con69510],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min58692.png')

LMin88890 = minimum_layer([[[[[0.5558, 0.8394], [0.534, 0.877]], [[0.0793, 0.6096], [0.1566, 0.7041]]]], [[[[0.0586, 0.5696], [0.2887, 0.5994]], [[0.8171, 0.5009], [0.3674, 0.1028]]]]], Min88890), 
LRes38750 = reshape_layer(Min88890, [2, 4], Res38750), 
LFla97827 = flatten_layer(Res38750, Fla97827), 
LGlo90787 = global_average_pooling2D_layer([[[[1.8146, 1.754], [1.9117, 1.7131]]]], Glo90787), 
LCon16143 = concatenate_layer([Glo90787,[[0.3648, 0.2319, 0.6906, 0.9301, 0.3301, 0.3453]]], 1, Con16143), 
LMin43269 = minimum_layer([Fla97827,Con16143], Min43269), 
LRes29830 = reshape_layer(Min43269, [8, 1], Res29830), 
LRes90104 = reshape_layer(Res29830, [8, 1, 1], Res90104), 
LRes46956 = reshape_layer(Res90104, [8, 1, 1, 1], Res46956), 
LUp_51677 = up_sampling3D_layer(Res46956, 2, 2, 2, Up_51677), 
LRes70665 = reshape_layer(Up_51677, [16, 2, 2], Res70665), 
LRes87933 = reshape_layer(Res70665, [16, 4], Res87933), 
LFla297 = flatten_layer(Res87933, Fla297), 
LGlo93282 = global_average_pooling3D_layer([[[[[1.5587]]], [[[1.3651]]]]], Glo93282), 
LCon69510 = concatenate_layer([Glo93282,[[0.6158, 0.7129, 0.0324, 0.3487, 0.4731, 0.4131, 0.8145, 0.8026, 0.8086, 0.8539, 0.3737, 0.0429, 0.2214, 0.6773, 0.3297, 0.8961, 0.2367, 0.1098, 0.9288, 0.0308, 0.3846, 0.2281, 0.9655, 0.6442, 0.6309, 0.2204, 0.9094, 0.0386, 0.1392, 0.6005, 0.3819, 0.7791, 0.7197, 0.9027, 0.2088, 0.519, 0.346, 0.8536, 0.5014, 0.3821, 0.8068, 0.4042, 0.6106, 0.9977, 0.8989, 0.2832, 0.3382, 0.8997, 0.5674, 0.9341, 0.4937, 0.0211, 0.0501, 0.7878, 0.7391, 0.442, 0.393, 0.8363, 0.6769, 0.3818, 0.6711, 0.3767, 0.3066]]], 1, Con69510), 
LMin58692 = minimum_layer([Fla297,Con69510], Min58692), 
exec_layers([LMin88890,LRes38750,LFla97827,LGlo90787,LCon16143,LMin43269,LRes29830,LRes90104,LRes46956,LUp_51677,LRes70665,LRes87933,LFla297,LGlo93282,LCon69510,LMin58692],["Min88890","Res38750","Fla97827","Glo90787","Con16143","Min43269","Res29830","Res90104","Res46956","Up_51677","Res70665","Res87933","Fla297","Glo93282","Con69510","Min58692"],Min58692,"Min58692")

Actual (Unparsed): [[0.0586000, 0.0586000, 0.0586000, 0.0324000, 0.0586000, 0.0586000, 0.0586000, 0.0586000, 0.5696000, 0.5696000, 0.5696000, 0.3737000, 0.0429000, 0.2214000, 0.5696000, 0.3297000, 0.2887000, 0.2367000, 0.1098000, 0.2887000, 0.0308000, 0.2887000, 0.2281000, 0.2887000, 0.2319000, 0.2319000, 0.2204000, 0.2319000, 0.0386000, 0.1392000, 0.2319000, 0.2319000, 0.0793000, 0.0793000, 0.0793000, 0.0793000, 0.0793000, 0.0793000, 0.0793000, 0.0793000, 0.3821000, 0.5009000, 0.4042000, 0.5009000, 0.5009000, 0.5009000, 0.2832000, 0.3382000, 0.1566000, 0.1566000, 0.1566000, 0.1566000, 0.0211000, 0.0501000, 0.1566000, 0.1566000, 0.1028000, 0.1028000, 0.1028000, 0.1028000, 0.1028000, 0.1028000, 0.1028000, 0.1028000]]

Expected (Unparsed): [[0.0586,0.0586,0.0586,0.0324,0.0586,0.0586,0.0586,0.0586,0.5696,0.5696,0.5696,0.3737,0.0429,0.2214,0.5696,0.3297,0.2887,0.2367,0.1098,0.2887,0.0308,0.2887,0.2281,0.2887,0.2319,0.2319,0.2204,0.2319,0.0386,0.1392,0.2319,0.2319,0.0793,0.0793,0.0793,0.0793,0.0793,0.0793,0.0793,0.0793,0.3821,0.5009,0.4042,0.5009,0.5009,0.5009,0.2832,0.3382,0.1566,0.1566,0.1566,0.1566,0.0211,0.0501,0.1566,0.1566,0.1028,0.1028,0.1028,0.1028,0.1028,0.1028,0.1028,0.1028]]

Actual:   [[0.0586, 0.0586, 0.0586, 0.0324, 0.0586, 0.0586, 0.0586, 0.0586, 0.5696, 0.5696, 0.5696, 0.3737, 0.0429, 0.2214, 0.5696, 0.3297, 0.2887, 0.2367, 0.1098, 0.2887, 0.0308, 0.2887, 0.2281, 0.2887, 0.2319, 0.2319, 0.2204, 0.2319, 0.0386, 0.1392, 0.2319, 0.2319, 0.0793, 0.0793, 0.0793, 0.0793, 0.0793, 0.0793, 0.0793, 0.0793, 0.3821, 0.5009, 0.4042, 0.5009, 0.5009, 0.5009, 0.2832, 0.3382, 0.1566, 0.1566, 0.1566, 0.1566, 0.0211, 0.0501, 0.1566, 0.1566, 0.1028, 0.1028, 0.1028, 0.1028, 0.1028, 0.1028, 0.1028, 0.1028]]

Expected: [[0.0586, 0.0586, 0.0586, 0.0324, 0.0586, 0.0586, 0.0586, 0.0586, 0.5696, 0.5696, 0.5696, 0.3737, 0.0429, 0.2214, 0.5696, 0.3297, 0.2887, 0.2367, 0.1098, 0.2887, 0.0308, 0.2887, 0.2281, 0.2887, 0.2319, 0.2319, 0.2204, 0.2319, 0.0386, 0.1392, 0.2319, 0.2319, 0.0793, 0.0793, 0.0793, 0.0793, 0.0793, 0.0793, 0.0793, 0.0793, 0.3821, 0.5009, 0.4042, 0.5009, 0.5009, 0.5009, 0.2832, 0.3382, 0.1566, 0.1566, 0.1566, 0.1566, 0.0211, 0.0501, 0.1566, 0.1566, 0.1028, 0.1028, 0.1028, 0.1028, 0.1028, 0.1028, 0.1028, 0.1028]]