import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Thr67270 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0Dot30878 = tf.keras.layers.Input(shape=([3, 2]))
in1Dot30878 = tf.keras.layers.Input(shape=([3, 2]))
in0Con65177 = tf.keras.layers.Input(shape=([2, 1, 3]))
in0Max62981 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Max62981 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con16348 = tf.keras.layers.Input(shape=([2, 2, 2]))

Thr67270 = keras.layers.ThresholdedReLU(theta=7.162721844887074, name = 'Thr67270', input_shape=(1, 2, 1, 1))(in0Thr67270)
Res76763 = keras.layers.Reshape((1, 2, 1), name = 'Res76763', )(Thr67270)
Ave20692 = keras.layers.AveragePooling2D(pool_size=(1, 2), strides=(1, 1), padding='valid', name = 'Ave20692', )(Res76763)
Loc74279 = keras.layers.LocallyConnected2D(4, (1, 1),strides=(1, 1), name = 'Loc74279', )(Ave20692)
Zer78636 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer78636', )(Loc74279)
Dot30878 = keras.layers.Dot(axes=(1, 1), name = 'Dot30878', )([in0Dot30878,in1Dot30878])
GRU94555 = keras.layers.GRU(1,reset_after=True, recurrent_activation='sigmoid', name = 'GRU94555', )(Dot30878)
Res10459 = keras.layers.Reshape((1, 1), name = 'Res10459', )(GRU94555)
Res41711 = keras.layers.Reshape((1, 1, 1), name = 'Res41711', )(Res10459)
Up_52403 = keras.layers.UpSampling2D(size=(2, 1), name = 'Up_52403', )(Res41711)
Con65177 = keras.layers.Concatenate(axis=3, name = 'Con65177', )([Up_52403,in0Con65177])
Sub65848 = keras.layers.Subtract(name = 'Sub65848', )([Zer78636,Con65177])
Zer77103 = keras.layers.ZeroPadding2D(padding=((0, 0), (1, 0)), name = 'Zer77103', )(Sub65848)
Max62981 = keras.layers.Maximum(name = 'Max62981', )([in0Max62981,in1Max62981])
Bat64673 = keras.layers.BatchNormalization(axis=3, epsilon=0.28724182262103054,  name = 'Bat64673', )(Max62981)
Con16348 = keras.layers.Concatenate(axis=3, name = 'Con16348', )([Bat64673,in0Con16348])
Add90991 = keras.layers.Add(name = 'Add90991', )([Zer77103,Con16348])
model = tf.keras.models.Model(inputs=[in0Thr67270,in0Dot30878,in1Dot30878,in0Con65177,in0Max62981,in1Max62981,in0Con16348], outputs=Add90991)
w = model.get_layer('Loc74279').get_weights() 
w[0] = np.array([[[0.3887, 0.5096, 0.3843, 0.2585]]])
w[1] = np.array([[[0, 0, 0, 0]]])
model.get_layer('Loc74279').set_weights(w) 
w = model.get_layer('GRU94555').get_weights() 
w[0] = np.array([[9, 2, 6], [9, 5, 2]])
w[1] = np.array([[6, 1, 10]])
w[2] = np.array([[9, 6, 2], [9, 7, 5]])
model.get_layer('GRU94555').set_weights(w) 
w = model.get_layer('Bat64673').get_weights() 
w[0] = np.array([0.5514, 0.3578])
w[1] = np.array([0.5729, 0.242])
w[2] = np.array([0.9917, 0.8492])
w[3] = np.array([0.8843, 0.2172])
model.get_layer('Bat64673').set_weights(w) 
in0Thr67270 = tf.constant([[[[[0.8542]], [[0.1597]]]]])
in0Dot30878 = tf.constant([[[0.309, 0.7311], [0.5444, 0.7748], [0.0129, 0.573]]])
in1Dot30878 = tf.constant([[[0.7453, 0.0043], [0.5182, 0.3918], [0.0721, 0.3413]]])
in0Con65177 = tf.constant([[[[0.9064, 0.6934, 0.0104]], [[0.5399, 0.5495, 0.86]]]])
in0Max62981 = tf.constant([[[[0.357, 0.5607], [0.5695, 0.2542]], [[0.0645, 0.5278], [0.9435, 0.99]]]])
in1Max62981 = tf.constant([[[[0.7473, 0.3031], [0.6174, 0.2786]], [[0.0743, 0.4108], [0.1211, 0.7365]]]])
in0Con16348 = tf.constant([[[[0.5536, 0.07], [0.2887, 0.722]], [[0.9578, 0.2486], [0.2738, 0.3897]]]])
print (np.array2string(model.predict([in0Thr67270,in0Dot30878,in1Dot30878,in0Con65177,in0Max62981,in1Max62981,in0Con16348],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add90991.png')

LThr67270 = thresholded_relu_layer([[[[[0.8542]], [[0.1597]]]]], 7.162721844887074, Thr67270), 
LRes76763 = reshape_layer(Thr67270, [1, 2, 1], Res76763), 
LAve20692 = average_pooling2D_layer(Res76763, 1, 2, 1, 1, false, Ave20692), 
LLoc74279 = locally_connected2D_layer(Ave20692, 1, 1,[[[0.3887, 0.5096, 0.3843, 0.2585]]],[[[0, 0, 0, 0]]], 1, 1, Loc74279), 
LZer78636 = zero_padding2D_layer(Loc74279, 1, 0, 0, 0, Zer78636), 
LDot30878 = dot_layer([[[0.309, 0.7311], [0.5444, 0.7748], [0.0129, 0.573]]], [[[0.7453, 0.0043], [0.5182, 0.3918], [0.0721, 0.3413]]], 1, 1, Dot30878), 
LGRU94555 = gru_layer(Dot30878,[[9, 2, 6], [9, 5, 2]],[[6, 1, 10]],[[9, 6, 2], [9, 7, 5]], true, GRU94555), 
LRes10459 = reshape_layer(GRU94555, [1, 1], Res10459), 
LRes41711 = reshape_layer(Res10459, [1, 1, 1], Res41711), 
LUp_52403 = up_sampling2D_layer(Res41711, 2, 1, Up_52403), 
LCon65177 = concatenate_layer([Up_52403,[[[[0.9064, 0.6934, 0.0104]], [[0.5399, 0.5495, 0.86]]]]], 3, Con65177), 
LSub65848 = subtract_layer(Zer78636,Con65177, Sub65848), 
LZer77103 = zero_padding2D_layer(Sub65848, 0, 0, 1, 0, Zer77103), 
LMax62981 = maximum_layer([[[[[0.357, 0.5607], [0.5695, 0.2542]], [[0.0645, 0.5278], [0.9435, 0.99]]]], [[[[0.7473, 0.3031], [0.6174, 0.2786]], [[0.0743, 0.4108], [0.1211, 0.7365]]]]], Max62981), 
LBat64673 = batch_normalization_layer(Max62981, 3, 0.28724182262103054, [0.5514, 0.3578], [0.5729, 0.242], [0.9917, 0.8492], [0.8843, 0.2172], Bat64673), 
LCon16348 = concatenate_layer([Bat64673,[[[[0.5536, 0.07], [0.2887, 0.722]], [[0.9578, 0.2486], [0.2738, 0.3897]]]]], 3, Con16348), 
LAdd90991 = add_layer([Zer77103,Con16348], Add90991), 
exec_layers([LThr67270,LRes76763,LAve20692,LLoc74279,LZer78636,LDot30878,LGRU94555,LRes10459,LRes41711,LUp_52403,LCon65177,LSub65848,LZer77103,LMax62981,LBat64673,LCon16348,LAdd90991],["Thr67270","Res76763","Ave20692","Loc74279","Zer78636","Dot30878","GRU94555","Res10459","Res41711","Up_52403","Con65177","Sub65848","Zer77103","Max62981","Bat64673","Con16348","Add90991"],Add90991,"Add90991")

Actual (Unparsed): [[[[0.4483944, 0.0966615, 0.5536000, 0.0700000], [0.3822189, -0.9518528, -0.4047000, 0.7116000]], [[0.1055453, 0.0800874, 0.9578000, 0.2486000], [0.5483453, -0.2269688, -0.2757000, -0.4703000]]]]

Expected (Unparsed): [[[[0.44839434859192984,0.09666152108791992,0.5536,0.07],[0.382218881640122,-0.9518528113248974,-0.4047,0.7116]],[[0.10554531668672879,0.08008739299014722,0.9578,0.2486],[0.5483452847668473,-0.22696877701621881,-0.2757,-0.4703]]]]

Actual:   [[[[0.4484, 0.0967, 0.5536, 0.07], [0.3823, -0.9518, -0.4047, 0.7116]], [[0.1056, 0.0801, 0.9578, 0.2486], [0.5484, -0.2269, -0.2757, -0.4703]]]]

Expected: [[[[0.4484, 0.0967, 0.5536, 0.07], [0.3823, -0.9518, -0.4047, 0.7116]], [[0.1056, 0.0801, 0.9578, 0.2486], [0.5484, -0.2269, -0.2757, -0.4703]]]]