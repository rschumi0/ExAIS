import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot21506 = tf.keras.layers.Input(shape=([2, 2]))
in1Dot21506 = tf.keras.layers.Input(shape=([2, 2]))
in0Con80783 = tf.keras.layers.Input(shape=([6, 10]))
in0Con67008 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))

Dot21506 = keras.layers.Dot(axes=(2, 2), name = 'Dot21506', )([in0Dot21506,in1Dot21506])
Zer3176 = keras.layers.ZeroPadding1D(padding=((4, 0)), name = 'Zer3176', )(Dot21506)
Con80783 = keras.layers.Concatenate(axis=2, name = 'Con80783', )([Zer3176,in0Con80783])
Con67008 = keras.layers.Conv3DTranspose(3, (2, 1, 1),strides=(1, 1, 1), padding='valid', name = 'Con67008', )(in0Con67008)
Res95593 = keras.layers.Reshape((3, 2, 6), name = 'Res95593', )(Con67008)
Res99922 = keras.layers.Reshape((3, 12), name = 'Res99922', )(Res95593)
Up_38524 = keras.layers.UpSampling1D(size=(2), name = 'Up_38524', )(Res99922)
Sub16054 = keras.layers.Subtract(name = 'Sub16054', )([Con80783,Up_38524])
model = tf.keras.models.Model(inputs=[in0Dot21506,in1Dot21506,in0Con80783,in0Con67008], outputs=Sub16054)
w = model.get_layer('Con67008').get_weights() 
w[0] = np.array([[[[[0.2312, 0.6151], [0.0522, 0.7742], [0.6382, 0.4672]]]], [[[[0.2351, 0.8234], [0.6659, 0.168], [0.3373, 0.6141]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con67008').set_weights(w) 
in0Dot21506 = tf.constant([[[0.2809, 0.1276], [0.171, 0.5111]]])
in1Dot21506 = tf.constant([[[0.3919, 0.3851], [0.3851, 0.3059]]])
in0Con80783 = tf.constant([[[0.3107, 0.7397, 0.2772, 0.331, 0.0871, 0.2728, 0.2297, 0.3638, 0.7322, 0.9978], [0.1383, 0.0555, 0.5385, 0.2195, 0.7496, 0.5724, 0.4722, 0.2953, 0.9935, 0.5164], [0.2418, 0.1671, 0.8778, 0.621, 0.6404, 0.9852, 0.5269, 0.0198, 0.1269, 0.6124], [0.747, 0.6548, 0.9461, 0.6709, 0.9697, 0.0302, 0.9568, 0.453, 0.9414, 0.4417], [0.7359, 0.4545, 0.0627, 0.0155, 0.4586, 0.5101, 0.8534, 0.3751, 0.5147, 0.5089], [0.6219, 0.523, 0.8153, 0.4549, 0.0526, 0.5692, 0.2691, 0.1949, 0.0861, 0.2712]]])
in0Con67008 = tf.constant([[[[[0.719, 0.1772], [0.1854, 0.1108]], [[0.9066, 0.8513], [0.6935, 0.0555]]], [[[0.3899, 0.4021], [0.594, 0.6258]], [[0.255, 0.6719], [0.8106, 0.2458]]]]])
print (np.array2string(model.predict([in0Dot21506,in1Dot21506,in0Con80783,in0Con67008],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub16054.png')

LDot21506 = dot_layer([[[0.2809, 0.1276], [0.171, 0.5111]]], [[[0.3919, 0.3851], [0.3851, 0.3059]]], 2, 2, Dot21506), 
LZer3176 = zero_padding1D_layer(Dot21506, 4, 0, Zer3176), 
LCon80783 = concatenate_layer([Zer3176,[[[0.3107, 0.7397, 0.2772, 0.331, 0.0871, 0.2728, 0.2297, 0.3638, 0.7322, 0.9978], [0.1383, 0.0555, 0.5385, 0.2195, 0.7496, 0.5724, 0.4722, 0.2953, 0.9935, 0.5164], [0.2418, 0.1671, 0.8778, 0.621, 0.6404, 0.9852, 0.5269, 0.0198, 0.1269, 0.6124], [0.747, 0.6548, 0.9461, 0.6709, 0.9697, 0.0302, 0.9568, 0.453, 0.9414, 0.4417], [0.7359, 0.4545, 0.0627, 0.0155, 0.4586, 0.5101, 0.8534, 0.3751, 0.5147, 0.5089], [0.6219, 0.523, 0.8153, 0.4549, 0.0526, 0.5692, 0.2691, 0.1949, 0.0861, 0.2712]]]], 2, Con80783), 
LCon67008 = conv3D_transpose_layer([[[[[0.719, 0.1772], [0.1854, 0.1108]], [[0.9066, 0.8513], [0.6935, 0.0555]]], [[[0.3899, 0.4021], [0.594, 0.6258]], [[0.255, 0.6719], [0.8106, 0.2458]]]]], 2, 1, 1,[[[[[0.2312, 0.6151], [0.0522, 0.7742], [0.6382, 0.4672]]]], [[[[0.2351, 0.8234], [0.6659, 0.168], [0.3373, 0.6141]]]]],[0, 0, 0], 1, 1, 1, false, Con67008), 
LRes95593 = reshape_layer(Con67008, [3, 2, 6], Res95593), 
LRes99922 = reshape_layer(Res95593, [3, 12], Res99922), 
LUp_38524 = up_sampling1D_layer(Res99922, 2, Up_38524), 
LSub16054 = subtract_layer(Con80783,Up_38524, Sub16054), 
exec_layers([LDot21506,LZer3176,LCon80783,LCon67008,LRes95593,LRes99922,LUp_38524,LSub16054],["Dot21506","Zer3176","Con80783","Con67008","Res95593","Res99922","Up_38524","Sub16054"],Sub16054,"Sub16054")

Actual (Unparsed): [[[-0.2752285, -0.1747200, -0.2309536, 0.6286825, 0.1817408, 0.1609120, -0.6461406, -0.4336010, -0.7466195, 0.1693247, 0.6530312, 0.5292787], [-0.2752285, -0.1747200, -0.4033536, -0.0555176, 0.4430408, 0.0494120, 0.0163594, -0.1340010, -0.5041195, 0.1008248, 0.9143312, 0.0478787], [-0.6524200, -0.8402103, -0.5462325, -0.4899826, 0.2202266, -0.1810423, -0.7459438, -0.2950193, -0.7783322, -0.5275428, -0.5768373, -0.2877628], [-0.6524200, -0.8402103, -0.0410325, -0.0022826, 0.2885266, -0.1311423, -0.4166438, -1.2500193, -0.3484322, -0.0943428, 0.2376627, -0.4584628], [-0.2635312, -0.1799798, 0.3574571, -0.2004331, -0.4379790, -0.5691600, -0.1545929, 0.2274163, 0.3547747, -0.0178638, -0.0663729, 0.0845388], [-0.1589151, -0.1049896, 0.2434571, -0.1319331, 0.3146210, -0.1297600, -0.5605929, 0.2865163, -0.2295253, -0.1980638, -0.4949729, -0.1531612]]]

Expected (Unparsed): [[[-0.27522852,-0.17472004,-0.23095364000000007,0.6286824400000001,0.18174076,0.16091196000000002,-0.64614055,-0.43360097999999997,-0.7466194799999999,0.16932475000000002,0.6530311999999999,0.5292787000000001],[-0.27522852,-0.17472004,-0.40335364000000007,-0.05551755999999999,0.44304076,0.049411960000000005,0.016359450000000053,-0.13400097999999994,-0.50411948,0.10082475000000002,0.9143312,0.047878699999999996],[-0.65241997,-0.8402102999999999,-0.54623252,-0.4899826399999999,0.22022657999999995,-0.18104226,-0.7459437699999999,-0.2950193200000001,-0.7783321899999999,-0.5275428499999999,-0.57683733,-0.2877627799999999],[-0.65241997,-0.8402102999999999,-0.04103252000000002,-0.0022826399999998914,0.28852658,-0.13114225999999995,-0.41664376999999986,-1.25001932,-0.3484321899999999,-0.09434284999999992,0.23766266999999996,-0.45846277999999996],[-0.26353116,-0.1799797800000001,0.35745711999999996,-0.20043312000000002,-0.4379790000000001,-0.56915998,-0.1545929600000001,0.22741629999999996,0.35477471,-0.017863779999999996,-0.06637293999999994,0.08453884],[-0.15891511999999997,-0.10498962000000006,0.24345711999999997,-0.13193312000000001,0.31462099999999993,-0.12975997999999994,-0.5605929600000001,0.2865163,-0.22952529000000005,-0.19806378,-0.49497294,-0.15316116000000002]]]

Actual:   [[[-0.2752, -0.1747, -0.2309, 0.6287, 0.1818, 0.161, -0.6461, -0.4336, -0.7466, 0.1694, 0.6531, 0.5293], [-0.2752, -0.1747, -0.4033, -0.0555, 0.4431, 0.0495, 0.0164, -0.134, -0.5041, 0.1009, 0.9144, 0.0479], [-0.6524, -0.8402, -0.5462, -0.4899, 0.2203, -0.181, -0.7459, -0.295, -0.7783, -0.5275, -0.5768, -0.2877], [-0.6524, -0.8402, -0.041, -0.0022, 0.2886, -0.1311, -0.4166, -1.25, -0.3484, -0.0943, 0.2377, -0.4584], [-0.2635, -0.1799, 0.3575, -0.2004, -0.4379, -0.5691, -0.1545, 0.2275, 0.3548, -0.0178, -0.0663, 0.0846], [-0.1589, -0.1049, 0.2435, -0.1319, 0.3147, -0.1297, -0.5605, 0.2866, -0.2295, -0.198, -0.4949, -0.1531]]]

Expected: [[[-0.2752, -0.1747, -0.2309, 0.6287, 0.1818, 0.161, -0.6461, -0.4336, -0.7466, 0.1694, 0.6531, 0.5293], [-0.2752, -0.1747, -0.4033, -0.0555, 0.4431, 0.0495, 0.0164, -0.134, -0.5041, 0.1009, 0.9144, 0.0479], [-0.6524, -0.8402, -0.5462, -0.4899, 0.2203, -0.181, -0.7459, -0.295, -0.7783, -0.5275, -0.5768, -0.2877], [-0.6524, -0.8402, -0.041, -0.0022, 0.2886, -0.1311, -0.4166, -1.25, -0.3484, -0.0943, 0.2377, -0.4584], [-0.2635, -0.1799, 0.3575, -0.2004, -0.4379, -0.5691, -0.1545, 0.2275, 0.3548, -0.0178, -0.0663, 0.0846], [-0.1589, -0.1049, 0.2435, -0.1319, 0.3147, -0.1297, -0.5605, 0.2866, -0.2295, -0.198, -0.4949, -0.1531]]]