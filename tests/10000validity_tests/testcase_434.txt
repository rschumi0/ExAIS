import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer79896 = tf.keras.layers.Input(shape=([4, 3]))

Zer79896 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer79896', )(in0Zer79896)
Sim68005 = keras.layers.SimpleRNN(1,name = 'Sim68005', )(Zer79896)
Res6702 = keras.layers.Reshape((1, 1), name = 'Res6702', )(Sim68005)
Glo95101 = keras.layers.GlobalMaxPool1D(name = 'Glo95101', )(Res6702)
model = tf.keras.models.Model(inputs=[in0Zer79896], outputs=Glo95101)
w = model.get_layer('Sim68005').get_weights() 
w[0] = np.array([[3], [6], [4]])
w[1] = np.array([[7]])
w[2] = np.array([2])
model.get_layer('Sim68005').set_weights(w) 
in0Zer79896 = tf.constant([[[1.3191, 1.9993, 1.4595], [1.9475, 1.5196, 1.0023], [1.7865, 1.6849, 1.2149], [1.8808, 1.5, 1.3592]]])
print (np.array2string(model.predict([in0Zer79896],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Glo95101.png')

LZer79896 = zero_padding1D_layer([[[1.3191, 1.9993, 1.4595], [1.9475, 1.5196, 1.0023], [1.7865, 1.6849, 1.2149], [1.8808, 1.5, 1.3592]]], 1, 1, Zer79896), 
LSim68005 = simple_rnn_layer(Zer79896,[[3], [6], [4]],[[7]],[2], Sim68005), 
LRes6702 = reshape_layer(Sim68005, [1, 1], Res6702), 
LGlo95101 = global_max_pool1D_layer(Res6702, Glo95101), 
exec_layers([LZer79896,LSim68005,LRes6702,LGlo95101],["Zer79896","Sim68005","Res6702","Glo95101"],Glo95101,"Glo95101")

Actual (Unparsed): [[1.0000000]]

Expected (Unparsed): [[0.999999969540041]]

Actual:   [[1]]

Expected: [[1]]