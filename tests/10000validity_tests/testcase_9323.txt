import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add92635 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Add92635 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Lea75876 = tf.keras.layers.Input(shape=([1, 2, 1]))

Add92635 = keras.layers.Add(name = 'Add92635', )([in0Add92635,in1Add92635])
Res9310 = keras.layers.Reshape((2, 4), name = 'Res9310', )(Add92635)
GRU82424 = keras.layers.GRU(3,reset_after=True, recurrent_activation='sigmoid', name = 'GRU82424', )(Res9310)
Res20787 = keras.layers.Reshape((3, 1), name = 'Res20787', )(GRU82424)
Res60427 = keras.layers.Reshape((3, 1, 1), name = 'Res60427', )(Res20787)
Zer85085 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer85085', )(Res60427)
Lea75876 = keras.layers.LeakyReLU(alpha=1.1212157443158153, name = 'Lea75876', input_shape=(1, 2, 1))(in0Lea75876)
Zer27128 = keras.layers.ZeroPadding2D(padding=((2, 0), (1, 0)), name = 'Zer27128', )(Lea75876)
Mul80340 = keras.layers.Multiply(name = 'Mul80340', )([Zer85085,Zer27128])
model = tf.keras.models.Model(inputs=[in0Add92635,in1Add92635,in0Lea75876], outputs=Mul80340)
w = model.get_layer('GRU82424').get_weights() 
w[0] = np.array([[9, 7, 9, 8, 1, 3, 9, 5, 1], [2, 7, 6, 7, 9, 5, 2, 8, 9], [5, 10, 5, 6, 3, 4, 2, 4, 7], [10, 9, 4, 1, 7, 9, 3, 1, 9]])
w[1] = np.array([[2, 5, 2, 9, 1, 9, 1, 5, 10], [6, 1, 7, 8, 9, 6, 10, 6, 8], [8, 1, 3, 5, 4, 8, 2, 5, 7]])
w[2] = np.array([[6, 4, 8, 2, 8, 3, 6, 10, 1], [4, 7, 10, 4, 3, 10, 7, 2, 10]])
model.get_layer('GRU82424').set_weights(w) 
in0Add92635 = tf.constant([[[[0.2129, 0.1681], [0.3605, 0.3962]], [[0.3565, 0.7849], [0.6535, 0.1362]]]])
in1Add92635 = tf.constant([[[[0.6743, 0.8042], [0.9186, 0.4306]], [[0.335, 0.2674], [0.0956, 0.2995]]]])
in0Lea75876 = tf.constant([[[[0.8456], [0.3812]]]])
print (np.array2string(model.predict([in0Add92635,in1Add92635,in0Lea75876],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul80340.png')

LAdd92635 = add_layer([[[[[0.2129, 0.1681], [0.3605, 0.3962]], [[0.3565, 0.7849], [0.6535, 0.1362]]]], [[[[0.6743, 0.8042], [0.9186, 0.4306]], [[0.335, 0.2674], [0.0956, 0.2995]]]]], Add92635), 
LRes9310 = reshape_layer(Add92635, [2, 4], Res9310), 
LGRU82424 = gru_layer(Res9310,[[9, 7, 9, 8, 1, 3, 9, 5, 1], [2, 7, 6, 7, 9, 5, 2, 8, 9], [5, 10, 5, 6, 3, 4, 2, 4, 7], [10, 9, 4, 1, 7, 9, 3, 1, 9]],[[2, 5, 2, 9, 1, 9, 1, 5, 10], [6, 1, 7, 8, 9, 6, 10, 6, 8], [8, 1, 3, 5, 4, 8, 2, 5, 7]],[[6, 4, 8, 2, 8, 3, 6, 10, 1], [4, 7, 10, 4, 3, 10, 7, 2, 10]], true, GRU82424), 
LRes20787 = reshape_layer(GRU82424, [3, 1], Res20787), 
LRes60427 = reshape_layer(Res20787, [3, 1, 1], Res60427), 
LZer85085 = zero_padding2D_layer(Res60427, 0, 0, 2, 0, Zer85085), 
LLea75876 = leaky_relu_layer([[[[0.8456], [0.3812]]]], 1.1212157443158153, Lea75876), 
LZer27128 = zero_padding2D_layer(Lea75876, 2, 0, 1, 0, Zer27128), 
LMul80340 = multiply_layer([Zer85085,Zer27128], Mul80340), 
exec_layers([LAdd92635,LRes9310,LGRU82424,LRes20787,LRes60427,LZer85085,LLea75876,LZer27128,LMul80340],["Add92635","Res9310","GRU82424","Res20787","Res60427","Zer85085","Lea75876","Zer27128","Mul80340"],Mul80340,"Mul80340")

Actual (Unparsed): [[[[0.0000000], [0.0000000], [0.0000000]], [[0.0000000], [0.0000000], [0.0000000]], [[0.0000000], [0.0000000], [0.0000000]]]]

Expected (Unparsed): [[[[0],[0],[0.0]],[[0],[0],[0.0]],[[0],[0.0],[8.464340339742193e-17]]]]

Actual:   [[[[0], [0], [0]], [[0], [0], [0]], [[0], [0], [0]]]]

Expected: [[[[0], [0], [0]], [[0], [0], [0]], [[0], [0], [0]]]]