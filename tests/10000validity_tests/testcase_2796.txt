import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con47943 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Mul16363 = tf.keras.layers.Input(shape=([2, 2]))
in1Mul16363 = tf.keras.layers.Input(shape=([2, 2]))
in0Con66816 = tf.keras.layers.Input(shape=([26]))

Con47943 = keras.layers.Conv3DTranspose(3, (1, 1, 2),strides=(1, 1, 1), padding='valid', name = 'Con47943', )(in0Con47943)
Res25961 = keras.layers.Reshape((2, 2, 9), name = 'Res25961', )(Con47943)
Con29306 = keras.layers.Conv2DTranspose(3, (2, 2),strides=(1, 1), padding='valid', name = 'Con29306', )(Res25961)
Res29501 = keras.layers.Reshape((3, 9), name = 'Res29501', )(Con29306)
Fla71844 = keras.layers.Flatten(name = 'Fla71844', )(Res29501)
Mul16363 = keras.layers.Multiply(name = 'Mul16363', )([in0Mul16363,in1Mul16363])
Per83792 = keras.layers.Permute((2,1), name = 'Per83792',)(Mul16363)
Res56836 = keras.layers.Reshape((2, 2, 1), name = 'Res56836', )(Per83792)
Glo76371 = keras.layers.GlobalAveragePooling2D(name = 'Glo76371', )(Res56836)
Con66816 = keras.layers.Concatenate(axis=1, name = 'Con66816', )([Glo76371,in0Con66816])
Add50157 = keras.layers.Add(name = 'Add50157', )([Fla71844,Con66816])
model = tf.keras.models.Model(inputs=[in0Con47943,in0Mul16363,in1Mul16363,in0Con66816], outputs=Add50157)
w = model.get_layer('Con47943').get_weights() 
w[0] = np.array([[[[[0.1928, 0.5058], [0.9894, 0.4076], [0.1315, 0.44]], [[0.7871, 0.64], [0.9785, 0.8696], [0.05, 0.5199]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con47943').set_weights(w) 
w = model.get_layer('Con29306').get_weights() 
w[0] = np.array([[[[0.609, 0.7492, 0.2705, 0.9395, 0.8349, 0.4377, 0.1539, 0.3538, 0.7934], [0.8344, 0.7965, 0.5411, 0.6986, 0.2205, 0.4612, 0.2138, 0.8728, 0.766], [0.753, 0.0756, 0.2684, 0.8944, 0.3022, 0.1981, 0.057, 0.6292, 0.542]], [[0.5247, 0.8955, 0.9157, 0.4177, 0.7924, 0.9773, 0.6036, 0.0688, 0.6794], [0.1287, 0.3757, 0.8792, 0.9165, 0.0224, 0.4115, 0.8048, 0.4301, 0.0429], [0.9873, 0.5563, 0.3258, 0.4627, 0.5284, 0.0403, 0.6672, 0.3664, 0.859]]], [[[0.4423, 0.5543, 0.1935, 0.5167, 0.4749, 0.9667, 0.862, 0.0429, 0.6064], [0.1992, 0.1816, 0.0974, 0.5364, 0.4871, 0.6702, 0.0957, 0.7916, 0.5992], [0.9443, 0.8233, 0.0757, 0.7535, 0.5714, 0.1414, 0.9296, 0.2059, 0.6458]], [[0.4655, 0.3303, 0.2539, 0.3735, 0.1734, 0.0898, 0.1994, 0.6411, 0.4777], [0.3024, 0.0252, 0.882, 0.5842, 0.6339, 0.1502, 0.5494, 0.1512, 0.9445], [0.6527, 0.1613, 0.1614, 0.595, 0.7754, 0.1909, 0.3243, 0.799, 0.3595]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con29306').set_weights(w) 
in0Con47943 = tf.constant([[[[[0.1208, 0.8952], [0.6708, 0.0572]], [[0.7334, 0.5276], [0.9332, 0.5695]]], [[[0.3907, 0.6173], [0.3649, 0.1475]], [[0.5809, 0.3832], [0.7517, 0.1822]]]]])
in0Mul16363 = tf.constant([[[0.1585, 0.8641], [0.1954, 0.0038]]])
in1Mul16363 = tf.constant([[[0.2545, 0.2506], [0.3362, 0.934]]])
in0Con66816 = tf.constant([[0.1807, 0.239, 0.1783, 0.3648, 0.8726, 0.5485, 0.3145, 0.8851, 0.8964, 0.7454, 0.7818, 0.3213, 0.6052, 0.692, 0.3281, 0.7198, 0.0707, 0.0715, 0.172, 0.6211, 0.8711, 0.5425, 0.9265, 0.1595, 0.4346, 0.4916]])
print (np.array2string(model.predict([in0Con47943,in0Mul16363,in1Mul16363,in0Con66816],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add50157.png')

LCon47943 = conv3D_transpose_layer([[[[[0.1208, 0.8952], [0.6708, 0.0572]], [[0.7334, 0.5276], [0.9332, 0.5695]]], [[[0.3907, 0.6173], [0.3649, 0.1475]], [[0.5809, 0.3832], [0.7517, 0.1822]]]]], 1, 1, 2,[[[[[0.1928, 0.5058], [0.9894, 0.4076], [0.1315, 0.44]], [[0.7871, 0.64], [0.9785, 0.8696], [0.05, 0.5199]]]]],[0, 0, 0], 1, 1, 1, false, Con47943), 
LRes25961 = reshape_layer(Con47943, [2, 2, 9], Res25961), 
LCon29306 = conv2D_transpose_layer(Res25961, 2, 2,[[[[0.609, 0.7492, 0.2705, 0.9395, 0.8349, 0.4377, 0.1539, 0.3538, 0.7934], [0.8344, 0.7965, 0.5411, 0.6986, 0.2205, 0.4612, 0.2138, 0.8728, 0.766], [0.753, 0.0756, 0.2684, 0.8944, 0.3022, 0.1981, 0.057, 0.6292, 0.542]], [[0.5247, 0.8955, 0.9157, 0.4177, 0.7924, 0.9773, 0.6036, 0.0688, 0.6794], [0.1287, 0.3757, 0.8792, 0.9165, 0.0224, 0.4115, 0.8048, 0.4301, 0.0429], [0.9873, 0.5563, 0.3258, 0.4627, 0.5284, 0.0403, 0.6672, 0.3664, 0.859]]], [[[0.4423, 0.5543, 0.1935, 0.5167, 0.4749, 0.9667, 0.862, 0.0429, 0.6064], [0.1992, 0.1816, 0.0974, 0.5364, 0.4871, 0.6702, 0.0957, 0.7916, 0.5992], [0.9443, 0.8233, 0.0757, 0.7535, 0.5714, 0.1414, 0.9296, 0.2059, 0.6458]], [[0.4655, 0.3303, 0.2539, 0.3735, 0.1734, 0.0898, 0.1994, 0.6411, 0.4777], [0.3024, 0.0252, 0.882, 0.5842, 0.6339, 0.1502, 0.5494, 0.1512, 0.9445], [0.6527, 0.1613, 0.1614, 0.595, 0.7754, 0.1909, 0.3243, 0.799, 0.3595]]]],[0, 0, 0], 1, 1, false, Con29306), 
LRes29501 = reshape_layer(Con29306, [3, 9], Res29501), 
LFla71844 = flatten_layer(Res29501, Fla71844), 
LMul16363 = multiply_layer([[[[0.1585, 0.8641], [0.1954, 0.0038]]], [[[0.2545, 0.2506], [0.3362, 0.934]]]], Mul16363), 
LPer83792 = permute_layer(Mul16363, 2,1, Per83792), 
LRes56836 = reshape_layer(Per83792, [2, 2, 1], Res56836), 
LGlo76371 = global_average_pooling2D_layer(Res56836, Glo76371), 
LCon66816 = concatenate_layer([Glo76371,[[0.1807, 0.239, 0.1783, 0.3648, 0.8726, 0.5485, 0.3145, 0.8851, 0.8964, 0.7454, 0.7818, 0.3213, 0.6052, 0.692, 0.3281, 0.7198, 0.0707, 0.0715, 0.172, 0.6211, 0.8711, 0.5425, 0.9265, 0.1595, 0.4346, 0.4916]]], 1, Con66816), 
LAdd50157 = add_layer([Fla71844,Con66816], Add50157), 
exec_layers([LCon47943,LRes25961,LCon29306,LRes29501,LFla71844,LMul16363,LPer83792,LRes56836,LGlo76371,LCon66816,LAdd50157],["Con47943","Res25961","Con29306","Res29501","Fla71844","Mul16363","Per83792","Res56836","Glo76371","Con66816","Add50157"],Add50157,"Add50157")

Actual (Unparsed): [[3.5866167, 3.1671387, 2.5883215, 9.3682977, 7.5528339, 7.3564792, 5.9932299, 4.1155037, 5.3618263, 6.9754397, 5.9066558, 6.0407158, 13.5878287, 12.5330314, 13.8793668, 6.9517667, 7.2428607, 7.9703768, 2.5791630, 2.2854373, 3.5214629, 5.3793485, 5.4330123, 7.0954399, 2.0687409, 3.1109911, 3.8103947]]

Expected (Unparsed): [[3.5866167314679998,3.1671386682239997,2.5883215058999998,9.368297750986,7.552833898683999,7.356479175043999,5.993229858,4.115503654581,5.3618262679179995,6.975439831925999,5.906655828061999,6.0407158355699995,13.587828747565002,12.533031438718998,13.879366954585997,6.9517667218820005,7.242860749896001,7.970376788773,2.5791630433559996,2.285437353448,3.521462938001,5.379348563705,5.433012383064,7.0954399394509995,2.068740879107,3.1109911276410003,3.810394710096]]

Actual:   [[3.5867, 3.1672, 2.5884, 9.3683, 7.5529, 7.3565, 5.9933, 4.1156, 5.3619, 6.9755, 5.9067, 6.0408, 13.5879, 12.5331, 13.8794, 6.9518, 7.2429, 7.9704, 2.5792, 2.2855, 3.5215, 5.3794, 5.4331, 7.0955, 2.0688, 3.111, 3.8104]]

Expected: [[3.5867, 3.1672, 2.5884, 9.3683, 7.5529, 7.3565, 5.9933, 4.1156, 5.3619, 6.9755, 5.9067, 6.0408, 13.5879, 12.5331, 13.8794, 6.9518, 7.2429, 7.9704, 2.5792, 2.2855, 3.5215, 5.3794, 5.4331, 7.0955, 2.0688, 3.111, 3.8104]]