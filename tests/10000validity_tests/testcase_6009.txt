import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max85952 = tf.keras.layers.Input(shape=([2, 2]))
in1Max85952 = tf.keras.layers.Input(shape=([2, 2]))
in0Con43559 = tf.keras.layers.Input(shape=([2, 2, 3, 2]))
in0Sub76453 = tf.keras.layers.Input(shape=([2, 2, 3, 3]))
in1Sub76453 = tf.keras.layers.Input(shape=([2, 2, 3, 3]))

Max85952 = keras.layers.Maximum(name = 'Max85952', )([in0Max85952,in1Max85952])
Bat86028 = keras.layers.BatchNormalization(axis=1, epsilon=0.21688927031217392,  name = 'Bat86028', )(Max85952)
Res315 = keras.layers.Reshape((2, 2, 1), name = 'Res315', )(Bat86028)
Res64066 = keras.layers.Reshape((2, 2, 1, 1), name = 'Res64066', )(Res315)
Zer7195 = keras.layers.ZeroPadding3D(padding=((0, 0), (0, 0), (2, 0)), name = 'Zer7195', )(Res64066)
Con43559 = keras.layers.Concatenate(axis=4, name = 'Con43559', )([Zer7195,in0Con43559])
Sub76453 = keras.layers.Subtract(name = 'Sub76453', )([in0Sub76453,in1Sub76453])
Min51412 = keras.layers.Minimum(name = 'Min51412', )([Con43559,Sub76453])
model = tf.keras.models.Model(inputs=[in0Max85952,in1Max85952,in0Con43559,in0Sub76453,in1Sub76453], outputs=Min51412)
w = model.get_layer('Bat86028').get_weights() 
w[0] = np.array([0.7328, 0.2418])
w[1] = np.array([0.6065, 0.6231])
w[2] = np.array([0.5891, 0.0552])
w[3] = np.array([0.0453, 0.4403])
model.get_layer('Bat86028').set_weights(w) 
in0Max85952 = tf.constant([[[0.823, 0.7323], [0.3369, 0.8006]]])
in1Max85952 = tf.constant([[[0.235, 0.4005], [0.8388, 0.7176]]])
in0Con43559 = tf.constant([[[[[0.8083, 0.4341], [0.085, 0.3711], [0.1906, 0.0303]], [[0.045, 0.6778], [0.0194, 0.7531], [0.3975, 0.7205]]], [[[0.974, 0.017], [0.9437, 0.149], [0.6975, 0.1915]], [[0.0845, 0.7059], [0.1266, 0.6122], [0.7687, 0.8476]]]]])
in0Sub76453 = tf.constant([[[[[0.0009, 0.195, 0.0783], [0.5853, 0.6209, 0.3603], [0.3906, 0.6709, 0.5843]], [[0.8934, 0.0591, 0.1718], [0.9957, 0.2208, 0.4269], [0.6187, 0.8423, 0.4867]]], [[[0.2153, 0.6141, 0.1306], [0.0007, 0.6733, 0.3862], [0.6377, 0.5407, 0.781]], [[0.9899, 0.9521, 0.0207], [0.2323, 0.5021, 0.8098], [0.4961, 0.3361, 0.2261]]]]])
in1Sub76453 = tf.constant([[[[[0.4729, 0.6034, 0.2916], [0.7468, 0.0411, 0.3081], [0.5154, 0.6563, 0.1396]], [[0.2685, 0.8313, 0.9122], [0.3852, 0.2173, 0.3668], [0.0804, 0.396, 0.5047]]], [[[0.9436, 0.1662, 0.88], [0.3561, 0.5989, 0.3455], [0.5163, 0.4507, 0.6285]], [[0.6669, 0.924, 0.1494], [0.2033, 0.7177, 0.005], [0.0671, 0.179, 0.3213]]]]])
print (np.array2string(model.predict([in0Max85952,in1Max85952,in0Con43559,in0Sub76453,in1Sub76453],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min51412.png')

LMax85952 = maximum_layer([[[[0.823, 0.7323], [0.3369, 0.8006]]], [[[0.235, 0.4005], [0.8388, 0.7176]]]], Max85952), 
LBat86028 = batch_normalization_layer(Max85952, 1, 0.21688927031217392, [0.7328, 0.2418], [0.6065, 0.6231], [0.5891, 0.0552], [0.0453, 0.4403], Bat86028), 
LRes315 = reshape_layer(Bat86028, [2, 2, 1], Res315), 
LRes64066 = reshape_layer(Res315, [2, 2, 1, 1], Res64066), 
LZer7195 = zero_padding3D_layer(Res64066, 0, 0, 0, 0, 2, 0, Zer7195), 
LCon43559 = concatenate_layer([Zer7195,[[[[[0.8083, 0.4341], [0.085, 0.3711], [0.1906, 0.0303]], [[0.045, 0.6778], [0.0194, 0.7531], [0.3975, 0.7205]]], [[[0.974, 0.017], [0.9437, 0.149], [0.6975, 0.1915]], [[0.0845, 0.7059], [0.1266, 0.6122], [0.7687, 0.8476]]]]]], 4, Con43559), 
LSub76453 = subtract_layer([[[[[0.0009, 0.195, 0.0783], [0.5853, 0.6209, 0.3603], [0.3906, 0.6709, 0.5843]], [[0.8934, 0.0591, 0.1718], [0.9957, 0.2208, 0.4269], [0.6187, 0.8423, 0.4867]]], [[[0.2153, 0.6141, 0.1306], [0.0007, 0.6733, 0.3862], [0.6377, 0.5407, 0.781]], [[0.9899, 0.9521, 0.0207], [0.2323, 0.5021, 0.8098], [0.4961, 0.3361, 0.2261]]]]], [[[[[0.4729, 0.6034, 0.2916], [0.7468, 0.0411, 0.3081], [0.5154, 0.6563, 0.1396]], [[0.2685, 0.8313, 0.9122], [0.3852, 0.2173, 0.3668], [0.0804, 0.396, 0.5047]]], [[[0.9436, 0.1662, 0.88], [0.3561, 0.5989, 0.3455], [0.5163, 0.4507, 0.6285]], [[0.6669, 0.924, 0.1494], [0.2033, 0.7177, 0.005], [0.0671, 0.179, 0.3213]]]]], Sub76453), 
LMin51412 = minimum_layer([Con43559,Sub76453], Min51412), 
exec_layers([LMax85952,LBat86028,LRes315,LRes64066,LZer7195,LCon43559,LSub76453,LMin51412],["Max85952","Bat86028","Res315","Res64066","Zer7195","Con43559","Sub76453","Min51412"],Min51412,"Min51412")

Actual (Unparsed): [[[[[-0.4720000, -0.4084000, -0.2133000], [-0.1615000, 0.0850000, 0.0522000], [-0.1248000, 0.0146000, 0.0303000]], [[0.0000000, -0.7722000, -0.7404000], [0.0000000, 0.0035000, 0.0601000], [0.5383000, 0.3975000, -0.0180000]]], [[[-0.7283000, 0.4479000, -0.7494000], [-0.3554000, 0.0744000, 0.0407000], [0.1214000, 0.0900000, 0.1525000]], [[0.0000000, 0.0281000, -0.1287000], [0.0000000, -0.2156000, 0.6122000], [0.4290000, 0.1571000, -0.0952000]]]]]

Expected (Unparsed): [[[[[-0.472,-0.40840000000000004,-0.21330000000000005],[-0.16149999999999998,0.085,0.052200000000000024],[-0.12479999999999997,0.014600000000000057,0.0303]],[[0,-0.7722,-0.7404],[0,0.003500000000000003,0.06009999999999999],[0.5383,0.3975,-0.018000000000000016]]],[[[-0.7283,0.44789999999999996,-0.7494000000000001],[-0.35540000000000005,0.07440000000000002,0.040700000000000014],[0.12140000000000006,0.08999999999999997,0.15250000000000008]],[[0,0.028099999999999903,-0.1287],[0,-0.2156,0.6122],[0.429,0.15710000000000002,-0.09519999999999998]]]]]

Actual:   [[[[[-0.472, -0.4084, -0.2133], [-0.1615, 0.085, 0.0522], [-0.1248, 0.0146, 0.0303]], [[0, -0.7722, -0.7404], [0, 0.0035, 0.0601], [0.5383, 0.3975, -0.018]]], [[[-0.7283, 0.4479, -0.7494], [-0.3554, 0.0744, 0.0407], [0.1214, 0.09, 0.1525]], [[0, 0.0281, -0.1287], [0, -0.2156, 0.6122], [0.429, 0.1571, -0.0952]]]]]

Expected: [[[[[-0.472, -0.4084, -0.2133], [-0.1614, 0.085, 0.0523], [-0.1247, 0.0147, 0.0303]], [[0, -0.7722, -0.7404], [0, 0.0036, 0.0601], [0.5383, 0.3975, -0.018]]], [[[-0.7283, 0.4479, -0.7494], [-0.3554, 0.0745, 0.0408], [0.1215, 0.09, 0.1526]], [[0, 0.0281, -0.1287], [0, -0.2156, 0.6122], [0.429, 0.1572, -0.0951]]]]]