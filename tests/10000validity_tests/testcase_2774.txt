import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ReL99023 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in0Ave90676 = tf.keras.layers.Input(shape=([1, 1, 1, 2]))
in1Ave90676 = tf.keras.layers.Input(shape=([1, 1, 1, 2]))
in0Con34861 = tf.keras.layers.Input(shape=([1]))

ReL99023 = keras.layers.ReLU(max_value=4.055922640901754, negative_slope=0.8439614795929289, threshold=9.510181682536619, name = 'ReL99023', input_shape=(1, 2, 2, 1))(in0ReL99023)
Res98287 = keras.layers.Reshape((1, 2, 2), name = 'Res98287', )(ReL99023)
Res79563 = keras.layers.Reshape((1, 4), name = 'Res79563', )(Res98287)
Fla5419 = keras.layers.Flatten(name = 'Fla5419', )(Res79563)
Ave90676 = keras.layers.Average(name = 'Ave90676', )([in0Ave90676,in1Ave90676])
Res44537 = keras.layers.Reshape((1, 1, 2), name = 'Res44537', )(Ave90676)
Res18376 = keras.layers.Reshape((1, 2), name = 'Res18376', )(Res44537)
Sim92170 = keras.layers.SimpleRNN(3,name = 'Sim92170', )(Res18376)
Con34861 = keras.layers.Concatenate(axis=1, name = 'Con34861', )([Sim92170,in0Con34861])
Min33796 = keras.layers.Minimum(name = 'Min33796', )([Fla5419,Con34861])
model = tf.keras.models.Model(inputs=[in0ReL99023,in0Ave90676,in1Ave90676,in0Con34861], outputs=Min33796)
w = model.get_layer('Sim92170').get_weights() 
w[0] = np.array([[3, 8, 9], [10, 7, 2]])
w[1] = np.array([[8, 2, 5], [7, 3, 3], [9, 7, 2]])
w[2] = np.array([2, 7, 5])
model.get_layer('Sim92170').set_weights(w) 
in0ReL99023 = tf.constant([[[[[0.1893], [0.9119]], [[0.7965], [0.9852]]]]])
in0Ave90676 = tf.constant([[[[[0.6953, 0.4247]]]]])
in1Ave90676 = tf.constant([[[[[0.8291, 0.0275]]]]])
in0Con34861 = tf.constant([[0.1109]])
print (np.array2string(model.predict([in0ReL99023,in0Ave90676,in1Ave90676,in0Con34861],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min33796.png')

LReL99023 = relu_layer([[[[[0.1893], [0.9119]], [[0.7965], [0.9852]]]]], 4.055922640901754, 0.8439614795929289, 9.510181682536619, ReL99023), 
LRes98287 = reshape_layer(ReL99023, [1, 2, 2], Res98287), 
LRes79563 = reshape_layer(Res98287, [1, 4], Res79563), 
LFla5419 = flatten_layer(Res79563, Fla5419), 
LAve90676 = average_layer([[[[[[0.6953, 0.4247]]]]], [[[[[0.8291, 0.0275]]]]]], Ave90676), 
LRes44537 = reshape_layer(Ave90676, [1, 1, 2], Res44537), 
LRes18376 = reshape_layer(Res44537, [1, 2], Res18376), 
LSim92170 = simple_rnn_layer(Res18376,[[3, 8, 9], [10, 7, 2]],[[8, 2, 5], [7, 3, 3], [9, 7, 2]],[2, 7, 5], Sim92170), 
LCon34861 = concatenate_layer([Sim92170,[[0.1109]]], 1, Con34861), 
LMin33796 = minimum_layer([Fla5419,Con34861], Min33796), 
exec_layers([LReL99023,LRes98287,LRes79563,LFla5419,LAve90676,LRes44537,LRes18376,LSim92170,LCon34861,LMin33796],["ReL99023","Res98287","Res79563","Fla5419","Ave90676","Res44537","Res18376","Sim92170","Con34861","Min33796"],Min33796,"Min33796")

Actual (Unparsed): [[-7.8664651, -7.2566185, -7.3540117, -7.1947562]]

Expected (Unparsed): [[-7.866465095904233,-7.256618530750382,-7.354011685495406,-7.19475615429622]]

Actual:   [[-7.8664, -7.2566, -7.354, -7.1947]]

Expected: [[-7.8664, -7.2566, -7.354, -7.1947]]