import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave70040 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Ave70040 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Glo18748 = tf.keras.layers.Input(shape=([2, 2]))
in0Con21148 = tf.keras.layers.Input(shape=([6]))
in0Con67621 = tf.keras.layers.Input(shape=([8, 1, 3]))
in0Glo7945 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0GRU13664 = tf.keras.layers.Input(shape=([2, 2]))
in0Con28019 = tf.keras.layers.Input(shape=([31]))

Ave70040 = keras.layers.Average(name = 'Ave70040', )([in0Ave70040,in1Ave70040])
Res65006 = keras.layers.Reshape((2, 4), name = 'Res65006', )(Ave70040)
Fla20081 = keras.layers.Flatten(name = 'Fla20081', )(Res65006)
Glo18748 = keras.layers.GlobalMaxPool1D(name = 'Glo18748', )(in0Glo18748)
Con21148 = keras.layers.Concatenate(axis=1, name = 'Con21148', )([Glo18748,in0Con21148])
Min55540 = keras.layers.Minimum(name = 'Min55540', )([Fla20081,Con21148])
Res31908 = keras.layers.Reshape((8, 1), name = 'Res31908', )(Min55540)
Res19004 = keras.layers.Reshape((8, 1, 1), name = 'Res19004', )(Res31908)
Con67621 = keras.layers.Concatenate(axis=3, name = 'Con67621', )([Res19004,in0Con67621])
Glo7945 = keras.layers.GlobalMaxPool2D(name = 'Glo7945', )(in0Glo7945)
Res15535 = keras.layers.Reshape((1, 1), name = 'Res15535', )(Glo7945)
Res65534 = keras.layers.Reshape((1, 1, 1), name = 'Res65534', )(Res15535)
Con87131 = keras.layers.Conv2D(4, (1, 1),strides=(1, 1), padding='same', dilation_rate=(1, 1), name = 'Con87131', )(Res65534)
Zer21748 = keras.layers.ZeroPadding2D(padding=((7, 0), (0, 0)), name = 'Zer21748', )(Con87131)
Mul7121 = keras.layers.Multiply(name = 'Mul7121', )([Con67621,Zer21748])
Res71977 = keras.layers.Reshape((8, 4), name = 'Res71977', )(Mul7121)
Fla73432 = keras.layers.Flatten(name = 'Fla73432', )(Res71977)
GRU13664 = keras.layers.GRU(1,reset_after=True, recurrent_activation='sigmoid', name = 'GRU13664', )(in0GRU13664)
Bat86335 = keras.layers.BatchNormalization(axis=1, epsilon=0.934738766109212,  name = 'Bat86335', )(GRU13664)
Con28019 = keras.layers.Concatenate(axis=1, name = 'Con28019', )([Bat86335,in0Con28019])
Sub44435 = keras.layers.Subtract(name = 'Sub44435', )([Fla73432,Con28019])
model = tf.keras.models.Model(inputs=[in0Ave70040,in1Ave70040,in0Glo18748,in0Con21148,in0Con67621,in0Glo7945,in0GRU13664,in0Con28019], outputs=Sub44435)
w = model.get_layer('Con87131').get_weights() 
w[0] = np.array([[[[0.3927, 0.8915, 0.577, 0.6334]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con87131').set_weights(w) 
w = model.get_layer('GRU13664').get_weights() 
w[0] = np.array([[9, 1, 3], [9, 4, 8]])
w[1] = np.array([[8, 8, 5]])
w[2] = np.array([[10, 10, 6], [10, 1, 5]])
model.get_layer('GRU13664').set_weights(w) 
w = model.get_layer('Bat86335').get_weights() 
w[0] = np.array([0.0756])
w[1] = np.array([0.8982])
w[2] = np.array([0.159])
w[3] = np.array([0.8138])
model.get_layer('Bat86335').set_weights(w) 
in0Ave70040 = tf.constant([[[[0.7323, 0.9976], [0.374, 0.2226]], [[0.2189, 0.553], [0.0406, 0.0684]]]])
in1Ave70040 = tf.constant([[[[0.1289, 0.0507], [0.4158, 0.606]], [[0.9055, 0.2389], [0.4997, 0.4745]]]])
in0Glo18748 = tf.constant([[[1.0229, 1.25], [1.2138, 1.8377]]])
in0Con21148 = tf.constant([[0.5081, 0.5611, 0.0286, 0.332, 0.6068, 0.5877]])
in0Con67621 = tf.constant([[[[0.1972, 0.0864, 0.7548]], [[0.6003, 0.1669, 0.3587]], [[0.05, 0.6724, 0.1738]], [[0.2849, 0.5442, 0.7331]], [[0.1189, 0.084, 0.9686]], [[0.6391, 0.6027, 0.6033]], [[0.7822, 0.5781, 0.0946]], [[0.3922, 0.9359, 0.5656]]]])
in0Glo7945 = tf.constant([[[[1.1535]], [[1.9817]]]])
in0GRU13664 = tf.constant([[[5, 2], [3, 6]]])
in0Con28019 = tf.constant([[0.4819, 0.9776, 0.2509, 0.1969, 0.6506, 0.65, 0.6906, 0.9009, 0.7336, 0.646, 0.7634, 0.2956, 0.3006, 0.018, 0.5831, 0.8559, 0.9482, 0.2431, 0.5102, 0.592, 0.3595, 0.7717, 0.9115, 0.2131, 0.3909, 0.0302, 0.0623, 0.1624, 0.9264, 0.8889, 0.5519]])
print (np.array2string(model.predict([in0Ave70040,in1Ave70040,in0Glo18748,in0Con21148,in0Con67621,in0Glo7945,in0GRU13664,in0Con28019],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub44435.png')

LAve70040 = average_layer([[[[[0.7323, 0.9976], [0.374, 0.2226]], [[0.2189, 0.553], [0.0406, 0.0684]]]], [[[[0.1289, 0.0507], [0.4158, 0.606]], [[0.9055, 0.2389], [0.4997, 0.4745]]]]], Ave70040), 
LRes65006 = reshape_layer(Ave70040, [2, 4], Res65006), 
LFla20081 = flatten_layer(Res65006, Fla20081), 
LGlo18748 = global_max_pool1D_layer([[[1.0229, 1.25], [1.2138, 1.8377]]], Glo18748), 
LCon21148 = concatenate_layer([Glo18748,[[0.5081, 0.5611, 0.0286, 0.332, 0.6068, 0.5877]]], 1, Con21148), 
LMin55540 = minimum_layer([Fla20081,Con21148], Min55540), 
LRes31908 = reshape_layer(Min55540, [8, 1], Res31908), 
LRes19004 = reshape_layer(Res31908, [8, 1, 1], Res19004), 
LCon67621 = concatenate_layer([Res19004,[[[[0.1972, 0.0864, 0.7548]], [[0.6003, 0.1669, 0.3587]], [[0.05, 0.6724, 0.1738]], [[0.2849, 0.5442, 0.7331]], [[0.1189, 0.084, 0.9686]], [[0.6391, 0.6027, 0.6033]], [[0.7822, 0.5781, 0.0946]], [[0.3922, 0.9359, 0.5656]]]]], 3, Con67621), 
LGlo7945 = global_max_pool2D_layer([[[[1.1535]], [[1.9817]]]], Glo7945), 
LRes15535 = reshape_layer(Glo7945, [1, 1], Res15535), 
LRes65534 = reshape_layer(Res15535, [1, 1, 1], Res65534), 
LCon87131 = conv2D_layer(Res65534, 1, 1,[[[[0.3927, 0.8915, 0.577, 0.6334]]]],[0, 0, 0, 0], 1, 1, true, 1, 1, Con87131), 
LZer21748 = zero_padding2D_layer(Con87131, 7, 0, 0, 0, Zer21748), 
LMul7121 = multiply_layer([Con67621,Zer21748], Mul7121), 
LRes71977 = reshape_layer(Mul7121, [8, 4], Res71977), 
LFla73432 = flatten_layer(Res71977, Fla73432), 
LGRU13664 = gru_layer([[[5, 2], [3, 6]]],[[9, 1, 3], [9, 4, 8]],[[8, 8, 5]],[[10, 10, 6], [10, 1, 5]], true, GRU13664), 
LBat86335 = batch_normalization_layer(GRU13664, 1, 0.934738766109212, [0.0756], [0.8982], [0.159], [0.8138], Bat86335), 
LCon28019 = concatenate_layer([Bat86335,[[0.4819, 0.9776, 0.2509, 0.1969, 0.6506, 0.65, 0.6906, 0.9009, 0.7336, 0.646, 0.7634, 0.2956, 0.3006, 0.018, 0.5831, 0.8559, 0.9482, 0.2431, 0.5102, 0.592, 0.3595, 0.7717, 0.9115, 0.2131, 0.3909, 0.0302, 0.0623, 0.1624, 0.9264, 0.8889, 0.5519]]], 1, Con28019), 
LSub44435 = subtract_layer(Fla73432,Con28019, Sub44435), 
exec_layers([LAve70040,LRes65006,LFla20081,LGlo18748,LCon21148,LMin55540,LRes31908,LRes19004,LCon67621,LGlo7945,LRes15535,LRes65534,LCon87131,LZer21748,LMul7121,LRes71977,LFla73432,LGRU13664,LBat86335,LCon28019,LSub44435],["Ave70040","Res65006","Fla20081","Glo18748","Con21148","Min55540","Res31908","Res19004","Con67621","Glo7945","Res15535","Res65534","Con87131","Zer21748","Mul7121","Res71977","Fla73432","GRU13664","Bat86335","Con28019","Sub44435"],Sub44435,"Sub44435")

Actual (Unparsed): [[-0.8891096, -0.4819000, -0.9776000, -0.2509000, -0.1969000, -0.6506000, -0.6500000, -0.6906000, -0.9009000, -0.7336000, -0.6460000, -0.7634000, -0.2956000, -0.3006000, -0.0180000, -0.5831000, -0.8559000, -0.9482000, -0.2431000, -0.5102000, -0.5920000, -0.3595000, -0.7717000, -0.9115000, -0.2131000, -0.3909000, -0.0302000, -0.0623000, 0.0488461, -0.2335060, 0.1812463, 0.1580460]]

Expected (Unparsed): [[-0.8891096357194651,-0.4819,-0.9776,-0.2509,-0.1969,-0.6506,-0.65,-0.6906,-0.9009,-0.7336,-0.646,-0.7634,-0.2956,-0.3006,-0.018,-0.5831,-0.8559,-0.9482,-0.2431,-0.5102,-0.592,-0.3595,-0.7717,-0.9115,-0.2131,-0.3909,-0.0302,-0.0623,0.048846079005500004,-0.23350592729000008,0.1812463383099998,0.15804608596800007]]

Actual:   [[-0.8891, -0.4819, -0.9776, -0.2509, -0.1969, -0.6506, -0.65, -0.6906, -0.9009, -0.7336, -0.646, -0.7634, -0.2956, -0.3006, -0.018, -0.5831, -0.8559, -0.9482, -0.2431, -0.5102, -0.592, -0.3595, -0.7717, -0.9115, -0.2131, -0.3909, -0.0302, -0.0623, 0.0489, -0.2335, 0.1813, 0.1581]]

Expected: [[-0.8891, -0.4819, -0.9776, -0.2509, -0.1969, -0.6506, -0.65, -0.6906, -0.9009, -0.7336, -0.646, -0.7634, -0.2956, -0.3006, -0.018, -0.5831, -0.8559, -0.9482, -0.2431, -0.5102, -0.592, -0.3595, -0.7717, -0.9115, -0.2131, -0.3909, -0.0302, -0.0623, 0.0489, -0.2335, 0.1813, 0.1581]]