import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con42558 = tf.keras.layers.Input(shape=([1, 1]))

Con42558 = keras.layers.Conv1D(3, (1),strides=(1), padding='valid', dilation_rate=(1), name = 'Con42558', )(in0Con42558)
LST60723 = keras.layers.LSTM(3,recurrent_activation='sigmoid', name = 'LST60723', )(Con42558)
model = tf.keras.models.Model(inputs=[in0Con42558], outputs=LST60723)
w = model.get_layer('Con42558').get_weights() 
w[0] = np.array([[[0.5742, 0.6144, 0.4457]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con42558').set_weights(w) 
w = model.get_layer('LST60723').get_weights() 
w[0] = np.array([[2, 9, 3, 1, 9, 2, 3, 4, 2, 6, 1, 8], [10, 4, 6, 5, 10, 3, 6, 7, 6, 1, 3, 5], [7, 2, 6, 10, 4, 8, 7, 5, 6, 5, 1, 3]])
w[1] = np.array([[8, 4, 1, 2, 6, 9, 4, 1, 5, 3, 4, 5], [4, 7, 3, 2, 2, 9, 6, 7, 8, 7, 1, 2], [2, 2, 6, 9, 3, 5, 4, 6, 9, 3, 1, 9]])
w[2] = np.array([2, 10, 2, 4, 5, 2, 9, 4, 8, 7, 1, 1])
model.get_layer('LST60723').set_weights(w) 
in0Con42558 = tf.constant([[[0.3487]]])
print (np.array2string(model.predict([in0Con42558],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='LST60723.png')

LCon42558 = conv1D_layer([[[0.3487]]], 1,[[[0.5742, 0.6144, 0.4457]]],[0, 0, 0], 1, false, 1, Con42558), 
LLST60723 = lstm_layer(Con42558,[[2, 9, 3, 1, 9, 2, 3, 4, 2, 6, 1, 8], [10, 4, 6, 5, 10, 3, 6, 7, 6, 1, 3, 5], [7, 2, 6, 10, 4, 8, 7, 5, 6, 5, 1, 3]],[[8, 4, 1, 2, 6, 9, 4, 1, 5, 3, 4, 5], [4, 7, 3, 2, 2, 9, 6, 7, 8, 7, 1, 2], [2, 2, 6, 9, 3, 5, 4, 6, 9, 3, 1, 9]],[2, 10, 2, 4, 5, 2, 9, 4, 8, 7, 1, 1], LST60723), 
exec_layers([LCon42558,LLST60723],["Con42558","LST60723"],LST60723,"LST60723")

Actual (Unparsed): [[0.7600121, 0.6706775, 0.7463157]]

Expected (Unparsed): [[0.7600121407698237,0.6706775363696479,0.7463157082181263]]

Actual:   [[0.7601, 0.6707, 0.7464]]

Expected: [[0.7601, 0.6707, 0.7464]]