import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot9644 = tf.keras.layers.Input(shape=([3]))
in1Dot9644 = tf.keras.layers.Input(shape=([3]))
in0Con14270 = tf.keras.layers.Input(shape=([2, 3, 1]))
in0Up_76461 = tf.keras.layers.Input(shape=([2, 3, 2]))

Dot9644 = keras.layers.Dot(axes=(1, 1), name = 'Dot9644', )([in0Dot9644,in1Dot9644])
Res62148 = keras.layers.Reshape((1, 1), name = 'Res62148', )(Dot9644)
Res31742 = keras.layers.Reshape((1, 1, 1), name = 'Res31742', )(Res62148)
Zer34720 = keras.layers.ZeroPadding2D(padding=((1, 0), (2, 0)), name = 'Zer34720', )(Res31742)
Con14270 = keras.layers.Concatenate(axis=3, name = 'Con14270', )([Zer34720,in0Con14270])
Up_76461 = keras.layers.UpSampling2D(size=(1, 1), name = 'Up_76461', )(in0Up_76461)
Ave89951 = keras.layers.Average(name = 'Ave89951', )([Con14270,Up_76461])
Res78146 = keras.layers.Reshape((2, 3, 2, 1), name = 'Res78146', )(Ave89951)
Con68188 = keras.layers.Conv3DTranspose(3, (2, 2, 1),strides=(1, 3, 2), padding='valid', name = 'Con68188', )(Res78146)
Fla12699 = keras.layers.Flatten(name = 'Fla12699', )(Con68188)
model = tf.keras.models.Model(inputs=[in0Dot9644,in1Dot9644,in0Con14270,in0Up_76461], outputs=Fla12699)
w = model.get_layer('Con68188').get_weights() 
w[0] = np.array([[[[[0.1453], [0.7981], [0.5434]]], [[[0.7468], [0.8239], [0.0205]]]], [[[[0.0021], [0.9168], [0.2367]]], [[[0.2465], [0.3764], [0.5216]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con68188').set_weights(w) 
in0Dot9644 = tf.constant([[0.9703, 0.0162, 0.1324]])
in1Dot9644 = tf.constant([[0.5859, 0.9486, 0.5008]])
in0Con14270 = tf.constant([[[[0.7387], [0.2599], [0.8543]], [[0.0534], [0.841], [0.7934]]]])
in0Up_76461 = tf.constant([[[[1.8129, 1.0567], [1.5914, 1.279], [1.3918, 1.1678]], [[1.4777, 1.9729], [1.393, 1.7823], [1.4501, 1.1381]]]])
print (np.array2string(model.predict([in0Dot9644,in1Dot9644,in0Con14270,in0Up_76461],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Fla12699.png')

LDot9644 = dot_layer([[0.9703, 0.0162, 0.1324]], [[0.5859, 0.9486, 0.5008]], 1, 1, Dot9644), 
LRes62148 = reshape_layer(Dot9644, [1, 1], Res62148), 
LRes31742 = reshape_layer(Res62148, [1, 1, 1], Res31742), 
LZer34720 = zero_padding2D_layer(Res31742, 1, 0, 2, 0, Zer34720), 
LCon14270 = concatenate_layer([Zer34720,[[[[0.7387], [0.2599], [0.8543]], [[0.0534], [0.841], [0.7934]]]]], 3, Con14270), 
LUp_76461 = up_sampling2D_layer([[[[1.8129, 1.0567], [1.5914, 1.279], [1.3918, 1.1678]], [[1.4777, 1.9729], [1.393, 1.7823], [1.4501, 1.1381]]]], 1, 1, Up_76461), 
LAve89951 = average_layer([Con14270,Up_76461], Ave89951), 
LRes78146 = reshape_layer(Ave89951, [2, 3, 2, 1], Res78146), 
LCon68188 = conv3D_transpose_layer(Res78146, 2, 2, 1,[[[[[0.1453], [0.7981], [0.5434]]], [[[0.7468], [0.8239], [0.0205]]]], [[[[0.0021], [0.9168], [0.2367]]], [[[0.2465], [0.3764], [0.5216]]]]],[0, 0, 0], 1, 3, 2, false, Con68188), 
LFla12699 = flatten_layer(Con68188, Fla12699), 
exec_layers([LDot9644,LRes62148,LRes31742,LZer34720,LCon14270,LUp_76461,LAve89951,LRes78146,LCon68188,LFla12699],["Dot9644","Res62148","Res31742","Zer34720","Con14270","Up_76461","Ave89951","Res78146","Con68188","Fla12699"],Fla12699,"Fla12699")

Actual (Unparsed): [[0.1317072, 0.7234377, 0.4925649, 0.0000000, 0.0000000, 0.0000000, 0.1304358, 0.7164544, 0.4878102, 0.0000000, 0.0000000, 0.0000000, 0.6769368, 0.7468241, 0.0185822, 0.0000000, 0.0000000, 0.0000000, 0.6704023, 0.7396150, 0.0184028, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.1156152, 0.6350482, 0.4323834, 0.0000000, 0.0000000, 0.0000000, 0.1118011, 0.6140981, 0.4181191, 0.0000000, 0.0000000, 0.0000000, 0.5942288, 0.6555772, 0.0163119, 0.0000000, 0.0000000, 0.0000000, 0.5746253, 0.6339499, 0.0157737, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.1011143, 0.5553978, 0.3781521, 0.0000000, 0.0000000, 0.0000000, 0.1469056, 0.8069190, 0.5494046, 0.0000000, 0.0000000, 0.0000000, 0.5196981, 0.5733520, 0.0142660, 0.0000000, 0.0000000, 0.0000000, 0.7550521, 0.8330041, 0.0207265, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.1092584, 1.4207095, 0.6160478, 0.0000000, 0.0000000, 0.0000000, 0.1490959, 1.6316064, 0.7630313, 0.0000000, 0.0000000, 0.0000000, 0.7752131, 0.9499263, 0.4879507, 0.0000000, 0.0000000, 0.0000000, 0.9779035, 1.1726286, 0.4890099, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.1028724, 1.2853744, 0.5668203, 0.0000000, 0.0000000, 0.0000000, 0.1921986, 1.7522597, 0.8948794, 0.0000000, 0.0000000, 0.0000000, 0.7162863, 0.8733478, 0.4293154, 0.0000000, 0.0000000, 0.0000000, 1.1692097, 1.3702894, 0.4282340, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.1540461, 1.4761147, 0.7353634, 0.0000000, 0.0000000, 0.0000000, 0.1424467, 1.6976957, 0.7641041, 0.0000000, 0.0000000, 0.0000000, 0.9557809, 1.1271438, 0.3845092, 0.0000000, 0.0000000, 0.0000000, 0.9704459, 1.1762406, 0.5471615, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0015516, 0.6773777, 0.1748858, 0.0000000, 0.0000000, 0.0000000, 0.0021276, 0.9288559, 0.2398126, 0.0000000, 0.0000000, 0.0000000, 0.1821265, 0.2781031, 0.3853842, 0.0000000, 0.0000000, 0.0000000, 0.2497415, 0.3813497, 0.5284590, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0014627, 0.6385512, 0.1648616, 0.0000000, 0.0000000, 0.0000000, 0.0027545, 1.2025207, 0.3104676, 0.0000000, 0.0000000, 0.0000000, 0.1716873, 0.2621626, 0.3632944, 0.0000000, 0.0000000, 0.0000000, 0.3233217, 0.4937051, 0.6841566, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0022053, 0.9627647, 0.2485672, 0.0000000, 0.0000000, 0.0000000, 0.0020281, 0.8853996, 0.2285930, 0.0000000, 0.0000000, 0.0000000, 0.2588585, 0.3952712, 0.5477509, 0.0000000, 0.0000000, 0.0000000, 0.2380574, 0.3635083, 0.5037352, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000]]

Expected (Unparsed): [[0.131707185,0.723437745,0.49256492999999996,0,0,0,0.13043581,0.71645437,0.48781018,0,0,0,0.67693686,0.746824155,0.018582225,0,0,0,0.67040236,0.73961503,0.01840285,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.11561521000000001,0.63504817,0.43238338,0,0,0,0.11180108500000001,0.614098045,0.41811912999999995,0,0,0,0.59422876,0.6555772299999999,0.01631185,0,0,0,0.57462526,0.6339498549999999,0.015773725,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.10111427,0.55539779,0.37815205999999996,0,0,0,0.14690556500000002,0.806919005,0.54940457,0,0,0,0.51969812,0.5733520099999999,0.01426595,0,0,0,0.75505214,0.8330040949999999,0.020726525000000003,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.10925845000000002,1.420709545,0.616047805,0,0,0,0.149095865,1.631606375,0.7630313,0,0,0,0.775213105,0.949926295,0.48795074499999996,0,0,0,0.97790347,1.172628565,0.4890098949999999,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.10287242,1.28537441,0.56682029,0,0,0,0.19219859000000003,1.752259625,0.894879425,0,0,0,0.71628625,0.8733478299999999,0.4293153699999999,0,0,0,1.169209645,1.370289415,0.42823394499999995,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.1540461515265,1.4761146655905,0.7353634351169999,0,0,0,0.14244668,1.6976957149999998,0.7641040849999999,0,0,0,0.9557809185339999,1.1271438145194999,0.38450922810249993,0,0,0,0.9704459249999999,1.1762406449999998,0.547161555,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.0015515849999999999,0.67737768,0.174885795,0,0,0,0.002127615,0.92885592,0.23981260499999998,0,0,0,0.182126525,0.27810314,0.38538416,0,0,0,0.249741475,0.38134966000000003,0.52845904,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.00146265,0.6385512,0.16486155,0,0,0,0.0027544649999999998,1.2025207199999999,0.310467555,0,0,0,0.17168725,0.2621626,0.36329439999999996,0,0,0,0.323321725,0.49370506000000003,0.68415664,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.0022052856105,0.9627646893839998,0.24856719238349997,0,0,0,0.002028075,0.8853995999999998,0.22859302499999998,0,0,0,0.25885852523249997,0.395271192282,0.5477509402079999,0,0,0,0.23805737499999996,0.36350829999999995,0.5037351999999999,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]

Actual:   [[0.1318, 0.7235, 0.4926, 0, 0, 0, 0.1305, 0.7165, 0.4879, 0, 0, 0, 0.677, 0.7469, 0.0186, 0, 0, 0, 0.6705, 0.7397, 0.0185, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1157, 0.6351, 0.4324, 0, 0, 0, 0.1119, 0.6141, 0.4182, 0, 0, 0, 0.5943, 0.6556, 0.0164, 0, 0, 0, 0.5747, 0.634, 0.0158, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1012, 0.5554, 0.3782, 0, 0, 0, 0.147, 0.807, 0.5495, 0, 0, 0, 0.5197, 0.5734, 0.0143, 0, 0, 0, 0.7551, 0.8331, 0.0208, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1093, 1.4208, 0.6161, 0, 0, 0, 0.1491, 1.6317, 0.7631, 0, 0, 0, 0.7753, 0.95, 0.488, 0, 0, 0, 0.978, 1.1727, 0.4891, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1029, 1.2854, 0.5669, 0, 0, 0, 0.1922, 1.7523, 0.8949, 0, 0, 0, 0.7163, 0.8734, 0.4294, 0, 0, 0, 1.1693, 1.3703, 0.4283, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1541, 1.4762, 0.7354, 0, 0, 0, 0.1425, 1.6977, 0.7642, 0, 0, 0, 0.9558, 1.1272, 0.3846, 0, 0, 0, 0.9705, 1.1763, 0.5472, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0016, 0.6774, 0.1749, 0, 0, 0, 0.0022, 0.9289, 0.2399, 0, 0, 0, 0.1822, 0.2782, 0.3854, 0, 0, 0, 0.2498, 0.3814, 0.5285, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0015, 0.6386, 0.1649, 0, 0, 0, 0.0028, 1.2026, 0.3105, 0, 0, 0, 0.1717, 0.2622, 0.3633, 0, 0, 0, 0.3234, 0.4938, 0.6842, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0023, 0.9628, 0.2486, 0, 0, 0, 0.0021, 0.8854, 0.2286, 0, 0, 0, 0.2589, 0.3953, 0.5478, 0, 0, 0, 0.2381, 0.3636, 0.5038, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]

Expected: [[0.1318, 0.7235, 0.4926, 0, 0, 0, 0.1305, 0.7165, 0.4879, 0, 0, 0, 0.677, 0.7469, 0.0186, 0, 0, 0, 0.6705, 0.7397, 0.0185, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1157, 0.6351, 0.4324, 0, 0, 0, 0.1119, 0.6141, 0.4182, 0, 0, 0, 0.5943, 0.6556, 0.0164, 0, 0, 0, 0.5747, 0.634, 0.0158, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1012, 0.5554, 0.3782, 0, 0, 0, 0.147, 0.807, 0.5495, 0, 0, 0, 0.5197, 0.5734, 0.0143, 0, 0, 0, 0.7551, 0.8331, 0.0208, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1093, 1.4208, 0.6161, 0, 0, 0, 0.1491, 1.6317, 0.7631, 0, 0, 0, 0.7753, 0.95, 0.488, 0, 0, 0, 0.978, 1.1727, 0.4891, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1029, 1.2854, 0.5669, 0, 0, 0, 0.1922, 1.7523, 0.8949, 0, 0, 0, 0.7163, 0.8734, 0.4294, 0, 0, 0, 1.1693, 1.3703, 0.4283, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1541, 1.4762, 0.7354, 0, 0, 0, 0.1425, 1.6977, 0.7642, 0, 0, 0, 0.9558, 1.1272, 0.3846, 0, 0, 0, 0.9705, 1.1763, 0.5472, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0016, 0.6774, 0.1749, 0, 0, 0, 0.0022, 0.9289, 0.2399, 0, 0, 0, 0.1822, 0.2782, 0.3854, 0, 0, 0, 0.2498, 0.3814, 0.5285, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0015, 0.6386, 0.1649, 0, 0, 0, 0.0028, 1.2026, 0.3105, 0, 0, 0, 0.1717, 0.2622, 0.3633, 0, 0, 0, 0.3234, 0.4938, 0.6842, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0023, 0.9628, 0.2486, 0, 0, 0, 0.0021, 0.8854, 0.2286, 0, 0, 0, 0.2589, 0.3953, 0.5478, 0, 0, 0, 0.2381, 0.3636, 0.5038, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]