import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min19806 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in1Min19806 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in0Lay95834 = tf.keras.layers.Input(shape=([4, 3]))
in0GRU85058 = tf.keras.layers.Input(shape=([3, 1]))
in0Con29346 = tf.keras.layers.Input(shape=([11]))
in0Con37338 = tf.keras.layers.Input(shape=([4]))

Min19806 = keras.layers.Minimum(name = 'Min19806', )([in0Min19806,in1Min19806])
Res85469 = keras.layers.Reshape((2, 2, 2), name = 'Res85469', )(Min19806)
Res19289 = keras.layers.Reshape((2, 4), name = 'Res19289', )(Res85469)
Up_26487 = keras.layers.UpSampling1D(size=(2), name = 'Up_26487', )(Res19289)
Mas87078 = keras.layers.Masking(mask_value=2, name = 'Mas87078', )(Up_26487)
Fla80131 = keras.layers.Flatten(name = 'Fla80131', )(Mas87078)
Lay95834 = keras.layers.LayerNormalization(axis=1, epsilon=2.779820624958734, name = 'Lay95834', )(in0Lay95834)
Fla47797 = keras.layers.Flatten(name = 'Fla47797', )(Lay95834)
GRU85058 = keras.layers.GRU(1,reset_after=True, recurrent_activation='sigmoid', name = 'GRU85058', )(in0GRU85058)
Con29346 = keras.layers.Concatenate(axis=1, name = 'Con29346', )([GRU85058,in0Con29346])
Min22268 = keras.layers.Minimum(name = 'Min22268', )([Fla47797,Con29346])
Con37338 = keras.layers.Concatenate(axis=1, name = 'Con37338', )([Min22268,in0Con37338])
Add92610 = keras.layers.Add(name = 'Add92610', )([Fla80131,Con37338])
model = tf.keras.models.Model(inputs=[in0Min19806,in1Min19806,in0Lay95834,in0GRU85058,in0Con29346,in0Con37338], outputs=Add92610)
w = model.get_layer('GRU85058').get_weights() 
w[0] = np.array([[6, 7, 8]])
w[1] = np.array([[9, 3, 5]])
w[2] = np.array([[9, 6, 3], [7, 7, 1]])
model.get_layer('GRU85058').set_weights(w) 
in0Min19806 = tf.constant([[[[[0.2424], [0.602]], [[0.3348], [0.5859]]], [[[0.3717], [0.9068]], [[0.4362], [0.2665]]]]])
in1Min19806 = tf.constant([[[[[0.7603], [0.2843]], [[0.1741], [0.6552]]], [[[0.203], [0.8824]], [[0.85], [0.2675]]]]])
in0Lay95834 = tf.constant([[[1.8402, 1.1836, 1.7239], [1.5868, 1.8092, 1.6377], [1.4448, 1.6897, 1.9383], [1.5398, 1.056, 1.1239]]])
in0GRU85058 = tf.constant([[[4], [3], [3]]])
in0Con29346 = tf.constant([[0.1894, 0.776, 0.394, 0.9535, 0.5321, 0.2228, 0.5965, 0.8821, 0.8772, 0.7751, 0.7552]])
in0Con37338 = tf.constant([[0.1433, 0.9934, 0.0438, 0.1598]])
print (np.array2string(model.predict([in0Min19806,in1Min19806,in0Lay95834,in0GRU85058,in0Con29346,in0Con37338],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add92610.png')

LMin19806 = minimum_layer([[[[[[0.2424], [0.602]], [[0.3348], [0.5859]]], [[[0.3717], [0.9068]], [[0.4362], [0.2665]]]]], [[[[[0.7603], [0.2843]], [[0.1741], [0.6552]]], [[[0.203], [0.8824]], [[0.85], [0.2675]]]]]], Min19806), 
LRes85469 = reshape_layer(Min19806, [2, 2, 2], Res85469), 
LRes19289 = reshape_layer(Res85469, [2, 4], Res19289), 
LUp_26487 = up_sampling1D_layer(Res19289, 2, Up_26487), 
LMas87078 = masking_layer(Up_26487, 2, Mas87078), 
LFla80131 = flatten_layer(Mas87078, Fla80131), 
LLay95834 = layer_normalization_layer([[[1.8402, 1.1836, 1.7239], [1.5868, 1.8092, 1.6377], [1.4448, 1.6897, 1.9383], [1.5398, 1.056, 1.1239]]], 1, 2.779820624958734, Lay95834), 
LFla47797 = flatten_layer(Lay95834, Fla47797), 
LGRU85058 = gru_layer([[[4], [3], [3]]],[[6, 7, 8]],[[9, 3, 5]],[[9, 6, 3], [7, 7, 1]], true, GRU85058), 
LCon29346 = concatenate_layer([GRU85058,[[0.1894, 0.776, 0.394, 0.9535, 0.5321, 0.2228, 0.5965, 0.8821, 0.8772, 0.7751, 0.7552]]], 1, Con29346), 
LMin22268 = minimum_layer([Fla47797,Con29346], Min22268), 
LCon37338 = concatenate_layer([Min22268,[[0.1433, 0.9934, 0.0438, 0.1598]]], 1, Con37338), 
LAdd92610 = add_layer([Fla80131,Con37338], Add92610), 
exec_layers([LMin19806,LRes85469,LRes19289,LUp_26487,LMas87078,LFla80131,LLay95834,LFla47797,LGRU85058,LCon29346,LMin22268,LCon37338,LAdd92610],["Min19806","Res85469","Res19289","Up_26487","Mas87078","Fla80131","Lay95834","Fla47797","GRU85058","Con29346","Min22268","Con37338","Add92610"],Add92610,"Add92610")

Actual (Unparsed): [[0.2424000, 0.1364528, 0.2437327, 0.5762805, 0.4630149, 0.3030438, 0.0796376, 0.7361325, 0.3992054, 0.8446987, 0.2131997, -0.0180819, 0.3463000, 1.8758000, 0.4800000, 0.4263000]]

Expected (Unparsed): [[0.24240000000000356,0.13645281526176486,0.24373268702096001,0.5762804837738532,0.46301491573876863,0.30304385598063144,0.07963754563019812,0.7361325292186248,0.399205371186232,0.8446986662192632,0.21319973978084147,-0.01808191418782351,0.34630000000000005,1.8758,0.48,0.4263]]

Actual:   [[0.2424, 0.1365, 0.2438, 0.5763, 0.4631, 0.3031, 0.0797, 0.7362, 0.3993, 0.8447, 0.2132, -0.018, 0.3463, 1.8758, 0.48, 0.4263]]

Expected: [[0.2425, 0.1365, 0.2438, 0.5763, 0.4631, 0.3031, 0.0797, 0.7362, 0.3993, 0.8447, 0.2132, -0.018, 0.3464, 1.8758, 0.48, 0.4263]]