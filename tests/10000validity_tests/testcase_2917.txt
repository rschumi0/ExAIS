import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ELU22614 = tf.keras.layers.Input(shape=([1, 1]))
in0Con79442 = tf.keras.layers.Input(shape=([2, 1]))
in0Sub20042 = tf.keras.layers.Input(shape=([2, 2]))
in1Sub20042 = tf.keras.layers.Input(shape=([2, 2]))
in0Min77375 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))
in1Min77375 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))
in0Dot9396 = tf.keras.layers.Input(shape=([3]))
in1Dot9396 = tf.keras.layers.Input(shape=([3]))
in0Con70596 = tf.keras.layers.Input(shape=([1]))

ELU22614 = keras.layers.ELU(alpha=-2.3512226897699406, name = 'ELU22614', input_shape=(1, 1))(in0ELU22614)
Zer23329 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer23329', )(ELU22614)
Con79442 = keras.layers.Concatenate(axis=2, name = 'Con79442', )([Zer23329,in0Con79442])
Sub20042 = keras.layers.Subtract(name = 'Sub20042', )([in0Sub20042,in1Sub20042])
Add90743 = keras.layers.Add(name = 'Add90743', )([Con79442,Sub20042])
Cro24098 = keras.layers.Cropping1D(cropping=((0, 1)), name = 'Cro24098', )(Add90743)
Glo43624 = keras.layers.GlobalAveragePooling1D(name = 'Glo43624', )(Cro24098)
Min77375 = keras.layers.Minimum(name = 'Min77375', )([in0Min77375,in1Min77375])
Res68409 = keras.layers.Reshape((1, 1, 1), name = 'Res68409', )(Min77375)
Res49639 = keras.layers.Reshape((1, 1), name = 'Res49639', )(Res68409)
Fla14207 = keras.layers.Flatten(name = 'Fla14207', )(Res49639)
Dot9396 = keras.layers.Dot(axes=(1, 1), name = 'Dot9396', )([in0Dot9396,in1Dot9396])
Add29719 = keras.layers.Add(name = 'Add29719', )([Fla14207,Dot9396])
Con70596 = keras.layers.Concatenate(axis=1, name = 'Con70596', )([Add29719,in0Con70596])
Add68062 = keras.layers.Add(name = 'Add68062', )([Glo43624,Con70596])
model = tf.keras.models.Model(inputs=[in0ELU22614,in0Con79442,in0Sub20042,in1Sub20042,in0Min77375,in1Min77375,in0Dot9396,in1Dot9396,in0Con70596], outputs=Add68062)
in0ELU22614 = tf.constant([[[0.2829]]])
in0Con79442 = tf.constant([[[0.3595], [0.8513]]])
in0Sub20042 = tf.constant([[[0.9305, 0.5682], [0.0944, 0.6376]]])
in1Sub20042 = tf.constant([[[0.5366, 0.3892], [0.0608, 0.8342]]])
in0Min77375 = tf.constant([[[[[0.8025]]]]])
in1Min77375 = tf.constant([[[[[0.9414]]]]])
in0Dot9396 = tf.constant([[0.4956, 0.8124, 0.0512]])
in1Dot9396 = tf.constant([[0.1328, 0.0029, 0.5486]])
in0Con70596 = tf.constant([[0.0178]])
print (np.array2string(model.predict([in0ELU22614,in0Con79442,in0Sub20042,in1Sub20042,in0Min77375,in1Min77375,in0Dot9396,in1Dot9396,in0Con70596],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add68062.png')

LELU22614 = elu_layer([[[0.2829]]], -2.3512226897699406, ELU22614), 
LZer23329 = zero_padding1D_layer(ELU22614, 1, 0, Zer23329), 
LCon79442 = concatenate_layer([Zer23329,[[[0.3595], [0.8513]]]], 2, Con79442), 
LSub20042 = subtract_layer([[[0.9305, 0.5682], [0.0944, 0.6376]]], [[[0.5366, 0.3892], [0.0608, 0.8342]]], Sub20042), 
LAdd90743 = add_layer([Con79442,Sub20042], Add90743), 
LCro24098 = cropping1D_layer(Add90743, 0, 1, Cro24098), 
LGlo43624 = global_average_pooling1D_layer(Cro24098, Glo43624), 
LMin77375 = minimum_layer([[[[[[0.8025]]]]], [[[[[0.9414]]]]]], Min77375), 
LRes68409 = reshape_layer(Min77375, [1, 1, 1], Res68409), 
LRes49639 = reshape_layer(Res68409, [1, 1], Res49639), 
LFla14207 = flatten_layer(Res49639, Fla14207), 
LDot9396 = dot_layer([[0.4956, 0.8124, 0.0512]], [[0.1328, 0.0029, 0.5486]], 1, 1, Dot9396), 
LAdd29719 = add_layer([Fla14207,Dot9396], Add29719), 
LCon70596 = concatenate_layer([Add29719,[[0.0178]]], 1, Con70596), 
LAdd68062 = add_layer([Glo43624,Con70596], Add68062), 
exec_layers([LELU22614,LZer23329,LCon79442,LSub20042,LAdd90743,LCro24098,LGlo43624,LMin77375,LRes68409,LRes49639,LFla14207,LDot9396,LAdd29719,LCon70596,LAdd68062],["ELU22614","Zer23329","Con79442","Sub20042","Add90743","Cro24098","Glo43624","Min77375","Res68409","Res49639","Fla14207","Dot9396","Add29719","Con70596","Add68062"],Add68062,"Add68062")

Actual (Unparsed): [[1.2926599, 0.5563000]]

Expected (Unparsed): [[1.29265996,0.5563]]

Actual:   [[1.2927, 0.5563]]

Expected: [[1.2927, 0.5563]]