import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ReL34209 = tf.keras.layers.Input(shape=([1, 1]))
in0Con35766 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Con94816 = tf.keras.layers.Input(shape=([1, 1, 2, 1]))
in0Up_99737 = tf.keras.layers.Input(shape=([1, 4, 2]))
in0Con74015 = tf.keras.layers.Input(shape=([2, 8, 4]))
in0Sub16268 = tf.keras.layers.Input(shape=([2]))
in1Sub16268 = tf.keras.layers.Input(shape=([2]))
in0Con81857 = tf.keras.layers.Input(shape=([3, 15, 2]))

ReL34209 = keras.layers.ReLU(max_value=7.2148860782409745, negative_slope=5.354395380293331, threshold=4.945130228341386, name = 'ReL34209', input_shape=(1, 1))(in0ReL34209)
Res46141 = keras.layers.Reshape((1, 1, 1), name = 'Res46141', )(ReL34209)
Res55388 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res55388', )(Res46141)
Zer10455 = keras.layers.ZeroPadding3D(padding=((0, 0), (0, 0), (1, 0)), name = 'Zer10455', )(Res55388)
Con35766 = keras.layers.Concatenate(axis=4, name = 'Con35766', )([Zer10455,in0Con35766])
Con94816 = keras.layers.Conv3DTranspose(3, (1, 1, 1),strides=(1, 1, 1), padding='same', name = 'Con94816', )(in0Con94816)
Max97899 = keras.layers.Maximum(name = 'Max97899', )([Con35766,Con94816])
Res4884 = keras.layers.Reshape((1, 1, 6), name = 'Res4884', )(Max97899)
Zer28864 = keras.layers.ZeroPadding2D(padding=((1, 0), (7, 0)), name = 'Zer28864', )(Res4884)
Up_99737 = keras.layers.UpSampling2D(size=(2, 2), name = 'Up_99737', )(in0Up_99737)
Con74015 = keras.layers.Concatenate(axis=3, name = 'Con74015', )([Up_99737,in0Con74015])
Max64387 = keras.layers.Maximum(name = 'Max64387', )([Zer28864,Con74015])
Zer32000 = keras.layers.ZeroPadding2D(padding=((1, 0), (7, 0)), name = 'Zer32000', )(Max64387)
Sub16268 = keras.layers.Subtract(name = 'Sub16268', )([in0Sub16268,in1Sub16268])
Res4182 = keras.layers.Reshape((2, 1), name = 'Res4182', )(Sub16268)
Res50268 = keras.layers.Reshape((2, 1, 1), name = 'Res50268', )(Res4182)
Con80516 = keras.layers.Conv2DTranspose(4, (2, 1),strides=(1, 1), padding='valid', name = 'Con80516', )(Res50268)
Zer86728 = keras.layers.ZeroPadding2D(padding=((0, 0), (14, 0)), name = 'Zer86728', )(Con80516)
Con81857 = keras.layers.Concatenate(axis=3, name = 'Con81857', )([Zer86728,in0Con81857])
Ave97376 = keras.layers.Average(name = 'Ave97376', )([Zer32000,Con81857])
model = tf.keras.models.Model(inputs=[in0ReL34209,in0Con35766,in0Con94816,in0Up_99737,in0Con74015,in0Sub16268,in1Sub16268,in0Con81857], outputs=Ave97376)
w = model.get_layer('Con94816').get_weights() 
w[0] = np.array([[[[[0.9483], [0.924], [0.2347]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con94816').set_weights(w) 
w = model.get_layer('Con80516').get_weights() 
w[0] = np.array([[[[0.084], [0.4038], [0.8514], [0.2163]]], [[[0.8658], [0.6593], [0.6949], [0.3795]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con80516').set_weights(w) 
in0ReL34209 = tf.constant([[[0.216]]])
in0Con35766 = tf.constant([[[[[0.8975, 0.9532], [0.6543, 0.6841]]]]])
in0Con94816 = tf.constant([[[[[0.8294], [0.7105]]]]])
in0Up_99737 = tf.constant([[[[1.0535, 1.1989], [1.5412, 1.5342], [1.705, 1.6894], [1.159, 1.8307]]]])
in0Con74015 = tf.constant([[[[0.353, 0.1152, 0.5691, 0.5476], [0.6152, 0.7789, 0.259, 0.7479], [0.4619, 0.1617, 0.7498, 0.5175], [0.5666, 0.0174, 0.7418, 0.3591], [0.4316, 0.2807, 0.3107, 0.7259], [0.0879, 0.7005, 0.7733, 0.6306], [0.4919, 0.9574, 0.9955, 0.1666], [0.5944, 0.6311, 0.7785, 0.9262]], [[0.8245, 0.3796, 0.7422, 0.9343], [0.7767, 0.2138, 0.6861, 0.3814], [0.2221, 0.8086, 0.7559, 0.1363], [0.1713, 0.3777, 0.8667, 0.7457], [0.611, 0.7574, 0.743, 0.3864], [0.7067, 0.995, 0.6244, 0.0284], [0.7217, 0.9168, 0.1535, 0.8839], [0.6326, 0.8631, 0.2155, 0.075]]]])
in0Sub16268 = tf.constant([[0.1804, 0.7523]])
in1Sub16268 = tf.constant([[0.0097, 0.2098]])
in0Con81857 = tf.constant([[[[0.8852, 0.1668], [0.7398, 0.6368], [0.4992, 0.1299], [0.0553, 0.7895], [0.0756, 0.6186], [0.9067, 0.1998], [0.2668, 0.202], [0.8071, 0.9737], [0.3337, 0.5005], [0.4707, 0.4253], [0.9319, 0.3907], [0.9036, 0.9023], [0.59, 0.3222], [0.9511, 0.6415], [0.4899, 0.8358]], [[0.4944, 0.9545], [0.9821, 0.5166], [0.2618, 0.2653], [0.2526, 0.1723], [0.6588, 0.6538], [0.6948, 0.978], [0.1093, 0.5934], [0.8325, 0.6996], [0.1491, 0.5137], [0.0935, 0.8742], [0.9147, 0.6691], [0.3358, 0.0048], [0.7312, 0.5473], [0.7946, 0.4079], [0.2178, 0.7133]], [[0.0342, 0.3439], [0.7031, 0.5538], [0.5677, 0.4536], [0.7684, 0.8568], [0.0339, 0.3284], [0.4242, 0.5447], [0.2144, 0.2456], [0.7638, 0.1636], [0.7123, 0.7207], [0.9369, 0.9231], [0.8179, 0.5423], [0.9378, 0.1825], [0.9417, 0.3874], [0.0133, 0.2797], [0.0078, 0.9442]]]])
print (np.array2string(model.predict([in0ReL34209,in0Con35766,in0Con94816,in0Up_99737,in0Con74015,in0Sub16268,in1Sub16268,in0Con81857],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave97376.png')

LReL34209 = relu_layer([[[0.216]]], 7.2148860782409745, 5.354395380293331, 4.945130228341386, ReL34209), 
LRes46141 = reshape_layer(ReL34209, [1, 1, 1], Res46141), 
LRes55388 = reshape_layer(Res46141, [1, 1, 1, 1], Res55388), 
LZer10455 = zero_padding3D_layer(Res55388, 0, 0, 0, 0, 1, 0, Zer10455), 
LCon35766 = concatenate_layer([Zer10455,[[[[[0.8975, 0.9532], [0.6543, 0.6841]]]]]], 4, Con35766), 
LCon94816 = conv3D_transpose_layer([[[[[0.8294], [0.7105]]]]], 1, 1, 1,[[[[[0.9483], [0.924], [0.2347]]]]],[0, 0, 0], 1, 1, 1, true, Con94816), 
LMax97899 = maximum_layer([Con35766,Con94816], Max97899), 
LRes4884 = reshape_layer(Max97899, [1, 1, 6], Res4884), 
LZer28864 = zero_padding2D_layer(Res4884, 1, 0, 7, 0, Zer28864), 
LUp_99737 = up_sampling2D_layer([[[[1.0535, 1.1989], [1.5412, 1.5342], [1.705, 1.6894], [1.159, 1.8307]]]], 2, 2, Up_99737), 
LCon74015 = concatenate_layer([Up_99737,[[[[0.353, 0.1152, 0.5691, 0.5476], [0.6152, 0.7789, 0.259, 0.7479], [0.4619, 0.1617, 0.7498, 0.5175], [0.5666, 0.0174, 0.7418, 0.3591], [0.4316, 0.2807, 0.3107, 0.7259], [0.0879, 0.7005, 0.7733, 0.6306], [0.4919, 0.9574, 0.9955, 0.1666], [0.5944, 0.6311, 0.7785, 0.9262]], [[0.8245, 0.3796, 0.7422, 0.9343], [0.7767, 0.2138, 0.6861, 0.3814], [0.2221, 0.8086, 0.7559, 0.1363], [0.1713, 0.3777, 0.8667, 0.7457], [0.611, 0.7574, 0.743, 0.3864], [0.7067, 0.995, 0.6244, 0.0284], [0.7217, 0.9168, 0.1535, 0.8839], [0.6326, 0.8631, 0.2155, 0.075]]]]], 3, Con74015), 
LMax64387 = maximum_layer([Zer28864,Con74015], Max64387), 
LZer32000 = zero_padding2D_layer(Max64387, 1, 0, 7, 0, Zer32000), 
LSub16268 = subtract_layer([[0.1804, 0.7523]], [[0.0097, 0.2098]], Sub16268), 
LRes4182 = reshape_layer(Sub16268, [2, 1], Res4182), 
LRes50268 = reshape_layer(Res4182, [2, 1, 1], Res50268), 
LCon80516 = conv2D_transpose_layer(Res50268, 2, 1,[[[[0.084], [0.4038], [0.8514], [0.2163]]], [[[0.8658], [0.6593], [0.6949], [0.3795]]]],[0, 0, 0, 0], 1, 1, false, Con80516), 
LZer86728 = zero_padding2D_layer(Con80516, 0, 0, 14, 0, Zer86728), 
LCon81857 = concatenate_layer([Zer86728,[[[[0.8852, 0.1668], [0.7398, 0.6368], [0.4992, 0.1299], [0.0553, 0.7895], [0.0756, 0.6186], [0.9067, 0.1998], [0.2668, 0.202], [0.8071, 0.9737], [0.3337, 0.5005], [0.4707, 0.4253], [0.9319, 0.3907], [0.9036, 0.9023], [0.59, 0.3222], [0.9511, 0.6415], [0.4899, 0.8358]], [[0.4944, 0.9545], [0.9821, 0.5166], [0.2618, 0.2653], [0.2526, 0.1723], [0.6588, 0.6538], [0.6948, 0.978], [0.1093, 0.5934], [0.8325, 0.6996], [0.1491, 0.5137], [0.0935, 0.8742], [0.9147, 0.6691], [0.3358, 0.0048], [0.7312, 0.5473], [0.7946, 0.4079], [0.2178, 0.7133]], [[0.0342, 0.3439], [0.7031, 0.5538], [0.5677, 0.4536], [0.7684, 0.8568], [0.0339, 0.3284], [0.4242, 0.5447], [0.2144, 0.2456], [0.7638, 0.1636], [0.7123, 0.7207], [0.9369, 0.9231], [0.8179, 0.5423], [0.9378, 0.1825], [0.9417, 0.3874], [0.0133, 0.2797], [0.0078, 0.9442]]]]], 3, Con81857), 
LAve97376 = average_layer([Zer32000,Con81857], Ave97376), 
exec_layers([LReL34209,LRes46141,LRes55388,LZer10455,LCon35766,LCon94816,LMax97899,LRes4884,LZer28864,LUp_99737,LCon74015,LMax64387,LZer32000,LSub16268,LRes4182,LRes50268,LCon80516,LZer86728,LCon81857,LAve97376],["ReL34209","Res46141","Res55388","Zer10455","Con35766","Con94816","Max97899","Res4884","Zer28864","Up_99737","Con74015","Max64387","Zer32000","Sub16268","Res4182","Res50268","Con80516","Zer86728","Con81857","Ave97376"],Ave97376,"Ave97376")

Actual (Unparsed): [[[[0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.4426000, 0.0834000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.3699000, 0.3184000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.2496000, 0.0649500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0276500, 0.3947500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0378000, 0.3093000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.4533500, 0.0999000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.1334000, 0.1010000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.4035500, 0.4868500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.1668500, 0.2502500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.2353500, 0.2126500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.4659500, 0.1953500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.4518000, 0.4511500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.2950000, 0.1611000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.4755500, 0.3207500], [0.0071694, 0.0344643, 0.0726670, 0.0184612, 0.2449500, 0.4179000]], [[0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.2472000, 0.4772500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.4910500, 0.2583000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.1309000, 0.1326500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.1263000, 0.0861500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.3294000, 0.3269000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.3474000, 0.4890000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0546500, 0.2967000], [0.5267500, 0.5994500, 0.1765000, 0.0576000, 0.7008000, 0.6236000], [0.5267500, 0.5994500, 0.3076000, 0.3894500, 0.2040500, 0.6308000], [0.7706000, 0.7671000, 0.2309500, 0.0808500, 0.4216500, 0.6958500], [0.7706000, 0.7671000, 0.2833000, 0.0087000, 0.8282500, 0.5141000], [0.8525000, 0.8447000, 0.2158000, 0.1403500, 0.3232500, 0.3653500], [0.8525000, 0.8447000, 0.0439500, 0.3502500, 0.7522500, 0.5889500], [0.5795000, 0.9153500, 0.2459500, 0.4787000, 0.8950500, 0.2872500], [0.6761810, 1.0811520, 0.5874520, 0.4066117, 0.4981500, 0.8197500]], [[0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0171000, 0.1719500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.3515500, 0.2769000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.2838500, 0.2268000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.3842000, 0.4284000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0169500, 0.1642000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.2121000, 0.2723500], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.1072000, 0.1228000], [0.5267500, 0.5994500, 0.4122500, 0.1898000, 0.7530000, 0.5489500], [0.5267500, 0.5994500, 0.3883500, 0.1069000, 0.6992000, 0.5510500], [0.7706000, 0.7671000, 0.1110500, 0.4043000, 0.8464000, 0.5297000], [0.7706000, 0.7671000, 0.0856500, 0.1888500, 0.8423000, 0.6440000], [0.8525000, 0.8447000, 0.3055000, 0.3787000, 0.8404000, 0.2844500], [0.8525000, 0.8447000, 0.3533500, 0.4975000, 0.7830500, 0.2079000], [0.5795000, 0.9153500, 0.3608500, 0.4584000, 0.0834000, 0.5818000], [0.8143483, 1.0941852, 0.6650916, 0.5344894, 0.3321510, 0.8141500]]]]

Expected (Unparsed): [[[[0,0,0,0,0.4426,0.0834],[0,0,0,0,0.3699,0.3184],[0,0,0,0,0.2496,0.06495],[0,0,0,0,0.02765,0.39475],[0,0,0,0,0.0378,0.3093],[0,0,0,0,0.45335,0.0999],[0,0,0,0,0.1334,0.101],[0,0,0,0,0.40355,0.48685],[0,0,0,0,0.16685,0.25025],[0,0,0,0,0.23535,0.21265],[0,0,0,0,0.46595,0.19535],[0,0,0,0,0.4518,0.45115],[0,0,0,0,0.295,0.1611],[0,0,0,0,0.47555,0.32075],[0.007169400000000001,0.03446433,0.07266699000000001,0.018461205,0.24495,0.4179]],[[0,0,0,0,0.2472,0.47725],[0,0,0,0,0.49105,0.2583],[0,0,0,0,0.1309,0.13265],[0,0,0,0,0.1263,0.08615],[0,0,0,0,0.3294,0.3269],[0,0,0,0,0.3474,0.489],[0,0,0,0,0.05465,0.2967],[0.52675,0.59945,0.1765,0.0576,0.7008000000000001,0.6235999999999999],[0.52675,0.59945,0.3076,0.38945,0.20405,0.6308],[0.7706,0.7671,0.23095,0.08085,0.42165,0.69585],[0.7706,0.7671,0.2833,0.0087,0.8282499999999999,0.5141],[0.8525,0.8447,0.2158,0.14035,0.32325,0.36535],[0.8525,0.8447,0.04395,0.35025,0.75225,0.5889500000000001],[0.5795,0.91535,0.24595,0.4787,0.89505,0.28725],[0.6761810300000001,1.081152005,0.5874519650000001,0.4066117,0.49815,0.81975]],[[0,0,0,0,0.0171,0.17195],[0,0,0,0,0.35155,0.2769],[0,0,0,0,0.28385,0.2268],[0,0,0,0,0.3842,0.4284],[0,0,0,0,0.01695,0.1642],[0,0,0,0,0.2121,0.27235],[0,0,0,0,0.1072,0.1228],[0.52675,0.59945,0.41225,0.1898,0.753,0.54895],[0.52675,0.59945,0.38835,0.1069,0.6992,0.55105],[0.7706,0.7671,0.11105,0.4043,0.8464,0.5297000000000001],[0.7706,0.7671,0.08565,0.18885,0.8423,0.644],[0.8525,0.8447,0.3055,0.3787,0.8404,0.28445],[0.8525,0.8447,0.35335,0.4975,0.78305,0.2079],[0.5795,0.91535,0.36085,0.4584,0.0834,0.5818],[0.81434825,1.094185125,0.6650916250000001,0.5344893749999999,0.33215100000000003,0.81415]]]]

Actual:   [[[[0, 0, 0, 0, 0.4426, 0.0834], [0, 0, 0, 0, 0.3699, 0.3184], [0, 0, 0, 0, 0.2496, 0.065], [0, 0, 0, 0, 0.0277, 0.3948], [0, 0, 0, 0, 0.0378, 0.3093], [0, 0, 0, 0, 0.4534, 0.0999], [0, 0, 0, 0, 0.1334, 0.101], [0, 0, 0, 0, 0.4036, 0.4869], [0, 0, 0, 0, 0.1669, 0.2503], [0, 0, 0, 0, 0.2354, 0.2127], [0, 0, 0, 0, 0.466, 0.1954], [0, 0, 0, 0, 0.4518, 0.4512], [0, 0, 0, 0, 0.295, 0.1611], [0, 0, 0, 0, 0.4756, 0.3208], [0.0072, 0.0345, 0.0727, 0.0185, 0.245, 0.4179]], [[0, 0, 0, 0, 0.2472, 0.4773], [0, 0, 0, 0, 0.4911, 0.2583], [0, 0, 0, 0, 0.1309, 0.1327], [0, 0, 0, 0, 0.1263, 0.0862], [0, 0, 0, 0, 0.3294, 0.3269], [0, 0, 0, 0, 0.3474, 0.489], [0, 0, 0, 0, 0.0547, 0.2967], [0.5268, 0.5995, 0.1765, 0.0576, 0.7008, 0.6236], [0.5268, 0.5995, 0.3076, 0.3895, 0.2041, 0.6308], [0.7706, 0.7671, 0.231, 0.0809, 0.4217, 0.6959], [0.7706, 0.7671, 0.2833, 0.0087, 0.8283, 0.5141], [0.8525, 0.8447, 0.2158, 0.1404, 0.3233, 0.3654], [0.8525, 0.8447, 0.044, 0.3503, 0.7523, 0.589], [0.5795, 0.9154, 0.246, 0.4787, 0.8951, 0.2873], [0.6762, 1.0812, 0.5875, 0.4067, 0.4982, 0.8198]], [[0, 0, 0, 0, 0.0171, 0.172], [0, 0, 0, 0, 0.3516, 0.2769], [0, 0, 0, 0, 0.2839, 0.2268], [0, 0, 0, 0, 0.3842, 0.4284], [0, 0, 0, 0, 0.017, 0.1642], [0, 0, 0, 0, 0.2121, 0.2724], [0, 0, 0, 0, 0.1072, 0.1228], [0.5268, 0.5995, 0.4123, 0.1898, 0.753, 0.549], [0.5268, 0.5995, 0.3884, 0.1069, 0.6992, 0.5511], [0.7706, 0.7671, 0.1111, 0.4043, 0.8464, 0.5297], [0.7706, 0.7671, 0.0857, 0.1889, 0.8423, 0.644], [0.8525, 0.8447, 0.3055, 0.3787, 0.8404, 0.2845], [0.8525, 0.8447, 0.3534, 0.4975, 0.7831, 0.2079], [0.5795, 0.9154, 0.3609, 0.4584, 0.0834, 0.5818], [0.8144, 1.0942, 0.6651, 0.5345, 0.3322, 0.8142]]]]

Expected: [[[[0, 0, 0, 0, 0.4426, 0.0834], [0, 0, 0, 0, 0.3699, 0.3184], [0, 0, 0, 0, 0.2496, 0.065], [0, 0, 0, 0, 0.0277, 0.3948], [0, 0, 0, 0, 0.0378, 0.3093], [0, 0, 0, 0, 0.4534, 0.0999], [0, 0, 0, 0, 0.1334, 0.101], [0, 0, 0, 0, 0.4036, 0.4869], [0, 0, 0, 0, 0.1669, 0.2503], [0, 0, 0, 0, 0.2354, 0.2127], [0, 0, 0, 0, 0.466, 0.1954], [0, 0, 0, 0, 0.4518, 0.4512], [0, 0, 0, 0, 0.295, 0.1611], [0, 0, 0, 0, 0.4756, 0.3208], [0.0072, 0.0345, 0.0727, 0.0185, 0.245, 0.4179]], [[0, 0, 0, 0, 0.2472, 0.4773], [0, 0, 0, 0, 0.4911, 0.2583], [0, 0, 0, 0, 0.1309, 0.1327], [0, 0, 0, 0, 0.1263, 0.0862], [0, 0, 0, 0, 0.3294, 0.3269], [0, 0, 0, 0, 0.3474, 0.489], [0, 0, 0, 0, 0.0547, 0.2967], [0.5268, 0.5995, 0.1765, 0.0576, 0.7009, 0.6236], [0.5268, 0.5995, 0.3076, 0.3895, 0.2041, 0.6308], [0.7706, 0.7671, 0.231, 0.0809, 0.4217, 0.6959], [0.7706, 0.7671, 0.2833, 0.0087, 0.8283, 0.5141], [0.8525, 0.8447, 0.2158, 0.1404, 0.3233, 0.3654], [0.8525, 0.8447, 0.044, 0.3503, 0.7523, 0.589], [0.5795, 0.9154, 0.246, 0.4787, 0.8951, 0.2873], [0.6762, 1.0812, 0.5875, 0.4067, 0.4982, 0.8198]], [[0, 0, 0, 0, 0.0171, 0.172], [0, 0, 0, 0, 0.3516, 0.2769], [0, 0, 0, 0, 0.2839, 0.2268], [0, 0, 0, 0, 0.3842, 0.4284], [0, 0, 0, 0, 0.017, 0.1642], [0, 0, 0, 0, 0.2121, 0.2724], [0, 0, 0, 0, 0.1072, 0.1228], [0.5268, 0.5995, 0.4123, 0.1898, 0.753, 0.549], [0.5268, 0.5995, 0.3884, 0.1069, 0.6992, 0.5511], [0.7706, 0.7671, 0.1111, 0.4043, 0.8464, 0.5298], [0.7706, 0.7671, 0.0857, 0.1889, 0.8423, 0.644], [0.8525, 0.8447, 0.3055, 0.3787, 0.8404, 0.2845], [0.8525, 0.8447, 0.3534, 0.4975, 0.7831, 0.2079], [0.5795, 0.9154, 0.3609, 0.4584, 0.0834, 0.5818], [0.8144, 1.0942, 0.6651, 0.5345, 0.3322, 0.8142]]]]