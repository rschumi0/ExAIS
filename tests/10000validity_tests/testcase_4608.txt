import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0LST77458 = tf.keras.layers.Input(shape=([2, 1]))
in0Con13891 = tf.keras.layers.Input(shape=([3, 3]))
in0Max53801 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in1Max53801 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))

LST77458 = keras.layers.LSTM(3,recurrent_activation='sigmoid', name = 'LST77458', )(in0LST77458)
Res17985 = keras.layers.Reshape((3, 1), name = 'Res17985', )(LST77458)
Con13891 = keras.layers.Concatenate(axis=2, name = 'Con13891', )([Res17985,in0Con13891])
Max53801 = keras.layers.Maximum(name = 'Max53801', )([in0Max53801,in1Max53801])
Res29436 = keras.layers.Reshape((2, 1, 4), name = 'Res29436', )(Max53801)
Res94146 = keras.layers.Reshape((2, 4), name = 'Res94146', )(Res29436)
Zer16271 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer16271', )(Res94146)
Dot45026 = keras.layers.Dot(axes=(1, 1), name = 'Dot45026', )([Con13891,Zer16271])
ReL23580 = keras.layers.ReLU(max_value=6.950284580206642, negative_slope=1.5002114941684144, threshold=3.778397381631006, name = 'ReL23580', )(Dot45026)
model = tf.keras.models.Model(inputs=[in0LST77458,in0Con13891,in0Max53801,in1Max53801], outputs=ReL23580)
w = model.get_layer('LST77458').get_weights() 
w[0] = np.array([[1, 8, 5, 3, 3, 6, 3, 1, 3, 10, 1, 7]])
w[1] = np.array([[10, 1, 8, 1, 2, 3, 9, 6, 3, 3, 1, 1], [10, 9, 1, 5, 8, 7, 2, 1, 6, 1, 6, 5], [1, 1, 8, 2, 6, 6, 5, 7, 6, 6, 4, 9]])
w[2] = np.array([3, 10, 7, 1, 9, 10, 1, 5, 10, 10, 4, 10])
model.get_layer('LST77458').set_weights(w) 
in0LST77458 = tf.constant([[[3], [6]]])
in0Con13891 = tf.constant([[[0.8797, 0.6384, 0.2086], [0.646, 0.465, 0.1494], [0.0355, 0.373, 0.9805]]])
in0Max53801 = tf.constant([[[[[0.2478, 0.7956], [0.6622, 0.8261]]], [[[0.2299, 0.4229], [0.7653, 0.4996]]]]])
in1Max53801 = tf.constant([[[[[0.542, 0.9876], [0.9239, 0.3414]]], [[[0.0953, 0.7291], [0.1255, 0.0433]]]]])
print (np.array2string(model.predict([in0LST77458,in0Con13891,in0Max53801,in1Max53801],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='ReL23580.png')

LLST77458 = lstm_layer([[[3], [6]]],[[1, 8, 5, 3, 3, 6, 3, 1, 3, 10, 1, 7]],[[10, 1, 8, 1, 2, 3, 9, 6, 3, 3, 1, 1], [10, 9, 1, 5, 8, 7, 2, 1, 6, 1, 6, 5], [1, 1, 8, 2, 6, 6, 5, 7, 6, 6, 4, 9]],[3, 10, 7, 1, 9, 10, 1, 5, 10, 10, 4, 10], LST77458), 
LRes17985 = reshape_layer(LST77458, [3, 1], Res17985), 
LCon13891 = concatenate_layer([Res17985,[[[0.8797, 0.6384, 0.2086], [0.646, 0.465, 0.1494], [0.0355, 0.373, 0.9805]]]], 2, Con13891), 
LMax53801 = maximum_layer([[[[[[0.2478, 0.7956], [0.6622, 0.8261]]], [[[0.2299, 0.4229], [0.7653, 0.4996]]]]], [[[[[0.542, 0.9876], [0.9239, 0.3414]]], [[[0.0953, 0.7291], [0.1255, 0.0433]]]]]], Max53801), 
LRes29436 = reshape_layer(Max53801, [2, 1, 4], Res29436), 
LRes94146 = reshape_layer(Res29436, [2, 4], Res94146), 
LZer16271 = zero_padding1D_layer(Res94146, 1, 0, Zer16271), 
LDot45026 = dot_layer(Con13891,Zer16271, 1, 1, Dot45026), 
LReL23580 = relu_layer(Dot45026, 6.950284580206642, 1.5002114941684144, 3.778397381631006, ReL23580), 
exec_layers([LLST77458,LRes17985,LCon13891,LMax53801,LRes29436,LRes94146,LZer16271,LDot45026,LReL23580],["LST77458","Res17985","Con13891","Max53801","Res29436","Res94146","Zer16271","Dot45026","ReL23580"],ReL23580,"ReL23580")

Actual (Unparsed): [[[-4.5520385, -3.1856260, -3.2253978, -3.7511079], [-5.1308792, -4.6724457, -4.7322518, -4.8411839], [-5.1616497, -4.5714581, -4.5956384, -4.8125436], [-5.2087428, -4.3745678, -4.3355964, -4.7483498]]]

Expected (Unparsed): [[[-4.5520384892647465,-3.185625988497257,-3.225397730560779,-3.7511078774095385],[-5.13087922948342,-4.672445801264631,-4.732251882500805,-4.841183964335592],[-5.161649692387435,-4.571458089397213,-4.595638348239071,-4.812543576721572],[-5.208742756390301,-4.374567797545126,-4.3355963234934345,-4.748349766919944]]]

Actual:   [[[-4.552, -3.1856, -3.2253, -3.7511], [-5.1308, -4.6724, -4.7322, -4.8411], [-5.1616, -4.5714, -4.5956, -4.8125], [-5.2087, -4.3745, -4.3355, -4.7483]]]

Expected: [[[-4.552, -3.1856, -3.2253, -3.7511], [-5.1308, -4.6724, -4.7322, -4.8411], [-5.1616, -4.5714, -4.5956, -4.8125], [-5.2087, -4.3745, -4.3355, -4.7483]]]