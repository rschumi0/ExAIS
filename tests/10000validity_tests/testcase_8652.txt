import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min33931 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in1Min33931 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0GRU63217 = tf.keras.layers.Input(shape=([1, 2]))
in0Con21360 = tf.keras.layers.Input(shape=([5]))

Min33931 = keras.layers.Minimum(name = 'Min33931', )([in0Min33931,in1Min33931])
Fla97076 = keras.layers.Flatten(name = 'Fla97076', )(Min33931)
GRU63217 = keras.layers.GRU(3,reset_after=True, recurrent_activation='sigmoid', name = 'GRU63217', )(in0GRU63217)
Lea87118 = keras.layers.LeakyReLU(alpha=7.73302627416558, name = 'Lea87118', )(GRU63217)
Con21360 = keras.layers.Concatenate(axis=1, name = 'Con21360', )([Lea87118,in0Con21360])
Mul14275 = keras.layers.Multiply(name = 'Mul14275', )([Fla97076,Con21360])
model = tf.keras.models.Model(inputs=[in0Min33931,in1Min33931,in0GRU63217,in0Con21360], outputs=Mul14275)
w = model.get_layer('GRU63217').get_weights() 
w[0] = np.array([[2, 8, 2, 7, 5, 2, 7, 3, 8], [8, 3, 4, 9, 3, 7, 4, 3, 9]])
w[1] = np.array([[5, 1, 4, 5, 2, 4, 5, 8, 9], [1, 2, 8, 1, 3, 4, 3, 7, 4], [6, 7, 8, 7, 8, 8, 4, 1, 3]])
w[2] = np.array([[1, 10, 1, 8, 5, 5, 7, 9, 7], [5, 6, 9, 5, 4, 2, 5, 7, 6]])
model.get_layer('GRU63217').set_weights(w) 
in0Min33931 = tf.constant([[[[[0.7497, 0.8813]], [[0.0767, 0.2238]]], [[[0.3457, 0.0111]], [[0.7072, 0.4427]]]]])
in1Min33931 = tf.constant([[[[[0.6303, 0.3951]], [[0.647, 0.7663]]], [[[0.4768, 0.7032]], [[0.8117, 0.3251]]]]])
in0GRU63217 = tf.constant([[[6, 7]]])
in0Con21360 = tf.constant([[0.2683, 0.1486, 0.1102, 0.0582, 0.8031]])
print (np.array2string(model.predict([in0Min33931,in1Min33931,in0GRU63217,in0Con21360],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul14275.png')

LMin33931 = minimum_layer([[[[[[0.7497, 0.8813]], [[0.0767, 0.2238]]], [[[0.3457, 0.0111]], [[0.7072, 0.4427]]]]], [[[[[0.6303, 0.3951]], [[0.647, 0.7663]]], [[[0.4768, 0.7032]], [[0.8117, 0.3251]]]]]], Min33931), 
LFla97076 = flatten_layer(Min33931, Fla97076), 
LGRU63217 = gru_layer([[[6, 7]]],[[2, 8, 2, 7, 5, 2, 7, 3, 8], [8, 3, 4, 9, 3, 7, 4, 3, 9]],[[5, 1, 4, 5, 2, 4, 5, 8, 9], [1, 2, 8, 1, 3, 4, 3, 7, 4], [6, 7, 8, 7, 8, 8, 4, 1, 3]],[[1, 10, 1, 8, 5, 5, 7, 9, 7], [5, 6, 9, 5, 4, 2, 5, 7, 6]], true, GRU63217), 
LLea87118 = leaky_relu_layer(GRU63217, 7.73302627416558, Lea87118), 
LCon21360 = concatenate_layer([Lea87118,[[0.2683, 0.1486, 0.1102, 0.0582, 0.8031]]], 1, Con21360), 
LMul14275 = multiply_layer([Fla97076,Con21360], Mul14275), 
exec_layers([LMin33931,LFla97076,LGRU63217,LLea87118,LCon21360,LMul14275],["Min33931","Fla97076","GRU63217","Lea87118","Con21360","Mul14275"],Mul14275,"Mul14275")

Actual (Unparsed): [[0.0000000, 0.0000000, 0.0000000, 0.0600455, 0.0513710, 0.0012232, 0.0411590, 0.2610878]]

Expected (Unparsed): [[0.0,0.0,0.0,0.060045539999999994,0.05137102,0.0012232200000000001,0.04115904,0.26108781000000003]]

Actual:   [[0, 0, 0, 0.0601, 0.0514, 0.0013, 0.0412, 0.2611]]

Expected: [[0, 0, 0, 0.0601, 0.0514, 0.0013, 0.0412, 0.2611]]