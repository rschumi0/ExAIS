import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ReL5390 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Con28207 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0Con12010 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))

ReL5390 = keras.layers.ReLU(max_value=8.854283639548548, negative_slope=9.294102472087264, threshold=9.145890586398664, name = 'ReL5390', input_shape=(2, 2, 1))(in0ReL5390)
Res25392 = keras.layers.Reshape((2, 2, 1, 1), name = 'Res25392', )(ReL5390)
Con28207 = keras.layers.Concatenate(axis=4, name = 'Con28207', )([Res25392,in0Con28207])
Con12010 = keras.layers.Conv3D(3, (1, 1, 1),strides=(1, 1, 1), padding='same', dilation_rate=(1, 1, 1), name = 'Con12010', )(in0Con12010)
Zer81150 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (0, 0)), name = 'Zer81150', )(Con12010)
Mul1301 = keras.layers.Multiply(name = 'Mul1301', )([Con28207,Zer81150])
Mas2495 = keras.layers.Masking(mask_value=2, name = 'Mas2495', )(Mul1301)
Res69069 = keras.layers.Reshape((2, 2, 3), name = 'Res69069', )(Mas2495)
Glo48537 = keras.layers.GlobalAveragePooling2D(name = 'Glo48537', )(Res69069)
ELU41252 = keras.layers.ELU(alpha=-0.5321705615030901, name = 'ELU41252', )(Glo48537)
model = tf.keras.models.Model(inputs=[in0ReL5390,in0Con28207,in0Con12010], outputs=ELU41252)
w = model.get_layer('Con12010').get_weights() 
w[0] = np.array([[[[[0.7929, 0.8232, 0.5333]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con12010').set_weights(w) 
in0ReL5390 = tf.constant([[[[0.8366], [0.6721]], [[0.1269], [0.9034]]]])
in0Con28207 = tf.constant([[[[[0.9991, 0.1787]], [[0.7421, 0.0342]]], [[[0.3726, 0.3664]], [[0.8072, 0.7177]]]]])
in0Con12010 = tf.constant([[[[[0.7377]]]]])
print (np.array2string(model.predict([in0ReL5390,in0Con28207,in0Con12010],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='ELU41252.png')

LReL5390 = relu_layer([[[[0.8366], [0.6721]], [[0.1269], [0.9034]]]], 8.854283639548548, 9.294102472087264, 9.145890586398664, ReL5390), 
LRes25392 = reshape_layer(ReL5390, [2, 2, 1, 1], Res25392), 
LCon28207 = concatenate_layer([Res25392,[[[[[0.9991, 0.1787]], [[0.7421, 0.0342]]], [[[0.3726, 0.3664]], [[0.8072, 0.7177]]]]]], 4, Con28207), 
LCon12010 = conv3D_layer([[[[[0.7377]]]]], 1, 1, 1,[[[[[0.7929, 0.8232, 0.5333]]]]],[0, 0, 0], 1, 1, 1, true, 1, 1, 1, Con12010), 
LZer81150 = zero_padding3D_layer(Con12010, 1, 0, 1, 0, 0, 0, Zer81150), 
LMul1301 = multiply_layer([Con28207,Zer81150], Mul1301), 
LMas2495 = masking_layer(Mul1301, 2, Mas2495), 
LRes69069 = reshape_layer(Mas2495, [2, 2, 3], Res69069), 
LGlo48537 = global_average_pooling2D_layer(Res69069, Glo48537), 
LELU41252 = elu_layer(Glo48537, -0.5321705615030901, ELU41252), 
exec_layers([LReL5390,LRes25392,LCon28207,LCon12010,LZer81150,LMul1301,LMas2495,LRes69069,LGlo48537,LELU41252],["ReL5390","Res25392","Con28207","Con12010","Zer81150","Mul1301","Mas2495","Res69069","Glo48537","ELU41252"],ELU41252,"ELU41252")

Actual (Unparsed): [[0.5321633, 0.1225480, 0.0705886]]

Expected (Unparsed): [[0.5321633006409111,0.12254802235200002,0.07058855993925]]

Actual:   [[0.5322, 0.1226, 0.0706]]

Expected: [[0.5322, 0.1226, 0.0706]]