import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat66108 = tf.keras.layers.Input(shape=([4, 3, 3]))
in0Add83375 = tf.keras.layers.Input(shape=([1, 2]))
in1Add83375 = tf.keras.layers.Input(shape=([1, 2]))
in0Con22884 = tf.keras.layers.Input(shape=([1]))
in0Fla55417 = tf.keras.layers.Input(shape=([2, 3, 2]))
in0Con5422 = tf.keras.layers.Input(shape=([33]))

Bat66108 = keras.layers.BatchNormalization(axis=1, epsilon=0.10423087000400089,  name = 'Bat66108', )(in0Bat66108)
Res52631 = keras.layers.Reshape((4, 9), name = 'Res52631', )(Bat66108)
Fla18469 = keras.layers.Flatten(name = 'Fla18469', )(Res52631)
Add83375 = keras.layers.Add(name = 'Add83375', )([in0Add83375,in1Add83375])
Fla3359 = keras.layers.Flatten(name = 'Fla3359', )(Add83375)
Con22884 = keras.layers.Concatenate(axis=1, name = 'Con22884', )([Fla3359,in0Con22884])
Fla55417 = keras.layers.Flatten(name = 'Fla55417', )(in0Fla55417)
Res1971 = keras.layers.Reshape((12, 1), name = 'Res1971', )(Fla55417)
LST82996 = keras.layers.LSTM(3,recurrent_activation='sigmoid', name = 'LST82996', )(Res1971)
Min5096 = keras.layers.Minimum(name = 'Min5096', )([Con22884,LST82996])
Con5422 = keras.layers.Concatenate(axis=1, name = 'Con5422', )([Min5096,in0Con5422])
Ave93274 = keras.layers.Average(name = 'Ave93274', )([Fla18469,Con5422])
model = tf.keras.models.Model(inputs=[in0Bat66108,in0Add83375,in1Add83375,in0Con22884,in0Fla55417,in0Con5422], outputs=Ave93274)
w = model.get_layer('Bat66108').get_weights() 
w[0] = np.array([0.3915, 0.702, 0.8213, 0.6661])
w[1] = np.array([0.2553, 0.2201, 0.8868, 0.6067])
w[2] = np.array([0.4414, 0.4072, 0.2905, 0.9511])
w[3] = np.array([0.9382, 0.121, 0.8577, 0.773])
model.get_layer('Bat66108').set_weights(w) 
w = model.get_layer('LST82996').get_weights() 
w[0] = np.array([[4, 9, 1, 1, 2, 8, 5, 6, 8, 3, 10, 7]])
w[1] = np.array([[10, 2, 7, 8, 4, 8, 4, 1, 6, 9, 2, 8], [3, 1, 3, 3, 1, 8, 8, 2, 1, 5, 2, 6], [4, 1, 6, 10, 6, 8, 5, 8, 8, 6, 5, 10]])
w[2] = np.array([8, 9, 6, 6, 10, 3, 4, 5, 6, 6, 1, 7])
model.get_layer('LST82996').set_weights(w) 
in0Bat66108 = tf.constant([[[[1.3539, 1.2338, 1.0097], [1.3599, 1.2645, 1.6934], [1.6074, 1.9058, 1.4146]], [[1.5435, 1.9534, 1.1384], [1.3393, 1.4407, 1.5452], [1.2437, 1.7325, 1.6372]], [[1.8756, 1.5807, 1.1618], [1.1603, 1.4477, 1.8299], [1.0795, 1.9678, 1.2678]], [[1.6713, 1.5514, 1.385], [1.467, 1.5915, 1.6239], [1.8226, 1.9069, 1.9432]]]])
in0Add83375 = tf.constant([[[0.4032, 0.3714]]])
in1Add83375 = tf.constant([[[0.9738, 0.3057]]])
in0Con22884 = tf.constant([[0.9239]])
in0Fla55417 = tf.constant([[[[1.7291, 1.3764], [1.2868, 1.5277], [1.7922, 1.5036]], [[1.707, 1.5735], [1.1657, 1.1294], [1.8657, 1.4398]]]])
in0Con5422 = tf.constant([[0.6532, 0.2602, 0.3823, 0.4359, 0.1529, 0.8717, 0.2732, 0.8731, 0.1784, 0.4133, 0.1794, 0.1728, 0.6072, 0.3912, 0.1329, 0.7449, 0.8481, 0.8129, 0.2271, 0.1366, 0.7402, 0.7543, 0.5084, 0.8677, 0.6322, 0.8535, 0.3509, 0.6721, 0.9038, 0.2451, 0.331, 0.1189, 0.6467]])
print (np.array2string(model.predict([in0Bat66108,in0Add83375,in1Add83375,in0Con22884,in0Fla55417,in0Con5422],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave93274.png')

LBat66108 = batch_normalization_layer([[[[1.3539, 1.2338, 1.0097], [1.3599, 1.2645, 1.6934], [1.6074, 1.9058, 1.4146]], [[1.5435, 1.9534, 1.1384], [1.3393, 1.4407, 1.5452], [1.2437, 1.7325, 1.6372]], [[1.8756, 1.5807, 1.1618], [1.1603, 1.4477, 1.8299], [1.0795, 1.9678, 1.2678]], [[1.6713, 1.5514, 1.385], [1.467, 1.5915, 1.6239], [1.8226, 1.9069, 1.9432]]]], 1, 0.10423087000400089, [0.3915, 0.702, 0.8213, 0.6661], [0.2553, 0.2201, 0.8868, 0.6067], [0.4414, 0.4072, 0.2905, 0.9511], [0.9382, 0.121, 0.8577, 0.773], Bat66108), 
LRes52631 = reshape_layer(Bat66108, [4, 9], Res52631), 
LFla18469 = flatten_layer(Res52631, Fla18469), 
LAdd83375 = add_layer([[[[0.4032, 0.3714]]], [[[0.9738, 0.3057]]]], Add83375), 
LFla3359 = flatten_layer(Add83375, Fla3359), 
LCon22884 = concatenate_layer([Fla3359,[[0.9239]]], 1, Con22884), 
LFla55417 = flatten_layer([[[[1.7291, 1.3764], [1.2868, 1.5277], [1.7922, 1.5036]], [[1.707, 1.5735], [1.1657, 1.1294], [1.8657, 1.4398]]]], Fla55417), 
LRes1971 = reshape_layer(Fla55417, [12, 1], Res1971), 
LLST82996 = lstm_layer(Res1971,[[4, 9, 1, 1, 2, 8, 5, 6, 8, 3, 10, 7]],[[10, 2, 7, 8, 4, 8, 4, 1, 6, 9, 2, 8], [3, 1, 3, 3, 1, 8, 8, 2, 1, 5, 2, 6], [4, 1, 6, 10, 6, 8, 5, 8, 8, 6, 5, 10]],[8, 9, 6, 6, 10, 3, 4, 5, 6, 6, 1, 7], LST82996), 
LMin5096 = minimum_layer([Con22884,LST82996], Min5096), 
LCon5422 = concatenate_layer([Min5096,[[0.6532, 0.2602, 0.3823, 0.4359, 0.1529, 0.8717, 0.2732, 0.8731, 0.1784, 0.4133, 0.1794, 0.1728, 0.6072, 0.3912, 0.1329, 0.7449, 0.8481, 0.8129, 0.2271, 0.1366, 0.7402, 0.7543, 0.5084, 0.8677, 0.6322, 0.8535, 0.3509, 0.6721, 0.9038, 0.2451, 0.331, 0.1189, 0.6467]]], 1, Con5422), 
LAve93274 = average_layer([Fla18469,Con5422], Ave93274), 
exec_layers([LBat66108,LRes52631,LFla18469,LAdd83375,LFla3359,LCon22884,LFla55417,LRes1971,LLST82996,LMin5096,LCon5422,LAve93274],["Bat66108","Res52631","Fla18469","Add83375","Fla3359","Con22884","Fla55417","Res1971","LST82996","Min5096","Con5422","Ave93274"],Ave93274,"Ave93274")

Actual (Unparsed): [[0.8025988, 0.6181227, 0.6985572, 0.6303492, 0.4155586, 0.5588394, 0.5691510, 0.4848617, 0.7500865, 1.0870502, 1.6901597, 0.7400408, 1.0060752, 0.9641201, 1.0381075, 1.0323201, 1.2858334, 1.0862002, 1.4795267, 1.4076529, 1.2146608, 0.9211327, 0.9962162, 1.4580422, 1.1509020, 1.3998806, 1.2864426, 0.8755477, 0.9435621, 0.6330915, 0.8228501, 0.9829714, 0.6651426, 0.7787488, 0.7026752, 0.9794832]]

Expected (Unparsed): [[0.8025988176819365,0.6181226774368302,0.698557165052184,0.6303491661102076,0.41555862670148275,0.5588393641480456,0.5691510372177486,0.4848616971712445,0.7500865089368036,1.087050236494531,1.6901596635288598,0.7400408588619212,1.0060752181963848,0.9641200118077071,1.0381075456576396,1.0323200676121402,1.285833431687232,1.0862001591905945,1.4795266863916936,1.4076529277538092,1.2146607355075911,0.9211326899397485,0.9962162207384191,1.4580422314247512,1.1509019686852855,1.3998805539617614,1.2864426223018122,0.8755476550704322,0.9435621248802839,0.6330915475354909,0.822850125313574,0.9829713805985902,0.6651425747450525,0.7787487869951147,0.7026752273206318,0.9794832318736126]]

Actual:   [[0.8026, 0.6182, 0.6986, 0.6304, 0.4156, 0.5589, 0.5692, 0.4849, 0.7501, 1.0871, 1.6902, 0.7401, 1.0061, 0.9642, 1.0382, 1.0324, 1.2859, 1.0863, 1.4796, 1.4077, 1.2147, 0.9212, 0.9963, 1.4581, 1.151, 1.3999, 1.2865, 0.8756, 0.9436, 0.6331, 0.8229, 0.983, 0.6652, 0.7788, 0.7027, 0.9795]]

Expected: [[0.8026, 0.6182, 0.6986, 0.6304, 0.4156, 0.5589, 0.5692, 0.4849, 0.7501, 1.0871, 1.6902, 0.7401, 1.0061, 0.9642, 1.0382, 1.0324, 1.2859, 1.0863, 1.4796, 1.4077, 1.2147, 0.9212, 0.9963, 1.4581, 1.151, 1.3999, 1.2865, 0.8756, 0.9436, 0.6331, 0.8229, 0.983, 0.6652, 0.7788, 0.7027, 0.9795]]