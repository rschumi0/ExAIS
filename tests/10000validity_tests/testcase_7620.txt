import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Den93135 = tf.keras.layers.Input(shape=([5, 5, 4]))

Den93135 = keras.layers.Dense(4,name = 'Den93135', )(in0Den93135)
Res33653 = keras.layers.Reshape((5, 20), name = 'Res33653', )(Den93135)
Per29474 = keras.layers.Permute((1,2), name = 'Per29474',)(Res33653)
Bat26993 = keras.layers.BatchNormalization(axis=1, epsilon=0.1496182501164427,  name = 'Bat26993', )(Per29474)
Fla40513 = keras.layers.Flatten(name = 'Fla40513', )(Bat26993)
model = tf.keras.models.Model(inputs=[in0Den93135], outputs=Fla40513)
w = model.get_layer('Den93135').get_weights() 
w[0] = np.array([[0.4819, 0.0186, 0.9444, 0.109], [0.273, 0.784, 0.2398, 0.0638], [0.2413, 0.9569, 0.721, 0.0899], [0.8852, 0.559, 0.3153, 0.2888]])
w[1] = np.array([0.4091, 0.6362, 0.5584, 0.3667])
model.get_layer('Den93135').set_weights(w) 
w = model.get_layer('Bat26993').get_weights() 
w[0] = np.array([0.094, 0.6651, 0.6114, 0.9043, 0.2739])
w[1] = np.array([0.1404, 0.3969, 0.343, 0.5488, 0.8926])
w[2] = np.array([0.8735, 0.6777, 0.7154, 0.9246, 0.0911])
w[3] = np.array([0.8201, 0.3021, 0.5256, 0.4892, 0.5179])
model.get_layer('Bat26993').set_weights(w) 
in0Den93135 = tf.constant([[[[0.2566, 0.3958, 0.5401, 0.0733], [0.9285, 0.1776, 0.4925, 0.8252], [0.9163, 0.7505, 0.4393, 0.6376], [0.6913, 0.3136, 0.9394, 0.9129], [0.4123, 0.6239, 0.083, 0.4338]], [[0.8979, 0.2117, 0.0796, 0.3006], [0.0306, 0.4989, 0.073, 0.3448], [0.9067, 0.0997, 0.2164, 0.864], [0.3357, 0.1273, 0.656, 0.5202], [0.4853, 0.0315, 0.0933, 0.8963]], [[0.5655, 0.347, 0.0199, 0.5165], [0.4497, 0.7457, 0.5547, 0.1003], [0.0443, 0.9559, 0.0509, 0.4438], [0.0336, 0.4344, 0.2859, 0.598], [0.35, 0.1618, 0.1001, 0.9516]], [[0.3518, 0.5665, 0.8066, 0.4128], [0.225, 0.3778, 0.5605, 0.135], [0.5682, 0.16, 0.1447, 0.1326], [0.4691, 0.3824, 0.3068, 0.6934], [0.6351, 0.1477, 0.8661, 0.7102]], [[0.3024, 0.1148, 0.2961, 0.9248], [0.7145, 0.7317, 0.3857, 0.6085], [0.9361, 0.6236, 0.8832, 0.3857], [0.6457, 0.869, 0.7356, 0.7472], [0.3403, 0.9401, 0.6489, 0.3013]]]])
print (np.array2string(model.predict([in0Den93135],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Fla40513.png')

LDen93135 = dense_layer([[[[0.2566, 0.3958, 0.5401, 0.0733], [0.9285, 0.1776, 0.4925, 0.8252], [0.9163, 0.7505, 0.4393, 0.6376], [0.6913, 0.3136, 0.9394, 0.9129], [0.4123, 0.6239, 0.083, 0.4338]], [[0.8979, 0.2117, 0.0796, 0.3006], [0.0306, 0.4989, 0.073, 0.3448], [0.9067, 0.0997, 0.2164, 0.864], [0.3357, 0.1273, 0.656, 0.5202], [0.4853, 0.0315, 0.0933, 0.8963]], [[0.5655, 0.347, 0.0199, 0.5165], [0.4497, 0.7457, 0.5547, 0.1003], [0.0443, 0.9559, 0.0509, 0.4438], [0.0336, 0.4344, 0.2859, 0.598], [0.35, 0.1618, 0.1001, 0.9516]], [[0.3518, 0.5665, 0.8066, 0.4128], [0.225, 0.3778, 0.5605, 0.135], [0.5682, 0.16, 0.1447, 0.1326], [0.4691, 0.3824, 0.3068, 0.6934], [0.6351, 0.1477, 0.8661, 0.7102]], [[0.3024, 0.1148, 0.2961, 0.9248], [0.7145, 0.7317, 0.3857, 0.6085], [0.9361, 0.6236, 0.8832, 0.3857], [0.6457, 0.869, 0.7356, 0.7472], [0.3403, 0.9401, 0.6489, 0.3013]]]], [[0.4819, 0.0186, 0.9444, 0.109], [0.273, 0.784, 0.2398, 0.0638], [0.2413, 0.9569, 0.721, 0.0899], [0.8852, 0.559, 0.3153, 0.2888]],[0.4091, 0.6362, 0.5584, 0.3667], Den93135), 
LRes33653 = reshape_layer(Den93135, [5, 20], Res33653), 
LPer29474 = permute_layer(Res33653, 1,2, Per29474), 
LBat26993 = batch_normalization_layer(Per29474, 1, 0.1496182501164427, [0.094, 0.6651, 0.6114, 0.9043, 0.2739], [0.1404, 0.3969, 0.343, 0.5488, 0.8926], [0.8735, 0.6777, 0.7154, 0.9246, 0.0911], [0.8201, 0.3021, 0.5256, 0.4892, 0.5179], Bat26993), 
LFla40513 = flatten_layer(Bat26993, Fla40513), 
exec_layers([LDen93135,LRes33653,LPer29474,LBat26993,LFla40513],["Den93135","Res33653","Per29474","Bat26993","Fla40513"],Fla40513,"Fla40513")

Actual (Unparsed): [[0.1368223, 0.2010698, 0.1818920, 0.1037586, 0.2244815, 0.2217068, 0.2568226, 0.1297405, 0.2217726, 0.2496899, 0.2595290, 0.1274743, 0.2348185, 0.2769641, 0.2719494, 0.1343535, 0.1698616, 0.1959006, 0.1805401, 0.1127834, 0.8988083, 0.7782647, 1.3188105, 0.2923472, 0.5999408, 1.0033213, 0.5854984, 0.2289735, 1.3989409, 1.1327343, 1.5738523, 0.4594108, 0.9379067, 1.3697269, 1.2531451, 0.3404157, 1.1784581, 0.9733660, 1.0860903, 0.4079304, 0.7321044, 0.7233089, 0.8173103, 0.2582021, 0.5934637, 1.1619435, 0.9963364, 0.2140760, 0.6265901, 1.0631234, 0.5592891, 0.2312884, 0.6605765, 0.9902169, 0.6209661, 0.2545188, 0.9181871, 0.8503627, 0.7779366, 0.3307930, 0.9659886, 1.8667575, 1.4693245, 0.2187861, 0.4931540, 1.2545659, 0.9827816, 0.0737230, 0.4970819, 0.6169062, 0.9503563, 0.0572491, 1.1176588, 1.3422812, 1.2370987, 0.2608132, 1.3051948, 1.7537426, 1.8130387, 0.3267218, 1.3569622, 1.3756957, 1.3235533, 1.0969603, 1.3933819, 1.5098740, 1.4918429, 1.0972904, 1.3934161, 1.6006861, 1.6500126, 1.0964986, 1.4642981, 1.6837703, 1.5803338, 1.1216871, 1.2821290, 1.5891782, 1.4212697, 1.0662638]]

Expected (Unparsed): [[0.13682231593889296,0.20106983273941081,0.1818919844670563,0.10375862696690152,0.22448145984603035,0.22170676269057285,0.25682263356994095,0.12974046833891967,0.2217725827447155,0.24968992202517926,0.25952903835039615,0.1274743008564815,0.23481846531893003,0.2769640875113094,0.271949402746732,0.13435350119304185,0.16986163870923912,0.1959005754200886,0.18054013183037904,0.1127833798922587,0.898808348340471,0.7782646866519429,1.3188105028642598,0.29234725108191045,0.5999407862227931,1.0033213456267676,0.5854983860474822,0.22897351144512848,1.3989409159813184,1.1327342524632458,1.573852242232663,0.45941082146591705,0.9379067154532348,1.3697268509942377,1.2531450821493941,0.34041567237251624,1.178458069666848,0.9733660022641919,1.0860902893848552,0.4079304197485411,0.7321043685484753,0.7233089212019612,0.8173102614626016,0.2582021006158671,0.5934637116727213,1.1619434394090888,0.9963363997960928,0.2140759567359842,0.6265901017682001,1.0631233796347035,0.5592890860939193,0.23128836700541178,0.6605765491297086,0.9902168986343269,0.6209661541878733,0.254518759967713,0.9181871342265591,0.8503626481359463,0.7779365643756765,0.3307930142384475,0.9659885856020244,1.8667575310234243,1.469324557899369,0.21878613050529594,0.49315398960436724,1.2545658586867334,0.9827815520316338,0.07372304259084128,0.49708189536038605,0.6169062263443311,0.9503563203807662,0.05724913661738196,1.1176587819681112,1.342281155983216,1.2370986903591978,0.2608131584721771,1.3051947678656155,1.7537426177115514,1.8130386570971375,0.3267218276392745,1.356962249193206,1.3756957539037982,1.3235533129330015,1.096960281315034,1.3933819074067442,1.5098740437329292,1.4918429279461125,1.0972904023659418,1.3934160787841092,1.600686133507866,1.650012629041067,1.0964986341532497,1.464298089021728,1.6837702923704643,1.5803337644041986,1.1216871197587222,1.2821289609871267,1.5891781771013087,1.4212697574974062,1.0662637572198685]]

Actual:   [[0.1369, 0.2011, 0.1819, 0.1038, 0.2245, 0.2218, 0.2569, 0.1298, 0.2218, 0.2497, 0.2596, 0.1275, 0.2349, 0.277, 0.272, 0.1344, 0.1699, 0.196, 0.1806, 0.1128, 0.8989, 0.7783, 1.3189, 0.2924, 0.6, 1.0034, 0.5855, 0.229, 1.399, 1.1328, 1.5739, 0.4595, 0.938, 1.3698, 1.2532, 0.3405, 1.1785, 0.9734, 1.0861, 0.408, 0.7322, 0.7234, 0.8174, 0.2583, 0.5935, 1.162, 0.9964, 0.2141, 0.6266, 1.0632, 0.5593, 0.2313, 0.6606, 0.9903, 0.621, 0.2546, 0.9182, 0.8504, 0.778, 0.3308, 0.966, 1.8668, 1.4694, 0.2188, 0.4932, 1.2546, 0.9828, 0.0738, 0.4971, 0.617, 0.9504, 0.0573, 1.1177, 1.3423, 1.2371, 0.2609, 1.3052, 1.7538, 1.8131, 0.3268, 1.357, 1.3757, 1.3236, 1.097, 1.3934, 1.5099, 1.4919, 1.0973, 1.3935, 1.6007, 1.6501, 1.0965, 1.4643, 1.6838, 1.5804, 1.1217, 1.2822, 1.5892, 1.4213, 1.0663]]

Expected: [[0.1369, 0.2011, 0.1819, 0.1038, 0.2245, 0.2218, 0.2569, 0.1298, 0.2218, 0.2497, 0.2596, 0.1275, 0.2349, 0.277, 0.272, 0.1344, 0.1699, 0.196, 0.1806, 0.1128, 0.8989, 0.7783, 1.3189, 0.2924, 0.6, 1.0034, 0.5855, 0.229, 1.399, 1.1328, 1.5739, 0.4595, 0.938, 1.3698, 1.2532, 0.3405, 1.1785, 0.9734, 1.0861, 0.408, 0.7322, 0.7234, 0.8174, 0.2583, 0.5935, 1.162, 0.9964, 0.2141, 0.6266, 1.0632, 0.5593, 0.2313, 0.6606, 0.9903, 0.621, 0.2546, 0.9182, 0.8504, 0.778, 0.3308, 0.966, 1.8668, 1.4694, 0.2188, 0.4932, 1.2546, 0.9828, 0.0738, 0.4971, 0.617, 0.9504, 0.0573, 1.1177, 1.3423, 1.2371, 0.2609, 1.3052, 1.7538, 1.8131, 0.3268, 1.357, 1.3757, 1.3236, 1.097, 1.3934, 1.5099, 1.4919, 1.0973, 1.3935, 1.6007, 1.6501, 1.0965, 1.4643, 1.6838, 1.5804, 1.1217, 1.2822, 1.5892, 1.4213, 1.0663]]