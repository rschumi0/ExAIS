import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max24451 = tf.keras.layers.Input(shape=([2, 1, 2]))
in1Max24451 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con76673 = tf.keras.layers.Input(shape=([2, 3, 3, 1]))
in0Sub93436 = tf.keras.layers.Input(shape=([2, 3, 3, 2]))
in1Sub93436 = tf.keras.layers.Input(shape=([2, 3, 3, 2]))

Max24451 = keras.layers.Maximum(name = 'Max24451', )([in0Max24451,in1Max24451])
Glo91789 = keras.layers.GlobalMaxPool2D(name = 'Glo91789', )(Max24451)
Res68411 = keras.layers.Reshape((2, 1), name = 'Res68411', )(Glo91789)
Glo74026 = keras.layers.GlobalAveragePooling1D(name = 'Glo74026', )(Res68411)
Res69299 = keras.layers.Reshape((1, 1), name = 'Res69299', )(Glo74026)
Res96524 = keras.layers.Reshape((1, 1, 1), name = 'Res96524', )(Res69299)
Res4519 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res4519', )(Res96524)
Zer69317 = keras.layers.ZeroPadding3D(padding=((1, 0), (2, 0), (2, 0)), name = 'Zer69317', )(Res4519)
Con76673 = keras.layers.Concatenate(axis=4, name = 'Con76673', )([Zer69317,in0Con76673])
Sub93436 = keras.layers.Subtract(name = 'Sub93436', )([in0Sub93436,in1Sub93436])
Sub73401 = keras.layers.Subtract(name = 'Sub73401', )([Con76673,Sub93436])
model = tf.keras.models.Model(inputs=[in0Max24451,in1Max24451,in0Con76673,in0Sub93436,in1Sub93436], outputs=Sub73401)
in0Max24451 = tf.constant([[[[0.2371, 0.8153]], [[0.2694, 0.5932]]]])
in1Max24451 = tf.constant([[[[0.9501, 0.4031]], [[0.7577, 0.3559]]]])
in0Con76673 = tf.constant([[[[[0.9796], [0.8155], [0.6163]], [[0.8688], [0.733], [0.18]], [[0.431], [0.5454], [0.8707]]], [[[0.369], [0.8549], [0.2555]], [[0.3599], [0.0736], [0.8112]], [[0.3714], [0.1986], [0.9177]]]]])
in0Sub93436 = tf.constant([[[[[0.6776, 0.9075], [0.322, 0.4229], [0.0198, 0.7486]], [[0.7594, 0.6514], [0.7811, 0.9807], [0.7646, 0.1002]], [[0.4881, 0.4036], [0.0997, 0.549], [0.4581, 0.7328]]], [[[0.5555, 0.7336], [0.7199, 0.324], [0.9482, 0.7368]], [[0.3854, 0.3107], [0.1409, 0.915], [0.519, 0.7856]], [[0.4847, 0.5922], [0.1594, 0.8321], [0.1314, 0.5033]]]]])
in1Sub93436 = tf.constant([[[[[0.9092, 0.7939], [0.3885, 0.6364], [0.4292, 0.1648]], [[0.6562, 0.6837], [0.2476, 0.8692], [0.5164, 0.7903]], [[0.5262, 0.5124], [0.2285, 0.6672], [0.8142, 0.383]]], [[[0.2254, 0.4207], [0.3623, 0.6071], [0.2033, 0.6442]], [[0.2726, 0.8714], [0.0487, 0.4161], [0.6139, 0.5625]], [[0.1598, 0.8531], [0.6458, 0.0005], [0.6801, 0.7781]]]]])
print (np.array2string(model.predict([in0Max24451,in1Max24451,in0Con76673,in0Sub93436,in1Sub93436],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub73401.png')

LMax24451 = maximum_layer([[[[[0.2371, 0.8153]], [[0.2694, 0.5932]]]], [[[[0.9501, 0.4031]], [[0.7577, 0.3559]]]]], Max24451), 
LGlo91789 = global_max_pool2D_layer(Max24451, Glo91789), 
LRes68411 = reshape_layer(Glo91789, [2, 1], Res68411), 
LGlo74026 = global_average_pooling1D_layer(Res68411, Glo74026), 
LRes69299 = reshape_layer(Glo74026, [1, 1], Res69299), 
LRes96524 = reshape_layer(Res69299, [1, 1, 1], Res96524), 
LRes4519 = reshape_layer(Res96524, [1, 1, 1, 1], Res4519), 
LZer69317 = zero_padding3D_layer(Res4519, 1, 0, 2, 0, 2, 0, Zer69317), 
LCon76673 = concatenate_layer([Zer69317,[[[[[0.9796], [0.8155], [0.6163]], [[0.8688], [0.733], [0.18]], [[0.431], [0.5454], [0.8707]]], [[[0.369], [0.8549], [0.2555]], [[0.3599], [0.0736], [0.8112]], [[0.3714], [0.1986], [0.9177]]]]]], 4, Con76673), 
LSub93436 = subtract_layer([[[[[0.6776, 0.9075], [0.322, 0.4229], [0.0198, 0.7486]], [[0.7594, 0.6514], [0.7811, 0.9807], [0.7646, 0.1002]], [[0.4881, 0.4036], [0.0997, 0.549], [0.4581, 0.7328]]], [[[0.5555, 0.7336], [0.7199, 0.324], [0.9482, 0.7368]], [[0.3854, 0.3107], [0.1409, 0.915], [0.519, 0.7856]], [[0.4847, 0.5922], [0.1594, 0.8321], [0.1314, 0.5033]]]]], [[[[[0.9092, 0.7939], [0.3885, 0.6364], [0.4292, 0.1648]], [[0.6562, 0.6837], [0.2476, 0.8692], [0.5164, 0.7903]], [[0.5262, 0.5124], [0.2285, 0.6672], [0.8142, 0.383]]], [[[0.2254, 0.4207], [0.3623, 0.6071], [0.2033, 0.6442]], [[0.2726, 0.8714], [0.0487, 0.4161], [0.6139, 0.5625]], [[0.1598, 0.8531], [0.6458, 0.0005], [0.6801, 0.7781]]]]], Sub93436), 
LSub73401 = subtract_layer(Con76673,Sub93436, Sub73401), 
exec_layers([LMax24451,LGlo91789,LRes68411,LGlo74026,LRes69299,LRes96524,LRes4519,LZer69317,LCon76673,LSub93436,LSub73401],["Max24451","Glo91789","Res68411","Glo74026","Res69299","Res96524","Res4519","Zer69317","Con76673","Sub93436","Sub73401"],Sub73401,"Sub73401")

Actual (Unparsed): [[[[[0.2316000, 0.8660000], [0.0665000, 1.0290000], [0.4094000, 0.0325000]], [[-0.1032000, 0.9011000], [-0.5335000, 0.6215000], [-0.2482000, 0.8701000]], [[0.0381000, 0.5398000], [0.1288000, 0.6636000], [0.3561000, 0.5209000]]], [[[-0.3301000, 0.0561000], [-0.3576000, 1.1380000], [-0.7449000, 0.1629000]], [[-0.1128000, 0.9206000], [-0.0922000, -0.4253000], [0.0949000, 0.5881000]], [[-0.3249000, 0.6323000], [0.4864000, -0.6330000], [1.4314000, 1.1925000]]]]]

Expected (Unparsed): [[[[[0.23160000000000003,0.8660000000000001],[0.0665,1.029],[0.40940000000000004,0.03249999999999986]],[[-0.10319999999999996,0.9011],[-0.5335000000000001,0.6214999999999999],[-0.24819999999999998,0.8701000000000001]],[[0.03810000000000002,0.5398],[0.12880000000000003,0.6636],[0.3561,0.5209]]],[[[-0.3301,0.05609999999999998],[-0.3576,1.138],[-0.7449,0.1629]],[[-0.11280000000000001,0.9206],[-0.0922,-0.4253],[0.09489999999999998,0.5881000000000001]],[[-0.3249,0.6323000000000001],[0.48640000000000005,-0.633],[1.4314,1.1925]]]]]

Actual:   [[[[[0.2316, 0.866], [0.0665, 1.029], [0.4094, 0.0325]], [[-0.1032, 0.9011], [-0.5335, 0.6215], [-0.2482, 0.8701]], [[0.0381, 0.5398], [0.1288, 0.6636], [0.3561, 0.5209]]], [[[-0.3301, 0.0561], [-0.3576, 1.138], [-0.7449, 0.1629]], [[-0.1128, 0.9206], [-0.0922, -0.4253], [0.0949, 0.5881]], [[-0.3249, 0.6323], [0.4864, -0.633], [1.4314, 1.1925]]]]]

Expected: [[[[[0.2317, 0.8661], [0.0665, 1.029], [0.4095, 0.0325]], [[-0.1031, 0.9011], [-0.5335, 0.6215], [-0.2481, 0.8702]], [[0.0382, 0.5398], [0.1289, 0.6636], [0.3561, 0.5209]]], [[[-0.3301, 0.0561], [-0.3576, 1.138], [-0.7449, 0.1629]], [[-0.1128, 0.9206], [-0.0922, -0.4253], [0.0949, 0.5882]], [[-0.3249, 0.6324], [0.4865, -0.633], [1.4314, 1.1925]]]]]