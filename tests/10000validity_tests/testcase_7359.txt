import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo76001 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con84118 = tf.keras.layers.Input(shape=([1, 2, 1, 3]))
in0Lea23688 = tf.keras.layers.Input(shape=([1, 2, 1, 2]))
in0Ave7214 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in1Ave7214 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in0Con69982 = tf.keras.layers.Input(shape=([1, 4]))

Glo76001 = keras.layers.GlobalAveragePooling2D(name = 'Glo76001', )(in0Glo76001)
Res11249 = keras.layers.Reshape((1, 1), name = 'Res11249', )(Glo76001)
Res76173 = keras.layers.Reshape((1, 1, 1), name = 'Res76173', )(Res11249)
Res53337 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res53337', )(Res76173)
Zer94280 = keras.layers.ZeroPadding3D(padding=((0, 0), (1, 0), (0, 0)), name = 'Zer94280', )(Res53337)
Con84118 = keras.layers.Concatenate(axis=4, name = 'Con84118', )([Zer94280,in0Con84118])
Lea23688 = keras.layers.LeakyReLU(alpha=5.903538486553696, name = 'Lea23688', input_shape=(1, 2, 1, 2))(in0Lea23688)
Den24458 = keras.layers.Dense(4,name = 'Den24458', )(Lea23688)
Sub35370 = keras.layers.Subtract(name = 'Sub35370', )([Con84118,Den24458])
Res19569 = keras.layers.Reshape((1, 2, 4), name = 'Res19569', )(Sub35370)
Res84603 = keras.layers.Reshape((1, 8), name = 'Res84603', )(Res19569)
Ave7214 = keras.layers.Average(name = 'Ave7214', )([in0Ave7214,in1Ave7214])
Res80448 = keras.layers.Reshape((2, 2, 2), name = 'Res80448', )(Ave7214)
Res96756 = keras.layers.Reshape((2, 4), name = 'Res96756', )(Res80448)
Cro60277 = keras.layers.Cropping1D(cropping=((0, 1)), name = 'Cro60277', )(Res96756)
Con69982 = keras.layers.Concatenate(axis=2, name = 'Con69982', )([Cro60277,in0Con69982])
Max70040 = keras.layers.Maximum(name = 'Max70040', )([Res84603,Con69982])
model = tf.keras.models.Model(inputs=[in0Glo76001,in0Con84118,in0Lea23688,in0Ave7214,in1Ave7214,in0Con69982], outputs=Max70040)
w = model.get_layer('Den24458').get_weights() 
w[0] = np.array([[0.5291, 0.913, 0.8695, 0.0797], [0.5285, 0.568, 0.2013, 0.9047]])
w[1] = np.array([0.8627, 0.8321, 0.5933, 0.6611])
model.get_layer('Den24458').set_weights(w) 
in0Glo76001 = tf.constant([[[[1.3991], [1.2717]]]])
in0Con84118 = tf.constant([[[[[0.0748, 0.1906, 0.9987]], [[0.9256, 0.8954, 0.7956]]]]])
in0Lea23688 = tf.constant([[[[[0.7571, 0.015]], [[0.9364, 0.4381]]]]])
in0Ave7214 = tf.constant([[[[[0.9338], [0.6317]], [[0.9283], [0.3978]]], [[[0.893], [0.1663]], [[0.4562], [0.2469]]]]])
in1Ave7214 = tf.constant([[[[[0.6995], [0.4092]], [[0.9637], [0.6515]]], [[[0.2041], [0.2464]], [[0.0485], [0.8428]]]]])
in0Con69982 = tf.constant([[[0.6001, 0.2535, 0.0414, 0.2269]]])
print (np.array2string(model.predict([in0Glo76001,in0Con84118,in0Lea23688,in0Ave7214,in1Ave7214,in0Con69982],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max70040.png')

LGlo76001 = global_average_pooling2D_layer([[[[1.3991], [1.2717]]]], Glo76001), 
LRes11249 = reshape_layer(Glo76001, [1, 1], Res11249), 
LRes76173 = reshape_layer(Res11249, [1, 1, 1], Res76173), 
LRes53337 = reshape_layer(Res76173, [1, 1, 1, 1], Res53337), 
LZer94280 = zero_padding3D_layer(Res53337, 0, 0, 1, 0, 0, 0, Zer94280), 
LCon84118 = concatenate_layer([Zer94280,[[[[[0.0748, 0.1906, 0.9987]], [[0.9256, 0.8954, 0.7956]]]]]], 4, Con84118), 
LLea23688 = leaky_relu_layer([[[[[0.7571, 0.015]], [[0.9364, 0.4381]]]]], 5.903538486553696, Lea23688), 
LDen24458 = dense_layer(Lea23688, [[0.5291, 0.913, 0.8695, 0.0797], [0.5285, 0.568, 0.2013, 0.9047]],[0.8627, 0.8321, 0.5933, 0.6611], Den24458), 
LSub35370 = subtract_layer(Con84118,Den24458, Sub35370), 
LRes19569 = reshape_layer(Sub35370, [1, 2, 4], Res19569), 
LRes84603 = reshape_layer(Res19569, [1, 8], Res84603), 
LAve7214 = average_layer([[[[[[0.9338], [0.6317]], [[0.9283], [0.3978]]], [[[0.893], [0.1663]], [[0.4562], [0.2469]]]]], [[[[[0.6995], [0.4092]], [[0.9637], [0.6515]]], [[[0.2041], [0.2464]], [[0.0485], [0.8428]]]]]], Ave7214), 
LRes80448 = reshape_layer(Ave7214, [2, 2, 2], Res80448), 
LRes96756 = reshape_layer(Res80448, [2, 4], Res96756), 
LCro60277 = cropping1D_layer(Res96756, 0, 1, Cro60277), 
LCon69982 = concatenate_layer([Cro60277,[[[0.6001, 0.2535, 0.0414, 0.2269]]]], 2, Con69982), 
LMax70040 = maximum_layer([Res84603,Con69982], Max70040), 
exec_layers([LGlo76001,LRes11249,LRes76173,LRes53337,LZer94280,LCon84118,LLea23688,LDen24458,LSub35370,LRes19569,LRes84603,LAve7214,LRes80448,LRes96756,LCro60277,LCon69982,LMax70040],["Glo76001","Res11249","Res76173","Res53337","Zer94280","Con84118","Lea23688","Den24458","Sub35370","Res19569","Res84603","Ave7214","Res80448","Res96756","Cro60277","Con69982","Max70040"],Max70040,"Max70040")

Actual (Unparsed): [[[0.8166500, 0.5204500, 0.9460000, 0.5246500, 0.6001000, 0.2535000, 0.0414000, 0.2269000]]]

Expected (Unparsed): [[[0.81665,0.5204500000000001,0.946,0.52465,0.6001,0.2535,0.0414,0.2269]]]

Actual:   [[[0.8167, 0.5205, 0.946, 0.5247, 0.6001, 0.2535, 0.0414, 0.2269]]]

Expected: [[[0.8167, 0.5205, 0.946, 0.5247, 0.6001, 0.2535, 0.0414, 0.2269]]]