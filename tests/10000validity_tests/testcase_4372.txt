import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Lea31288 = tf.keras.layers.Input(shape=([2, 1]))
in0Con34965 = tf.keras.layers.Input(shape=([3, 1]))
in0Max82762 = tf.keras.layers.Input(shape=([1, 2]))
in0Add12241 = tf.keras.layers.Input(shape=([1, 1]))
in1Add12241 = tf.keras.layers.Input(shape=([1, 1]))

Lea31288 = keras.layers.LeakyReLU(alpha=9.417970592059618, name = 'Lea31288', input_shape=(2, 1))(in0Lea31288)
Zer62079 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer62079', )(Lea31288)
Con34965 = keras.layers.Concatenate(axis=2, name = 'Con34965', )([Zer62079,in0Con34965])
Max82762 = keras.layers.MaxPool1D(pool_size=(1), name = 'Max82762', )(in0Max82762)
Zer31104 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer31104', )(Max82762)
Sub23474 = keras.layers.Subtract(name = 'Sub23474', )([Con34965,Zer31104])
Fla90041 = keras.layers.Flatten(name = 'Fla90041', )(Sub23474)
Res52313 = keras.layers.Reshape((6, 1), name = 'Res52313', )(Fla90041)
Add12241 = keras.layers.Add(name = 'Add12241', )([in0Add12241,in1Add12241])
Zer81848 = keras.layers.ZeroPadding1D(padding=((5, 0)), name = 'Zer81848', )(Add12241)
Min86855 = keras.layers.Minimum(name = 'Min86855', )([Res52313,Zer81848])
model = tf.keras.models.Model(inputs=[in0Lea31288,in0Con34965,in0Max82762,in0Add12241,in1Add12241], outputs=Min86855)
in0Lea31288 = tf.constant([[[0.3198], [0.0669]]])
in0Con34965 = tf.constant([[[0.4425], [0.4616], [0.3689]]])
in0Max82762 = tf.constant([[[1.8834, 1.9494]]])
in0Add12241 = tf.constant([[[0.7486]]])
in1Add12241 = tf.constant([[[0.7566]]])
print (np.array2string(model.predict([in0Lea31288,in0Con34965,in0Max82762,in0Add12241,in1Add12241],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min86855.png')

LLea31288 = leaky_relu_layer([[[0.3198], [0.0669]]], 9.417970592059618, Lea31288), 
LZer62079 = zero_padding1D_layer(Lea31288, 1, 0, Zer62079), 
LCon34965 = concatenate_layer([Zer62079,[[[0.4425], [0.4616], [0.3689]]]], 2, Con34965), 
LMax82762 = max_pool1D_layer([[[1.8834, 1.9494]]], 1, Max82762), 
LZer31104 = zero_padding1D_layer(Max82762, 1, 1, Zer31104), 
LSub23474 = subtract_layer(Con34965,Zer31104, Sub23474), 
LFla90041 = flatten_layer(Sub23474, Fla90041), 
LRes52313 = reshape_layer(Fla90041, [6, 1], Res52313), 
LAdd12241 = add_layer([[[[0.7486]]], [[[0.7566]]]], Add12241), 
LZer81848 = zero_padding1D_layer(Add12241, 5, 0, Zer81848), 
LMin86855 = minimum_layer([Res52313,Zer81848], Min86855), 
exec_layers([LLea31288,LZer62079,LCon34965,LMax82762,LZer31104,LSub23474,LFla90041,LRes52313,LAdd12241,LZer81848,LMin86855],["Lea31288","Zer62079","Con34965","Max82762","Zer31104","Sub23474","Fla90041","Res52313","Add12241","Zer81848","Min86855"],Min86855,"Min86855")

Actual (Unparsed): [[[0.0000000], [0.0000000], [-1.5636000], [-1.4877999], [0.0000000], [0.3689000]]]

Expected (Unparsed): [[[0],[0],[-1.5636],[-1.4878],[0],[0.3689]]]

Actual:   [[[0], [0], [-1.5636], [-1.4877], [0], [0.3689]]]

Expected: [[[0], [0], [-1.5636], [-1.4878], [0], [0.3689]]]