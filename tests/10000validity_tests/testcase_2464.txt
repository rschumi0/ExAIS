import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max92572 = tf.keras.layers.Input(shape=([2, 1, 2]))
in1Max92572 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con98084 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Dep20015 = tf.keras.layers.Input(shape=([1, 1, 2]))

Max92572 = keras.layers.Maximum(name = 'Max92572', )([in0Max92572,in1Max92572])
Lea24039 = keras.layers.LeakyReLU(alpha=5.930322829075112, name = 'Lea24039', )(Max92572)
Con98084 = keras.layers.Concatenate(axis=3, name = 'Con98084', )([Lea24039,in0Con98084])
Dep20015 = keras.layers.DepthwiseConv2D((1, 1),strides=(1, 1), padding='valid', name = 'Dep20015', )(in0Dep20015)
Con54610 = keras.layers.Conv2DTranspose(2, (1, 1),strides=(1, 1), padding='same', name = 'Con54610', )(Dep20015)
Con36567 = keras.layers.Conv2D(3, (1, 1),strides=(1, 1), padding='valid', dilation_rate=(1, 1), name = 'Con36567', )(Con54610)
Zer66180 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer66180', )(Con36567)
Max67412 = keras.layers.Maximum(name = 'Max67412', )([Con98084,Zer66180])
model = tf.keras.models.Model(inputs=[in0Max92572,in1Max92572,in0Con98084,in0Dep20015], outputs=Max67412)
w = model.get_layer('Dep20015').get_weights() 
w[0] = np.array([[[[0.9095], [0.5416]]]])
w[1] = np.array([0, 0])
model.get_layer('Dep20015').set_weights(w) 
w = model.get_layer('Con54610').get_weights() 
w[0] = np.array([[[[0.2882, 0.1864], [0.0645, 0.9295]]]])
w[1] = np.array([0, 0])
model.get_layer('Con54610').set_weights(w) 
w = model.get_layer('Con36567').get_weights() 
w[0] = np.array([[[[0.5901, 0.6263, 0.9331], [0.234, 0.6114, 0.6429]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con36567').set_weights(w) 
in0Max92572 = tf.constant([[[[0.5605, 0.9223]], [[0.2426, 0.1099]]]])
in1Max92572 = tf.constant([[[[0.2117, 0.5693]], [[0.4481, 0.4575]]]])
in0Con98084 = tf.constant([[[[0.8226]], [[0.2571]]]])
in0Dep20015 = tf.constant([[[[0.2629, 0.1295]]]])
print (np.array2string(model.predict([in0Max92572,in1Max92572,in0Con98084,in0Dep20015],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max67412.png')

LMax92572 = maximum_layer([[[[[0.5605, 0.9223]], [[0.2426, 0.1099]]]], [[[[0.2117, 0.5693]], [[0.4481, 0.4575]]]]], Max92572), 
LLea24039 = leaky_relu_layer(Max92572, 5.930322829075112, Lea24039), 
LCon98084 = concatenate_layer([Lea24039,[[[[0.8226]], [[0.2571]]]]], 3, Con98084), 
LDep20015 = depthwise_conv2D_layer([[[[0.2629, 0.1295]]]], 1, 1,[[[[0.9095], [0.5416]]]],[0, 0], 1, 1, false, Dep20015), 
LCon54610 = conv2D_transpose_layer(Dep20015, 1, 1,[[[[0.2882, 0.1864], [0.0645, 0.9295]]]],[0, 0], 1, 1, true, Con54610), 
LCon36567 = conv2D_layer(Con54610, 1, 1,[[[[0.5901, 0.6263, 0.9331], [0.234, 0.6114, 0.6429]]]],[0, 0, 0], 1, 1, false, 1, 1, Con36567), 
LZer66180 = zero_padding2D_layer(Con36567, 1, 0, 0, 0, Zer66180), 
LMax67412 = maximum_layer([Con98084,Zer66180], Max67412), 
exec_layers([LMax92572,LLea24039,LCon98084,LDep20015,LCon54610,LCon36567,LZer66180,LMax67412],["Max92572","Lea24039","Con98084","Dep20015","Con54610","Con36567","Zer66180","Max67412"],Max67412,"Max67412")

Actual (Unparsed): [[[[0.5605000, 0.9223000, 0.8226000]], [[0.4481000, 0.4575000, 0.2571000]]]]

Expected (Unparsed): [[[[0.5605,0.9223,0.8226]],[[0.4481,0.4575,0.2571]]]]

Actual:   [[[[0.5605, 0.9223, 0.8226]], [[0.4481, 0.4575, 0.2571]]]]

Expected: [[[[0.5605, 0.9223, 0.8226]], [[0.4481, 0.4575, 0.2571]]]]