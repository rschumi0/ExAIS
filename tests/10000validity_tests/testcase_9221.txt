import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ReL78237 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0Dot98754 = tf.keras.layers.Input(shape=([3]))
in1Dot98754 = tf.keras.layers.Input(shape=([3]))
in0Con3396 = tf.keras.layers.Input(shape=([7]))

ReL78237 = keras.layers.ReLU(max_value=4.414730175013135, negative_slope=1.527187188439266, threshold=9.645489853900713, name = 'ReL78237', input_shape=(2, 2, 1, 2))(in0ReL78237)
ReL93592 = keras.layers.ReLU(max_value=8.542756390962282, negative_slope=6.782909810874412, threshold=3.197588570499165, name = 'ReL93592', )(ReL78237)
Res77078 = keras.layers.Reshape((2, 2, 2), name = 'Res77078', )(ReL93592)
Res64152 = keras.layers.Reshape((2, 4), name = 'Res64152', )(Res77078)
Fla78998 = keras.layers.Flatten(name = 'Fla78998', )(Res64152)
Dot98754 = keras.layers.Dot(axes=(1, 1), name = 'Dot98754', )([in0Dot98754,in1Dot98754])
Con3396 = keras.layers.Concatenate(axis=1, name = 'Con3396', )([Dot98754,in0Con3396])
Min30562 = keras.layers.Minimum(name = 'Min30562', )([Fla78998,Con3396])
model = tf.keras.models.Model(inputs=[in0ReL78237,in0Dot98754,in1Dot98754,in0Con3396], outputs=Min30562)
in0ReL78237 = tf.constant([[[[[0.0043, 0.828]], [[0.0362, 0.8551]]], [[[0.9453, 0.2158]], [[0.503, 0.6915]]]]])
in0Dot98754 = tf.constant([[0.6445, 0.0072, 0.9118]])
in1Dot98754 = tf.constant([[0.6091, 0.1797, 0.7652]])
in0Con3396 = tf.constant([[0.6191, 0.4509, 0.6975, 0.8016, 0.3545, 0.2888, 0.2496]])
print (np.array2string(model.predict([in0ReL78237,in0Dot98754,in1Dot98754,in0Con3396],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min30562.png')

LReL78237 = relu_layer([[[[[0.0043, 0.828]], [[0.0362, 0.8551]]], [[[0.9453, 0.2158]], [[0.503, 0.6915]]]]], 4.414730175013135, 1.527187188439266, 9.645489853900713, ReL78237), 
LReL93592 = relu_layer(ReL78237, 8.542756390962282, 6.782909810874412, 3.197588570499165, ReL93592), 
LRes77078 = reshape_layer(ReL93592, [2, 2, 2], Res77078), 
LRes64152 = reshape_layer(Res77078, [2, 4], Res64152), 
LFla78998 = flatten_layer(Res64152, Fla78998), 
LDot98754 = dot_layer([[0.6445, 0.0072, 0.9118]], [[0.6091, 0.1797, 0.7652]], 1, 1, Dot98754), 
LCon3396 = concatenate_layer([Dot98754,[[0.6191, 0.4509, 0.6975, 0.8016, 0.3545, 0.2888, 0.2496]]], 1, Con3396), 
LMin30562 = minimum_layer([Fla78998,Con3396], Min30562), 
exec_layers([LReL78237,LReL93592,LRes77078,LRes64152,LFla78998,LDot98754,LCon3396,LMin30562],["ReL78237","ReL93592","Res77078","Res64152","Fla78998","Dot98754","Con3396","Min30562"],Min30562,"Min30562")

Actual (Unparsed): [[-121.5598517, -113.0273303, -121.2294068, -112.7466079, -111.8122465, -119.3689712, -116.3939314, -114.4413028]]

Expected (Unparsed): [[-121.55985168059767,-113.02733039055744,-121.22940682306181,-112.74660764324642,-111.81224632193813,-119.36897119881607,-116.39393160369703,-114.44130290007607]]

Actual:   [[-121.5598, -113.0273, -121.2294, -112.7466, -111.8122, -119.3689, -116.3939, -114.4413]]

Expected: [[-121.5598, -113.0273, -121.2294, -112.7466, -111.8122, -119.3689, -116.3939, -114.4413]]