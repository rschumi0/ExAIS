import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat42783 = tf.keras.layers.Input(shape=([1, 4, 3]))
in0Min90456 = tf.keras.layers.Input(shape=([1, 1]))
in1Min90456 = tf.keras.layers.Input(shape=([1, 1]))
in0Con5025 = tf.keras.layers.Input(shape=([11]))

Bat42783 = keras.layers.BatchNormalization(axis=2, epsilon=0.8594891686997137,  name = 'Bat42783', )(in0Bat42783)
Res62058 = keras.layers.Reshape((1, 12), name = 'Res62058', )(Bat42783)
Fla80193 = keras.layers.Flatten(name = 'Fla80193', )(Res62058)
Min90456 = keras.layers.Minimum(name = 'Min90456', )([in0Min90456,in1Min90456])
Res52700 = keras.layers.Reshape((1, 1, 1), name = 'Res52700', )(Min90456)
Glo18107 = keras.layers.GlobalAveragePooling2D(name = 'Glo18107', )(Res52700)
Con5025 = keras.layers.Concatenate(axis=1, name = 'Con5025', )([Glo18107,in0Con5025])
Mul20361 = keras.layers.Multiply(name = 'Mul20361', )([Fla80193,Con5025])
Res75523 = keras.layers.Reshape((12, 1), name = 'Res75523', )(Mul20361)
Res76398 = keras.layers.Reshape((12, 1, 1), name = 'Res76398', )(Res75523)
Loc56172 = keras.layers.LocallyConnected2D(2, (3, 1),strides=(1, 1), name = 'Loc56172', )(Res76398)
model = tf.keras.models.Model(inputs=[in0Bat42783,in0Min90456,in1Min90456,in0Con5025], outputs=Loc56172)
w = model.get_layer('Bat42783').get_weights() 
w[0] = np.array([0.4956, 0.8839, 0.8183, 0.2734])
w[1] = np.array([0.9842, 0.6697, 0.7931, 0.3163])
w[2] = np.array([0.8132, 0.0066, 0.1231, 0.727])
w[3] = np.array([0.0454, 0.6252, 0.7261, 0.0122])
model.get_layer('Bat42783').set_weights(w) 
w = model.get_layer('Loc56172').get_weights() 
w[0] = np.array([[[0.4574, 0.2689], [0.9734, 0.7846], [0.134, 0.5026]], [[0.7271, 0.1487], [0.6362, 0.1326], [0.2207, 0.6628]], [[0.0513, 0.9218], [0.076, 0.7286], [0.1847, 0.2299]], [[0.8539, 0.9288], [0.595, 0.4812], [0.4865, 0.6766]], [[0.3105, 0.4817], [0.0774, 0.8776], [0.8379, 0.9771]], [[0.1416, 0.8981], [0.7865, 0.502], [0.2793, 0.1244]], [[0.8074, 0.1428], [0.3478, 0.7962], [0.5715, 0.304]], [[0.4326, 0.5931], [0.1987, 0.9543], [0.3018, 0.6676]], [[0.8875, 0.1091], [0.5755, 0.4263], [0.4942, 0.5025]], [[0.5397, 0.3877], [0.4632, 0.498], [0.3915, 0.8649]]])
w[1] = np.array([[[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]]])
model.get_layer('Loc56172').set_weights(w) 
in0Bat42783 = tf.constant([[[[1.9, 1.5019, 1.3611], [1.847, 1.4134, 1.0567], [1.3419, 1.1437, 1.3277], [1.6713, 1.2271, 1.3543]]]])
in0Min90456 = tf.constant([[[0.6752]]])
in1Min90456 = tf.constant([[[0.8892]]])
in0Con5025 = tf.constant([[0.0056, 0.1108, 0.1388, 0.983, 0.6304, 0.7478, 0.375, 0.7595, 0.1606, 0.7377, 0.2838]])
print (np.array2string(model.predict([in0Bat42783,in0Min90456,in1Min90456,in0Con5025],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Loc56172.png')

LBat42783 = batch_normalization_layer([[[[1.9, 1.5019, 1.3611], [1.847, 1.4134, 1.0567], [1.3419, 1.1437, 1.3277], [1.6713, 1.2271, 1.3543]]]], 2, 0.8594891686997137, [0.4956, 0.8839, 0.8183, 0.2734], [0.9842, 0.6697, 0.7931, 0.3163], [0.8132, 0.0066, 0.1231, 0.727], [0.0454, 0.6252, 0.7261, 0.0122], Bat42783), 
LRes62058 = reshape_layer(Bat42783, [1, 12], Res62058), 
LFla80193 = flatten_layer(Res62058, Fla80193), 
LMin90456 = minimum_layer([[[[0.6752]]], [[[0.8892]]]], Min90456), 
LRes52700 = reshape_layer(Min90456, [1, 1, 1], Res52700), 
LGlo18107 = global_average_pooling2D_layer(Res52700, Glo18107), 
LCon5025 = concatenate_layer([Glo18107,[[0.0056, 0.1108, 0.1388, 0.983, 0.6304, 0.7478, 0.375, 0.7595, 0.1606, 0.7377, 0.2838]]], 1, Con5025), 
LMul20361 = multiply_layer([Fla80193,Con5025], Mul20361), 
LRes75523 = reshape_layer(Mul20361, [12, 1], Res75523), 
LRes76398 = reshape_layer(Res75523, [12, 1, 1], Res76398), 
LLoc56172 = locally_connected2D_layer(Res76398, 3, 1,[[[0.4574, 0.2689], [0.9734, 0.7846], [0.134, 0.5026]], [[0.7271, 0.1487], [0.6362, 0.1326], [0.2207, 0.6628]], [[0.0513, 0.9218], [0.076, 0.7286], [0.1847, 0.2299]], [[0.8539, 0.9288], [0.595, 0.4812], [0.4865, 0.6766]], [[0.3105, 0.4817], [0.0774, 0.8776], [0.8379, 0.9771]], [[0.1416, 0.8981], [0.7865, 0.502], [0.2793, 0.1244]], [[0.8074, 0.1428], [0.3478, 0.7962], [0.5715, 0.304]], [[0.4326, 0.5931], [0.1987, 0.9543], [0.3018, 0.6676]], [[0.8875, 0.1091], [0.5755, 0.4263], [0.4942, 0.5025]], [[0.5397, 0.3877], [0.4632, 0.498], [0.3915, 0.8649]]],[[[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]], [[0, 0]]], 1, 1, Loc56172), 
exec_layers([LBat42783,LRes62058,LFla80193,LMin90456,LRes52700,LGlo18107,LCon5025,LMul20361,LRes75523,LRes76398,LLoc56172],["Bat42783","Res62058","Fla80193","Min90456","Res52700","Glo18107","Con5025","Mul20361","Res75523","Res76398","Loc56172"],Loc56172,"Loc56172")

Actual (Unparsed): [[[[0.5049970, 0.3581012]], [[0.1563793, 0.2042025]], [[0.3352394, 0.7143900]], [[1.6651975, 1.6685073]], [[1.5789562, 2.7504973]], [[1.2126066, 1.4734312]], [[1.8310456, 0.9679589]], [[0.5028145, 1.5296792]], [[1.2857517, 0.3427064]], [[0.2650575, 0.3296401]]]]

Expected (Unparsed): [[[[0.5049970531878253,0.3581011817559391]],[[0.15637931677974767,0.2042024772022349]],[[0.3352393605018676,0.714390006006392]],[[1.6651974860392076,1.6685073131112909]],[[1.5789562466791165,2.7504973495712015]],[[1.2126065890574769,1.4734312062225645]],[[1.8310455707588942,0.9679589134217839]],[[0.5028145073648588,1.529679116266084]],[[1.2857516887271938,0.3427063986150151]],[[0.2650574984286316,0.329640144729945]]]]

Actual:   [[[[0.505, 0.3582]], [[0.1564, 0.2043]], [[0.3353, 0.7144]], [[1.6652, 1.6686]], [[1.579, 2.7505]], [[1.2127, 1.4735]], [[1.8311, 0.968]], [[0.5029, 1.5297]], [[1.2858, 0.3428]], [[0.2651, 0.3297]]]]

Expected: [[[[0.505, 0.3582]], [[0.1564, 0.2043]], [[0.3353, 0.7144]], [[1.6652, 1.6686]], [[1.579, 2.7505]], [[1.2127, 1.4735]], [[1.8311, 0.968]], [[0.5029, 1.5297]], [[1.2858, 0.3428]], [[0.2651, 0.3297]]]]