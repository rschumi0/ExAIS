import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ELU11351 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con73312 = tf.keras.layers.Input(shape=([1, 1, 1, 3]))
in0ReL82103 = tf.keras.layers.Input(shape=([1, 1, 1]))

ELU11351 = keras.layers.ELU(alpha=-7.3333937064561, name = 'ELU11351', input_shape=(1, 2, 1))(in0ELU11351)
Glo13194 = keras.layers.GlobalMaxPool2D(name = 'Glo13194', )(ELU11351)
Res61312 = keras.layers.Reshape((1, 1), name = 'Res61312', )(Glo13194)
Res87773 = keras.layers.Reshape((1, 1, 1), name = 'Res87773', )(Res61312)
Res88543 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res88543', )(Res87773)
Con73312 = keras.layers.Concatenate(axis=4, name = 'Con73312', )([Res88543,in0Con73312])
ReL82103 = keras.layers.ReLU(max_value=5.013151476060883, negative_slope=0.2256154350459796, threshold=3.906515610774658, name = 'ReL82103', input_shape=(1, 1, 1))(in0ReL82103)
Res92489 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res92489', )(ReL82103)
Con98164 = keras.layers.Conv3DTranspose(4, (1, 1, 1),strides=(1, 1, 1), padding='valid', name = 'Con98164', )(Res92489)
Add59944 = keras.layers.Add(name = 'Add59944', )([Con73312,Con98164])
model = tf.keras.models.Model(inputs=[in0ELU11351,in0Con73312,in0ReL82103], outputs=Add59944)
w = model.get_layer('Con98164').get_weights() 
w[0] = np.array([[[[[0.8331], [0.9303], [0.8629], [0.3125]]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con98164').set_weights(w) 
in0ELU11351 = tf.constant([[[[0.3908], [0.5144]]]])
in0Con73312 = tf.constant([[[[[0.4553, 0.3565, 0.8775]]]]])
in0ReL82103 = tf.constant([[[[0.0934]]]])
print (np.array2string(model.predict([in0ELU11351,in0Con73312,in0ReL82103],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add59944.png')

LELU11351 = elu_layer([[[[0.3908], [0.5144]]]], -7.3333937064561, ELU11351), 
LGlo13194 = global_max_pool2D_layer(ELU11351, Glo13194), 
LRes61312 = reshape_layer(Glo13194, [1, 1], Res61312), 
LRes87773 = reshape_layer(Res61312, [1, 1, 1], Res87773), 
LRes88543 = reshape_layer(Res87773, [1, 1, 1, 1], Res88543), 
LCon73312 = concatenate_layer([Res88543,[[[[[0.4553, 0.3565, 0.8775]]]]]], 4, Con73312), 
LReL82103 = relu_layer([[[[0.0934]]]], 5.013151476060883, 0.2256154350459796, 3.906515610774658, ReL82103), 
LRes92489 = reshape_layer(ReL82103, [1, 1, 1, 1], Res92489), 
LCon98164 = conv3D_transpose_layer(Res92489, 1, 1, 1,[[[[[0.8331], [0.9303], [0.8629], [0.3125]]]]],[0, 0, 0, 0], 1, 1, 1, false, Con98164), 
LAdd59944 = add_layer([Con73312,Con98164], Add59944), 
exec_layers([LELU11351,LGlo13194,LRes61312,LRes87773,LRes88543,LCon73312,LReL82103,LRes92489,LCon98164,LAdd59944],["ELU11351","Glo13194","Res61312","Res87773","Res88543","Con73312","ReL82103","Res92489","Con98164","Add59944"],Add59944,"Add59944")

Actual (Unparsed): [[[[[-0.2023140, -0.3450350, -0.3858509, 0.6086570]]]]]

Expected (Unparsed): [[[[[-0.202314045032556,-0.34503498510837466,-0.38585091760724116,0.6086569570607685]]]]]

Actual:   [[[[[-0.2023, -0.345, -0.3858, 0.6087]]]]]

Expected: [[[[[-0.2023, -0.345, -0.3858, 0.6087]]]]]