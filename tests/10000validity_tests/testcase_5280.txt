import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo10760 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Dep19075 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Max5124 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Max5124 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con55494 = tf.keras.layers.Input(shape=([3]))

Glo10760 = keras.layers.GlobalMaxPool3D(name = 'Glo10760', )(in0Glo10760)
Res75871 = keras.layers.Reshape((2, 1), name = 'Res75871', )(Glo10760)
Dep19075 = keras.layers.DepthwiseConv2D((1, 1),strides=(1, 1), padding='valid', name = 'Dep19075', )(in0Dep19075)
Ave63890 = keras.layers.AveragePooling2D(pool_size=(1, 1), name = 'Ave63890', )(Dep19075)
Res55176 = keras.layers.Reshape((1, 1), name = 'Res55176', )(Ave63890)
Zer57383 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer57383', )(Res55176)
Dot97956 = keras.layers.Dot(axes=(2, 2), name = 'Dot97956', )([Res75871,Zer57383])
Fla41068 = keras.layers.Flatten(name = 'Fla41068', )(Dot97956)
Max5124 = keras.layers.Maximum(name = 'Max5124', )([in0Max5124,in1Max5124])
Con31679 = keras.layers.Conv2DTranspose(3, (1, 1),strides=(1, 1), padding='valid', name = 'Con31679', )(Max5124)
Res5266 = keras.layers.Reshape((2, 3), name = 'Res5266', )(Con31679)
LST23227 = keras.layers.LSTM(1,recurrent_activation='sigmoid', name = 'LST23227', )(Res5266)
Con55494 = keras.layers.Concatenate(axis=1, name = 'Con55494', )([LST23227,in0Con55494])
Add45527 = keras.layers.Add(name = 'Add45527', )([Fla41068,Con55494])
model = tf.keras.models.Model(inputs=[in0Glo10760,in0Dep19075,in0Max5124,in1Max5124,in0Con55494], outputs=Add45527)
w = model.get_layer('Dep19075').get_weights() 
w[0] = np.array([[[[0.5278]]]])
w[1] = np.array([0])
model.get_layer('Dep19075').set_weights(w) 
w = model.get_layer('Con31679').get_weights() 
w[0] = np.array([[[[0.9609], [0.1101], [0.9932]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con31679').set_weights(w) 
w = model.get_layer('LST23227').get_weights() 
w[0] = np.array([[6, 7, 8, 4], [1, 5, 2, 8], [8, 9, 9, 7]])
w[1] = np.array([[7, 10, 6, 7]])
w[2] = np.array([10, 3, 9, 9])
model.get_layer('LST23227').set_weights(w) 
in0Glo10760 = tf.constant([[[[[1.5584, 1.2652], [1.4218, 1.5615]]]]])
in0Dep19075 = tf.constant([[[[0.6215]]]])
in0Max5124 = tf.constant([[[[0.9723]], [[0.6341]]]])
in1Max5124 = tf.constant([[[[0.4248]], [[0.0014]]]])
in0Con55494 = tf.constant([[0.4689, 0.4493, 0.1788]])
print (np.array2string(model.predict([in0Glo10760,in0Dep19075,in0Max5124,in1Max5124,in0Con55494],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add45527.png')

LGlo10760 = global_max_pool3D_layer([[[[[1.5584, 1.2652], [1.4218, 1.5615]]]]], Glo10760), 
LRes75871 = reshape_layer(Glo10760, [2, 1], Res75871), 
LDep19075 = depthwise_conv2D_layer([[[[0.6215]]]], 1, 1,[[[[0.5278]]]],[0], 1, 1, false, Dep19075), 
LAve63890 = average_pooling2D_layer(Dep19075, 1, 1, Ave63890), 
LRes55176 = reshape_layer(Ave63890, [1, 1], Res55176), 
LZer57383 = zero_padding1D_layer(Res55176, 1, 0, Zer57383), 
LDot97956 = dot_layer(Res75871,Zer57383, 2, 2, Dot97956), 
LFla41068 = flatten_layer(Dot97956, Fla41068), 
LMax5124 = maximum_layer([[[[[0.9723]], [[0.6341]]]], [[[[0.4248]], [[0.0014]]]]], Max5124), 
LCon31679 = conv2D_transpose_layer(Max5124, 1, 1,[[[[0.9609], [0.1101], [0.9932]]]],[0, 0, 0], 1, 1, false, Con31679), 
LRes5266 = reshape_layer(Con31679, [2, 3], Res5266), 
LLST23227 = lstm_layer(Res5266,[[6, 7, 8, 4], [1, 5, 2, 8], [8, 9, 9, 7]],[[7, 10, 6, 7]],[10, 3, 9, 9], LST23227), 
LCon55494 = concatenate_layer([LST23227,[[0.4689, 0.4493, 0.1788]]], 1, Con55494), 
LAdd45527 = add_layer([Fla41068,Con55494], Add45527), 
exec_layers([LGlo10760,LRes75871,LDep19075,LAve63890,LRes55176,LZer57383,LDot97956,LFla41068,LMax5124,LCon31679,LRes5266,LLST23227,LCon55494,LAdd45527],["Glo10760","Res75871","Dep19075","Ave63890","Res55176","Zer57383","Dot97956","Fla41068","Max5124","Con31679","Res5266","LST23227","Con55494","Add45527"],Add45527,"Add45527")

Actual (Unparsed): [[0.9640276, 0.9800984, 0.4493000, 0.6910153]]

Expected (Unparsed): [[0.9640275796590428,0.98009836768,0.4493,0.69101525355]]

Actual:   [[0.9641, 0.9801, 0.4493, 0.6911]]

Expected: [[0.9641, 0.9801, 0.4493, 0.6911]]