import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat738 = tf.keras.layers.Input(shape=([4, 4]))
in0Con65304 = tf.keras.layers.Input(shape=([4, 12]))
in0Zer95955 = tf.keras.layers.Input(shape=([2, 4, 2, 4]))

Bat738 = keras.layers.BatchNormalization(axis=1, epsilon=0.46668898552925275,  name = 'Bat738', )(in0Bat738)
Bat13216 = keras.layers.BatchNormalization(axis=2, epsilon=0.3138029218837414,  name = 'Bat13216', )(Bat738)
Con65304 = keras.layers.Concatenate(axis=2, name = 'Con65304', )([Bat13216,in0Con65304])
Zer95955 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer95955', )(in0Zer95955)
Res83443 = keras.layers.Reshape((4, 6, 16), name = 'Res83443', )(Zer95955)
Ave43808 = keras.layers.AveragePooling2D(pool_size=(2, 4), name = 'Ave43808', )(Res83443)
Res78910 = keras.layers.Reshape((2, 16), name = 'Res78910', )(Ave43808)
Dot3088 = keras.layers.Dot(axes=(2, 2), name = 'Dot3088', )([Con65304,Res78910])
model = tf.keras.models.Model(inputs=[in0Bat738,in0Con65304,in0Zer95955], outputs=Dot3088)
w = model.get_layer('Bat738').get_weights() 
w[0] = np.array([0.1561, 0.6201, 0.9615, 0.7962])
w[1] = np.array([0.8021, 0.9586, 0.8085, 0.9238])
w[2] = np.array([0.6027, 0.1448, 0.4652, 0.2289])
w[3] = np.array([0.7246, 0.9418, 0.4675, 0.2214])
model.get_layer('Bat738').set_weights(w) 
w = model.get_layer('Bat13216').get_weights() 
w[0] = np.array([0.6942, 0.1518, 0.3284, 0.859])
w[1] = np.array([0.4423, 0.5823, 0.2444, 0.2404])
w[2] = np.array([0.21, 0.1033, 0.3087, 0.6915])
w[3] = np.array([0.9696, 0.4247, 0.6405, 0.0447])
model.get_layer('Bat13216').set_weights(w) 
in0Bat738 = tf.constant([[[1.3782, 1.5845, 1.892, 1.9638], [1.9983, 1.3912, 1.0321, 1.8836], [1.2615, 1.0195, 1.0501, 1.6441], [1.3022, 1.0993, 1.4888, 1.3524]]])
in0Con65304 = tf.constant([[[0.6278, 0.8535, 0.6875, 0.3664, 0.3079, 0.3005, 0.8409, 0.7838, 0.5086, 0.6338, 0.4971, 0.7865], [0.655, 0.6831, 0.2669, 0.8467, 0.3009, 0.3127, 0.696, 0.3446, 0.3172, 0.0736, 0.0214, 0.773], [0.1481, 0.4159, 0.698, 0.8119, 0.4453, 0.8728, 0.4255, 0.6655, 0.2622, 0.6955, 0.974, 0.9524], [0.5172, 0.3909, 0.8422, 0.7414, 0.6219, 0.4949, 0.6698, 0.031, 0.0093, 0.6999, 0.3668, 0.0886]]])
in0Zer95955 = tf.constant([[[[[1.4005, 1.6662, 1.9838, 1.422], [1.7252, 1.7696, 1.8424, 1.2011]], [[1.3508, 1.3465, 1.9579, 1.0719], [1.8107, 1.7797, 1.7285, 1.9866]], [[1.5788, 1.2844, 1.538, 1.5243], [1.7743, 1.0272, 1.5286, 1.1986]], [[1.0768, 1.6719, 1.8537, 1.9316], [1.307, 1.8664, 1.3291, 1.3178]]], [[[1.3787, 1.0397, 1.42, 1.5473], [1.3605, 1.759, 1.8013, 1.6288]], [[1.2008, 1.8143, 1.302, 1.8636], [1.2606, 1.1437, 1.9109, 1.3532]], [[1.1788, 1.6884, 1.6592, 1.6952], [1.7486, 1.2778, 1.6177, 1.9205]], [[1.4244, 1.684, 1.9539, 1.1534], [1.7964, 1.0546, 1.976, 1.4427]]]]])
print (np.array2string(model.predict([in0Bat738,in0Con65304,in0Zer95955],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot3088.png')

LBat738 = batch_normalization_layer([[[1.3782, 1.5845, 1.892, 1.9638], [1.9983, 1.3912, 1.0321, 1.8836], [1.2615, 1.0195, 1.0501, 1.6441], [1.3022, 1.0993, 1.4888, 1.3524]]], 1, 0.46668898552925275, [0.1561, 0.6201, 0.9615, 0.7962], [0.8021, 0.9586, 0.8085, 0.9238], [0.6027, 0.1448, 0.4652, 0.2289], [0.7246, 0.9418, 0.4675, 0.2214], Bat738), 
LBat13216 = batch_normalization_layer(Bat738, 2, 0.3138029218837414, [0.6942, 0.1518, 0.3284, 0.859], [0.4423, 0.5823, 0.2444, 0.2404], [0.21, 0.1033, 0.3087, 0.6915], [0.9696, 0.4247, 0.6405, 0.0447], Bat13216), 
LCon65304 = concatenate_layer([Bat13216,[[[0.6278, 0.8535, 0.6875, 0.3664, 0.3079, 0.3005, 0.8409, 0.7838, 0.5086, 0.6338, 0.4971, 0.7865], [0.655, 0.6831, 0.2669, 0.8467, 0.3009, 0.3127, 0.696, 0.3446, 0.3172, 0.0736, 0.0214, 0.773], [0.1481, 0.4159, 0.698, 0.8119, 0.4453, 0.8728, 0.4255, 0.6655, 0.2622, 0.6955, 0.974, 0.9524], [0.5172, 0.3909, 0.8422, 0.7414, 0.6219, 0.4949, 0.6698, 0.031, 0.0093, 0.6999, 0.3668, 0.0886]]]], 2, Con65304), 
LZer95955 = zero_padding3D_layer([[[[[1.4005, 1.6662, 1.9838, 1.422], [1.7252, 1.7696, 1.8424, 1.2011]], [[1.3508, 1.3465, 1.9579, 1.0719], [1.8107, 1.7797, 1.7285, 1.9866]], [[1.5788, 1.2844, 1.538, 1.5243], [1.7743, 1.0272, 1.5286, 1.1986]], [[1.0768, 1.6719, 1.8537, 1.9316], [1.307, 1.8664, 1.3291, 1.3178]]], [[[1.3787, 1.0397, 1.42, 1.5473], [1.3605, 1.759, 1.8013, 1.6288]], [[1.2008, 1.8143, 1.302, 1.8636], [1.2606, 1.1437, 1.9109, 1.3532]], [[1.1788, 1.6884, 1.6592, 1.6952], [1.7486, 1.2778, 1.6177, 1.9205]], [[1.4244, 1.684, 1.9539, 1.1534], [1.7964, 1.0546, 1.976, 1.4427]]]]], 1, 1, 1, 1, 1, 1, Zer95955), 
LRes83443 = reshape_layer(Zer95955, [4, 6, 16], Res83443), 
LAve43808 = average_pooling2D_layer(Res83443, 2, 4, Ave43808), 
LRes78910 = reshape_layer(Ave43808, [2, 16], Res78910), 
LDot3088 = dot_layer(Con65304,Res78910, 2, 2, Dot3088), 
exec_layers([LBat738,LBat13216,LCon65304,LZer95955,LRes83443,LAve43808,LRes78910,LDot3088],["Bat738","Bat13216","Con65304","Zer95955","Res83443","Ave43808","Res78910","Dot3088"],Dot3088,"Dot3088")

Actual (Unparsed): [[[2.7952468, 2.7556891], [2.3407485, 2.3847967], [2.6204476, 2.5968203], [2.5790381, 2.4629145]]]

Expected (Unparsed): [[[2.7952467725,2.75568905875],[2.34074851125,2.38479675875],[2.620447505,2.59682032375],[2.5790380699999993,2.4629145625]]]

Actual:   [[[2.7953, 2.7557], [2.3408, 2.3848], [2.6205, 2.5969], [2.5791, 2.463]]]

Expected: [[[2.7953, 2.7557], [2.3408, 2.3848], [2.6205, 2.5969], [2.5791, 2.463]]]