import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo6402 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Glo92240 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con38269 = tf.keras.layers.Input(shape=([1]))

Glo6402 = keras.layers.GlobalMaxPool2D(name = 'Glo6402', )(in0Glo6402)
Glo92240 = keras.layers.GlobalAveragePooling2D(name = 'Glo92240', )(in0Glo92240)
Con38269 = keras.layers.Concatenate(axis=1, name = 'Con38269', )([Glo92240,in0Con38269])
Sub52908 = keras.layers.Subtract(name = 'Sub52908', )([Glo6402,Con38269])
Bat79412 = keras.layers.BatchNormalization(axis=1, epsilon=0.21979509143721032,  name = 'Bat79412', )(Sub52908)
model = tf.keras.models.Model(inputs=[in0Glo6402,in0Glo92240,in0Con38269], outputs=Bat79412)
w = model.get_layer('Bat79412').get_weights() 
w[0] = np.array([0.9904, 0.5846])
w[1] = np.array([0.486, 0.902])
w[2] = np.array([0.6879, 0.3845])
w[3] = np.array([0.3572, 0.7296])
model.get_layer('Bat79412').set_weights(w) 
in0Glo6402 = tf.constant([[[[1.5637, 1.769]], [[1.3736, 1.7163]]]])
in0Glo92240 = tf.constant([[[[1.2127]]]])
in0Con38269 = tf.constant([[0.2222]])
print (np.array2string(model.predict([in0Glo6402,in0Glo92240,in0Con38269],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat79412.png')

LGlo6402 = global_max_pool2D_layer([[[[1.5637, 1.769]], [[1.3736, 1.7163]]]], Glo6402), 
LGlo92240 = global_average_pooling2D_layer([[[[1.2127]]]], Glo92240), 
LCon38269 = concatenate_layer([Glo92240,[[0.2222]]], 1, Con38269), 
LSub52908 = subtract_layer(Glo6402,Con38269, Sub52908), 
LBat79412 = batch_normalization_layer(Sub52908, 1, 0.21979509143721032, [0.9904, 0.5846], [0.486, 0.902], [0.6879, 0.3845], [0.3572, 0.7296], Bat79412), 
exec_layers([LGlo6402,LGlo92240,LCon38269,LSub52908,LBat79412],["Glo6402","Glo92240","Con38269","Sub52908","Bat79412"],Bat79412,"Bat79412")

Actual (Unparsed): [[0.0467360, 1.5993544]]

Expected (Unparsed): [[0.04673602896191409,1.5993544198642593]]

Actual:   [[0.0468, 1.5994]]

Expected: [[0.0468, 1.5994]]