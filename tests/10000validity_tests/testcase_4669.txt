import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Thr62574 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con20240 = tf.keras.layers.Input(shape=([1, 2]))
in0Add44089 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))
in1Add44089 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))
in0Con79905 = tf.keras.layers.Input(shape=([4, 5, 3, 1]))
in0Sub43004 = tf.keras.layers.Input(shape=([3, 3, 2, 2]))
in1Sub43004 = tf.keras.layers.Input(shape=([3, 3, 2, 2]))

Thr62574 = keras.layers.ThresholdedReLU(theta=4.407837299192606, name = 'Thr62574', input_shape=(1, 2, 1))(in0Thr62574)
Res19452 = keras.layers.Reshape((1, 2), name = 'Res19452', )(Thr62574)
Con20240 = keras.layers.Concatenate(axis=2, name = 'Con20240', )([Res19452,in0Con20240])
Add44089 = keras.layers.Add(name = 'Add44089', )([in0Add44089,in1Add44089])
Res17230 = keras.layers.Reshape((1, 1, 1), name = 'Res17230', )(Add44089)
Res27180 = keras.layers.Reshape((1, 1), name = 'Res27180', )(Res17230)
Con62630 = keras.layers.Conv1D(4, (1),strides=(1), padding='same', dilation_rate=(1), name = 'Con62630', )(Res27180)
Add23057 = keras.layers.Add(name = 'Add23057', )([Con20240,Con62630])
Glo20618 = keras.layers.GlobalAveragePooling1D(name = 'Glo20618', )(Add23057)
Res46553 = keras.layers.Reshape((4, 1), name = 'Res46553', )(Glo20618)
Res54087 = keras.layers.Reshape((4, 1, 1), name = 'Res54087', )(Res46553)
Res91289 = keras.layers.Reshape((4, 1, 1, 1), name = 'Res91289', )(Res54087)
Zer60668 = keras.layers.ZeroPadding3D(padding=((0, 0), (4, 0), (2, 0)), name = 'Zer60668', )(Res91289)
Con79905 = keras.layers.Concatenate(axis=4, name = 'Con79905', )([Zer60668,in0Con79905])
Sub43004 = keras.layers.Subtract(name = 'Sub43004', )([in0Sub43004,in1Sub43004])
Thr25179 = keras.layers.ThresholdedReLU(theta=2.770124548988588, name = 'Thr25179', )(Sub43004)
ReL83012 = keras.layers.ReLU(max_value=2.315999240345276, negative_slope=8.702466357418025, threshold=0.3303454246170068, name = 'ReL83012', )(Thr25179)
Zer76659 = keras.layers.ZeroPadding3D(padding=((1, 0), (2, 0), (1, 0)), name = 'Zer76659', )(ReL83012)
Ave91166 = keras.layers.Average(name = 'Ave91166', )([Con79905,Zer76659])
model = tf.keras.models.Model(inputs=[in0Thr62574,in0Con20240,in0Add44089,in1Add44089,in0Con79905,in0Sub43004,in1Sub43004], outputs=Ave91166)
w = model.get_layer('Con62630').get_weights() 
w[0] = np.array([[[0.426, 0.9903, 0.0109, 0.8528]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con62630').set_weights(w) 
in0Thr62574 = tf.constant([[[[0.6072], [0.7086]]]])
in0Con20240 = tf.constant([[[0.9023, 0.4246]]])
in0Add44089 = tf.constant([[[[[0.4772]]]]])
in1Add44089 = tf.constant([[[[[0.3179]]]]])
in0Con79905 = tf.constant([[[[[0.7671], [0.3161], [0.8511]], [[0.1988], [0.1822], [0.8634]], [[0.0756], [0.1918], [0.718]], [[0.0856], [0.6794], [0.4887]], [[0.3876], [0.2777], [0.9853]]], [[[0.8259], [0.013], [0.8934]], [[0.3198], [0.7892], [0.4631]], [[0.6029], [0.6522], [0.9829]], [[0.3781], [0.2173], [0.2064]], [[0.6819], [0.5501], [0.4737]]], [[[0.4406], [0.8483], [0.5558]], [[0.9881], [0.7918], [0.4049]], [[0.0679], [0.6446], [0.4974]], [[0.8287], [0.5158], [0.3146]], [[0.6194], [0.4502], [0.4068]]], [[[0.0776], [0.123], [0.3297]], [[0.6741], [0.0474], [0.4899]], [[0.2145], [0.8746], [0.5026]], [[0.8848], [0.8793], [0.9235]], [[0.2628], [0.3324], [0.0999]]]]])
in0Sub43004 = tf.constant([[[[[0.6617, 0.957], [0.819, 0.2944]], [[0.8258, 0.6541], [0.723, 0.8329]], [[0.3647, 0.5723], [0.8974, 0.5351]]], [[[0.8, 0.3486], [0.1969, 0.978]], [[0.4068, 0.902], [0.1769, 0.0179]], [[0.0929, 0.0815], [0.1106, 0.6861]]], [[[0.7495, 0.1349], [0.9985, 0.1151]], [[0.5252, 0.3293], [0.0486, 0.388]], [[0.2496, 0.4634], [0.9476, 0.8085]]]]])
in1Sub43004 = tf.constant([[[[[0.403, 0.0673], [0.0046, 0.8513]], [[0.619, 0.8025], [0.9047, 0.9733]], [[0.6904, 0.948], [0.3812, 0.5388]]], [[[0.4472, 0.8845], [0.5856, 0.3467]], [[0.6766, 0.1761], [0.3176, 0.6307]], [[0.4625, 0.1863], [0.5599, 0.9526]]], [[[0.9373, 0.1654], [0.9584, 0.1051]], [[0.4575, 0.3975], [0.9849, 0.9993]], [[0.6432, 0.3065], [0.5251, 0.5221]]]]])
print (np.array2string(model.predict([in0Thr62574,in0Con20240,in0Add44089,in1Add44089,in0Con79905,in0Sub43004,in1Sub43004],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave91166.png')

LThr62574 = thresholded_relu_layer([[[[0.6072], [0.7086]]]], 4.407837299192606, Thr62574), 
LRes19452 = reshape_layer(Thr62574, [1, 2], Res19452), 
LCon20240 = concatenate_layer([Res19452,[[[0.9023, 0.4246]]]], 2, Con20240), 
LAdd44089 = add_layer([[[[[[0.4772]]]]], [[[[[0.3179]]]]]], Add44089), 
LRes17230 = reshape_layer(Add44089, [1, 1, 1], Res17230), 
LRes27180 = reshape_layer(Res17230, [1, 1], Res27180), 
LCon62630 = conv1D_layer(Res27180, 1,[[[0.426, 0.9903, 0.0109, 0.8528]]],[0, 0, 0, 0], 1, true, 1, Con62630), 
LAdd23057 = add_layer([Con20240,Con62630], Add23057), 
LGlo20618 = global_average_pooling1D_layer(Add23057, Glo20618), 
LRes46553 = reshape_layer(Glo20618, [4, 1], Res46553), 
LRes54087 = reshape_layer(Res46553, [4, 1, 1], Res54087), 
LRes91289 = reshape_layer(Res54087, [4, 1, 1, 1], Res91289), 
LZer60668 = zero_padding3D_layer(Res91289, 0, 0, 4, 0, 2, 0, Zer60668), 
LCon79905 = concatenate_layer([Zer60668,[[[[[0.7671], [0.3161], [0.8511]], [[0.1988], [0.1822], [0.8634]], [[0.0756], [0.1918], [0.718]], [[0.0856], [0.6794], [0.4887]], [[0.3876], [0.2777], [0.9853]]], [[[0.8259], [0.013], [0.8934]], [[0.3198], [0.7892], [0.4631]], [[0.6029], [0.6522], [0.9829]], [[0.3781], [0.2173], [0.2064]], [[0.6819], [0.5501], [0.4737]]], [[[0.4406], [0.8483], [0.5558]], [[0.9881], [0.7918], [0.4049]], [[0.0679], [0.6446], [0.4974]], [[0.8287], [0.5158], [0.3146]], [[0.6194], [0.4502], [0.4068]]], [[[0.0776], [0.123], [0.3297]], [[0.6741], [0.0474], [0.4899]], [[0.2145], [0.8746], [0.5026]], [[0.8848], [0.8793], [0.9235]], [[0.2628], [0.3324], [0.0999]]]]]], 4, Con79905), 
LSub43004 = subtract_layer([[[[[0.6617, 0.957], [0.819, 0.2944]], [[0.8258, 0.6541], [0.723, 0.8329]], [[0.3647, 0.5723], [0.8974, 0.5351]]], [[[0.8, 0.3486], [0.1969, 0.978]], [[0.4068, 0.902], [0.1769, 0.0179]], [[0.0929, 0.0815], [0.1106, 0.6861]]], [[[0.7495, 0.1349], [0.9985, 0.1151]], [[0.5252, 0.3293], [0.0486, 0.388]], [[0.2496, 0.4634], [0.9476, 0.8085]]]]], [[[[[0.403, 0.0673], [0.0046, 0.8513]], [[0.619, 0.8025], [0.9047, 0.9733]], [[0.6904, 0.948], [0.3812, 0.5388]]], [[[0.4472, 0.8845], [0.5856, 0.3467]], [[0.6766, 0.1761], [0.3176, 0.6307]], [[0.4625, 0.1863], [0.5599, 0.9526]]], [[[0.9373, 0.1654], [0.9584, 0.1051]], [[0.4575, 0.3975], [0.9849, 0.9993]], [[0.6432, 0.3065], [0.5251, 0.5221]]]]], Sub43004), 
LThr25179 = thresholded_relu_layer(Sub43004, 2.770124548988588, Thr25179), 
LReL83012 = relu_layer(Thr25179, 2.315999240345276, 8.702466357418025, 0.3303454246170068, ReL83012), 
LZer76659 = zero_padding3D_layer(ReL83012, 1, 0, 2, 0, 1, 0, Zer76659), 
LAve91166 = average_layer([Con79905,Zer76659], Ave91166), 
exec_layers([LThr62574,LRes19452,LCon20240,LAdd44089,LRes17230,LRes27180,LCon62630,LAdd23057,LGlo20618,LRes46553,LRes54087,LRes91289,LZer60668,LCon79905,LSub43004,LThr25179,LReL83012,LZer76659,LAve91166],["Thr62574","Res19452","Con20240","Add44089","Res17230","Res27180","Con62630","Add23057","Glo20618","Res46553","Res54087","Res91289","Zer60668","Con79905","Sub43004","Thr25179","ReL83012","Zer76659","Ave91166"],Ave91166,"Ave91166")

Actual (Unparsed): [[[[[0.0000000, 0.3835500], [0.0000000, 0.1580500], [0.0000000, 0.4255500]], [[0.0000000, 0.0994000], [0.0000000, 0.0911000], [0.0000000, 0.4317000]], [[0.0000000, 0.0378000], [0.0000000, 0.0959000], [0.0000000, 0.3590000]], [[0.0000000, 0.0428000], [0.0000000, 0.3397000], [0.0000000, 0.2443500]], [[0.0000000, 0.1938000], [0.0000000, 0.1388500], [0.1693563, 0.4926500]]], [[[0.0000000, 0.4129500], [0.0000000, 0.0065000], [0.0000000, 0.4467000]], [[0.0000000, 0.1599000], [0.0000000, 0.3946000], [0.0000000, 0.2315500]], [[0.0000000, 0.3014500], [-1.4374100, -1.1113100], [-1.4374100, -0.9459600]], [[0.0000000, 0.1890500], [-1.4374100, -1.3287600], [-1.4374100, -1.3342100]], [[0.0000000, 0.3409500], [-1.4374100, -1.1623600], [-1.0437162, -1.2005600]]], [[[0.0000000, 0.2203000], [0.0000000, 0.4241500], [0.0000000, 0.2779000]], [[0.0000000, 0.4940500], [0.0000000, 0.3959000], [0.0000000, 0.2024500]], [[0.0000000, 0.0339500], [-1.4374100, -1.1151100], [-1.4374100, -1.1887100]], [[0.0000000, 0.4143500], [-1.4374100, -1.1795100], [-1.4374100, -1.2801100]], [[0.0000000, 0.3097000], [-1.4374100, -1.2123100], [-0.9819267, -1.2340100]]], [[[0.0000000, 0.0388000], [0.0000000, 0.0615000], [0.0000000, 0.1648500]], [[0.0000000, 0.3370500], [0.0000000, 0.0237000], [0.0000000, 0.2449500]], [[0.0000000, 0.1072500], [-1.4374100, -1.0001100], [-1.4374100, -1.1861100]], [[0.0000000, 0.4424000], [-1.4374100, -0.9977600], [-1.4374100, -0.9756600]], [[0.0000000, 0.1314000], [-1.4374100, -1.2712100], [-0.8860793, -1.3874600]]]]]

Expected (Unparsed): [[[[[0,0.38355],[0,0.15805],[0,0.42555]],[[0,0.0994],[0,0.0911],[0,0.4317]],[[0,0.0378],[0,0.0959],[0,0.359]],[[0,0.0428],[0,0.3397],[0,0.24435]],[[0,0.1938],[0,0.13885],[0.16935630000000002,0.49265]]],[[[0,0.41295],[0,0.0065],[0,0.4467]],[[0,0.1599],[0,0.3946],[0,0.23155]],[[0,0.30145],[-1.437409972028237,-1.111309972028237],[-1.437409972028237,-0.945959972028237]],[[0,0.18905],[-1.437409972028237,-1.328759972028237],[-1.437409972028237,-1.334209972028237]],[[0,0.34095],[-1.437409972028237,-1.162359972028237],[-1.043716207028237,-1.200559972028237]]],[[[0,0.2203],[0,0.42415],[0,0.2779]],[[0,0.49405],[0,0.3959],[0,0.20245]],[[0,0.03395],[-1.437409972028237,-1.115109972028237],[-1.437409972028237,-1.188709972028237]],[[0,0.41435],[-1.437409972028237,-1.179509972028237],[-1.437409972028237,-1.280109972028237]],[[0,0.3097],[-1.437409972028237,-1.2123099720282369],[-0.9819266770282369,-1.234009972028237]]],[[[0,0.0388],[0,0.0615],[0,0.16485]],[[0,0.33705],[0,0.0237],[0,0.24495]],[[0,0.10725],[-1.437409972028237,-1.000109972028237],[-1.437409972028237,-1.1861099720282369]],[[0,0.4424],[-1.437409972028237,-0.997759972028237],[-1.437409972028237,-0.975659972028237]],[[0,0.1314],[-1.437409972028237,-1.271209972028237],[-0.886079332028237,-1.387459972028237]]]]]

Actual:   [[[[[0, 0.3836], [0, 0.1581], [0, 0.4256]], [[0, 0.0994], [0, 0.0911], [0, 0.4317]], [[0, 0.0378], [0, 0.0959], [0, 0.359]], [[0, 0.0428], [0, 0.3397], [0, 0.2444]], [[0, 0.1938], [0, 0.1389], [0.1694, 0.4927]]], [[[0, 0.413], [0, 0.0065], [0, 0.4467]], [[0, 0.1599], [0, 0.3946], [0, 0.2316]], [[0, 0.3015], [-1.4374, -1.1113], [-1.4374, -0.9459]], [[0, 0.1891], [-1.4374, -1.3287], [-1.4374, -1.3342]], [[0, 0.341], [-1.4374, -1.1623], [-1.0437, -1.2005]]], [[[0, 0.2203], [0, 0.4242], [0, 0.2779]], [[0, 0.4941], [0, 0.3959], [0, 0.2025]], [[0, 0.034], [-1.4374, -1.1151], [-1.4374, -1.1887]], [[0, 0.4144], [-1.4374, -1.1795], [-1.4374, -1.2801]], [[0, 0.3097], [-1.4374, -1.2123], [-0.9819, -1.234]]], [[[0, 0.0388], [0, 0.0615], [0, 0.1649]], [[0, 0.3371], [0, 0.0237], [0, 0.245]], [[0, 0.1073], [-1.4374, -1.0001], [-1.4374, -1.1861]], [[0, 0.4424], [-1.4374, -0.9977], [-1.4374, -0.9756]], [[0, 0.1314], [-1.4374, -1.2712], [-0.886, -1.3874]]]]]

Expected: [[[[[0, 0.3836], [0, 0.1581], [0, 0.4256]], [[0, 0.0994], [0, 0.0911], [0, 0.4317]], [[0, 0.0378], [0, 0.0959], [0, 0.359]], [[0, 0.0428], [0, 0.3397], [0, 0.2444]], [[0, 0.1938], [0, 0.1389], [0.1694, 0.4927]]], [[[0, 0.413], [0, 0.0065], [0, 0.4467]], [[0, 0.1599], [0, 0.3946], [0, 0.2316]], [[0, 0.3015], [-1.4374, -1.1113], [-1.4374, -0.9459]], [[0, 0.1891], [-1.4374, -1.3287], [-1.4374, -1.3342]], [[0, 0.341], [-1.4374, -1.1623], [-1.0437, -1.2005]]], [[[0, 0.2203], [0, 0.4242], [0, 0.2779]], [[0, 0.4941], [0, 0.3959], [0, 0.2025]], [[0, 0.034], [-1.4374, -1.1151], [-1.4374, -1.1887]], [[0, 0.4144], [-1.4374, -1.1795], [-1.4374, -1.2801]], [[0, 0.3097], [-1.4374, -1.2123], [-0.9819, -1.234]]], [[[0, 0.0388], [0, 0.0615], [0, 0.1649]], [[0, 0.3371], [0, 0.0237], [0, 0.245]], [[0, 0.1073], [-1.4374, -1.0001], [-1.4374, -1.1861]], [[0, 0.4424], [-1.4374, -0.9977], [-1.4374, -0.9756]], [[0, 0.1314], [-1.4374, -1.2712], [-0.886, -1.3874]]]]]