import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min73488 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Min73488 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Con71676 = tf.keras.layers.Input(shape=([2, 1]))
in0Add94428 = tf.keras.layers.Input(shape=([1, 1]))
in1Add94428 = tf.keras.layers.Input(shape=([1, 1]))
in0Con22487 = tf.keras.layers.Input(shape=([1]))
in0Sub88143 = tf.keras.layers.Input(shape=([2]))
in1Sub88143 = tf.keras.layers.Input(shape=([2]))
in0Sof17208 = tf.keras.layers.Input(shape=([1, 1, 2]))

Min73488 = keras.layers.Minimum(name = 'Min73488', )([in0Min73488,in1Min73488])
Res15397 = keras.layers.Reshape((2, 2, 4), name = 'Res15397', )(Min73488)
Res90187 = keras.layers.Reshape((2, 8), name = 'Res90187', )(Res15397)
Con71676 = keras.layers.Concatenate(axis=2, name = 'Con71676', )([Res90187,in0Con71676])
Add94428 = keras.layers.Add(name = 'Add94428', )([in0Add94428,in1Add94428])
Fla61019 = keras.layers.Flatten(name = 'Fla61019', )(Add94428)
Con22487 = keras.layers.Concatenate(axis=1, name = 'Con22487', )([Fla61019,in0Con22487])
Sub88143 = keras.layers.Subtract(name = 'Sub88143', )([in0Sub88143,in1Sub88143])
Mul73825 = keras.layers.Multiply(name = 'Mul73825', )([Con22487,Sub88143])
Res91403 = keras.layers.Reshape((2, 1), name = 'Res91403', )(Mul73825)
Res78334 = keras.layers.Reshape((2, 1, 1), name = 'Res78334', )(Res91403)
Res71728 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res71728', )(Res78334)
Zer14524 = keras.layers.ZeroPadding3D(padding=((0, 0), (2, 0), (2, 0)), name = 'Zer14524', )(Res71728)
Sof17208 = keras.layers.Softmax(axis=1, name = 'Sof17208', input_shape=(1, 1, 2))(in0Sof17208)
Res11741 = keras.layers.Reshape((1, 1, 2, 1), name = 'Res11741', )(Sof17208)
Up_99805 = keras.layers.UpSampling3D(size=(1, 2, 1), name = 'Up_99805', )(Res11741)
Zer62693 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (1, 0)), name = 'Zer62693', )(Up_99805)
Sub37588 = keras.layers.Subtract(name = 'Sub37588', )([Zer14524,Zer62693])
Res60071 = keras.layers.Reshape((2, 3, 3), name = 'Res60071', )(Sub37588)
Con4699 = keras.layers.Conv2D(3, (1, 2),strides=(1, 1), padding='same', dilation_rate=(1, 1), name = 'Con4699', )(Res60071)
Res28568 = keras.layers.Reshape((2, 9), name = 'Res28568', )(Con4699)
Dot11265 = keras.layers.Dot(axes=(1, 1), name = 'Dot11265', )([Con71676,Res28568])
model = tf.keras.models.Model(inputs=[in0Min73488,in1Min73488,in0Con71676,in0Add94428,in1Add94428,in0Con22487,in0Sub88143,in1Sub88143,in0Sof17208], outputs=Dot11265)
w = model.get_layer('Con4699').get_weights() 
w[0] = np.array([[[[0.2864, 0.0807, 0.7036], [0.4687, 0.9261, 0.3639], [0.3957, 0.4083, 0.4583]], [[0.9384, 0.4744, 0.4301], [0.2995, 0.9072, 0.3675], [0.4715, 0.3256, 0.8697]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con4699').set_weights(w) 
in0Min73488 = tf.constant([[[[[0.7146, 0.0892], [0.1264, 0.5639]], [[0.2853, 0.1972], [0.9791, 0.47]]], [[[0.9129, 0.3619], [0.3455, 0.1478]], [[0.9104, 0.8642], [0.8445, 0.4575]]]]])
in1Min73488 = tf.constant([[[[[0.1803, 0.7651], [0.1891, 0.4711]], [[0.9901, 0.5123], [0.1067, 0.5723]]], [[[0.2584, 0.9486], [0.5699, 0.3394]], [[0.9728, 0.7877], [0.0188, 0.9375]]]]])
in0Con71676 = tf.constant([[[0.8969], [0.6156]]])
in0Add94428 = tf.constant([[[0.8306]]])
in1Add94428 = tf.constant([[[0.8575]]])
in0Con22487 = tf.constant([[0.9356]])
in0Sub88143 = tf.constant([[0.0565, 0.4286]])
in1Sub88143 = tf.constant([[0.5769, 0.7962]])
in0Sof17208 = tf.constant([[[[0.3089, 0.7521]]]])
print (np.array2string(model.predict([in0Min73488,in1Min73488,in0Con71676,in0Add94428,in1Add94428,in0Con22487,in0Sub88143,in1Sub88143,in0Sof17208],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot11265.png')

LMin73488 = minimum_layer([[[[[[0.7146, 0.0892], [0.1264, 0.5639]], [[0.2853, 0.1972], [0.9791, 0.47]]], [[[0.9129, 0.3619], [0.3455, 0.1478]], [[0.9104, 0.8642], [0.8445, 0.4575]]]]], [[[[[0.1803, 0.7651], [0.1891, 0.4711]], [[0.9901, 0.5123], [0.1067, 0.5723]]], [[[0.2584, 0.9486], [0.5699, 0.3394]], [[0.9728, 0.7877], [0.0188, 0.9375]]]]]], Min73488), 
LRes15397 = reshape_layer(Min73488, [2, 2, 4], Res15397), 
LRes90187 = reshape_layer(Res15397, [2, 8], Res90187), 
LCon71676 = concatenate_layer([Res90187,[[[0.8969], [0.6156]]]], 2, Con71676), 
LAdd94428 = add_layer([[[[0.8306]]], [[[0.8575]]]], Add94428), 
LFla61019 = flatten_layer(Add94428, Fla61019), 
LCon22487 = concatenate_layer([Fla61019,[[0.9356]]], 1, Con22487), 
LSub88143 = subtract_layer([[0.0565, 0.4286]], [[0.5769, 0.7962]], Sub88143), 
LMul73825 = multiply_layer([Con22487,Sub88143], Mul73825), 
LRes91403 = reshape_layer(Mul73825, [2, 1], Res91403), 
LRes78334 = reshape_layer(Res91403, [2, 1, 1], Res78334), 
LRes71728 = reshape_layer(Res78334, [2, 1, 1, 1], Res71728), 
LZer14524 = zero_padding3D_layer(Res71728, 0, 0, 2, 0, 2, 0, Zer14524), 
LSof17208 = softmax_layer([[[[0.3089, 0.7521]]]], 1, Sof17208), 
LRes11741 = reshape_layer(Sof17208, [1, 1, 2, 1], Res11741), 
LUp_99805 = up_sampling3D_layer(Res11741, 1, 2, 1, Up_99805), 
LZer62693 = zero_padding3D_layer(Up_99805, 1, 0, 1, 0, 1, 0, Zer62693), 
LSub37588 = subtract_layer(Zer14524,Zer62693, Sub37588), 
LRes60071 = reshape_layer(Sub37588, [2, 3, 3], Res60071), 
LCon4699 = conv2D_layer(Res60071, 1, 2,[[[[0.2864, 0.0807, 0.7036], [0.4687, 0.9261, 0.3639], [0.3957, 0.4083, 0.4583]], [[0.9384, 0.4744, 0.4301], [0.2995, 0.9072, 0.3675], [0.4715, 0.3256, 0.8697]]]],[0, 0, 0], 1, 1, true, 1, 1, Con4699), 
LRes28568 = reshape_layer(Con4699, [2, 9], Res28568), 
LDot11265 = dot_layer(Con71676,Res28568, 1, 1, Dot11265), 
exec_layers([LMin73488,LRes15397,LRes90187,LCon71676,LAdd94428,LFla61019,LCon22487,LSub88143,LMul73825,LRes91403,LRes78334,LRes71728,LZer14524,LSof17208,LRes11741,LUp_99805,LZer62693,LSub37588,LRes60071,LCon4699,LRes28568,LDot11265],["Min73488","Res15397","Res90187","Con71676","Add94428","Fla61019","Con22487","Sub88143","Mul73825","Res91403","Res78334","Res71728","Zer14524","Sof17208","Res11741","Up_99805","Zer62693","Sub37588","Res60071","Con4699","Res28568","Dot11265"],Dot11265,"Dot11265")

Actual (Unparsed): [[[-0.1992264, -0.3185555, -0.3196925, -0.5391713, -0.7438729, -0.7471926, -0.3212025, -0.4457660, -0.3257766], [-0.2790249, -0.4461503, -0.4477427, -0.6874847, -0.9951105, -0.9216964, -0.3930854, -0.5657341, -0.3905103], [-0.2663805, -0.4259324, -0.4274526, -0.6734132, -0.9618124, -0.9114384, -0.3896087, -0.5548900, -0.3894183], [-0.1139538, -0.1822078, -0.1828582, -0.4608124, -0.5307345, -0.7085182, -0.3116352, -0.3869563, -0.3344875], [-0.7019184, -1.1223411, -1.1263468, -1.7546730, -2.5207336, -2.3651651, -1.0100229, -1.4450140, -1.0068943], [-0.6073167, -0.9710766, -0.9745424, -1.4976206, -2.1667982, -2.0084654, -0.8566375, -1.2324528, -0.8512002], [-0.0144948, -0.0231766, -0.0232594, -0.0779900, -0.0808886, -0.1258610, -0.0559000, -0.0659985, -0.0613792], [-0.3527325, -0.5640060, -0.5660190, -1.0170615, -1.3601627, -1.4381093, -0.6211052, -0.8433151, -0.6374954], [-0.4746276, -0.7589117, -0.7616203, -1.4780808, -1.9058499, -2.1371504, -0.9276808, -1.2296082, -0.9642797]]]

Expected (Unparsed): [[[-0.1992264,-0.31855552000000004,-0.31969248000000006,-0.539171332872434,-0.7438729456781856,-0.7471926104923772,-0.3212024829387532,-0.4457659825319508,-0.32577659615575083],[-0.27902489999999996,-0.44615032000000004,-0.44774268,-0.687484701545648,-0.9951105041087231,-0.9216964445434783,-0.3930854327881504,-0.5657340666449376,-0.3905102908385376],[-0.26638049999999996,-0.4259324,-0.4274526,-0.6734131855199439,-0.9618124298733696,-0.9114383896218351,-0.38960873556785114,-0.5548900649794128,-0.3894183356602128],[-0.11395379999999998,-0.18220784,-0.18285816,-0.46081236316253793,-0.5307344700184992,-0.7085181990635403,-0.31163523669017235,-0.3869563015127556,-0.3344875257293556],[-0.7019183999999999,-1.1223411200000002,-1.12634688,-1.754673055128814,-2.5207336495735775,-2.3651651773775813,-1.010022924374277,-1.4450140880617068,-1.0068943655515068],[-0.6073166999999999,-0.9710765600000001,-0.97454244,-1.4976206614213599,-2.166798235569024,-2.008465447894288,-0.8566374948853279,-1.232452767686832,-0.8512002594388319],[-0.014494799999999999,-0.023176640000000002,-0.023259360000000003,-0.07799001229467399,-0.0808886127914016,-0.1258610146949692,-0.0559000213807052,-0.0659985465194388,-0.0613792069112388],[-0.35273249999999995,-0.5640060000000001,-0.566019,-1.017061492986,-1.3601626475424,-1.4381092308588,-0.6211051493627999,-0.8433151154532,-0.6374953856532],[-0.4746276,-0.7589116800000001,-0.7616203200000001,-1.478080800663078,-1.9058499305024352,-2.1371504135072725,-0.9276807618544644,-1.2296081804427037,-0.9642796802373036]]]

Actual:   [[[-0.1992, -0.3185, -0.3196, -0.5391, -0.7438, -0.7471, -0.3212, -0.4457, -0.3257], [-0.279, -0.4461, -0.4477, -0.6874, -0.9951, -0.9216, -0.393, -0.5657, -0.3905], [-0.2663, -0.4259, -0.4274, -0.6734, -0.9618, -0.9114, -0.3896, -0.5548, -0.3894], [-0.1139, -0.1822, -0.1828, -0.4608, -0.5307, -0.7085, -0.3116, -0.3869, -0.3344], [-0.7019, -1.1223, -1.1263, -1.7546, -2.5207, -2.3651, -1.01, -1.445, -1.0068], [-0.6073, -0.971, -0.9745, -1.4976, -2.1667, -2.0084, -0.8566, -1.2324, -0.8512], [-0.0144, -0.0231, -0.0232, -0.0779, -0.0808, -0.1258, -0.0559, -0.0659, -0.0613], [-0.3527, -0.564, -0.566, -1.017, -1.3601, -1.4381, -0.6211, -0.8433, -0.6374], [-0.4746, -0.7589, -0.7616, -1.478, -1.9058, -2.1371, -0.9276, -1.2296, -0.9642]]]

Expected: [[[-0.1992, -0.3185, -0.3196, -0.5391, -0.7438, -0.7471, -0.3212, -0.4457, -0.3257], [-0.279, -0.4461, -0.4477, -0.6874, -0.9951, -0.9216, -0.393, -0.5657, -0.3905], [-0.2663, -0.4259, -0.4274, -0.6734, -0.9618, -0.9114, -0.3896, -0.5548, -0.3894], [-0.1139, -0.1822, -0.1828, -0.4608, -0.5307, -0.7085, -0.3116, -0.3869, -0.3344], [-0.7019, -1.1223, -1.1263, -1.7546, -2.5207, -2.3651, -1.01, -1.445, -1.0068], [-0.6073, -0.971, -0.9745, -1.4976, -2.1667, -2.0084, -0.8566, -1.2324, -0.8512], [-0.0144, -0.0231, -0.0232, -0.0779, -0.0808, -0.1258, -0.0559, -0.0659, -0.0613], [-0.3527, -0.564, -0.566, -1.017, -1.3601, -1.4381, -0.6211, -0.8433, -0.6374], [-0.4746, -0.7589, -0.7616, -1.478, -1.9058, -2.1371, -0.9276, -1.2296, -0.9642]]]