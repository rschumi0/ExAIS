import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub75937 = tf.keras.layers.Input(shape=([2]))
in1Sub75937 = tf.keras.layers.Input(shape=([2]))
in0Bat50548 = tf.keras.layers.Input(shape=([3, 1]))
in0Con26085 = tf.keras.layers.Input(shape=([3, 3, 1]))
in0Lea75631 = tf.keras.layers.Input(shape=([1, 2, 2]))

Sub75937 = keras.layers.Subtract(name = 'Sub75937', )([in0Sub75937,in1Sub75937])
Res23155 = keras.layers.Reshape((2, 1), name = 'Res23155', )(Sub75937)
Sim24879 = keras.layers.SimpleRNN(3,name = 'Sim24879', )(Res23155)
Res22913 = keras.layers.Reshape((3, 1), name = 'Res22913', )(Sim24879)
Bat50548 = keras.layers.BatchNormalization(axis=2, epsilon=0.5258594189361308,  name = 'Bat50548', )(in0Bat50548)
Mul5246 = keras.layers.Multiply(name = 'Mul5246', )([Res22913,Bat50548])
Res89607 = keras.layers.Reshape((3, 1, 1), name = 'Res89607', )(Mul5246)
Zer40762 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer40762', )(Res89607)
Con26085 = keras.layers.Concatenate(axis=3, name = 'Con26085', )([Zer40762,in0Con26085])
Lea75631 = keras.layers.LeakyReLU(alpha=6.664994567736093, name = 'Lea75631', input_shape=(1, 2, 2))(in0Lea75631)
Zer33401 = keras.layers.ZeroPadding2D(padding=((2, 0), (1, 0)), name = 'Zer33401', )(Lea75631)
Sub41918 = keras.layers.Subtract(name = 'Sub41918', )([Con26085,Zer33401])
model = tf.keras.models.Model(inputs=[in0Sub75937,in1Sub75937,in0Bat50548,in0Con26085,in0Lea75631], outputs=Sub41918)
w = model.get_layer('Sim24879').get_weights() 
w[0] = np.array([[3, 6, 3]])
w[1] = np.array([[6, 5, 7], [1, 3, 1], [3, 9, 10]])
w[2] = np.array([10, 10, 10])
model.get_layer('Sim24879').set_weights(w) 
w = model.get_layer('Bat50548').get_weights() 
w[0] = np.array([0.2761])
w[1] = np.array([0.9339])
w[2] = np.array([0.2333])
w[3] = np.array([0.3786])
model.get_layer('Bat50548').set_weights(w) 
in0Sub75937 = tf.constant([[0.5367, 0.1375]])
in1Sub75937 = tf.constant([[0.6713, 0.8043]])
in0Bat50548 = tf.constant([[[1.2896], [1.0056], [1.234]]])
in0Con26085 = tf.constant([[[[0.9862], [0.477], [0.9381]], [[0.2894], [0.6787], [0.3546]], [[0.4828], [0.0801], [0.8289]]]])
in0Lea75631 = tf.constant([[[[0.864, 0.9647], [0.3219, 0.504]]]])
print (np.array2string(model.predict([in0Sub75937,in1Sub75937,in0Bat50548,in0Con26085,in0Lea75631],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub41918.png')

LSub75937 = subtract_layer([[0.5367, 0.1375]], [[0.6713, 0.8043]], Sub75937), 
LRes23155 = reshape_layer(Sub75937, [2, 1], Res23155), 
LSim24879 = simple_rnn_layer(Res23155,[[3, 6, 3]],[[6, 5, 7], [1, 3, 1], [3, 9, 10]],[10, 10, 10], Sim24879), 
LRes22913 = reshape_layer(Sim24879, [3, 1], Res22913), 
LBat50548 = batch_normalization_layer([[[1.2896], [1.0056], [1.234]]], 2, 0.5258594189361308, [0.2761], [0.9339], [0.2333], [0.3786], Bat50548), 
LMul5246 = multiply_layer([Res22913,Bat50548], Mul5246), 
LRes89607 = reshape_layer(Mul5246, [3, 1, 1], Res89607), 
LZer40762 = zero_padding2D_layer(Res89607, 0, 0, 2, 0, Zer40762), 
LCon26085 = concatenate_layer([Zer40762,[[[[0.9862], [0.477], [0.9381]], [[0.2894], [0.6787], [0.3546]], [[0.4828], [0.0801], [0.8289]]]]], 3, Con26085), 
LLea75631 = leaky_relu_layer([[[[0.864, 0.9647], [0.3219, 0.504]]]], 6.664994567736093, Lea75631), 
LZer33401 = zero_padding2D_layer(Lea75631, 2, 0, 1, 0, Zer33401), 
LSub41918 = subtract_layer(Con26085,Zer33401, Sub41918), 
exec_layers([LSub75937,LRes23155,LSim24879,LRes22913,LBat50548,LMul5246,LRes89607,LZer40762,LCon26085,LLea75631,LZer33401,LSub41918],["Sub75937","Res23155","Sim24879","Res22913","Bat50548","Mul5246","Res89607","Zer40762","Con26085","Lea75631","Zer33401","Sub41918"],Sub41918,"Sub41918")

Actual (Unparsed): [[[[0.0000000, 0.9862000], [0.0000000, 0.4770000], [1.2405614, 0.9381000]], [[0.0000000, 0.2894000], [0.0000000, 0.6787000], [1.1581115, 0.3546000]], [[0.0000000, 0.4828000], [-0.8640000, -0.8846000], [0.9025198, 0.3249000]]]]

Expected (Unparsed): [[[[0,0.9862],[0,0.477],[1.2405614208273381,0.9381]],[[0,0.2894],[0,0.6787],[1.1581115074362904,0.3546]],[[0,0.4828],[-0.864,-0.8846],[0.9025198180648655,0.32489999999999997]]]]

Actual:   [[[[0, 0.9862], [0, 0.477], [1.2406, 0.9381]], [[0, 0.2894], [0, 0.6787], [1.1582, 0.3546]], [[0, 0.4828], [-0.864, -0.8846], [0.9026, 0.3249]]]]

Expected: [[[[0, 0.9862], [0, 0.477], [1.2406, 0.9381]], [[0, 0.2894], [0, 0.6787], [1.1582, 0.3546]], [[0, 0.4828], [-0.864, -0.8846], [0.9026, 0.3249]]]]