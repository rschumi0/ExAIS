import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Cro92598 = tf.keras.layers.Input(shape=([3, 4, 2]))
in0Con88847 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Cro71287 = tf.keras.layers.Input(shape=([1, 4, 4]))

Cro92598 = keras.layers.Cropping2D(cropping=((1, 0), (0, 2)), name = 'Cro92598', )(in0Cro92598)
Con88847 = keras.layers.Concatenate(axis=3, name = 'Con88847', )([Cro92598,in0Con88847])
Cro71287 = keras.layers.Cropping2D(cropping=((0, 0), (2, 0)), name = 'Cro71287', )(in0Cro71287)
Zer97111 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer97111', )(Cro71287)
Max3879 = keras.layers.Maximum(name = 'Max3879', )([Con88847,Zer97111])
Res87383 = keras.layers.Reshape((2, 8), name = 'Res87383', )(Max3879)
Bat77127 = keras.layers.BatchNormalization(axis=2, epsilon=0.8604138474197952,  name = 'Bat77127', )(Res87383)
model = tf.keras.models.Model(inputs=[in0Cro92598,in0Con88847,in0Cro71287], outputs=Bat77127)
w = model.get_layer('Bat77127').get_weights() 
w[0] = np.array([0.6724, 0.7048, 0.5749, 0.3991, 0.2544, 0.6533, 0.1201, 0.07])
w[1] = np.array([0.5475, 0.1745, 0.2019, 0.0192, 0.8757, 0.5113, 0.1926, 0.5723])
w[2] = np.array([0.8369, 0.0046, 0.6849, 0.9856, 0.4065, 0.3873, 0.3835, 0.2535])
w[3] = np.array([0.6323, 0.3588, 0.3416, 0.6072, 0.5222, 0.3605, 0.5392, 0.5596])
model.get_layer('Bat77127').set_weights(w) 
in0Cro92598 = tf.constant([[[[1.2431, 1.8296], [1.8306, 1.5811], [1.5229, 1.9261], [1.993, 1.6772]], [[1.0446, 1.2648], [1.4641, 1.982], [1.7687, 1.2836], [1.7888, 1.8722]], [[1.5033, 1.6644], [1.9765, 1.2106], [1.1819, 1.6098], [1.1371, 1.5046]]]])
in0Con88847 = tf.constant([[[[0.374, 0.1376], [0.8654, 0.3925]], [[0.3623, 0.8107], [0.2728, 0.9572]]]])
in0Cro71287 = tf.constant([[[[1.1965, 1.0093, 1.7968, 1.7875], [1.0205, 1.3761, 1.3199, 1.9149], [1.7492, 1.8789, 1.404, 1.1726], [1.1213, 1.0075, 1.188, 1.5766]]]])
print (np.array2string(model.predict([in0Cro92598,in0Con88847,in0Cro71287],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat77127.png')

LCro92598 = cropping2D_layer([[[[1.2431, 1.8296], [1.8306, 1.5811], [1.5229, 1.9261], [1.993, 1.6772]], [[1.0446, 1.2648], [1.4641, 1.982], [1.7687, 1.2836], [1.7888, 1.8722]], [[1.5033, 1.6644], [1.9765, 1.2106], [1.1819, 1.6098], [1.1371, 1.5046]]]], 1, 0, 0, 2, Cro92598), 
LCon88847 = concatenate_layer([Cro92598,[[[[0.374, 0.1376], [0.8654, 0.3925]], [[0.3623, 0.8107], [0.2728, 0.9572]]]]], 3, Con88847), 
LCro71287 = cropping2D_layer([[[[1.1965, 1.0093, 1.7968, 1.7875], [1.0205, 1.3761, 1.3199, 1.9149], [1.7492, 1.8789, 1.404, 1.1726], [1.1213, 1.0075, 1.188, 1.5766]]]], 0, 0, 2, 0, Cro71287), 
LZer97111 = zero_padding2D_layer(Cro71287, 1, 0, 0, 0, Zer97111), 
LMax3879 = maximum_layer([Con88847,Zer97111], Max3879), 
LRes87383 = reshape_layer(Max3879, [2, 8], Res87383), 
LBat77127 = batch_normalization_layer(Res87383, 2, 0.8604138474197952, [0.6724, 0.7048, 0.5749, 0.3991, 0.2544, 0.6533, 0.1201, 0.07], [0.5475, 0.1745, 0.2019, 0.0192, 0.8757, 0.5113, 0.1926, 0.5723], [0.8369, 0.0046, 0.6849, 0.9856, 0.4065, 0.3873, 0.3835, 0.2535], [0.6323, 0.3588, 0.3416, 0.6072, 0.5222, 0.3605, 0.5392, 0.5596], Bat77127), 
exec_layers([LCro92598,LCon88847,LCro71287,LZer97111,LMax3879,LRes87383,LBat77127],["Cro92598","Con88847","Cro71287","Zer97111","Max3879","Res87383","Bat77127"],Bat77127,"Bat77127")

Actual (Unparsed): [[[0.6618078, 0.9788877, 0.0388735, -0.2601648, 1.1045169, 1.4541642, 0.2415211, 0.5804652], [1.0495848, 1.3708688, 0.5789743, 0.0808052, 1.2153771, 0.9980750, 0.2742704, 0.6500221]]]

Expected (Unparsed): [[[0.6618078142661962,0.9788877116052725,0.038873466049600486,-0.26016479714877216,1.1045169002703226,1.4541641924911328,0.24152105547405497,0.5804651948040421],[1.0495848288639902,1.3708687413599132,0.5789742379020016,0.08080520880521275,1.2153771306962995,0.9980749982303565,0.27427044849320864,0.6500220809009216]]]

Actual:   [[[0.6619, 0.9789, 0.0389, -0.2601, 1.1046, 1.4542, 0.2416, 0.5805], [1.0496, 1.3709, 0.579, 0.0809, 1.2154, 0.9981, 0.2743, 0.6501]]]

Expected: [[[0.6619, 0.9789, 0.0389, -0.2601, 1.1046, 1.4542, 0.2416, 0.5805], [1.0496, 1.3709, 0.579, 0.0809, 1.2154, 0.9981, 0.2743, 0.6501]]]