import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0GRU2253 = tf.keras.layers.Input(shape=([1, 2]))
in0Dot85810 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot85810 = tf.keras.layers.Input(shape=([3, 3]))
in0Con45689 = tf.keras.layers.Input(shape=([3, 3]))
in0Mul91129 = tf.keras.layers.Input(shape=([1, 1, 2]))
in1Mul91129 = tf.keras.layers.Input(shape=([1, 1, 2]))

GRU2253 = keras.layers.GRU(1,reset_after=False, recurrent_activation='sigmoid', name = 'GRU2253', )(in0GRU2253)
Res60236 = keras.layers.Reshape((1, 1), name = 'Res60236', )(GRU2253)
Per51473 = keras.layers.Permute((1,2), name = 'Per51473',)(Res60236)
Zer2649 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer2649', )(Per51473)
Dot85810 = keras.layers.Dot(axes=(2, 2), name = 'Dot85810', )([in0Dot85810,in1Dot85810])
Glo75677 = keras.layers.GlobalAveragePooling1D(name = 'Glo75677', )(Dot85810)
Res53536 = keras.layers.Reshape((3, 1), name = 'Res53536', )(Glo75677)
Con45689 = keras.layers.Concatenate(axis=2, name = 'Con45689', )([Res53536,in0Con45689])
Mul91129 = keras.layers.Multiply(name = 'Mul91129', )([in0Mul91129,in1Mul91129])
Den6280 = keras.layers.Dense(4,name = 'Den6280', )(Mul91129)
Res92742 = keras.layers.Reshape((1, 4), name = 'Res92742', )(Den6280)
Dot70437 = keras.layers.Dot(axes=(2, 2), name = 'Dot70437', )([Con45689,Res92742])
Max11929 = keras.layers.Maximum(name = 'Max11929', )([Zer2649,Dot70437])
Lea56778 = keras.layers.LeakyReLU(alpha=0.5452379862893612, name = 'Lea56778', )(Max11929)
model = tf.keras.models.Model(inputs=[in0GRU2253,in0Dot85810,in1Dot85810,in0Con45689,in0Mul91129,in1Mul91129], outputs=Lea56778)
w = model.get_layer('GRU2253').get_weights() 
w[0] = np.array([[4, 9, 8], [4, 1, 7]])
w[1] = np.array([[3, 2, 2]])
w[2] = np.array([3, 10, 10])
model.get_layer('GRU2253').set_weights(w) 
w = model.get_layer('Den6280').get_weights() 
w[0] = np.array([[0.3312, 0.4249, 0.5235, 0.2965], [0.364, 0.1731, 0.5022, 0.1201]])
w[1] = np.array([0.405, 0.8927, 0.3147, 0.2204])
model.get_layer('Den6280').set_weights(w) 
in0GRU2253 = tf.constant([[[6, 8]]])
in0Dot85810 = tf.constant([[[0.0123, 0.0242, 0.6706], [0.1902, 0.522, 0.0764], [0.628, 0.7404, 0.1132]]])
in1Dot85810 = tf.constant([[[0.0851, 0.3089, 0.2388], [0.4341, 0.0072, 0.3], [0.4334, 0.2163, 0.6959]]])
in0Con45689 = tf.constant([[[0.4457, 0.8786, 0.4334], [0.0775, 0.6787, 0.6639], [0.4756, 0.0646, 0.9581]]])
in0Mul91129 = tf.constant([[[[0.516, 0.7124]]]])
in1Mul91129 = tf.constant([[[[0.8597, 0.8589]]]])
print (np.array2string(model.predict([in0GRU2253,in0Dot85810,in1Dot85810,in0Con45689,in0Mul91129,in1Mul91129],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Lea56778.png')

LGRU2253 = gru_layer([[[6, 8]]],[[4, 9, 8], [4, 1, 7]],[[3, 2, 2]],[3, 10, 10], false, GRU2253), 
LRes60236 = reshape_layer(GRU2253, [1, 1], Res60236), 
LPer51473 = permute_layer(Res60236, 1,2, Per51473), 
LZer2649 = zero_padding1D_layer(Per51473, 2, 0, Zer2649), 
LDot85810 = dot_layer([[[0.0123, 0.0242, 0.6706], [0.1902, 0.522, 0.0764], [0.628, 0.7404, 0.1132]]], [[[0.0851, 0.3089, 0.2388], [0.4341, 0.0072, 0.3], [0.4334, 0.2163, 0.6959]]], 2, 2, Dot85810), 
LGlo75677 = global_average_pooling1D_layer(Dot85810, Glo75677), 
LRes53536 = reshape_layer(Glo75677, [3, 1], Res53536), 
LCon45689 = concatenate_layer([Res53536,[[[0.4457, 0.8786, 0.4334], [0.0775, 0.6787, 0.6639], [0.4756, 0.0646, 0.9581]]]], 2, Con45689), 
LMul91129 = multiply_layer([[[[[0.516, 0.7124]]]], [[[[0.8597, 0.8589]]]]], Mul91129), 
LDen6280 = dense_layer(Mul91129, [[0.3312, 0.4249, 0.5235, 0.2965], [0.364, 0.1731, 0.5022, 0.1201]],[0.405, 0.8927, 0.3147, 0.2204], Den6280), 
LRes92742 = reshape_layer(Den6280, [1, 4], Res92742), 
LDot70437 = dot_layer(Con45689,Res92742, 2, 2, Dot70437), 
LMax11929 = maximum_layer([Zer2649,Dot70437], Max11929), 
LLea56778 = leaky_relu_layer(Max11929, 0.5452379862893612, Lea56778), 
exec_layers([LGRU2253,LRes60236,LPer51473,LZer2649,LDot85810,LGlo75677,LRes53536,LCon45689,LMul91129,LDen6280,LRes92742,LDot70437,LMax11929,LLea56778],["GRU2253","Res60236","Per51473","Zer2649","Dot85810","Glo75677","Res53536","Con45689","Mul91129","Den6280","Res92742","Dot70437","Max11929","Lea56778"],Lea56778,"Lea56778")

Actual (Unparsed): [[[1.6378935], [1.1163078], [1.3467320]]]

Expected (Unparsed): [[[1.6378935348923365],[1.1163078547796261],[1.3467320269067529]]]

Actual:   [[[1.6379], [1.1164], [1.3468]]]

Expected: [[[1.6379], [1.1164], [1.3468]]]