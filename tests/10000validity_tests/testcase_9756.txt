import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo34485 = tf.keras.layers.Input(shape=([2, 1]))

Glo34485 = keras.layers.GlobalAveragePooling1D(name = 'Glo34485', )(in0Glo34485)
ELU68478 = keras.layers.ELU(alpha=6.204499867277619, name = 'ELU68478', )(Glo34485)
Res92253 = keras.layers.Reshape((1, 1), name = 'Res92253', )(ELU68478)
Res68645 = keras.layers.Reshape((1, 1, 1), name = 'Res68645', )(Res92253)
Glo72276 = keras.layers.GlobalMaxPool2D(name = 'Glo72276', )(Res68645)
Lay23182 = keras.layers.LayerNormalization(axis=1, epsilon=2.4527334686914823, name = 'Lay23182', )(Glo72276)
model = tf.keras.models.Model(inputs=[in0Glo34485], outputs=Lay23182)
in0Glo34485 = tf.constant([[[1.4601], [1.4456]]])
print (np.array2string(model.predict([in0Glo34485],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Lay23182.png')

LGlo34485 = global_average_pooling1D_layer([[[1.4601], [1.4456]]], Glo34485), 
LELU68478 = elu_layer(Glo34485, 6.204499867277619, ELU68478), 
LRes92253 = reshape_layer(ELU68478, [1, 1], Res92253), 
LRes68645 = reshape_layer(Res92253, [1, 1, 1], Res68645), 
LGlo72276 = global_max_pool2D_layer(Res68645, Glo72276), 
LLay23182 = layer_normalization_layer(Glo72276, 1, 2.4527334686914823, Lay23182), 
exec_layers([LGlo34485,LELU68478,LRes92253,LRes68645,LGlo72276,LLay23182],["Glo34485","ELU68478","Res92253","Res68645","Glo72276","Lay23182"],Lay23182,"Lay23182")

Actual (Unparsed): [[0.0000000]]

Expected (Unparsed): [[0.0]]

Actual:   [[0]]

Expected: [[0]]