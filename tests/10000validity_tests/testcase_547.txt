import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add38662 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Add38662 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con18730 = tf.keras.layers.Input(shape=([6, 2]))
in0Zer65725 = tf.keras.layers.Input(shape=([4, 3]))

Add38662 = keras.layers.Add(name = 'Add38662', )([in0Add38662,in1Add38662])
ELU70669 = keras.layers.ELU(alpha=0.005482684571187946, name = 'ELU70669', )(Add38662)
Glo98365 = keras.layers.GlobalMaxPool2D(name = 'Glo98365', )(ELU70669)
Res47299 = keras.layers.Reshape((2, 1), name = 'Res47299', )(Glo98365)
Zer30368 = keras.layers.ZeroPadding1D(padding=((4, 0)), name = 'Zer30368', )(Res47299)
Con18730 = keras.layers.Concatenate(axis=2, name = 'Con18730', )([Zer30368,in0Con18730])
Zer65725 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer65725', )(in0Zer65725)
Add65791 = keras.layers.Add(name = 'Add65791', )([Con18730,Zer65725])
model = tf.keras.models.Model(inputs=[in0Add38662,in1Add38662,in0Con18730,in0Zer65725], outputs=Add65791)
in0Add38662 = tf.constant([[[[0.8357, 0.3352], [0.0444, 0.4305]], [[0.6323, 0.3338], [0.498, 0.5481]]]])
in1Add38662 = tf.constant([[[[0.9777, 0.8524], [0.3648, 0.1697]], [[0.7605, 0.2327], [0.8669, 0.3429]]]])
in0Con18730 = tf.constant([[[0.5586, 0.4216], [0.1345, 0.9379], [0.1253, 0.1846], [0.5885, 0.6986], [0.2501, 0.8589], [0.8702, 0.0981]]])
in0Zer65725 = tf.constant([[[1.0114, 1.4357, 1.7388], [1.4322, 1.9429, 1.5843], [1.7993, 1.8408, 1.9466], [1.5561, 1.0593, 1.5482]]])
print (np.array2string(model.predict([in0Add38662,in1Add38662,in0Con18730,in0Zer65725],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add65791.png')

LAdd38662 = add_layer([[[[[0.8357, 0.3352], [0.0444, 0.4305]], [[0.6323, 0.3338], [0.498, 0.5481]]]], [[[[0.9777, 0.8524], [0.3648, 0.1697]], [[0.7605, 0.2327], [0.8669, 0.3429]]]]], Add38662), 
LELU70669 = elu_layer(Add38662, 0.005482684571187946, ELU70669), 
LGlo98365 = global_max_pool2D_layer(ELU70669, Glo98365), 
LRes47299 = reshape_layer(Glo98365, [2, 1], Res47299), 
LZer30368 = zero_padding1D_layer(Res47299, 4, 0, Zer30368), 
LCon18730 = concatenate_layer([Zer30368,[[[0.5586, 0.4216], [0.1345, 0.9379], [0.1253, 0.1846], [0.5885, 0.6986], [0.2501, 0.8589], [0.8702, 0.0981]]]], 2, Con18730), 
LZer65725 = zero_padding1D_layer([[[1.0114, 1.4357, 1.7388], [1.4322, 1.9429, 1.5843], [1.7993, 1.8408, 1.9466], [1.5561, 1.0593, 1.5482]]], 1, 1, Zer65725), 
LAdd65791 = add_layer([Con18730,Zer65725], Add65791), 
exec_layers([LAdd38662,LELU70669,LGlo98365,LRes47299,LZer30368,LCon18730,LZer65725,LAdd65791],["Add38662","ELU70669","Glo98365","Res47299","Zer30368","Con18730","Zer65725","Add65791"],Add65791,"Add65791")

Actual (Unparsed): [[[0.0000000, 0.5586000, 0.4216000], [1.0114000, 1.5702001, 2.6767001], [1.4322000, 2.0681999, 1.7689000], [1.7993000, 2.4293001, 2.6452000], [3.3695000, 1.3093999, 2.4071000], [1.1876000, 0.8702000, 0.0981000]]]

Expected (Unparsed): [[[0,0.5586,0.4216],[1.0114,1.5702,2.6767],[1.4322,2.0682,1.7689],[1.7993,2.4293,2.6452],[3.3695000000000004,1.3094,2.4071],[1.1876,0.8702,0.0981]]]

Actual:   [[[0, 0.5586, 0.4216], [1.0114, 1.5703, 2.6768], [1.4322, 2.0682, 1.7689], [1.7993, 2.4294, 2.6452], [3.3695, 1.3094, 2.4071], [1.1876, 0.8702, 0.0981]]]

Expected: [[[0, 0.5586, 0.4216], [1.0114, 1.5702, 2.6767], [1.4322, 2.0682, 1.7689], [1.7993, 2.4293, 2.6452], [3.3696, 1.3094, 2.4071], [1.1876, 0.8702, 0.0981]]]