import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Loc5781 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con27236 = tf.keras.layers.Input(shape=([3, 3, 2, 2]))
in0Sub30290 = tf.keras.layers.Input(shape=([3, 3, 2]))
in1Sub30290 = tf.keras.layers.Input(shape=([3, 3, 2]))

Loc5781 = keras.layers.LocallyConnected2D(2, (2, 2),strides=(1, 1), name = 'Loc5781', )(in0Loc5781)
Res69282 = keras.layers.Reshape((1, 1, 2, 1), name = 'Res69282', )(Loc5781)
Zer6425 = keras.layers.ZeroPadding3D(padding=((2, 0), (2, 0), (0, 0)), name = 'Zer6425', )(Res69282)
Con27236 = keras.layers.Concatenate(axis=4, name = 'Con27236', )([Zer6425,in0Con27236])
Sub30290 = keras.layers.Subtract(name = 'Sub30290', )([in0Sub30290,in1Sub30290])
Res17600 = keras.layers.Reshape((3, 3, 2, 1), name = 'Res17600', )(Sub30290)
Con35808 = keras.layers.Conv3D(3, (3, 3, 1),strides=(1, 1, 1), padding='same', dilation_rate=(1, 1, 1), name = 'Con35808', )(Res17600)
Bat21799 = keras.layers.BatchNormalization(axis=1, epsilon=0.9115638605758998,  name = 'Bat21799', )(Con35808)
Ave31717 = keras.layers.Average(name = 'Ave31717', )([Con27236,Bat21799])
model = tf.keras.models.Model(inputs=[in0Loc5781,in0Con27236,in0Sub30290,in1Sub30290], outputs=Ave31717)
w = model.get_layer('Loc5781').get_weights() 
w[0] = np.array([[[0.9743, 0.9223], [0.9172, 0.9189], [0.0087, 0.8443], [0.9592, 0.3666], [0.0197, 0.4849], [0.8257, 0.5321], [0.017, 0.8377], [0.6045, 0.1156]]])
w[1] = np.array([[[0, 0]]])
model.get_layer('Loc5781').set_weights(w) 
w = model.get_layer('Con35808').get_weights() 
w[0] = np.array([[[[[0.1537, 0.2165, 0.9699]]], [[[0.0235, 0.0462, 0.9898]]], [[[0.5181, 0.1154, 0.7311]]]], [[[[0.0972, 0.3995, 0.9818]]], [[[0.2721, 0.3233, 0.6864]]], [[[0.5238, 0.3464, 0.617]]]], [[[[0.4442, 0.4875, 0.9318]]], [[[0.6183, 0.5027, 0.344]]], [[[0.1534, 0.1311, 0.1273]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con35808').set_weights(w) 
w = model.get_layer('Bat21799').get_weights() 
w[0] = np.array([0.0988, 0.2912, 0.2263])
w[1] = np.array([0.2839, 0.779, 0.9797])
w[2] = np.array([0.5533, 0.3246, 0.144])
w[3] = np.array([0.1375, 0.5096, 0.0345])
model.get_layer('Bat21799').set_weights(w) 
in0Loc5781 = tf.constant([[[[0.5327, 0.9886], [0.3503, 0.9955]], [[0.2583, 0.9254], [0.827, 0.5392]]]])
in0Con27236 = tf.constant([[[[[0.3939, 0.2625], [0.2085, 0.3037]], [[0.5593, 0.2678], [0.9395, 0.7195]], [[0.179, 0.71], [0.768, 0.1293]]], [[[0.8399, 0.6376], [0.1983, 0.2393]], [[0.0902, 0.6205], [0.4863, 0.9525]], [[0.3598, 0.4219], [0.6395, 0.6847]]], [[[0.9888, 0.3614], [0.5202, 0.6597]], [[0.7316, 0.9817], [0.9477, 0.6716]], [[0.0164, 0.7991], [0.9364, 0.4255]]]]])
in0Sub30290 = tf.constant([[[[0.4135, 0.7721], [0.8614, 0.8144], [0.5725, 0.4725]], [[0.4706, 0.6098], [0.0909, 0.0773], [0.5847, 0.0366]], [[0.4987, 0.3423], [0.177, 0.8867], [0.862, 0.8112]]]])
in1Sub30290 = tf.constant([[[[0.5995, 0.8675], [0.8711, 0.1527], [0.1855, 0.9809]], [[0.3113, 0.8747], [0.291, 0.9952], [0.138, 0.7897]], [[0.2048, 0.0397], [0.5898, 0.7686], [0.7802, 0.8417]]]])
print (np.array2string(model.predict([in0Loc5781,in0Con27236,in0Sub30290,in1Sub30290],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave31717.png')

LLoc5781 = locally_connected2D_layer([[[[0.5327, 0.9886], [0.3503, 0.9955]], [[0.2583, 0.9254], [0.827, 0.5392]]]], 2, 2,[[[0.9743, 0.9223], [0.9172, 0.9189], [0.0087, 0.8443], [0.9592, 0.3666], [0.0197, 0.4849], [0.8257, 0.5321], [0.017, 0.8377], [0.6045, 0.1156]]],[[[0, 0]]], 1, 1, Loc5781), 
LRes69282 = reshape_layer(Loc5781, [1, 1, 2, 1], Res69282), 
LZer6425 = zero_padding3D_layer(Res69282, 2, 0, 2, 0, 0, 0, Zer6425), 
LCon27236 = concatenate_layer([Zer6425,[[[[[0.3939, 0.2625], [0.2085, 0.3037]], [[0.5593, 0.2678], [0.9395, 0.7195]], [[0.179, 0.71], [0.768, 0.1293]]], [[[0.8399, 0.6376], [0.1983, 0.2393]], [[0.0902, 0.6205], [0.4863, 0.9525]], [[0.3598, 0.4219], [0.6395, 0.6847]]], [[[0.9888, 0.3614], [0.5202, 0.6597]], [[0.7316, 0.9817], [0.9477, 0.6716]], [[0.0164, 0.7991], [0.9364, 0.4255]]]]]], 4, Con27236), 
LSub30290 = subtract_layer([[[[0.4135, 0.7721], [0.8614, 0.8144], [0.5725, 0.4725]], [[0.4706, 0.6098], [0.0909, 0.0773], [0.5847, 0.0366]], [[0.4987, 0.3423], [0.177, 0.8867], [0.862, 0.8112]]]], [[[[0.5995, 0.8675], [0.8711, 0.1527], [0.1855, 0.9809]], [[0.3113, 0.8747], [0.291, 0.9952], [0.138, 0.7897]], [[0.2048, 0.0397], [0.5898, 0.7686], [0.7802, 0.8417]]]], Sub30290), 
LRes17600 = reshape_layer(Sub30290, [3, 3, 2, 1], Res17600), 
LCon35808 = conv3D_layer(Res17600, 3, 3, 1,[[[[[0.1537, 0.2165, 0.9699]]], [[[0.0235, 0.0462, 0.9898]]], [[[0.5181, 0.1154, 0.7311]]]], [[[[0.0972, 0.3995, 0.9818]]], [[[0.2721, 0.3233, 0.6864]]], [[[0.5238, 0.3464, 0.617]]]], [[[[0.4442, 0.4875, 0.9318]]], [[[0.6183, 0.5027, 0.344]]], [[[0.1534, 0.1311, 0.1273]]]]],[0, 0, 0], 1, 1, 1, true, 1, 1, 1, Con35808), 
LBat21799 = batch_normalization_layer(Con35808, 1, 0.9115638605758998, [0.0988, 0.2912, 0.2263], [0.2839, 0.779, 0.9797], [0.5533, 0.3246, 0.144], [0.1375, 0.5096, 0.0345], Bat21799), 
LAve31717 = average_layer([Con27236,Bat21799], Ave31717), 
exec_layers([LLoc5781,LRes69282,LZer6425,LCon27236,LSub30290,LRes17600,LCon35808,LBat21799,LAve31717],["Loc5781","Res69282","Zer6425","Con27236","Sub30290","Res17600","Con35808","Bat21799","Ave31717"],Ave31717,"Ave31717")

Actual (Unparsed): [[[[[0.1158478, 0.3117485, 0.2414819], [0.1160377, 0.2168547, 0.2736159]], [[0.1247921, 0.3993629, 0.2581334], [0.0720365, 0.5517541, 0.4455149]], [[0.1293313, 0.2167371, 0.4810350], [0.0695702, 0.4642445, 0.1406695]]], [[[0.3556603, 0.7778782, 0.6495092], [0.3489908, 0.4289688, 0.4402292]], [[0.3809470, 0.4076709, 0.7248200], [0.2607284, 0.5307989, 0.7228583]], [[0.3470352, 0.5200012, 0.5763520], [0.3289968, 0.6148683, 0.5480860]]], [[[0.4456231, 0.9600872, 0.6489610], [0.4338262, 0.7355921, 0.7270190]], [[0.4975637, 0.8492615, 1.0033501], [0.4257640, 0.9425092, 0.6510705]], [[2.2151041, 0.4625515, 0.8608905], [2.1716009, 0.9184745, 0.5066207]]]]]

Expected (Unparsed): [[[[[0.11584780432593522,0.3117485265766329,0.2414819243972273],[0.11603774752738952,0.21685474192392748,0.2736159216915903]],[[0.12479207592208913,0.3993628533020008,0.2581334325263275],[0.07203651360219908,0.551754069349313,0.4455149394327014]],[[0.1293313340360251,0.21673710871380214,0.48103498413041296],[0.0695702042008955,0.46424444685567196,0.14066950417789806]]],[[[0.3556602956010601,0.7778781537443878,0.6495091501719994],[0.34899079094417607,0.428968835375256,0.4402292085757942]],[[0.3809470270570232,0.4076709003887483,0.7248200167521321],[0.26072839998525105,0.5307989428349393,0.7228583486267108]],[[0.3470352252855674,0.5200011742872409,0.576352008644399],[0.3289968036823498,0.6148682958475506,0.5480860378030109]]],[[[0.4456230801880608,0.9600871916376368,0.6489610455444952],[0.4338261947184299,0.7355920442038533,0.7270190576394915]],[[0.49756369892873453,0.8492615066406899,1.003350070728811],[0.4257639934495879,0.9425091606004503,0.6510705074922309]],[[2.2151040681587864,0.46255148176843364,0.8608905044339512],[2.1716008464781336,0.9184744979803252,0.5066206741781812]]]]]

Actual:   [[[[[0.1159, 0.3118, 0.2415], [0.1161, 0.2169, 0.2737]], [[0.1248, 0.3994, 0.2582], [0.0721, 0.5518, 0.4456]], [[0.1294, 0.2168, 0.4811], [0.0696, 0.4643, 0.1407]]], [[[0.3557, 0.7779, 0.6496], [0.349, 0.429, 0.4403]], [[0.381, 0.4077, 0.7249], [0.2608, 0.5308, 0.7229]], [[0.3471, 0.5201, 0.5764], [0.329, 0.6149, 0.5481]]], [[[0.4457, 0.9601, 0.649], [0.4339, 0.7356, 0.7271]], [[0.4976, 0.8493, 1.0034], [0.4258, 0.9426, 0.6511]], [[2.2152, 0.4626, 0.8609], [2.1717, 0.9185, 0.5067]]]]]

Expected: [[[[[0.1159, 0.3118, 0.2415], [0.1161, 0.2169, 0.2737]], [[0.1248, 0.3994, 0.2582], [0.0721, 0.5518, 0.4456]], [[0.1294, 0.2168, 0.4811], [0.0696, 0.4643, 0.1407]]], [[[0.3557, 0.7779, 0.6496], [0.349, 0.429, 0.4403]], [[0.381, 0.4077, 0.7249], [0.2608, 0.5308, 0.7229]], [[0.3471, 0.5201, 0.5764], [0.329, 0.6149, 0.5481]]], [[[0.4457, 0.9601, 0.649], [0.4339, 0.7356, 0.7271]], [[0.4976, 0.8493, 1.0034], [0.4258, 0.9426, 0.6511]], [[2.2152, 0.4626, 0.8609], [2.1717, 0.9185, 0.5067]]]]]