import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0PRe45519 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in0Con67596 = tf.keras.layers.Input(shape=([2, 2]))
in0Con16009 = tf.keras.layers.Input(shape=([2, 1]))

PRe45519 = keras.layers.PReLU(name = 'PRe45519', input_shape=(2, 2, 1, 1))(in0PRe45519)
Res93579 = keras.layers.Reshape((2, 2, 1), name = 'Res93579', )(PRe45519)
Glo49894 = keras.layers.GlobalMaxPool2D(name = 'Glo49894', )(Res93579)
Res25835 = keras.layers.Reshape((1, 1), name = 'Res25835', )(Glo49894)
Zer74067 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer74067', )(Res25835)
Con67596 = keras.layers.Concatenate(axis=2, name = 'Con67596', )([Zer74067,in0Con67596])
Con16009 = keras.layers.Conv1D(3, (1),strides=(1), padding='same', dilation_rate=(1), name = 'Con16009', )(in0Con16009)
Max64383 = keras.layers.Maximum(name = 'Max64383', )([Con67596,Con16009])
model = tf.keras.models.Model(inputs=[in0PRe45519,in0Con67596,in0Con16009], outputs=Max64383)
w = model.get_layer('PRe45519').get_weights() 
w[0] = np.array([[[[0.3466]], [[0.6955]]], [[[0.1183]], [[0.7043]]]])
model.get_layer('PRe45519').set_weights(w) 
w = model.get_layer('Con16009').get_weights() 
w[0] = np.array([[[0.8811, 0.6434, 0.9812]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con16009').set_weights(w) 
in0PRe45519 = tf.constant([[[[[0.1773]], [[0.6416]]], [[[0.0336]], [[0.4891]]]]])
in0Con67596 = tf.constant([[[0.8913, 0.7545], [0.371, 0.9793]]])
in0Con16009 = tf.constant([[[0.6872], [0.9195]]])
print (np.array2string(model.predict([in0PRe45519,in0Con67596,in0Con16009],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max64383.png')

LPRe45519 = prelu_layer([[[[[0.1773]], [[0.6416]]], [[[0.0336]], [[0.4891]]]]], [[[[0.3466]], [[0.6955]]], [[[0.1183]], [[0.7043]]]], PRe45519), 
LRes93579 = reshape_layer(PRe45519, [2, 2, 1], Res93579), 
LGlo49894 = global_max_pool2D_layer(Res93579, Glo49894), 
LRes25835 = reshape_layer(Glo49894, [1, 1], Res25835), 
LZer74067 = zero_padding1D_layer(Res25835, 1, 0, Zer74067), 
LCon67596 = concatenate_layer([Zer74067,[[[0.8913, 0.7545], [0.371, 0.9793]]]], 2, Con67596), 
LCon16009 = conv1D_layer([[[0.6872], [0.9195]]], 1,[[[0.8811, 0.6434, 0.9812]]],[0, 0, 0], 1, true, 1, Con16009), 
LMax64383 = maximum_layer([Con67596,Con16009], Max64383), 
exec_layers([LPRe45519,LRes93579,LGlo49894,LRes25835,LZer74067,LCon67596,LCon16009,LMax64383],["PRe45519","Res93579","Glo49894","Res25835","Zer74067","Con67596","Con16009","Max64383"],Max64383,"Max64383")

Actual (Unparsed): [[[0.6054919, 0.8913000, 0.7545000], [0.8101714, 0.5916063, 0.9793000]]]

Expected (Unparsed): [[[0.6054919200000001,0.8913,0.7545],[0.81017145,0.5916062999999999,0.9793]]]

Actual:   [[[0.6055, 0.8913, 0.7545], [0.8102, 0.5917, 0.9793]]]

Expected: [[[0.6055, 0.8913, 0.7545], [0.8102, 0.5917, 0.9793]]]