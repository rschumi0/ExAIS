import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub74843 = tf.keras.layers.Input(shape=([3, 2, 3, 2]))
in1Sub74843 = tf.keras.layers.Input(shape=([3, 2, 3, 2]))
in0Mas64951 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con23279 = tf.keras.layers.Input(shape=([3, 2, 4]))

Sub74843 = keras.layers.Subtract(name = 'Sub74843', )([in0Sub74843,in1Sub74843])
Res5596 = keras.layers.Reshape((3, 2, 6), name = 'Res5596', )(Sub74843)
Mas64951 = keras.layers.Masking(mask_value=2, name = 'Mas64951', )(in0Mas64951)
Zer36329 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer36329', )(Mas64951)
Con23279 = keras.layers.Concatenate(axis=3, name = 'Con23279', )([Zer36329,in0Con23279])
Max35480 = keras.layers.Maximum(name = 'Max35480', )([Res5596,Con23279])
Res72133 = keras.layers.Reshape((3, 12), name = 'Res72133', )(Max35480)
Glo25357 = keras.layers.GlobalAveragePooling1D(name = 'Glo25357', )(Res72133)
model = tf.keras.models.Model(inputs=[in0Sub74843,in1Sub74843,in0Mas64951,in0Con23279], outputs=Glo25357)
in0Sub74843 = tf.constant([[[[[0.9044, 0.7782], [0.0696, 0.9345], [0.2403, 0.1115]], [[0.4855, 0.4103], [0.1897, 0.9367], [0.4972, 0.0144]]], [[[0.1347, 0.1056], [0.668, 0.0189], [0.1043, 0.2288]], [[0.2621, 0.3844], [0.6319, 0.9217], [0.9196, 0.0611]]], [[[0.8902, 0.854], [0.0415, 0.6936], [0.4921, 0.22]], [[0.9354, 0.5743], [0.7164, 0.8095], [0.8555, 0.091]]]]])
in1Sub74843 = tf.constant([[[[[0.9476, 0.3359], [0.2936, 0.7122], [0.8015, 0.0577]], [[0.2733, 0.7633], [0.7514, 0.013], [0.9382, 0.86]]], [[[0.0651, 0.3842], [0.4271, 0.8884], [0.5158, 0.6021]], [[0.8862, 0.844], [0.6425, 0.8102], [0.4795, 0.6782]]], [[[0.2976, 0.2151], [0.4285, 0.539], [0.8432, 0.6718]], [[0.438, 0.4373], [0.6378, 0.5709], [0.3443, 0.4231]]]]])
in0Mas64951 = tf.constant([[[[1.3849, 1.7301]], [[1.4619, 1.8138]]]])
in0Con23279 = tf.constant([[[[0.3866, 0.2829, 0.2959, 0.224], [0.568, 0.4611, 0.4928, 0.767]], [[0.4705, 0.1526, 0.5233, 0.0449], [0.6052, 0.797, 0.9654, 0.8774]], [[0.629, 0.0278, 0.0197, 0.8022], [0.2862, 0.1532, 0.2898, 0.0246]]]])
print (np.array2string(model.predict([in0Sub74843,in1Sub74843,in0Mas64951,in0Con23279],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Glo25357.png')

LSub74843 = subtract_layer([[[[[0.9044, 0.7782], [0.0696, 0.9345], [0.2403, 0.1115]], [[0.4855, 0.4103], [0.1897, 0.9367], [0.4972, 0.0144]]], [[[0.1347, 0.1056], [0.668, 0.0189], [0.1043, 0.2288]], [[0.2621, 0.3844], [0.6319, 0.9217], [0.9196, 0.0611]]], [[[0.8902, 0.854], [0.0415, 0.6936], [0.4921, 0.22]], [[0.9354, 0.5743], [0.7164, 0.8095], [0.8555, 0.091]]]]], [[[[[0.9476, 0.3359], [0.2936, 0.7122], [0.8015, 0.0577]], [[0.2733, 0.7633], [0.7514, 0.013], [0.9382, 0.86]]], [[[0.0651, 0.3842], [0.4271, 0.8884], [0.5158, 0.6021]], [[0.8862, 0.844], [0.6425, 0.8102], [0.4795, 0.6782]]], [[[0.2976, 0.2151], [0.4285, 0.539], [0.8432, 0.6718]], [[0.438, 0.4373], [0.6378, 0.5709], [0.3443, 0.4231]]]]], Sub74843), 
LRes5596 = reshape_layer(Sub74843, [3, 2, 6], Res5596), 
LMas64951 = masking_layer([[[[1.3849, 1.7301]], [[1.4619, 1.8138]]]], 2, Mas64951), 
LZer36329 = zero_padding2D_layer(Mas64951, 1, 0, 1, 0, Zer36329), 
LCon23279 = concatenate_layer([Zer36329,[[[[0.3866, 0.2829, 0.2959, 0.224], [0.568, 0.4611, 0.4928, 0.767]], [[0.4705, 0.1526, 0.5233, 0.0449], [0.6052, 0.797, 0.9654, 0.8774]], [[0.629, 0.0278, 0.0197, 0.8022], [0.2862, 0.1532, 0.2898, 0.0246]]]]], 3, Con23279), 
LMax35480 = maximum_layer([Res5596,Con23279], Max35480), 
LRes72133 = reshape_layer(Max35480, [3, 12], Res72133), 
LGlo25357 = global_average_pooling1D_layer(Res72133, Glo25357), 
exec_layers([LSub74843,LRes5596,LMas64951,LZer36329,LCon23279,LMax35480,LRes72133,LGlo25357],["Sub74843","Res5596","Mas64951","Zer36329","Con23279","Max35480","Res72133","Glo25357"],Glo25357,"Glo25357")

Actual (Unparsed): [[0.2207333, 0.3604000, 0.4953667, 0.1967000, 0.2796333, 0.3570333, 1.0196667, 1.1813000, 0.4864667, 0.6531000, 0.6564667, 0.5563333]]

Expected (Unparsed): [[0.22073333333333334,0.3604,0.4953666666666667,0.19669999999999999,0.27963333333333334,0.3570333333333333,1.0196666666666667,1.1813,0.48646666666666666,0.6530999999999999,0.6564666666666668,0.5563333333333333]]

Actual:   [[0.2208, 0.3604, 0.4954, 0.1967, 0.2797, 0.3571, 1.0197, 1.1813, 0.4865, 0.6531, 0.6565, 0.5564]]

Expected: [[0.2208, 0.3604, 0.4954, 0.1967, 0.2797, 0.3571, 1.0197, 1.1813, 0.4865, 0.6531, 0.6565, 0.5564]]