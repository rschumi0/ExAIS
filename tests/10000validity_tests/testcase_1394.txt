import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo57205 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con40743 = tf.keras.layers.Input(shape=([4, 3]))
in0Max85897 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in1Max85897 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0Per6568 = tf.keras.layers.Input(shape=([3, 4]))
in0Add48402 = tf.keras.layers.Input(shape=([2, 1, 1, 1]))
in1Add48402 = tf.keras.layers.Input(shape=([2, 1, 1, 1]))
in0Con69095 = tf.keras.layers.Input(shape=([4, 2]))
in0Con43737 = tf.keras.layers.Input(shape=([4, 1]))
in0Bat26514 = tf.keras.layers.Input(shape=([1, 4]))
in0Ave48344 = tf.keras.layers.Input(shape=([2, 2]))
in1Ave48344 = tf.keras.layers.Input(shape=([2, 2]))
in0Con67546 = tf.keras.layers.Input(shape=([2, 2]))

Glo57205 = keras.layers.GlobalMaxPool2D(name = 'Glo57205', )(in0Glo57205)
Res5398 = keras.layers.Reshape((2, 1), name = 'Res5398', )(Glo57205)
Zer56658 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer56658', )(Res5398)
Con40743 = keras.layers.Concatenate(axis=2, name = 'Con40743', )([Zer56658,in0Con40743])
Max85897 = keras.layers.Maximum(name = 'Max85897', )([in0Max85897,in1Max85897])
Res97612 = keras.layers.Reshape((2, 2, 2), name = 'Res97612', )(Max85897)
Res63500 = keras.layers.Reshape((2, 4), name = 'Res63500', )(Res97612)
Per291 = keras.layers.Permute((1,2), name = 'Per291',)(Res63500)
Zer41111 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer41111', )(Per291)
Per6568 = keras.layers.Permute((2,1), name = 'Per6568',)(in0Per6568)
Add48402 = keras.layers.Add(name = 'Add48402', )([in0Add48402,in1Add48402])
Res88770 = keras.layers.Reshape((2, 1, 1), name = 'Res88770', )(Add48402)
Res34094 = keras.layers.Reshape((2, 1), name = 'Res34094', )(Res88770)
Zer37304 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer37304', )(Res34094)
Con69095 = keras.layers.Concatenate(axis=2, name = 'Con69095', )([Zer37304,in0Con69095])
Min1417 = keras.layers.Minimum(name = 'Min1417', )([Per6568,Con69095])
Con43737 = keras.layers.Concatenate(axis=2, name = 'Con43737', )([Min1417,in0Con43737])
Add93850 = keras.layers.Add(name = 'Add93850', )([Zer41111,Con43737])
Ave77623 = keras.layers.Average(name = 'Ave77623', )([Con40743,Add93850])
Bat26514 = keras.layers.BatchNormalization(axis=2, epsilon=0.1969330118337586,  name = 'Bat26514', )(in0Bat26514)
Zer3626 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer3626', )(Bat26514)
Ave48344 = keras.layers.Average(name = 'Ave48344', )([in0Ave48344,in1Ave48344])
Con67546 = keras.layers.Concatenate(axis=2, name = 'Con67546', )([Ave48344,in0Con67546])
Add37012 = keras.layers.Add(name = 'Add37012', )([Zer3626,Con67546])
Zer42135 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer42135', )(Add37012)
Sub49205 = keras.layers.Subtract(name = 'Sub49205', )([Ave77623,Zer42135])
model = tf.keras.models.Model(inputs=[in0Glo57205,in0Con40743,in0Max85897,in1Max85897,in0Per6568,in0Add48402,in1Add48402,in0Con69095,in0Con43737,in0Bat26514,in0Ave48344,in1Ave48344,in0Con67546], outputs=Sub49205)
w = model.get_layer('Bat26514').get_weights() 
w[0] = np.array([0.6655, 0.8699, 0.4923, 0.5732])
w[1] = np.array([0.3353, 0.1328, 0.6017, 0.123])
w[2] = np.array([0.3792, 0.6606, 0.5453, 0.2328])
w[3] = np.array([0.0885, 0.258, 0.6835, 0.0904])
model.get_layer('Bat26514').set_weights(w) 
in0Glo57205 = tf.constant([[[[1.067, 1.0096], [1.6798, 1.1718]], [[1.7097, 1.4558], [1.6802, 1.5132]]]])
in0Con40743 = tf.constant([[[0.7641, 0.6942, 0.7436], [0.1448, 0.3059, 0.7855], [0.1694, 0.1806, 0.0948], [0.2257, 0.3744, 0.0367]]])
in0Max85897 = tf.constant([[[[[0.0581, 0.3956]], [[0.6461, 0.483]]], [[[0.0114, 0.1029]], [[0.821, 0.6669]]]]])
in1Max85897 = tf.constant([[[[[0.4471, 0.3228]], [[0.4441, 0.2625]]], [[[0.1519, 0.8374]], [[0.7258, 0.9065]]]]])
in0Per6568 = tf.constant([[[1.9149, 1.4315, 1.2876, 1.2908], [1.8205, 1.8146, 1.6189, 1.3584], [1.4119, 1.6935, 1.5604, 1.466]]])
in0Add48402 = tf.constant([[[[[0.9268]]], [[[0.9835]]]]])
in1Add48402 = tf.constant([[[[[0.6911]]], [[[0.1416]]]]])
in0Con69095 = tf.constant([[[0.0521, 0.0296], [0.4882, 0.9386], [0.4925, 0.9887], [0.1188, 0.5013]]])
in0Con43737 = tf.constant([[[0.7514], [0.4284], [0.5834], [0.2346]]])
in0Bat26514 = tf.constant([[[1.2545, 1.096, 1.7617, 1.9728]]])
in0Ave48344 = tf.constant([[[0.6088, 0.3472], [0.9983, 0.7202]]])
in1Ave48344 = tf.constant([[[0.1667, 0.7952], [0.1819, 0.9638]]])
in0Con67546 = tf.constant([[[0.007, 0.6747], [0.0173, 0.2553]]])
print (np.array2string(model.predict([in0Glo57205,in0Con40743,in0Max85897,in1Max85897,in0Per6568,in0Add48402,in1Add48402,in0Con69095,in0Con43737,in0Bat26514,in0Ave48344,in1Ave48344,in0Con67546],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub49205.png')

LGlo57205 = global_max_pool2D_layer([[[[1.067, 1.0096], [1.6798, 1.1718]], [[1.7097, 1.4558], [1.6802, 1.5132]]]], Glo57205), 
LRes5398 = reshape_layer(Glo57205, [2, 1], Res5398), 
LZer56658 = zero_padding1D_layer(Res5398, 2, 0, Zer56658), 
LCon40743 = concatenate_layer([Zer56658,[[[0.7641, 0.6942, 0.7436], [0.1448, 0.3059, 0.7855], [0.1694, 0.1806, 0.0948], [0.2257, 0.3744, 0.0367]]]], 2, Con40743), 
LMax85897 = maximum_layer([[[[[[0.0581, 0.3956]], [[0.6461, 0.483]]], [[[0.0114, 0.1029]], [[0.821, 0.6669]]]]], [[[[[0.4471, 0.3228]], [[0.4441, 0.2625]]], [[[0.1519, 0.8374]], [[0.7258, 0.9065]]]]]], Max85897), 
LRes97612 = reshape_layer(Max85897, [2, 2, 2], Res97612), 
LRes63500 = reshape_layer(Res97612, [2, 4], Res63500), 
LPer291 = permute_layer(Res63500, 1,2, Per291), 
LZer41111 = zero_padding1D_layer(Per291, 2, 0, Zer41111), 
LPer6568 = permute_layer([[[1.9149, 1.4315, 1.2876, 1.2908], [1.8205, 1.8146, 1.6189, 1.3584], [1.4119, 1.6935, 1.5604, 1.466]]], 2,1, Per6568), 
LAdd48402 = add_layer([[[[[[0.9268]]], [[[0.9835]]]]], [[[[[0.6911]]], [[[0.1416]]]]]], Add48402), 
LRes88770 = reshape_layer(Add48402, [2, 1, 1], Res88770), 
LRes34094 = reshape_layer(Res88770, [2, 1], Res34094), 
LZer37304 = zero_padding1D_layer(Res34094, 1, 1, Zer37304), 
LCon69095 = concatenate_layer([Zer37304,[[[0.0521, 0.0296], [0.4882, 0.9386], [0.4925, 0.9887], [0.1188, 0.5013]]]], 2, Con69095), 
LMin1417 = minimum_layer([Per6568,Con69095], Min1417), 
LCon43737 = concatenate_layer([Min1417,[[[0.7514], [0.4284], [0.5834], [0.2346]]]], 2, Con43737), 
LAdd93850 = add_layer([Zer41111,Con43737], Add93850), 
LAve77623 = average_layer([Con40743,Add93850], Ave77623), 
LBat26514 = batch_normalization_layer([[[1.2545, 1.096, 1.7617, 1.9728]]], 2, 0.1969330118337586, [0.6655, 0.8699, 0.4923, 0.5732], [0.3353, 0.1328, 0.6017, 0.123], [0.3792, 0.6606, 0.5453, 0.2328], [0.0885, 0.258, 0.6835, 0.0904], Bat26514), 
LZer3626 = zero_padding1D_layer(Bat26514, 1, 0, Zer3626), 
LAve48344 = average_layer([[[[0.6088, 0.3472], [0.9983, 0.7202]]], [[[0.1667, 0.7952], [0.1819, 0.9638]]]], Ave48344), 
LCon67546 = concatenate_layer([Ave48344,[[[0.007, 0.6747], [0.0173, 0.2553]]]], 2, Con67546), 
LAdd37012 = add_layer([Zer3626,Con67546], Add37012), 
LZer42135 = zero_padding1D_layer(Add37012, 2, 0, Zer42135), 
LSub49205 = subtract_layer(Ave77623,Zer42135, Sub49205), 
exec_layers([LGlo57205,LRes5398,LZer56658,LCon40743,LMax85897,LRes97612,LRes63500,LPer291,LZer41111,LPer6568,LAdd48402,LRes88770,LRes34094,LZer37304,LCon69095,LMin1417,LCon43737,LAdd93850,LAve77623,LBat26514,LZer3626,LAve48344,LCon67546,LAdd37012,LZer42135,LSub49205],["Glo57205","Res5398","Zer56658","Con40743","Max85897","Res97612","Res63500","Per291","Zer41111","Per6568","Add48402","Res88770","Res34094","Zer37304","Con69095","Min1417","Con43737","Add93850","Ave77623","Bat26514","Zer3626","Ave48344","Con67546","Add37012","Zer42135","Sub49205"],Sub49205,"Sub49205")

Actual (Unparsed): [[[0.0000000, 0.4081000, 0.3619000, 0.7475000], [0.7157500, 0.3165000, 0.6222500, 0.6069500], [1.2532000, -0.0424500, 0.9007000, -0.0941000], [-1.1831673, -0.9453942, -0.4088519, -1.6500414]]]

Expected (Unparsed): [[[0,0.4081,0.3619,0.7475],[0.71575,0.3165,0.62225,0.60695],[1.2532,-0.04244999999999999,0.9007000000000001,-0.09409999999999996],[-1.1831672627110041,-0.9453943080049185,-0.4088518932586367,-1.65004134632857]]]

Actual:   [[[0, 0.4081, 0.3619, 0.7475], [0.7158, 0.3165, 0.6223, 0.607], [1.2532, -0.0424, 0.9007, -0.0941], [-1.1831, -0.9453, -0.4088, -1.65]]]

Expected: [[[0, 0.4081, 0.3619, 0.7475], [0.7158, 0.3165, 0.6223, 0.607], [1.2532, -0.0424, 0.9008, -0.094], [-1.1831, -0.9453, -0.4088, -1.65]]]