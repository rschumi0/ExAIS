import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Lay86908 = tf.keras.layers.Input(shape=([1, 4]))
in0Min95351 = tf.keras.layers.Input(shape=([1, 2]))
in1Min95351 = tf.keras.layers.Input(shape=([1, 2]))
in0Den92232 = tf.keras.layers.Input(shape=([2, 2]))
in0Con2641 = tf.keras.layers.Input(shape=([10]))

Lay86908 = keras.layers.LayerNormalization(axis=1, epsilon=2.161130457052103, name = 'Lay86908', )(in0Lay86908)
Zer61281 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer61281', )(Lay86908)
Fla21093 = keras.layers.Flatten(name = 'Fla21093', )(Zer61281)
Min95351 = keras.layers.Minimum(name = 'Min95351', )([in0Min95351,in1Min95351])
Fla21353 = keras.layers.Flatten(name = 'Fla21353', )(Min95351)
Den92232 = keras.layers.Dense(2,name = 'Den92232', )(in0Den92232)
Glo28072 = keras.layers.GlobalMaxPool1D(name = 'Glo28072', )(Den92232)
Mul775 = keras.layers.Multiply(name = 'Mul775', )([Fla21353,Glo28072])
Con2641 = keras.layers.Concatenate(axis=1, name = 'Con2641', )([Mul775,in0Con2641])
Min59812 = keras.layers.Minimum(name = 'Min59812', )([Fla21093,Con2641])
model = tf.keras.models.Model(inputs=[in0Lay86908,in0Min95351,in1Min95351,in0Den92232,in0Con2641], outputs=Min59812)
w = model.get_layer('Den92232').get_weights() 
w[0] = np.array([[0.6396, 0.188], [0.5069, 0.7807]])
w[1] = np.array([0.5699, 0.8815])
model.get_layer('Den92232').set_weights(w) 
in0Lay86908 = tf.constant([[[1.4542, 1.5823, 1.712, 1.57]]])
in0Min95351 = tf.constant([[[0.4662, 0.1559]]])
in1Min95351 = tf.constant([[[0.3744, 0.6405]]])
in0Den92232 = tf.constant([[[0.082, 0.7346], [0.8832, 0.5158]]])
in0Con2641 = tf.constant([[0.8451, 0.9027, 0.5616, 0.2676, 0.8941, 0.418, 0.6714, 0.6068, 0.2841, 0.9663]])
print (np.array2string(model.predict([in0Lay86908,in0Min95351,in1Min95351,in0Den92232,in0Con2641],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min59812.png')

LLay86908 = layer_normalization_layer([[[1.4542, 1.5823, 1.712, 1.57]]], 1, 2.161130457052103, Lay86908), 
LZer61281 = zero_padding1D_layer(Lay86908, 1, 1, Zer61281), 
LFla21093 = flatten_layer(Zer61281, Fla21093), 
LMin95351 = minimum_layer([[[[0.4662, 0.1559]]], [[[0.3744, 0.6405]]]], Min95351), 
LFla21353 = flatten_layer(Min95351, Fla21353), 
LDen92232 = dense_layer([[[0.082, 0.7346], [0.8832, 0.5158]]], [[0.6396, 0.188], [0.5069, 0.7807]],[0.5699, 0.8815], Den92232), 
LGlo28072 = global_max_pool1D_layer(Den92232, Glo28072), 
LMul775 = multiply_layer([Fla21353,Glo28072], Mul775), 
LCon2641 = concatenate_layer([Mul775,[[0.8451, 0.9027, 0.5616, 0.2676, 0.8941, 0.418, 0.6714, 0.6068, 0.2841, 0.9663]]], 1, Con2641), 
LMin59812 = minimum_layer([Fla21093,Con2641], Min59812), 
exec_layers([LLay86908,LZer61281,LFla21093,LMin95351,LFla21353,LDen92232,LGlo28072,LMul775,LCon2641,LMin59812],["Lay86908","Zer61281","Fla21093","Min95351","Fla21353","Den92232","Glo28072","Mul775","Con2641","Min59812"],Min59812,"Min59812")

Actual (Unparsed): [[0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000]]

Expected (Unparsed): [[0,0,0,0,0.0,0.0,0.0,0.0,0,0,0,0]]

Actual:   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]

Expected: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]