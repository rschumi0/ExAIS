import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave3875 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Ave3875 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Add91310 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in1Add91310 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0Ave54714 = tf.keras.layers.Input(shape=([1, 1]))
in1Ave54714 = tf.keras.layers.Input(shape=([1, 1]))
in0Con39137 = tf.keras.layers.Input(shape=([2, 3]))
in0Con92631 = tf.keras.layers.Input(shape=([4, 4]))

Ave3875 = keras.layers.Average(name = 'Ave3875', )([in0Ave3875,in1Ave3875])
Res71194 = keras.layers.Reshape((2, 2, 4), name = 'Res71194', )(Ave3875)
Res30237 = keras.layers.Reshape((2, 8), name = 'Res30237', )(Res71194)
Zer48231 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer48231', )(Res30237)
Thr84609 = keras.layers.ThresholdedReLU(theta=9.165026347666368, name = 'Thr84609', )(Zer48231)
Add91310 = keras.layers.Add(name = 'Add91310', )([in0Add91310,in1Add91310])
Res98459 = keras.layers.Reshape((2, 2, 2), name = 'Res98459', )(Add91310)
Res66200 = keras.layers.Reshape((2, 4), name = 'Res66200', )(Res98459)
Ave54714 = keras.layers.Average(name = 'Ave54714', )([in0Ave54714,in1Ave54714])
Zer42984 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer42984', )(Ave54714)
Con39137 = keras.layers.Concatenate(axis=2, name = 'Con39137', )([Zer42984,in0Con39137])
Min17332 = keras.layers.Minimum(name = 'Min17332', )([Res66200,Con39137])
Zer83065 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer83065', )(Min17332)
Con92631 = keras.layers.Concatenate(axis=2, name = 'Con92631', )([Zer83065,in0Con92631])
Sub11962 = keras.layers.Subtract(name = 'Sub11962', )([Thr84609,Con92631])
model = tf.keras.models.Model(inputs=[in0Ave3875,in1Ave3875,in0Add91310,in1Add91310,in0Ave54714,in1Ave54714,in0Con39137,in0Con92631], outputs=Sub11962)
in0Ave3875 = tf.constant([[[[[0.3273, 0.6953], [0.9559, 0.8896]], [[0.5372, 0.6596], [0.9607, 0.9811]]], [[[0.8061, 0.0991], [0.673, 0.8382]], [[0.7032, 0.8364], [0.1767, 0.7966]]]]])
in1Ave3875 = tf.constant([[[[[0.7614, 0.1146], [0.4583, 0.0191]], [[0.9085, 0.8631], [0.8529, 0.7215]]], [[[0.7008, 0.5938], [0.3754, 0.4702]], [[0.5478, 0.3198], [0.722, 0.7978]]]]])
in0Add91310 = tf.constant([[[[[0.2081, 0.6653]], [[0.7374, 0.2303]]], [[[0.8806, 0.8651]], [[0.6313, 0.2576]]]]])
in1Add91310 = tf.constant([[[[[0.0373, 0.984]], [[0.9501, 0.8622]]], [[[0.0976, 0.2609]], [[0.7781, 0.179]]]]])
in0Ave54714 = tf.constant([[[0.1186]]])
in1Ave54714 = tf.constant([[[0.0651]]])
in0Con39137 = tf.constant([[[0.3853, 0.4148, 0.4578], [0.4987, 0.1517, 0.9669]]])
in0Con92631 = tf.constant([[[0.2428, 0.1623, 0.327, 0.7597], [0.5195, 0.3949, 0.6475, 0.278], [0.7366, 0.7191, 0.2549, 0.5096], [0.5121, 0.115, 0.9572, 0.5527]]])
print (np.array2string(model.predict([in0Ave3875,in1Ave3875,in0Add91310,in1Add91310,in0Ave54714,in1Ave54714,in0Con39137,in0Con92631],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub11962.png')

LAve3875 = average_layer([[[[[[0.3273, 0.6953], [0.9559, 0.8896]], [[0.5372, 0.6596], [0.9607, 0.9811]]], [[[0.8061, 0.0991], [0.673, 0.8382]], [[0.7032, 0.8364], [0.1767, 0.7966]]]]], [[[[[0.7614, 0.1146], [0.4583, 0.0191]], [[0.9085, 0.8631], [0.8529, 0.7215]]], [[[0.7008, 0.5938], [0.3754, 0.4702]], [[0.5478, 0.3198], [0.722, 0.7978]]]]]], Ave3875), 
LRes71194 = reshape_layer(Ave3875, [2, 2, 4], Res71194), 
LRes30237 = reshape_layer(Res71194, [2, 8], Res30237), 
LZer48231 = zero_padding1D_layer(Res30237, 1, 1, Zer48231), 
LThr84609 = thresholded_relu_layer(Zer48231, 9.165026347666368, Thr84609), 
LAdd91310 = add_layer([[[[[[0.2081, 0.6653]], [[0.7374, 0.2303]]], [[[0.8806, 0.8651]], [[0.6313, 0.2576]]]]], [[[[[0.0373, 0.984]], [[0.9501, 0.8622]]], [[[0.0976, 0.2609]], [[0.7781, 0.179]]]]]], Add91310), 
LRes98459 = reshape_layer(Add91310, [2, 2, 2], Res98459), 
LRes66200 = reshape_layer(Res98459, [2, 4], Res66200), 
LAve54714 = average_layer([[[[0.1186]]], [[[0.0651]]]], Ave54714), 
LZer42984 = zero_padding1D_layer(Ave54714, 1, 0, Zer42984), 
LCon39137 = concatenate_layer([Zer42984,[[[0.3853, 0.4148, 0.4578], [0.4987, 0.1517, 0.9669]]]], 2, Con39137), 
LMin17332 = minimum_layer([Res66200,Con39137], Min17332), 
LZer83065 = zero_padding1D_layer(Min17332, 2, 0, Zer83065), 
LCon92631 = concatenate_layer([Zer83065,[[[0.2428, 0.1623, 0.327, 0.7597], [0.5195, 0.3949, 0.6475, 0.278], [0.7366, 0.7191, 0.2549, 0.5096], [0.5121, 0.115, 0.9572, 0.5527]]]], 2, Con92631), 
LSub11962 = subtract_layer(Thr84609,Con92631, Sub11962), 
exec_layers([LAve3875,LRes71194,LRes30237,LZer48231,LThr84609,LAdd91310,LRes98459,LRes66200,LAve54714,LZer42984,LCon39137,LMin17332,LZer83065,LCon92631,LSub11962],["Ave3875","Res71194","Res30237","Zer48231","Thr84609","Add91310","Res98459","Res66200","Ave54714","Zer42984","Con39137","Min17332","Zer83065","Con92631","Sub11962"],Sub11962,"Sub11962")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.0000000, 0.0000000, -0.2428000, -0.1623000, -0.3270000, -0.7597000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, -0.5195000, -0.3949000, -0.6475000, -0.2780000], [0.0000000, -0.3853000, -0.4148000, -0.4578000, -0.7366000, -0.7191000, -0.2549000, -0.5096000], [-0.0918500, -0.4987000, -0.1517000, -0.4366000, -0.5121000, -0.1150000, -0.9572000, -0.5527000]]]

Expected (Unparsed): [[[0,0,0,0,-0.2428,-0.1623,-0.327,-0.7597],[0,0,0,0,-0.5195,-0.3949,-0.6475,-0.278],[0,-0.3853,-0.4148,-0.4578,-0.7366,-0.7191,-0.2549,-0.5096],[-0.09185,-0.4987,-0.1517,-0.4366,-0.5121,-0.115,-0.9572,-0.5527]]]

Actual:   [[[0, 0, 0, 0, -0.2428, -0.1623, -0.327, -0.7597], [0, 0, 0, 0, -0.5195, -0.3949, -0.6475, -0.278], [0, -0.3853, -0.4148, -0.4578, -0.7366, -0.7191, -0.2549, -0.5096], [-0.0918, -0.4987, -0.1517, -0.4366, -0.5121, -0.115, -0.9572, -0.5527]]]

Expected: [[[0, 0, 0, 0, -0.2428, -0.1623, -0.327, -0.7597], [0, 0, 0, 0, -0.5195, -0.3949, -0.6475, -0.278], [0, -0.3853, -0.4148, -0.4578, -0.7366, -0.7191, -0.2549, -0.5096], [-0.0918, -0.4987, -0.1517, -0.4366, -0.5121, -0.115, -0.9572, -0.5527]]]