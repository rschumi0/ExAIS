import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo47758 = tf.keras.layers.Input(shape=([1, 2, 1, 2]))
in0Con96875 = tf.keras.layers.Input(shape=([1]))
in0GRU81732 = tf.keras.layers.Input(shape=([2, 3]))
in0Con24211 = tf.keras.layers.Input(shape=([3, 1]))
in0PRe22283 = tf.keras.layers.Input(shape=([2, 2]))

Glo47758 = keras.layers.GlobalAveragePooling3D(name = 'Glo47758', )(in0Glo47758)
Con96875 = keras.layers.Concatenate(axis=1, name = 'Con96875', )([Glo47758,in0Con96875])
GRU81732 = keras.layers.GRU(3,reset_after=True, recurrent_activation='sigmoid', name = 'GRU81732', )(in0GRU81732)
Res12942 = keras.layers.Reshape((3, 1), name = 'Res12942', )(GRU81732)
Con24211 = keras.layers.Concatenate(axis=2, name = 'Con24211', )([Res12942,in0Con24211])
PRe22283 = keras.layers.PReLU(name = 'PRe22283', input_shape=(2, 2))(in0PRe22283)
Zer71868 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer71868', )(PRe22283)
Sub37561 = keras.layers.Subtract(name = 'Sub37561', )([Con24211,Zer71868])
GRU57740 = keras.layers.GRU(3,reset_after=True, recurrent_activation='sigmoid', name = 'GRU57740', )(Sub37561)
Max46572 = keras.layers.Maximum(name = 'Max46572', )([Con96875,GRU57740])
model = tf.keras.models.Model(inputs=[in0Glo47758,in0Con96875,in0GRU81732,in0Con24211,in0PRe22283], outputs=Max46572)
w = model.get_layer('GRU81732').get_weights() 
w[0] = np.array([[7, 3, 10, 2, 6, 5, 10, 7, 9], [7, 6, 7, 10, 5, 5, 2, 1, 2], [4, 2, 3, 3, 5, 2, 6, 4, 7]])
w[1] = np.array([[2, 5, 10, 1, 8, 1, 5, 2, 1], [3, 4, 10, 1, 1, 8, 3, 6, 1], [7, 5, 1, 3, 8, 8, 1, 9, 1]])
w[2] = np.array([[5, 6, 7, 6, 3, 8, 9, 2, 2], [9, 3, 6, 10, 3, 5, 9, 2, 2]])
model.get_layer('GRU81732').set_weights(w) 
w = model.get_layer('PRe22283').get_weights() 
w[0] = np.array([[0.7196, 0.1264], [0.1467, 0.0938]])
model.get_layer('PRe22283').set_weights(w) 
w = model.get_layer('GRU57740').get_weights() 
w[0] = np.array([[3, 1, 4, 2, 4, 5, 2, 4, 7], [6, 6, 9, 10, 7, 8, 5, 3, 7]])
w[1] = np.array([[5, 6, 1, 2, 9, 7, 5, 9, 2], [3, 10, 2, 6, 6, 8, 1, 6, 6], [3, 7, 4, 1, 6, 1, 4, 6, 4]])
w[2] = np.array([[7, 8, 2, 9, 7, 7, 3, 7, 10], [7, 7, 8, 7, 5, 7, 4, 1, 4]])
model.get_layer('GRU57740').set_weights(w) 
in0Glo47758 = tf.constant([[[[[1.9676, 1.9584]], [[1.9053, 1.3585]]]]])
in0Con96875 = tf.constant([[0.5304]])
in0GRU81732 = tf.constant([[[1, 6, 4], [6, 2, 5]]])
in0Con24211 = tf.constant([[[0.4677], [0.5856], [0.1931]]])
in0PRe22283 = tf.constant([[[0.7712, 0.5339], [0.6907, 0.2207]]])
print (np.array2string(model.predict([in0Glo47758,in0Con96875,in0GRU81732,in0Con24211,in0PRe22283],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max46572.png')

LGlo47758 = global_average_pooling3D_layer([[[[[1.9676, 1.9584]], [[1.9053, 1.3585]]]]], Glo47758), 
LCon96875 = concatenate_layer([Glo47758,[[0.5304]]], 1, Con96875), 
LGRU81732 = gru_layer([[[1, 6, 4], [6, 2, 5]]],[[7, 3, 10, 2, 6, 5, 10, 7, 9], [7, 6, 7, 10, 5, 5, 2, 1, 2], [4, 2, 3, 3, 5, 2, 6, 4, 7]],[[2, 5, 10, 1, 8, 1, 5, 2, 1], [3, 4, 10, 1, 1, 8, 3, 6, 1], [7, 5, 1, 3, 8, 8, 1, 9, 1]],[[5, 6, 7, 6, 3, 8, 9, 2, 2], [9, 3, 6, 10, 3, 5, 9, 2, 2]], true, GRU81732), 
LRes12942 = reshape_layer(GRU81732, [3, 1], Res12942), 
LCon24211 = concatenate_layer([Res12942,[[[0.4677], [0.5856], [0.1931]]]], 2, Con24211), 
LPRe22283 = prelu_layer([[[0.7712, 0.5339], [0.6907, 0.2207]]], [[0.7196, 0.1264], [0.1467, 0.0938]], PRe22283), 
LZer71868 = zero_padding1D_layer(PRe22283, 1, 0, Zer71868), 
LSub37561 = subtract_layer(Con24211,Zer71868, Sub37561), 
LGRU57740 = gru_layer(Sub37561,[[3, 1, 4, 2, 4, 5, 2, 4, 7], [6, 6, 9, 10, 7, 8, 5, 3, 7]],[[5, 6, 1, 2, 9, 7, 5, 9, 2], [3, 10, 2, 6, 6, 8, 1, 6, 6], [3, 7, 4, 1, 6, 1, 4, 6, 4]],[[7, 8, 2, 9, 7, 7, 3, 7, 10], [7, 7, 8, 7, 5, 7, 4, 1, 4]], true, GRU57740), 
LMax46572 = maximum_layer([Con96875,GRU57740], Max46572), 
exec_layers([LGlo47758,LCon96875,LGRU81732,LRes12942,LCon24211,LPRe22283,LZer71868,LSub37561,LGRU57740,LMax46572],["Glo47758","Con96875","GRU81732","Res12942","Con24211","PRe22283","Zer71868","Sub37561","GRU57740","Max46572"],Max46572,"Max46572")

Actual (Unparsed): [[1.9364500, 1.6584500, 0.5304000]]

Expected (Unparsed): [[1.93645,1.65845,0.5304]]

Actual:   [[1.9365, 1.6585, 0.5304]]

Expected: [[1.9365, 1.6585, 0.5304]]