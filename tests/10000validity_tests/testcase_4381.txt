import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Lea85713 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in0Bat56060 = tf.keras.layers.Input(shape=([3, 3, 2]))

Lea85713 = keras.layers.LeakyReLU(alpha=8.612022070071749, name = 'Lea85713', input_shape=(2, 1, 2, 1))(in0Lea85713)
Res10717 = keras.layers.Reshape((2, 1, 2), name = 'Res10717', )(Lea85713)
Zer13200 = keras.layers.ZeroPadding2D(padding=((1, 0), (2, 0)), name = 'Zer13200', )(Res10717)
Bat56060 = keras.layers.BatchNormalization(axis=3, epsilon=0.9476594567274463,  name = 'Bat56060', )(in0Bat56060)
Max55934 = keras.layers.Maximum(name = 'Max55934', )([Zer13200,Bat56060])
Res53491 = keras.layers.Reshape((3, 6), name = 'Res53491', )(Max55934)
GRU79822 = keras.layers.GRU(2,reset_after=True, recurrent_activation='sigmoid', name = 'GRU79822', )(Res53491)
model = tf.keras.models.Model(inputs=[in0Lea85713,in0Bat56060], outputs=GRU79822)
w = model.get_layer('Bat56060').get_weights() 
w[0] = np.array([0.5509, 0.6562])
w[1] = np.array([0.5693, 0.8379])
w[2] = np.array([0.3309, 0.9036])
w[3] = np.array([0.0187, 0.6007])
model.get_layer('Bat56060').set_weights(w) 
w = model.get_layer('GRU79822').get_weights() 
w[0] = np.array([[10, 5, 7, 10, 1, 10], [2, 10, 8, 7, 2, 3], [3, 7, 7, 7, 10, 3], [2, 6, 9, 5, 2, 4], [5, 7, 3, 1, 4, 5], [9, 10, 5, 8, 5, 9]])
w[1] = np.array([[5, 7, 1, 8, 7, 3], [4, 6, 3, 9, 4, 9]])
w[2] = np.array([[8, 10, 8, 2, 2, 6], [2, 7, 1, 2, 4, 10]])
model.get_layer('GRU79822').set_weights(w) 
in0Lea85713 = tf.constant([[[[[0.7508], [0.7352]]], [[[0.2944], [0.3553]]]]])
in0Bat56060 = tf.constant([[[[1.5566, 1.4488], [1.4346, 1.2773], [1.5413, 1.3581]], [[1.6749, 1.8172], [1.3021, 1.9095], [1.8967, 1.6751]], [[1.8655, 1.3419], [1.657, 1.6768], [1.3163, 1.3611]]]])
print (np.array2string(model.predict([in0Lea85713,in0Bat56060],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='GRU79822.png')

LLea85713 = leaky_relu_layer([[[[[0.7508], [0.7352]]], [[[0.2944], [0.3553]]]]], 8.612022070071749, Lea85713), 
LRes10717 = reshape_layer(Lea85713, [2, 1, 2], Res10717), 
LZer13200 = zero_padding2D_layer(Res10717, 1, 0, 2, 0, Zer13200), 
LBat56060 = batch_normalization_layer([[[[1.5566, 1.4488], [1.4346, 1.2773], [1.5413, 1.3581]], [[1.6749, 1.8172], [1.3021, 1.9095], [1.8967, 1.6751]], [[1.8655, 1.3419], [1.657, 1.6768], [1.3163, 1.3611]]]], 3, 0.9476594567274463, [0.5509, 0.6562], [0.5693, 0.8379], [0.3309, 0.9036], [0.0187, 0.6007], Bat56060), 
LMax55934 = maximum_layer([Zer13200,Bat56060], Max55934), 
LRes53491 = reshape_layer(Max55934, [3, 6], Res53491), 
LGRU79822 = gru_layer(Res53491,[[10, 5, 7, 10, 1, 10], [2, 10, 8, 7, 2, 3], [3, 7, 7, 7, 10, 3], [2, 6, 9, 5, 2, 4], [5, 7, 3, 1, 4, 5], [9, 10, 5, 8, 5, 9]],[[5, 7, 1, 8, 7, 3], [4, 6, 3, 9, 4, 9]],[[8, 10, 8, 2, 2, 6], [2, 7, 1, 2, 4, 10]], true, GRU79822), 
exec_layers([LLea85713,LRes10717,LZer13200,LBat56060,LMax55934,LRes53491,LGRU79822],["Lea85713","Res10717","Zer13200","Bat56060","Max55934","Res53491","GRU79822"],GRU79822,"GRU79822")

Actual (Unparsed): [[0.0000000, 0.0000000]]

Expected (Unparsed): [[0.0,0.0]]

Actual:   [[0, 0]]

Expected: [[0, 0]]