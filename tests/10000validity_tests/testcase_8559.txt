import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add6723 = tf.keras.layers.Input(shape=([1, 1, 2]))
in1Add6723 = tf.keras.layers.Input(shape=([1, 1, 2]))

Add6723 = keras.layers.Add(name = 'Add6723', )([in0Add6723,in1Add6723])
Lea28211 = keras.layers.LeakyReLU(alpha=1.333444030748485, name = 'Lea28211', )(Add6723)
Res83841 = keras.layers.Reshape((1, 2), name = 'Res83841', )(Lea28211)
Glo2822 = keras.layers.GlobalMaxPool1D(name = 'Glo2822', )(Res83841)
model = tf.keras.models.Model(inputs=[in0Add6723,in1Add6723], outputs=Glo2822)
in0Add6723 = tf.constant([[[[0.6148, 0.9896]]]])
in1Add6723 = tf.constant([[[[0.6685, 0.578]]]])
print (np.array2string(model.predict([in0Add6723,in1Add6723],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Glo2822.png')

LAdd6723 = add_layer([[[[[0.6148, 0.9896]]]], [[[[0.6685, 0.578]]]]], Add6723), 
LLea28211 = leaky_relu_layer(Add6723, 1.333444030748485, Lea28211), 
LRes83841 = reshape_layer(Lea28211, [1, 2], Res83841), 
LGlo2822 = global_max_pool1D_layer(Res83841, Glo2822), 
exec_layers([LAdd6723,LLea28211,LRes83841,LGlo2822],["Add6723","Lea28211","Res83841","Glo2822"],Glo2822,"Glo2822")

Actual (Unparsed): [[1.2833000, 1.5676000]]

Expected (Unparsed): [[1.2833,1.5676]]

Actual:   [[1.2833, 1.5676]]

Expected: [[1.2833, 1.5676]]