import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max56553 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in1Max56553 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in0Dot422 = tf.keras.layers.Input(shape=([3]))
in1Dot422 = tf.keras.layers.Input(shape=([3]))
in0Con35486 = tf.keras.layers.Input(shape=([3]))
in0Con48387 = tf.keras.layers.Input(shape=([4, 2]))
in0Dot94907 = tf.keras.layers.Input(shape=([3, 2]))
in1Dot94907 = tf.keras.layers.Input(shape=([3, 2]))

Max56553 = keras.layers.Maximum(name = 'Max56553', )([in0Max56553,in1Max56553])
Sof84543 = keras.layers.Softmax(axis=1, name = 'Sof84543', )(Max56553)
Res18173 = keras.layers.Reshape((2, 1, 2), name = 'Res18173', )(Sof84543)
Res50975 = keras.layers.Reshape((2, 2), name = 'Res50975', )(Res18173)
Fla44353 = keras.layers.Flatten(name = 'Fla44353', )(Res50975)
Dot422 = keras.layers.Dot(axes=(1, 1), name = 'Dot422', )([in0Dot422,in1Dot422])
Con35486 = keras.layers.Concatenate(axis=1, name = 'Con35486', )([Dot422,in0Con35486])
Sub22643 = keras.layers.Subtract(name = 'Sub22643', )([Fla44353,Con35486])
Res33379 = keras.layers.Reshape((4, 1), name = 'Res33379', )(Sub22643)
Con48387 = keras.layers.Concatenate(axis=2, name = 'Con48387', )([Res33379,in0Con48387])
Dot94907 = keras.layers.Dot(axes=(2, 2), name = 'Dot94907', )([in0Dot94907,in1Dot94907])
Zer99538 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer99538', )(Dot94907)
Dot58300 = keras.layers.Dot(axes=(2, 2), name = 'Dot58300', )([Con48387,Zer99538])
model = tf.keras.models.Model(inputs=[in0Max56553,in1Max56553,in0Dot422,in1Dot422,in0Con35486,in0Con48387,in0Dot94907,in1Dot94907], outputs=Dot58300)
in0Max56553 = tf.constant([[[[[0.8818], [0.2468]]], [[[0.734], [0.8116]]]]])
in1Max56553 = tf.constant([[[[[0.7879], [0.5317]]], [[[0.2603], [0.978]]]]])
in0Dot422 = tf.constant([[0.1938, 0.3724, 0.7981]])
in1Dot422 = tf.constant([[0.1122, 0.3806, 0.6545]])
in0Con35486 = tf.constant([[0.0628, 0.6435, 0.2894]])
in0Con48387 = tf.constant([[[0.7814, 0.2107], [0.7516, 0.7539], [0.9837, 0.0631], [0.6572, 0.4998]]])
in0Dot94907 = tf.constant([[[0.4009, 0.6442], [0.0098, 0.8913], [0.0563, 0.186]]])
in1Dot94907 = tf.constant([[[0.0044, 0.9278], [0.1318, 0.7677], [0.2472, 0.5094]]])
print (np.array2string(model.predict([in0Max56553,in1Max56553,in0Dot422,in1Dot422,in0Con35486,in0Con48387,in0Dot94907,in1Dot94907],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot58300.png')

LMax56553 = maximum_layer([[[[[[0.8818], [0.2468]]], [[[0.734], [0.8116]]]]], [[[[[0.7879], [0.5317]]], [[[0.2603], [0.978]]]]]], Max56553), 
LSof84543 = softmax_layer(Max56553, 1, Sof84543), 
LRes18173 = reshape_layer(Sof84543, [2, 1, 2], Res18173), 
LRes50975 = reshape_layer(Res18173, [2, 2], Res50975), 
LFla44353 = flatten_layer(Res50975, Fla44353), 
LDot422 = dot_layer([[0.1938, 0.3724, 0.7981]], [[0.1122, 0.3806, 0.6545]], 1, 1, Dot422), 
LCon35486 = concatenate_layer([Dot422,[[0.0628, 0.6435, 0.2894]]], 1, Con35486), 
LSub22643 = subtract_layer(Fla44353,Con35486, Sub22643), 
LRes33379 = reshape_layer(Sub22643, [4, 1], Res33379), 
LCon48387 = concatenate_layer([Res33379,[[[0.7814, 0.2107], [0.7516, 0.7539], [0.9837, 0.0631], [0.6572, 0.4998]]]], 2, Con48387), 
LDot94907 = dot_layer([[[0.4009, 0.6442], [0.0098, 0.8913], [0.0563, 0.186]]], [[[0.0044, 0.9278], [0.1318, 0.7677], [0.2472, 0.5094]]], 2, 2, Dot94907), 
LZer99538 = zero_padding1D_layer(Dot94907, 1, 0, Zer99538), 
LDot58300 = dot_layer(Con48387,Zer99538, 2, 2, Dot58300), 
exec_layers([LMax56553,LSof84543,LRes18173,LRes50975,LFla44353,LDot422,LCon35486,LSub22643,LRes33379,LCon48387,LDot94907,LZer99538,LDot58300],["Max56553","Sof84543","Res18173","Res50975","Fla44353","Dot422","Con35486","Sub22643","Res33379","Con48387","Dot94907","Zer99538","Dot58300"],Dot58300,"Dot58300")

Actual (Unparsed): [[[0.0000000, 0.4284641, 0.5086741, 0.1145301], [0.0000000, 0.9298142, 1.1301629, 0.2514107], [0.0000000, 0.4572975, 0.5539953, 0.1234474], [0.0000000, 0.7653291, 0.9436070, 0.2083948]]]

Expected (Unparsed): [[[0.0,0.42846404714065156,0.5086740731593258,0.11453005390386847],[0.0,0.9298141198410896,1.1301628062266413,0.2514107017553996],[0.0,0.4572974549462485,0.5539952815684994,0.12344738223078155],[0.0,0.7653290410749103,0.9436069602073589,0.20839482516460042]]]

Actual:   [[[0, 0.4285, 0.5087, 0.1146], [0, 0.9299, 1.1302, 0.2515], [0, 0.4573, 0.554, 0.1235], [0, 0.7654, 0.9437, 0.2084]]]

Expected: [[[0, 0.4285, 0.5087, 0.1146], [0, 0.9299, 1.1302, 0.2515], [0, 0.4573, 0.554, 0.1235], [0, 0.7654, 0.9437, 0.2084]]]