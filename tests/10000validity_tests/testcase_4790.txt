import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot18979 = tf.keras.layers.Input(shape=([2]))
in1Dot18979 = tf.keras.layers.Input(shape=([2]))
in0Max85649 = tf.keras.layers.Input(shape=([1, 1, 2]))

Dot18979 = keras.layers.Dot(axes=(1, 1), name = 'Dot18979', )([in0Dot18979,in1Dot18979])
Thr89 = keras.layers.ThresholdedReLU(theta=9.66952399263916, name = 'Thr89', )(Dot18979)
Max85649 = keras.layers.MaxPool2D(pool_size=(1, 1), name = 'Max85649', )(in0Max85649)
Bat42136 = keras.layers.BatchNormalization(axis=3, epsilon=0.22866401030620648,  name = 'Bat42136', )(Max85649)
Res21910 = keras.layers.Reshape((1, 2), name = 'Res21910', )(Bat42136)
Sim47671 = keras.layers.SimpleRNN(1,name = 'Sim47671', )(Res21910)
Add9343 = keras.layers.Add(name = 'Add9343', )([Thr89,Sim47671])
model = tf.keras.models.Model(inputs=[in0Dot18979,in1Dot18979,in0Max85649], outputs=Add9343)
w = model.get_layer('Bat42136').get_weights() 
w[0] = np.array([0.5623, 0.1752])
w[1] = np.array([0.4757, 0.5283])
w[2] = np.array([0.1063, 0.0137])
w[3] = np.array([0.7069, 0.6376])
model.get_layer('Bat42136').set_weights(w) 
w = model.get_layer('Sim47671').get_weights() 
w[0] = np.array([[6], [9]])
w[1] = np.array([[7]])
w[2] = np.array([9])
model.get_layer('Sim47671').set_weights(w) 
in0Dot18979 = tf.constant([[0.5893, 0.9331]])
in1Dot18979 = tf.constant([[0.4675, 0.9811]])
in0Max85649 = tf.constant([[[[1.5464, 1.6789]]]])
print (np.array2string(model.predict([in0Dot18979,in1Dot18979,in0Max85649],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add9343.png')

LDot18979 = dot_layer([[0.5893, 0.9331]], [[0.4675, 0.9811]], 1, 1, Dot18979), 
LThr89 = thresholded_relu_layer(Dot18979, 9.66952399263916, Thr89), 
LMax85649 = max_pool2D_layer([[[[1.5464, 1.6789]]]], 1, 1, Max85649), 
LBat42136 = batch_normalization_layer(Max85649, 3, 0.22866401030620648, [0.5623, 0.1752], [0.4757, 0.5283], [0.1063, 0.0137], [0.7069, 0.6376], Bat42136), 
LRes21910 = reshape_layer(Bat42136, [1, 2], Res21910), 
LSim47671 = simple_rnn_layer(Res21910,[[6], [9]],[[7]],[9], Sim47671), 
LAdd9343 = add_layer([Thr89,Sim47671], Add9343), 
exec_layers([LDot18979,LThr89,LMax85649,LBat42136,LRes21910,LSim47671,LAdd9343],["Dot18979","Thr89","Max85649","Bat42136","Res21910","Sim47671","Add9343"],Add9343,"Add9343")

Actual (Unparsed): [[1.0000000]]

Expected (Unparsed): [[1.0]]

Actual:   [[1]]

Expected: [[1]]