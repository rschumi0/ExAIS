import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub46893 = tf.keras.layers.Input(shape=([3, 3, 3]))
in1Sub46893 = tf.keras.layers.Input(shape=([3, 3, 3]))

Sub46893 = keras.layers.Subtract(name = 'Sub46893', )([in0Sub46893,in1Sub46893])
Res71155 = keras.layers.Reshape((3, 9), name = 'Res71155', )(Sub46893)
Zer52600 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer52600', )(Res71155)
Sim85691 = keras.layers.SimpleRNN(3,name = 'Sim85691', )(Zer52600)
Lay42886 = keras.layers.LayerNormalization(axis=1, epsilon=1.8691132694790387, name = 'Lay42886', )(Sim85691)
model = tf.keras.models.Model(inputs=[in0Sub46893,in1Sub46893], outputs=Lay42886)
w = model.get_layer('Sim85691').get_weights() 
w[0] = np.array([[6, 9, 10], [5, 10, 7], [8, 7, 7], [3, 9, 1], [3, 8, 3], [10, 2, 1], [9, 7, 2], [6, 7, 6], [9, 8, 5]])
w[1] = np.array([[4, 6, 2], [5, 7, 7], [6, 5, 8]])
w[2] = np.array([8, 7, 6])
model.get_layer('Sim85691').set_weights(w) 
in0Sub46893 = tf.constant([[[[0.5347, 0.5068, 0.8867], [0.6661, 0.4927, 0.5345], [0.8454, 0.5462, 0.8578]], [[0.0446, 0.3868, 0.9321], [0.3716, 0.0476, 0.2918], [0.028, 0.8771, 0.4127]], [[0.48, 0.5642, 0.9689], [0.6735, 0.3971, 0.6609], [0.5633, 0.2629, 0.1528]]]])
in1Sub46893 = tf.constant([[[[0.5252, 0.7324, 0.4144], [0.0031, 0.3585, 0.4667], [0.3797, 0.8505, 0.6588]], [[0.1211, 0.0604, 0.7967], [0.434, 0.1759, 0.6283], [0.4232, 0.7184, 0.6032]], [[0.218, 0.3967, 0.1748], [0.5658, 0.315, 0.2051], [0.5044, 0.3964, 0.0341]]]])
print (np.array2string(model.predict([in0Sub46893,in1Sub46893],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Lay42886.png')

LSub46893 = subtract_layer([[[[0.5347, 0.5068, 0.8867], [0.6661, 0.4927, 0.5345], [0.8454, 0.5462, 0.8578]], [[0.0446, 0.3868, 0.9321], [0.3716, 0.0476, 0.2918], [0.028, 0.8771, 0.4127]], [[0.48, 0.5642, 0.9689], [0.6735, 0.3971, 0.6609], [0.5633, 0.2629, 0.1528]]]], [[[[0.5252, 0.7324, 0.4144], [0.0031, 0.3585, 0.4667], [0.3797, 0.8505, 0.6588]], [[0.1211, 0.0604, 0.7967], [0.434, 0.1759, 0.6283], [0.4232, 0.7184, 0.6032]], [[0.218, 0.3967, 0.1748], [0.5658, 0.315, 0.2051], [0.5044, 0.3964, 0.0341]]]], Sub46893), 
LRes71155 = reshape_layer(Sub46893, [3, 9], Res71155), 
LZer52600 = zero_padding1D_layer(Res71155, 2, 0, Zer52600), 
LSim85691 = simple_rnn_layer(Zer52600,[[6, 9, 10], [5, 10, 7], [8, 7, 7], [3, 9, 1], [3, 8, 3], [10, 2, 1], [9, 7, 2], [6, 7, 6], [9, 8, 5]],[[4, 6, 2], [5, 7, 7], [6, 5, 8]],[8, 7, 6], Sim85691), 
LLay42886 = layer_normalization_layer(Sim85691, 1, 1.8691132694790387, Lay42886), 
exec_layers([LSub46893,LRes71155,LZer52600,LSim85691,LLay42886],["Sub46893","Res71155","Zer52600","Sim85691","Lay42886"],Lay42886,"Lay42886")

Actual (Unparsed): [[0.0000000, 0.0000000, 0.0000000]]

Expected (Unparsed): [[0.0,0.0,0.0]]

Actual:   [[0, 0, 0]]

Expected: [[0, 0, 0]]