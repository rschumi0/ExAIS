import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add77157 = tf.keras.layers.Input(shape=([1, 1, 1]))
in1Add77157 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Lea72208 = tf.keras.layers.Input(shape=([2, 1]))
in0Con727 = tf.keras.layers.Input(shape=([6]))
in0Max90042 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in1Max90042 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in0Glo71162 = tf.keras.layers.Input(shape=([2, 2]))
in0Con31371 = tf.keras.layers.Input(shape=([6]))

Add77157 = keras.layers.Add(name = 'Add77157', )([in0Add77157,in1Add77157])
Res20748 = keras.layers.Reshape((1, 1), name = 'Res20748', )(Add77157)
Zer25663 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer25663', )(Res20748)
Lea72208 = keras.layers.LeakyReLU(alpha=9.158193871275854, name = 'Lea72208', input_shape=(2, 1))(in0Lea72208)
Min68164 = keras.layers.Minimum(name = 'Min68164', )([Zer25663,Lea72208])
Fla74579 = keras.layers.Flatten(name = 'Fla74579', )(Min68164)
Con727 = keras.layers.Concatenate(axis=1, name = 'Con727', )([Fla74579,in0Con727])
Max90042 = keras.layers.Maximum(name = 'Max90042', )([in0Max90042,in1Max90042])
Res53568 = keras.layers.Reshape((2, 2, 2), name = 'Res53568', )(Max90042)
Res87500 = keras.layers.Reshape((2, 4), name = 'Res87500', )(Res53568)
Fla35195 = keras.layers.Flatten(name = 'Fla35195', )(Res87500)
Glo71162 = keras.layers.GlobalAveragePooling1D(name = 'Glo71162', )(in0Glo71162)
Con31371 = keras.layers.Concatenate(axis=1, name = 'Con31371', )([Glo71162,in0Con31371])
Add64977 = keras.layers.Add(name = 'Add64977', )([Fla35195,Con31371])
Sub97990 = keras.layers.Subtract(name = 'Sub97990', )([Con727,Add64977])
Res47558 = keras.layers.Reshape((8, 1), name = 'Res47558', )(Sub97990)
Up_33478 = keras.layers.UpSampling1D(size=(2), name = 'Up_33478', )(Res47558)
model = tf.keras.models.Model(inputs=[in0Add77157,in1Add77157,in0Lea72208,in0Con727,in0Max90042,in1Max90042,in0Glo71162,in0Con31371], outputs=Up_33478)
in0Add77157 = tf.constant([[[[0.1929]]]])
in1Add77157 = tf.constant([[[[0.9298]]]])
in0Lea72208 = tf.constant([[[0.9485], [0.54]]])
in0Con727 = tf.constant([[0.5782, 0.1459, 0.661, 0.8491, 0.707, 0.4431]])
in0Max90042 = tf.constant([[[[[0.8332], [0.9182]], [[0.3693], [0.6673]]], [[[0.0916], [0.9551]], [[0.9303], [0.2743]]]]])
in1Max90042 = tf.constant([[[[[0.2273], [0.8102]], [[0.9343], [0.5062]]], [[[0.9174], [0.0829]], [[0.298], [0.0782]]]]])
in0Glo71162 = tf.constant([[[1.3472, 1.5197], [1.662, 1.4128]]])
in0Con31371 = tf.constant([[0.4828, 0.6505, 0.8309, 0.4957, 0.1759, 0.0042]])
print (np.array2string(model.predict([in0Add77157,in1Add77157,in0Lea72208,in0Con727,in0Max90042,in1Max90042,in0Glo71162,in0Con31371],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Up_33478.png')

LAdd77157 = add_layer([[[[[0.1929]]]], [[[[0.9298]]]]], Add77157), 
LRes20748 = reshape_layer(Add77157, [1, 1], Res20748), 
LZer25663 = zero_padding1D_layer(Res20748, 1, 0, Zer25663), 
LLea72208 = leaky_relu_layer([[[0.9485], [0.54]]], 9.158193871275854, Lea72208), 
LMin68164 = minimum_layer([Zer25663,Lea72208], Min68164), 
LFla74579 = flatten_layer(Min68164, Fla74579), 
LCon727 = concatenate_layer([Fla74579,[[0.5782, 0.1459, 0.661, 0.8491, 0.707, 0.4431]]], 1, Con727), 
LMax90042 = maximum_layer([[[[[[0.8332], [0.9182]], [[0.3693], [0.6673]]], [[[0.0916], [0.9551]], [[0.9303], [0.2743]]]]], [[[[[0.2273], [0.8102]], [[0.9343], [0.5062]]], [[[0.9174], [0.0829]], [[0.298], [0.0782]]]]]], Max90042), 
LRes53568 = reshape_layer(Max90042, [2, 2, 2], Res53568), 
LRes87500 = reshape_layer(Res53568, [2, 4], Res87500), 
LFla35195 = flatten_layer(Res87500, Fla35195), 
LGlo71162 = global_average_pooling1D_layer([[[1.3472, 1.5197], [1.662, 1.4128]]], Glo71162), 
LCon31371 = concatenate_layer([Glo71162,[[0.4828, 0.6505, 0.8309, 0.4957, 0.1759, 0.0042]]], 1, Con31371), 
LAdd64977 = add_layer([Fla35195,Con31371], Add64977), 
LSub97990 = subtract_layer(Con727,Add64977, Sub97990), 
LRes47558 = reshape_layer(Sub97990, [8, 1], Res47558), 
LUp_33478 = up_sampling1D_layer(Res47558, 2, Up_33478), 
exec_layers([LAdd77157,LRes20748,LZer25663,LLea72208,LMin68164,LFla74579,LCon727,LMax90042,LRes53568,LRes87500,LFla35195,LGlo71162,LCon31371,LAdd64977,LSub97990,LRes47558,LUp_33478],["Add77157","Res20748","Zer25663","Lea72208","Min68164","Fla74579","Con727","Max90042","Res53568","Res87500","Fla35195","Glo71162","Con31371","Add64977","Sub97990","Res47558","Up_33478"],Up_33478,"Up_33478")

Actual (Unparsed): [[[-2.3378000], [-2.3378000], [-1.8444500], [-1.8444500], [-0.8389000], [-0.8389000], [-1.1719000], [-1.1719000], [-1.0873000], [-1.0873000], [-0.6017000], [-0.6017000], [-0.3992000], [-0.3992000], [0.1646000], [0.1646000]]]

Expected (Unparsed): [[[-2.3378],[-2.3378],[-1.8444500000000001],[-1.8444500000000001],[-0.8389],[-0.8389],[-1.1719000000000002],[-1.1719000000000002],[-1.0873],[-1.0873],[-0.6016999999999999],[-0.6016999999999999],[-0.3992000000000001],[-0.3992000000000001],[0.16460000000000002],[0.16460000000000002]]]

Actual:   [[[-2.3378], [-2.3378], [-1.8444], [-1.8444], [-0.8389], [-0.8389], [-1.1719], [-1.1719], [-1.0873], [-1.0873], [-0.6017], [-0.6017], [-0.3992], [-0.3992], [0.1646], [0.1646]]]

Expected: [[[-2.3378], [-2.3378], [-1.8444], [-1.8444], [-0.8389], [-0.8389], [-1.1719], [-1.1719], [-1.0873], [-1.0873], [-0.6016], [-0.6016], [-0.3992], [-0.3992], [0.1647], [0.1647]]]