import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub91693 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Sub91693 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Add59316 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in1Add59316 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))

Sub91693 = keras.layers.Subtract(name = 'Sub91693', )([in0Sub91693,in1Sub91693])
Res95492 = keras.layers.Reshape((2, 2, 4), name = 'Res95492', )(Sub91693)
Res59680 = keras.layers.Reshape((2, 8), name = 'Res59680', )(Res95492)
Add59316 = keras.layers.Add(name = 'Add59316', )([in0Add59316,in1Add59316])
Res69988 = keras.layers.Reshape((2, 1, 4), name = 'Res69988', )(Add59316)
Res84928 = keras.layers.Reshape((2, 4), name = 'Res84928', )(Res69988)
Dot34088 = keras.layers.Dot(axes=(1, 1), name = 'Dot34088', )([Res59680,Res84928])
model = tf.keras.models.Model(inputs=[in0Sub91693,in1Sub91693,in0Add59316,in1Add59316], outputs=Dot34088)
in0Sub91693 = tf.constant([[[[[0.6305, 0.3632], [0.4006, 0.1217]], [[0.2215, 0.1312], [0.3906, 0.0973]]], [[[0.085, 0.0216], [0.1615, 0.438]], [[0.7232, 0.75], [0.1358, 0.1439]]]]])
in1Sub91693 = tf.constant([[[[[0.8274, 0.9507], [0.5618, 0.6142]], [[0.4801, 0.4325], [0.2666, 0.0855]]], [[[0.393, 0.2704], [0.7578, 0.9314]], [[0.7899, 0.9956], [0.4733, 0.8875]]]]])
in0Add59316 = tf.constant([[[[[0.9377, 0.5764], [0.5236, 0.4748]]], [[[0.2644, 0.109], [0.8387, 0.378]]]]])
in1Add59316 = tf.constant([[[[[0.461, 0.1347], [0.2367, 0.3012]]], [[[0.9601, 0.2817], [0.5639, 0.8724]]]]])
print (np.array2string(model.predict([in0Sub91693,in1Sub91693,in0Add59316,in1Add59316],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot34088.png')

LSub91693 = subtract_layer([[[[[0.6305, 0.3632], [0.4006, 0.1217]], [[0.2215, 0.1312], [0.3906, 0.0973]]], [[[0.085, 0.0216], [0.1615, 0.438]], [[0.7232, 0.75], [0.1358, 0.1439]]]]], [[[[[0.8274, 0.9507], [0.5618, 0.6142]], [[0.4801, 0.4325], [0.2666, 0.0855]]], [[[0.393, 0.2704], [0.7578, 0.9314]], [[0.7899, 0.9956], [0.4733, 0.8875]]]]], Sub91693), 
LRes95492 = reshape_layer(Sub91693, [2, 2, 4], Res95492), 
LRes59680 = reshape_layer(Res95492, [2, 8], Res59680), 
LAdd59316 = add_layer([[[[[[0.9377, 0.5764], [0.5236, 0.4748]]], [[[0.2644, 0.109], [0.8387, 0.378]]]]], [[[[[0.461, 0.1347], [0.2367, 0.3012]]], [[[0.9601, 0.2817], [0.5639, 0.8724]]]]]], Add59316), 
LRes69988 = reshape_layer(Add59316, [2, 1, 4], Res69988), 
LRes84928 = reshape_layer(Res69988, [2, 4], Res84928), 
LDot34088 = dot_layer(Res59680,Res84928, 1, 1, Dot34088), 
exec_layers([LSub91693,LRes95492,LRes59680,LAdd59316,LRes69988,LRes84928,LDot34088],["Sub91693","Res95492","Res59680","Add59316","Res69988","Res84928","Dot34088"],Dot34088,"Dot34088")

Actual (Unparsed): [[[-0.6525500, -0.2603512, -0.5817039, -0.5379176], [-1.1263918, -0.5149774, -0.7956431, -0.7669995], [-0.9556398, -0.3476037, -0.9589307, -0.8707047], [-1.2930280, -0.5429881, -1.0664906, -0.9991274], [-0.4433780, -0.2099501, -0.2901670, -0.2840753], [-0.7221655, -0.3102103, -0.5735569, -0.5409070], [-0.2398300, -0.0436849, -0.3791003, -0.3257860], [-0.8940335, -0.2821335, -1.0340018, -0.9206406]]]

Expected (Unparsed): [[[-0.6525500300000001,-0.26035119000000007,-0.5817038700000001,-0.5379176000000001],[-1.1263918499999999,-0.51497741,-0.79564313,-0.7669995199999999],[-0.95563979,-0.34760373,-0.95893074,-0.87070472],[-1.29302805,-0.5429881299999999,-1.06649059,-0.9991273599999999],[-0.4433779700000002,-0.20995015000000009,-0.2901670000000002,-0.28407528000000015],[-0.7221655100000001,-0.31021035,-0.5735569500000001,-0.54090704],[-0.23982995000000001,-0.04368485000000001,-0.37910030000000006,-0.325786],[-0.8940335399999999,-0.28213353999999996,-1.03400182,-0.9206406399999999]]]

Actual:   [[[-0.6525, -0.2603, -0.5817, -0.5379], [-1.1263, -0.5149, -0.7956, -0.7669], [-0.9556, -0.3476, -0.9589, -0.8707], [-1.293, -0.5429, -1.0664, -0.9991], [-0.4433, -0.2099, -0.2901, -0.284], [-0.7221, -0.3102, -0.5735, -0.5409], [-0.2398, -0.0436, -0.3791, -0.3257], [-0.894, -0.2821, -1.034, -0.9206]]]

Expected: [[[-0.6525, -0.2603, -0.5817, -0.5379], [-1.1263, -0.5149, -0.7956, -0.7669], [-0.9556, -0.3476, -0.9589, -0.8707], [-1.293, -0.5429, -1.0664, -0.9991], [-0.4433, -0.2099, -0.2901, -0.284], [-0.7221, -0.3102, -0.5735, -0.5409], [-0.2398, -0.0436, -0.3791, -0.3257], [-0.894, -0.2821, -1.034, -0.9206]]]