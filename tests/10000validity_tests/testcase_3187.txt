import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max41656 = tf.keras.layers.Input(shape=([2, 2]))
in0Add94773 = tf.keras.layers.Input(shape=([1, 1]))
in1Add94773 = tf.keras.layers.Input(shape=([1, 1]))
in0Fla10064 = tf.keras.layers.Input(shape=([4, 1, 2]))
in0Con79545 = tf.keras.layers.Input(shape=([1]))

Max41656 = keras.layers.MaxPool1D(pool_size=(2), name = 'Max41656', )(in0Max41656)
Add94773 = keras.layers.Add(name = 'Add94773', )([in0Add94773,in1Add94773])
Dot59568 = keras.layers.Dot(axes=(1, 1), name = 'Dot59568', )([Max41656,Add94773])
Den28302 = keras.layers.Dense(1,name = 'Den28302', )(Dot59568)
Fla43643 = keras.layers.Flatten(name = 'Fla43643', )(Den28302)
Fla10064 = keras.layers.Flatten(name = 'Fla10064', )(in0Fla10064)
Res80891 = keras.layers.Reshape((8, 1), name = 'Res80891', )(Fla10064)
LST47755 = keras.layers.LSTM(1,recurrent_activation='sigmoid', name = 'LST47755', )(Res80891)
Lea25362 = keras.layers.LeakyReLU(alpha=1.5006965981752876, name = 'Lea25362', )(LST47755)
Con79545 = keras.layers.Concatenate(axis=1, name = 'Con79545', )([Lea25362,in0Con79545])
Add43648 = keras.layers.Add(name = 'Add43648', )([Fla43643,Con79545])
model = tf.keras.models.Model(inputs=[in0Max41656,in0Add94773,in1Add94773,in0Fla10064,in0Con79545], outputs=Add43648)
w = model.get_layer('Den28302').get_weights() 
w[0] = np.array([[0.1086]])
w[1] = np.array([0.7397])
model.get_layer('Den28302').set_weights(w) 
w = model.get_layer('LST47755').get_weights() 
w[0] = np.array([[9, 4, 1, 6]])
w[1] = np.array([[2, 7, 9, 8]])
w[2] = np.array([4, 10, 7, 2])
model.get_layer('LST47755').set_weights(w) 
in0Max41656 = tf.constant([[[1.6329, 1.2341], [1.1496, 1.9337]]])
in0Add94773 = tf.constant([[[0.8273]]])
in1Add94773 = tf.constant([[[0.9356]]])
in0Fla10064 = tf.constant([[[[1.3808, 1.8522]], [[1.4551, 1.7205]], [[1.14, 1.3674]], [[1.2009, 1.2649]]]])
in0Con79545 = tf.constant([[0.2821]])
print (np.array2string(model.predict([in0Max41656,in0Add94773,in1Add94773,in0Fla10064,in0Con79545],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add43648.png')

LMax41656 = max_pool1D_layer([[[1.6329, 1.2341], [1.1496, 1.9337]]], 2, Max41656), 
LAdd94773 = add_layer([[[[0.8273]]], [[[0.9356]]]], Add94773), 
LDot59568 = dot_layer(Max41656,Add94773, 1, 1, Dot59568), 
LDen28302 = dense_layer(Dot59568, [[0.1086]],[0.7397], Den28302), 
LFla43643 = flatten_layer(Den28302, Fla43643), 
LFla10064 = flatten_layer([[[[1.3808, 1.8522]], [[1.4551, 1.7205]], [[1.14, 1.3674]], [[1.2009, 1.2649]]]], Fla10064), 
LRes80891 = reshape_layer(Fla10064, [8, 1], Res80891), 
LLST47755 = lstm_layer(Res80891,[[9, 4, 1, 6]],[[2, 7, 9, 8]],[4, 10, 7, 2], LST47755), 
LLea25362 = leaky_relu_layer(LST47755, 1.5006965981752876, Lea25362), 
LCon79545 = concatenate_layer([Lea25362,[[0.2821]]], 1, Con79545), 
LAdd43648 = add_layer([Fla43643,Con79545], Add43648), 
exec_layers([LMax41656,LAdd94773,LDot59568,LDen28302,LFla43643,LFla10064,LRes80891,LLST47755,LLea25362,LCon79545,LAdd43648],["Max41656","Add94773","Dot59568","Den28302","Fla43643","Fla10064","Res80891","LST47755","Lea25362","Con79545","Add43648"],Add43648,"Add43648")

Actual (Unparsed): [[2.0523200, 1.3920087]]

Expected (Unparsed): [[2.0523199918926265,1.392008682678]]

Actual:   [[2.0524, 1.3921]]

Expected: [[2.0524, 1.3921]]