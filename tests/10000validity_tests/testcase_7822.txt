import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con74894 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in0Con61265 = tf.keras.layers.Input(shape=([2, 2]))
in0Con50294 = tf.keras.layers.Input(shape=([1, 3, 3]))
in0GRU15103 = tf.keras.layers.Input(shape=([3, 1]))
in0Con78506 = tf.keras.layers.Input(shape=([16]))

Con74894 = keras.layers.Conv3DTranspose(3, (1, 2, 1),strides=(1, 1, 1), padding='valid', name = 'Con74894', )(in0Con74894)
Res5233 = keras.layers.Reshape((1, 3, 6), name = 'Res5233', )(Con74894)
Con61265 = keras.layers.Conv1D(4, (1),strides=(1), padding='same', dilation_rate=(1), name = 'Con61265', )(in0Con61265)
Sof56020 = keras.layers.Softmax(axis=1, name = 'Sof56020', )(Con61265)
Res82677 = keras.layers.Reshape((2, 4, 1), name = 'Res82677', )(Sof56020)
Sep87158 = keras.layers.SeparableConv2D(3, (2, 3),strides=(2, 2), padding='valid', name = 'Sep87158', )(Res82677)
Zer84525 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer84525', )(Sep87158)
Con50294 = keras.layers.Concatenate(axis=3, name = 'Con50294', )([Zer84525,in0Con50294])
Sub29108 = keras.layers.Subtract(name = 'Sub29108', )([Res5233,Con50294])
Res88567 = keras.layers.Reshape((1, 18), name = 'Res88567', )(Sub29108)
Fla34748 = keras.layers.Flatten(name = 'Fla34748', )(Res88567)
GRU15103 = keras.layers.GRU(2,reset_after=True, recurrent_activation='sigmoid', name = 'GRU15103', )(in0GRU15103)
Con78506 = keras.layers.Concatenate(axis=1, name = 'Con78506', )([GRU15103,in0Con78506])
Sub18036 = keras.layers.Subtract(name = 'Sub18036', )([Fla34748,Con78506])
model = tf.keras.models.Model(inputs=[in0Con74894,in0Con61265,in0Con50294,in0GRU15103,in0Con78506], outputs=Sub18036)
w = model.get_layer('Con74894').get_weights() 
w[0] = np.array([[[[[0.5193], [0.5196], [0.4305]]], [[[0.5926], [0.3918], [0.9526]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con74894').set_weights(w) 
w = model.get_layer('Con61265').get_weights() 
w[0] = np.array([[[0.8185, 0.368, 0.8813, 0.841], [0.2267, 0.4137, 0.2053, 0.5258]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con61265').set_weights(w) 
w = model.get_layer('Sep87158').get_weights() 
w[0] = np.array([[[[0.6547]], [[0.5296]], [[0.2955]]], [[[0.3723]], [[0.7111]], [[0.4587]]]])
w[1] = np.array([[[[0.7474, 0.2651, 0.3171]]]])
w[2] = np.array([0, 0, 0])
model.get_layer('Sep87158').set_weights(w) 
w = model.get_layer('GRU15103').get_weights() 
w[0] = np.array([[6, 5, 1, 7, 6, 9]])
w[1] = np.array([[5, 7, 1, 4, 10, 6], [3, 8, 5, 9, 3, 10]])
w[2] = np.array([[1, 9, 5, 2, 2, 3], [9, 2, 7, 6, 7, 8]])
model.get_layer('GRU15103').set_weights(w) 
in0Con74894 = tf.constant([[[[[0.4664], [0.5325]], [[0.3394], [0.2506]]]]])
in0Con61265 = tf.constant([[[0.7159, 0.8014], [0.191, 0.0763]]])
in0Con50294 = tf.constant([[[[0.8927, 0.2353, 0.2544], [0.593, 0.3407, 0.8773], [0.2831, 0.3708, 0.4038]]]])
in0GRU15103 = tf.constant([[[3], [5], [9]]])
in0Con78506 = tf.constant([[0.8365, 0.7857, 0.7012, 0.3965, 0.0795, 0.8615, 0.3006, 0.507, 0.9917, 0.9473, 0.5335, 0.364, 0.7863, 0.2623, 0.0947, 0.2191]])
print (np.array2string(model.predict([in0Con74894,in0Con61265,in0Con50294,in0GRU15103,in0Con78506],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub18036.png')

LCon74894 = conv3D_transpose_layer([[[[[0.4664], [0.5325]], [[0.3394], [0.2506]]]]], 1, 2, 1,[[[[[0.5193], [0.5196], [0.4305]]], [[[0.5926], [0.3918], [0.9526]]]]],[0, 0, 0], 1, 1, 1, false, Con74894), 
LRes5233 = reshape_layer(Con74894, [1, 3, 6], Res5233), 
LCon61265 = conv1D_layer([[[0.7159, 0.8014], [0.191, 0.0763]]], 1,[[[0.8185, 0.368, 0.8813, 0.841], [0.2267, 0.4137, 0.2053, 0.5258]]],[0, 0, 0, 0], 1, true, 1, Con61265), 
LSof56020 = softmax_layer(Con61265, 1, Sof56020), 
LRes82677 = reshape_layer(Sof56020, [2, 4, 1], Res82677), 
LSep87158 = separable_conv2D_layer(Res82677, 2, 3,[[[[[0.6547]], [[0.5296]], [[0.2955]]], [[[0.3723]], [[0.7111]], [[0.4587]]]],[[[[0.7474, 0.2651, 0.3171]]]]],[0, 0, 0], 2, 2, false, Sep87158), 
LZer84525 = zero_padding2D_layer(Sep87158, 0, 0, 2, 0, Zer84525), 
LCon50294 = concatenate_layer([Zer84525,[[[[0.8927, 0.2353, 0.2544], [0.593, 0.3407, 0.8773], [0.2831, 0.3708, 0.4038]]]]], 3, Con50294), 
LSub29108 = subtract_layer(Res5233,Con50294, Sub29108), 
LRes88567 = reshape_layer(Sub29108, [1, 18], Res88567), 
LFla34748 = flatten_layer(Res88567, Fla34748), 
LGRU15103 = gru_layer([[[3], [5], [9]]],[[6, 5, 1, 7, 6, 9]],[[5, 7, 1, 4, 10, 6], [3, 8, 5, 9, 3, 10]],[[1, 9, 5, 2, 2, 3], [9, 2, 7, 6, 7, 8]], true, GRU15103), 
LCon78506 = concatenate_layer([GRU15103,[[0.8365, 0.7857, 0.7012, 0.3965, 0.0795, 0.8615, 0.3006, 0.507, 0.9917, 0.9473, 0.5335, 0.364, 0.7863, 0.2623, 0.0947, 0.2191]]], 1, Con78506), 
LSub18036 = subtract_layer(Fla34748,Con78506, Sub18036), 
exec_layers([LCon74894,LRes5233,LCon61265,LSof56020,LRes82677,LSep87158,LZer84525,LCon50294,LSub29108,LRes88567,LFla34748,LGRU15103,LCon78506,LSub18036],["Con74894","Res5233","Con61265","Sof56020","Res82677","Sep87158","Zer84525","Con50294","Sub29108","Res88567","Fla34748","GRU15103","Con78506","Sub18036"],Sub18036,"Sub18036")

Actual (Unparsed): [[0.2422015, 0.2423414, -0.6357148, -1.4018728, -0.6598130, -0.4216587, 0.3731391, -0.5024123, 0.2898043, -0.6543039, -0.9935547, -1.2094572, -1.4576305, -0.6301482, -0.9404021, -0.3968945, -0.3673149, -0.3841784]]

Expected (Unparsed): [[0.24220151999930853,0.24234143999489072,-0.6357148,-1.40187275,-0.6598130000000001,-0.4216587500000001,0.37313905999999997,-0.5024122400000001,0.28980434,-0.65430392,-0.9935547400000001,-1.2094572000000001,-1.4576304448529362,-0.63014822098811,-0.9404020534263662,-0.39689443999999996,-0.36731492000000004,-0.38417844]]

Actual:   [[0.2423, 0.2424, -0.6357, -1.4018, -0.6598, -0.4216, 0.3732, -0.5024, 0.2899, -0.6543, -0.9935, -1.2094, -1.4576, -0.6301, -0.9404, -0.3968, -0.3673, -0.3841]]

Expected: [[0.2423, 0.2424, -0.6357, -1.4018, -0.6598, -0.4216, 0.3732, -0.5024, 0.2899, -0.6543, -0.9935, -1.2094, -1.4576, -0.6301, -0.9404, -0.3968, -0.3673, -0.3841]]