import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add47523 = tf.keras.layers.Input(shape=([1, 2]))
in1Add47523 = tf.keras.layers.Input(shape=([1, 2]))
in0Con59710 = tf.keras.layers.Input(shape=([7]))
in0Sub59839 = tf.keras.layers.Input(shape=([3, 3, 3, 3]))
in1Sub59839 = tf.keras.layers.Input(shape=([3, 3, 3, 3]))
in0Con786 = tf.keras.layers.Input(shape=([9, 2]))
in0Lea53336 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Add44360 = tf.keras.layers.Input(shape=([1, 2]))
in1Add44360 = tf.keras.layers.Input(shape=([1, 2]))
in0Con1353 = tf.keras.layers.Input(shape=([1, 1]))

Add47523 = keras.layers.Add(name = 'Add47523', )([in0Add47523,in1Add47523])
Fla73222 = keras.layers.Flatten(name = 'Fla73222', )(Add47523)
Con59710 = keras.layers.Concatenate(axis=1, name = 'Con59710', )([Fla73222,in0Con59710])
Sub59839 = keras.layers.Subtract(name = 'Sub59839', )([in0Sub59839,in1Sub59839])
Res29702 = keras.layers.Reshape((3, 3, 9), name = 'Res29702', )(Sub59839)
Glo46227 = keras.layers.GlobalAveragePooling2D(name = 'Glo46227', )(Res29702)
Sub1591 = keras.layers.Subtract(name = 'Sub1591', )([Con59710,Glo46227])
Res97490 = keras.layers.Reshape((9, 1), name = 'Res97490', )(Sub1591)
Con786 = keras.layers.Concatenate(axis=2, name = 'Con786', )([Res97490,in0Con786])
Lea53336 = keras.layers.LeakyReLU(alpha=2.8005062718888345, name = 'Lea53336', input_shape=(2, 2, 1))(in0Lea53336)
Res56462 = keras.layers.Reshape((2, 2), name = 'Res56462', )(Lea53336)
Ave41866 = keras.layers.AveragePooling1D(pool_size=(2), name = 'Ave41866', )(Res56462)
Den21543 = keras.layers.Dense(3,name = 'Den21543', )(Ave41866)
Add44360 = keras.layers.Add(name = 'Add44360', )([in0Add44360,in1Add44360])
Con1353 = keras.layers.Concatenate(axis=2, name = 'Con1353', )([Add44360,in0Con1353])
Add87711 = keras.layers.Add(name = 'Add87711', )([Den21543,Con1353])
Zer1583 = keras.layers.ZeroPadding1D(padding=((8, 0)), name = 'Zer1583', )(Add87711)
Sub90882 = keras.layers.Subtract(name = 'Sub90882', )([Con786,Zer1583])
model = tf.keras.models.Model(inputs=[in0Add47523,in1Add47523,in0Con59710,in0Sub59839,in1Sub59839,in0Con786,in0Lea53336,in0Add44360,in1Add44360,in0Con1353], outputs=Sub90882)
w = model.get_layer('Den21543').get_weights() 
w[0] = np.array([[0.965, 0.5939, 0.2917], [0.3523, 0.4728, 0.7342]])
w[1] = np.array([0.4586, 0.0722, 0.047])
model.get_layer('Den21543').set_weights(w) 
in0Add47523 = tf.constant([[[0.5208, 0.5724]]])
in1Add47523 = tf.constant([[[0.2633, 0.6526]]])
in0Con59710 = tf.constant([[0.6655, 0.7333, 0.1894, 0.7494, 0.8357, 0.4814, 0.4621]])
in0Sub59839 = tf.constant([[[[[0.7765, 0.6113, 0.0476], [0.4406, 0.7845, 0.9613], [0.0642, 0.9976, 0.5764]], [[0.1916, 0.3348, 0.2414], [0.8193, 0.855, 0.6806], [0.4344, 0.9336, 0.1779]], [[0.4986, 0.3016, 0.8233], [0.7089, 0.4556, 0.091], [0.8996, 0.9262, 0.9885]]], [[[0.6186, 0.6911, 0.3959], [0.6271, 0.0678, 0.2217], [0.1878, 0.0602, 0.0714]], [[0.5147, 0.9077, 0.5558], [0.3974, 0.0317, 0.8816], [0.8173, 0.3758, 0.5933]], [[0.7457, 0.6043, 0.061], [0.3428, 0.9313, 0.4845], [0.0057, 0.614, 0.3155]]], [[[0.8912, 0.4386, 0.1411], [0.6089, 0.2599, 0.5817], [0.9121, 0.892, 0.3912]], [[0.825, 0.1048, 0.0766], [0.3441, 0.4817, 0.9715], [0.9727, 0.1051, 0.8873]], [[0.2387, 0.0669, 0.9938], [0.6791, 0.5764, 0.0839], [0.2715, 0.1946, 0.9572]]]]])
in1Sub59839 = tf.constant([[[[[0.8945, 0.6975, 0.059], [0.2724, 0.3574, 0.8434], [0.1994, 0.4024, 0.2394]], [[0.821, 0.72, 0.0496], [0.4433, 0.7021, 0.2969], [0.0311, 0.3934, 0.3205]], [[0.0132, 0.4056, 0.5759], [0.3308, 0.8444, 0.7571], [0.9125, 0.3705, 0.3229]]], [[[0.2003, 0.8594, 0.922], [0.2675, 0.1829, 0.864], [0.0048, 0.8429, 0.9616]], [[0.0882, 0.1386, 0.6326], [0.7071, 0.1124, 0.1173], [0.853, 0.5523, 0.6703]], [[0.0043, 0.315, 0.5416], [0.3342, 0.4221, 0.248], [0.3593, 0.4688, 0.644]]], [[[0.6407, 0.9239, 0.7027], [0.2175, 0.3251, 0.4134], [0.6284, 0.8478, 0.6322]], [[0.0609, 0.4351, 0.0553], [0.0819, 0.1018, 0.703], [0.6808, 0.2348, 0.5869]], [[0.6426, 0.6597, 0.5294], [0.3826, 0.6514, 0.6114], [0.6556, 0.5743, 0.1757]]]]])
in0Con786 = tf.constant([[[0.2491, 0.5482], [0.0656, 0.8093], [0.7987, 0.281], [0.1518, 0.2268], [0.0184, 0.4453], [0.4841, 0.1998], [0.9068, 0.2361], [0.6078, 0.1983], [0.0144, 0.372]]])
in0Lea53336 = tf.constant([[[[0.6958], [0.7755]], [[0.6606], [0.5173]]]])
in0Add44360 = tf.constant([[[0.8813, 0.6908]]])
in1Add44360 = tf.constant([[[0.3783, 0.4046]]])
in0Con1353 = tf.constant([[[0.609]]])
print (np.array2string(model.predict([in0Add47523,in1Add47523,in0Con59710,in0Sub59839,in1Sub59839,in0Con786,in0Lea53336,in0Add44360,in1Add44360,in0Con1353],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub90882.png')

LAdd47523 = add_layer([[[[0.5208, 0.5724]]], [[[0.2633, 0.6526]]]], Add47523), 
LFla73222 = flatten_layer(Add47523, Fla73222), 
LCon59710 = concatenate_layer([Fla73222,[[0.6655, 0.7333, 0.1894, 0.7494, 0.8357, 0.4814, 0.4621]]], 1, Con59710), 
LSub59839 = subtract_layer([[[[[0.7765, 0.6113, 0.0476], [0.4406, 0.7845, 0.9613], [0.0642, 0.9976, 0.5764]], [[0.1916, 0.3348, 0.2414], [0.8193, 0.855, 0.6806], [0.4344, 0.9336, 0.1779]], [[0.4986, 0.3016, 0.8233], [0.7089, 0.4556, 0.091], [0.8996, 0.9262, 0.9885]]], [[[0.6186, 0.6911, 0.3959], [0.6271, 0.0678, 0.2217], [0.1878, 0.0602, 0.0714]], [[0.5147, 0.9077, 0.5558], [0.3974, 0.0317, 0.8816], [0.8173, 0.3758, 0.5933]], [[0.7457, 0.6043, 0.061], [0.3428, 0.9313, 0.4845], [0.0057, 0.614, 0.3155]]], [[[0.8912, 0.4386, 0.1411], [0.6089, 0.2599, 0.5817], [0.9121, 0.892, 0.3912]], [[0.825, 0.1048, 0.0766], [0.3441, 0.4817, 0.9715], [0.9727, 0.1051, 0.8873]], [[0.2387, 0.0669, 0.9938], [0.6791, 0.5764, 0.0839], [0.2715, 0.1946, 0.9572]]]]], [[[[[0.8945, 0.6975, 0.059], [0.2724, 0.3574, 0.8434], [0.1994, 0.4024, 0.2394]], [[0.821, 0.72, 0.0496], [0.4433, 0.7021, 0.2969], [0.0311, 0.3934, 0.3205]], [[0.0132, 0.4056, 0.5759], [0.3308, 0.8444, 0.7571], [0.9125, 0.3705, 0.3229]]], [[[0.2003, 0.8594, 0.922], [0.2675, 0.1829, 0.864], [0.0048, 0.8429, 0.9616]], [[0.0882, 0.1386, 0.6326], [0.7071, 0.1124, 0.1173], [0.853, 0.5523, 0.6703]], [[0.0043, 0.315, 0.5416], [0.3342, 0.4221, 0.248], [0.3593, 0.4688, 0.644]]], [[[0.6407, 0.9239, 0.7027], [0.2175, 0.3251, 0.4134], [0.6284, 0.8478, 0.6322]], [[0.0609, 0.4351, 0.0553], [0.0819, 0.1018, 0.703], [0.6808, 0.2348, 0.5869]], [[0.6426, 0.6597, 0.5294], [0.3826, 0.6514, 0.6114], [0.6556, 0.5743, 0.1757]]]]], Sub59839), 
LRes29702 = reshape_layer(Sub59839, [3, 3, 9], Res29702), 
LGlo46227 = global_average_pooling2D_layer(Res29702, Glo46227), 
LSub1591 = subtract_layer(Con59710,Glo46227, Sub1591), 
LRes97490 = reshape_layer(Sub1591, [9, 1], Res97490), 
LCon786 = concatenate_layer([Res97490,[[[0.2491, 0.5482], [0.0656, 0.8093], [0.7987, 0.281], [0.1518, 0.2268], [0.0184, 0.4453], [0.4841, 0.1998], [0.9068, 0.2361], [0.6078, 0.1983], [0.0144, 0.372]]]], 2, Con786), 
LLea53336 = leaky_relu_layer([[[[0.6958], [0.7755]], [[0.6606], [0.5173]]]], 2.8005062718888345, Lea53336), 
LRes56462 = reshape_layer(Lea53336, [2, 2], Res56462), 
LAve41866 = average_pooling1D_layer(Res56462, 2, Ave41866), 
LDen21543 = dense_layer(Ave41866, [[0.965, 0.5939, 0.2917], [0.3523, 0.4728, 0.7342]],[0.4586, 0.0722, 0.047], Den21543), 
LAdd44360 = add_layer([[[[0.8813, 0.6908]]], [[[0.3783, 0.4046]]]], Add44360), 
LCon1353 = concatenate_layer([Add44360,[[[0.609]]]], 2, Con1353), 
LAdd87711 = add_layer([Den21543,Con1353], Add87711), 
LZer1583 = zero_padding1D_layer(Add87711, 8, 0, Zer1583), 
LSub90882 = subtract_layer(Con786,Zer1583, Sub90882), 
exec_layers([LAdd47523,LFla73222,LCon59710,LSub59839,LRes29702,LGlo46227,LSub1591,LRes97490,LCon786,LLea53336,LRes56462,LAve41866,LDen21543,LAdd44360,LCon1353,LAdd87711,LZer1583,LSub90882],["Add47523","Fla73222","Con59710","Sub59839","Res29702","Glo46227","Sub1591","Res97490","Con786","Lea53336","Res56462","Ave41866","Den21543","Add44360","Con1353","Add87711","Zer1583","Sub90882"],Sub90882,"Sub90882")

Actual (Unparsed): [[[0.5691111, 0.2491000, 0.5482000], [1.3465222, 0.0656000, 0.8093000], [0.7467889, 0.7987000, 0.2810000], [0.5187555, 0.1518000, 0.2268000], [0.1067000, 0.0184000, 0.4453000], [0.7379222, 0.4841000, 0.1998000], [0.8089889, 0.9068000, 0.2361000], [0.4356333, 0.6078000, 0.1983000], [-2.1833119, -1.8616009, -0.9564178]]]

Expected (Unparsed): [[[0.5691111111111111,0.2491,0.5482],[1.3465222222222224,0.0656,0.8093],[0.7467888888888888,0.7987,0.281],[0.5187555555555555,0.1518,0.2268],[0.10669999999999999,0.0184,0.4453],[0.7379222222222221,0.4841,0.1998],[0.8089888888888889,0.9068,0.2361],[0.4356333333333333,0.6078,0.1983],[-2.1833119422222222,-1.8616008999999998,-0.9564178199999999]]]

Actual:   [[[0.5692, 0.2491, 0.5482], [1.3466, 0.0656, 0.8093], [0.7468, 0.7987, 0.281], [0.5188, 0.1518, 0.2268], [0.1067, 0.0184, 0.4453], [0.738, 0.4841, 0.1998], [0.809, 0.9068, 0.2361], [0.4357, 0.6078, 0.1983], [-2.1833, -1.8616, -0.9564]]]

Expected: [[[0.5692, 0.2491, 0.5482], [1.3466, 0.0656, 0.8093], [0.7468, 0.7987, 0.281], [0.5188, 0.1518, 0.2268], [0.1067, 0.0184, 0.4453], [0.738, 0.4841, 0.1998], [0.809, 0.9068, 0.2361], [0.4357, 0.6078, 0.1983], [-2.1833, -1.8616, -0.9564]]]