import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul29407 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in1Mul29407 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Con99726 = tf.keras.layers.Input(shape=([20]))
in0Con19560 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Glo94462 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con71933 = tf.keras.layers.Input(shape=([23]))

Mul29407 = keras.layers.Multiply(name = 'Mul29407', )([in0Mul29407,in1Mul29407])
Res72365 = keras.layers.Reshape((1, 1, 4), name = 'Res72365', )(Mul29407)
Res64410 = keras.layers.Reshape((1, 4), name = 'Res64410', )(Res72365)
Fla12262 = keras.layers.Flatten(name = 'Fla12262', )(Res64410)
Con99726 = keras.layers.Concatenate(axis=1, name = 'Con99726', )([Fla12262,in0Con99726])
Con19560 = keras.layers.Conv3D(3, (2, 2, 1),strides=(1, 1, 1), padding='same', dilation_rate=(1, 1, 1), name = 'Con19560', )(in0Con19560)
Lea60666 = keras.layers.LeakyReLU(alpha=0.543388599683056, name = 'Lea60666', )(Con19560)
Res16470 = keras.layers.Reshape((2, 2, 6), name = 'Res16470', )(Lea60666)
Res674 = keras.layers.Reshape((2, 12), name = 'Res674', )(Res16470)
Fla34566 = keras.layers.Flatten(name = 'Fla34566', )(Res674)
Glo94462 = keras.layers.GlobalMaxPool2D(name = 'Glo94462', )(in0Glo94462)
Con71933 = keras.layers.Concatenate(axis=1, name = 'Con71933', )([Glo94462,in0Con71933])
Sub60996 = keras.layers.Subtract(name = 'Sub60996', )([Fla34566,Con71933])
Min79433 = keras.layers.Minimum(name = 'Min79433', )([Con99726,Sub60996])
model = tf.keras.models.Model(inputs=[in0Mul29407,in1Mul29407,in0Con99726,in0Con19560,in0Glo94462,in0Con71933], outputs=Min79433)
w = model.get_layer('Con19560').get_weights() 
w[0] = np.array([[[[[0.7947, 0.0299, 0.9735], [0.3641, 0.6047, 0.3817]]], [[[0.3074, 0.3111, 0.3669], [0.3695, 0.369, 0.6469]]]], [[[[0.9733, 0.6176, 0.5973], [0.3654, 0.2574, 0.6571]]], [[[0.6513, 0.663, 0.7895], [0.8357, 0.9755, 0.1516]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con19560').set_weights(w) 
in0Mul29407 = tf.constant([[[[[0.2875, 0.8528], [0.5509, 0.5982]]]]])
in1Mul29407 = tf.constant([[[[[0.5284, 0.0029], [0.4443, 0.6964]]]]])
in0Con99726 = tf.constant([[0.6593, 0.1758, 0.2967, 0.9639, 0.7676, 0.4008, 0.5308, 0.3861, 0.3966, 0.3927, 0.1953, 0.1498, 0.3363, 0.8602, 0.9632, 0.7484, 0.2021, 0.0224, 0.5041, 0.1872]])
in0Con19560 = tf.constant([[[[[0.2625, 0.9367], [0.6856, 0.5445]], [[0.5717, 0.7616], [0.5766, 0.0652]]], [[[0.9957, 0.3794], [0.3927, 0.3031]], [[0.0872, 0.5352], [0.305, 0.8803]]]]])
in0Glo94462 = tf.constant([[[[1.4716]]]])
in0Con71933 = tf.constant([[0.0904, 0.1443, 0.6797, 0.4586, 0.0666, 0.0826, 0.8666, 0.1407, 0.8042, 0.5163, 0.8791, 0.3252, 0.6353, 0.0675, 0.7888, 0.3852, 0.3112, 0.9968, 0.4266, 0.1023, 0.2224, 0.3463, 0.8381]])
print (np.array2string(model.predict([in0Mul29407,in1Mul29407,in0Con99726,in0Con19560,in0Glo94462,in0Con71933],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min79433.png')

LMul29407 = multiply_layer([[[[[[0.2875, 0.8528], [0.5509, 0.5982]]]]], [[[[[0.5284, 0.0029], [0.4443, 0.6964]]]]]], Mul29407), 
LRes72365 = reshape_layer(Mul29407, [1, 1, 4], Res72365), 
LRes64410 = reshape_layer(Res72365, [1, 4], Res64410), 
LFla12262 = flatten_layer(Res64410, Fla12262), 
LCon99726 = concatenate_layer([Fla12262,[[0.6593, 0.1758, 0.2967, 0.9639, 0.7676, 0.4008, 0.5308, 0.3861, 0.3966, 0.3927, 0.1953, 0.1498, 0.3363, 0.8602, 0.9632, 0.7484, 0.2021, 0.0224, 0.5041, 0.1872]]], 1, Con99726), 
LCon19560 = conv3D_layer([[[[[0.2625, 0.9367], [0.6856, 0.5445]], [[0.5717, 0.7616], [0.5766, 0.0652]]], [[[0.9957, 0.3794], [0.3927, 0.3031]], [[0.0872, 0.5352], [0.305, 0.8803]]]]], 2, 2, 1,[[[[[0.7947, 0.0299, 0.9735], [0.3641, 0.6047, 0.3817]]], [[[0.3074, 0.3111, 0.3669], [0.3695, 0.369, 0.6469]]]], [[[[0.9733, 0.6176, 0.5973], [0.3654, 0.2574, 0.6571]]], [[[0.6513, 0.663, 0.7895], [0.8357, 0.9755, 0.1516]]]]],[0, 0, 0], 1, 1, 1, true, 1, 1, 1, Con19560), 
LLea60666 = leaky_relu_layer(Con19560, 0.543388599683056, Lea60666), 
LRes16470 = reshape_layer(Lea60666, [2, 2, 6], Res16470), 
LRes674 = reshape_layer(Res16470, [2, 12], Res674), 
LFla34566 = flatten_layer(Res674, Fla34566), 
LGlo94462 = global_max_pool2D_layer([[[[1.4716]]]], Glo94462), 
LCon71933 = concatenate_layer([Glo94462,[[0.0904, 0.1443, 0.6797, 0.4586, 0.0666, 0.0826, 0.8666, 0.1407, 0.8042, 0.5163, 0.8791, 0.3252, 0.6353, 0.0675, 0.7888, 0.3852, 0.3112, 0.9968, 0.4266, 0.1023, 0.2224, 0.3463, 0.8381]]], 1, Con71933), 
LSub60996 = subtract_layer(Fla34566,Con71933, Sub60996), 
LMin79433 = minimum_layer([Con99726,Sub60996], Min79433), 
exec_layers([LMul29407,LRes72365,LRes64410,LFla12262,LCon99726,LCon19560,LLea60666,LRes16470,LRes674,LFla34566,LGlo94462,LCon71933,LSub60996,LMin79433],["Mul29407","Res72365","Res64410","Fla12262","Con99726","Con19560","Lea60666","Res16470","Res674","Fla34566","Glo94462","Con71933","Sub60996","Min79433"],Min79433,"Min79433")

Actual (Unparsed): [[0.1519150, 0.0024731, 0.2447649, 0.4165865, 0.6593000, 0.1758000, 0.2967000, -0.1973514, 0.7676000, 0.2962815, -0.0446760, 0.3861000, 0.3966000, -0.1514886, 0.1953000, 0.0526652, 0.2295425, 0.8602000, -0.7326358, -0.1003573, 0.1868750, 0.0224000, 0.1951369, -0.2051720]]

Expected (Unparsed): [[0.151915,0.0024731199999999997,0.24476486999999997,0.41658648,0.6593,0.1758,0.2967,-0.19735144999999998,0.7676,0.2962814599999999,-0.04467599999999994,0.3861,0.3966,-0.15148867,0.1953,0.05266525,0.22954249999999998,0.8602,-0.73263584,-0.10035728,0.18687504,0.0224,0.19513690999999994,-0.20517198999999997]]

Actual:   [[0.152, 0.0025, 0.2448, 0.4166, 0.6593, 0.1758, 0.2967, -0.1973, 0.7676, 0.2963, -0.0446, 0.3861, 0.3966, -0.1514, 0.1953, 0.0527, 0.2296, 0.8602, -0.7326, -0.1003, 0.1869, 0.0224, 0.1952, -0.2051]]

Expected: [[0.152, 0.0025, 0.2448, 0.4166, 0.6593, 0.1758, 0.2967, -0.1973, 0.7676, 0.2963, -0.0446, 0.3861, 0.3966, -0.1514, 0.1953, 0.0527, 0.2296, 0.8602, -0.7326, -0.1003, 0.1869, 0.0224, 0.1952, -0.2051]]