import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max10477 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Max10477 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Dot73349 = tf.keras.layers.Input(shape=([3]))
in1Dot73349 = tf.keras.layers.Input(shape=([3]))
in0ELU35992 = tf.keras.layers.Input(shape=([2, 1, 1, 1]))

Max10477 = keras.layers.Maximum(name = 'Max10477', )([in0Max10477,in1Max10477])
Res68052 = keras.layers.Reshape((2, 1), name = 'Res68052', )(Max10477)
Fla91550 = keras.layers.Flatten(name = 'Fla91550', )(Res68052)
Dot73349 = keras.layers.Dot(axes=(1, 1), name = 'Dot73349', )([in0Dot73349,in1Dot73349])
Bat63390 = keras.layers.BatchNormalization(axis=1, epsilon=0.9977575018476733,  name = 'Bat63390', )(Dot73349)
Den50728 = keras.layers.Dense(2,name = 'Den50728', )(Bat63390)
Mul65425 = keras.layers.Multiply(name = 'Mul65425', )([Fla91550,Den50728])
Res94037 = keras.layers.Reshape((2, 1), name = 'Res94037', )(Mul65425)
Res76040 = keras.layers.Reshape((2, 1, 1), name = 'Res76040', )(Res94037)
Res38098 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res38098', )(Res76040)
ELU35992 = keras.layers.ELU(alpha=-4.132599995653057, name = 'ELU35992', input_shape=(2, 1, 1, 1))(in0ELU35992)
Add66139 = keras.layers.Add(name = 'Add66139', )([Res38098,ELU35992])
model = tf.keras.models.Model(inputs=[in0Max10477,in1Max10477,in0Dot73349,in1Dot73349,in0ELU35992], outputs=Add66139)
w = model.get_layer('Bat63390').get_weights() 
w[0] = np.array([0.0386])
w[1] = np.array([0.4708])
w[2] = np.array([0.375])
w[3] = np.array([0.7194])
model.get_layer('Bat63390').set_weights(w) 
w = model.get_layer('Den50728').get_weights() 
w[0] = np.array([[0.7341, 0.3521]])
w[1] = np.array([0.9605, 0.1327])
model.get_layer('Den50728').set_weights(w) 
in0Max10477 = tf.constant([[[[0.2023]], [[0.5313]]]])
in1Max10477 = tf.constant([[[[0.9278]], [[0.2116]]]])
in0Dot73349 = tf.constant([[0.3499, 0.0935, 0.2469]])
in1Dot73349 = tf.constant([[0.1129, 0.1236, 0.3567]])
in0ELU35992 = tf.constant([[[[[0.6016]]], [[[0.9988]]]]])
print (np.array2string(model.predict([in0Max10477,in1Max10477,in0Dot73349,in1Dot73349,in0ELU35992],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add66139.png')

LMax10477 = maximum_layer([[[[[0.2023]], [[0.5313]]]], [[[[0.9278]], [[0.2116]]]]], Max10477), 
LRes68052 = reshape_layer(Max10477, [2, 1], Res68052), 
LFla91550 = flatten_layer(Res68052, Fla91550), 
LDot73349 = dot_layer([[0.3499, 0.0935, 0.2469]], [[0.1129, 0.1236, 0.3567]], 1, 1, Dot73349), 
LBat63390 = batch_normalization_layer(Dot73349, 1, 0.9977575018476733, [0.0386], [0.4708], [0.375], [0.7194], Bat63390), 
LDen50728 = dense_layer(Bat63390, [[0.7341, 0.3521]],[0.9605, 0.1327], Den50728), 
LMul65425 = multiply_layer([Fla91550,Den50728], Mul65425), 
LRes94037 = reshape_layer(Mul65425, [2, 1], Res94037), 
LRes76040 = reshape_layer(Res94037, [2, 1, 1], Res76040), 
LRes38098 = reshape_layer(Res76040, [2, 1, 1, 1], Res38098), 
LELU35992 = elu_layer([[[[[0.6016]]], [[[0.9988]]]]], -4.132599995653057, ELU35992), 
LAdd66139 = add_layer([Res38098,ELU35992], Add66139), 
exec_layers([LMax10477,LRes68052,LFla91550,LDot73349,LBat63390,LDen50728,LMul65425,LRes94037,LRes76040,LRes38098,LELU35992,LAdd66139],["Max10477","Res68052","Fla91550","Dot73349","Bat63390","Den50728","Mul65425","Res94037","Res76040","Res38098","ELU35992","Add66139"],Add66139,"Add66139")

Actual (Unparsed): [[[[[1.8086806]]], [[[1.1560766]]]]]

Expected (Unparsed): [[[[[1.808680603988185]]],[[[1.1560766542736385]]]]]

Actual:   [[[[[1.8087]]], [[[1.1561]]]]]

Expected: [[[[[1.8087]]], [[[1.1561]]]]]