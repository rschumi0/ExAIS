import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max23323 = tf.keras.layers.Input(shape=([2, 2, 1]))
in1Max23323 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Glo60106 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con97705 = tf.keras.layers.Input(shape=([2]))
in0Con35730 = tf.keras.layers.Input(shape=([50]))
in0Sub37678 = tf.keras.layers.Input(shape=([2, 3, 3, 3]))
in1Sub37678 = tf.keras.layers.Input(shape=([2, 3, 3, 3]))
in0Dot68413 = tf.keras.layers.Input(shape=([3]))
in1Dot68413 = tf.keras.layers.Input(shape=([3]))
in0Con82033 = tf.keras.layers.Input(shape=([53]))

Max23323 = keras.layers.Maximum(name = 'Max23323', )([in0Max23323,in1Max23323])
Res24339 = keras.layers.Reshape((2, 2), name = 'Res24339', )(Max23323)
Fla22040 = keras.layers.Flatten(name = 'Fla22040', )(Res24339)
Glo60106 = keras.layers.GlobalAveragePooling2D(name = 'Glo60106', )(in0Glo60106)
Con97705 = keras.layers.Concatenate(axis=1, name = 'Con97705', )([Glo60106,in0Con97705])
Mul92655 = keras.layers.Multiply(name = 'Mul92655', )([Fla22040,Con97705])
ReL82960 = keras.layers.ReLU(max_value=1.1092210774370914, negative_slope=1.5693667886303118, threshold=5.255855203644714, name = 'ReL82960', )(Mul92655)
Con35730 = keras.layers.Concatenate(axis=1, name = 'Con35730', )([ReL82960,in0Con35730])
Sub37678 = keras.layers.Subtract(name = 'Sub37678', )([in0Sub37678,in1Sub37678])
Res97728 = keras.layers.Reshape((2, 3, 9), name = 'Res97728', )(Sub37678)
Res80929 = keras.layers.Reshape((2, 27), name = 'Res80929', )(Res97728)
Fla56568 = keras.layers.Flatten(name = 'Fla56568', )(Res80929)
Dot68413 = keras.layers.Dot(axes=(1, 1), name = 'Dot68413', )([in0Dot68413,in1Dot68413])
Con82033 = keras.layers.Concatenate(axis=1, name = 'Con82033', )([Dot68413,in0Con82033])
Max42845 = keras.layers.Maximum(name = 'Max42845', )([Fla56568,Con82033])
Thr87855 = keras.layers.ThresholdedReLU(theta=9.406443999665576, name = 'Thr87855', )(Max42845)
Add60366 = keras.layers.Add(name = 'Add60366', )([Con35730,Thr87855])
model = tf.keras.models.Model(inputs=[in0Max23323,in1Max23323,in0Glo60106,in0Con97705,in0Con35730,in0Sub37678,in1Sub37678,in0Dot68413,in1Dot68413,in0Con82033], outputs=Add60366)
in0Max23323 = tf.constant([[[[0.8468], [0.0511]], [[0.6973], [0.9622]]]])
in1Max23323 = tf.constant([[[[0.0305], [0.2928]], [[0.8911], [0.345]]]])
in0Glo60106 = tf.constant([[[[1.1213, 1.6362]], [[1.1878, 1.5027]]]])
in0Con97705 = tf.constant([[0.6756, 0.0352]])
in0Con35730 = tf.constant([[0.7172, 0.9168, 0.2394, 0.8059, 0.7055, 0.9612, 0.0636, 0.6172, 0.5091, 0.4501, 0.3847, 0.8966, 0.1706, 0.5722, 0.2509, 0.7103, 0.9732, 0.4833, 0.6011, 0.4327, 0.4095, 0.4363, 0.4758, 0.4975, 0.7576, 0.5798, 0.1935, 0.085, 0.6881, 0.8528, 0.5817, 0.6126, 0.2285, 0.1589, 0.5266, 0.5399, 0.1026, 0.7965, 0.5558, 0.1849, 0.9316, 0.9413, 0.9074, 0.9562, 0.0341, 0.8287, 0.5546, 0.6504, 0.5958, 0.1713]])
in0Sub37678 = tf.constant([[[[[0.8582, 0.6555, 0.5451], [0.4555, 0.1295, 0.0997], [0.3335, 0.3223, 0.9606]], [[0.9218, 0.7528, 0.3057], [0.1034, 0.0113, 0.2655], [0.5896, 0.0444, 0.4555]], [[0.7588, 0.9985, 0.6975], [0.9287, 0.5461, 0.1175], [0.6533, 0.9862, 0.3807]]], [[[0.3266, 0.6214, 0.6186], [0.3688, 0.8635, 0.6199], [0.4175, 0.043, 0.5972]], [[0.5406, 0.0914, 0.8831], [0.6689, 0.9527, 0.881], [0.2581, 0.5334, 0.3919]], [[0.6236, 0.1027, 0.2262], [0.9285, 0.8348, 0.6382], [0.8668, 0.5072, 0.1955]]]]])
in1Sub37678 = tf.constant([[[[[0.1036, 0.5132, 0.408], [0.2581, 0.7685, 0.4844], [0.1897, 0.0185, 0.4686]], [[0.1799, 0.647, 0.2428], [0.5249, 0.2419, 0.6382], [0.078, 0.1861, 0.6301]], [[0.1196, 0.5328, 0.6685], [0.8089, 0.3631, 0.8689], [0.4598, 0.7824, 0.1255]]], [[[0.8107, 0.7972, 0.1562], [0.489, 0.7478, 0.1366], [0.7511, 0.199, 0.7853]], [[0.9883, 0.5523, 0.5879], [0.5787, 0.7087, 0.9349], [0.5909, 0.3772, 0.7131]], [[0.1783, 0.9392, 0.5984], [0.0988, 0.2505, 0.3414], [0.5565, 0.8562, 0.7282]]]]])
in0Dot68413 = tf.constant([[0.3584, 0.6754, 0.6837]])
in1Dot68413 = tf.constant([[0.5013, 0.7143, 0.6313]])
in0Con82033 = tf.constant([[0.8276, 0.8636, 0.9057, 0.8435, 0.9464, 0.931, 0.3649, 0.8201, 0.2778, 0.8654, 0.1748, 0.5887, 0.9767, 0.9571, 0.9142, 0.6498, 0.5709, 0.0651, 0.8588, 0.4699, 0.3398, 0.9561, 0.2299, 0.6584, 0.2603, 0.6577, 0.7666, 0.7288, 0.4814, 0.3844, 0.3772, 0.7664, 0.9816, 0.7933, 0.1499, 0.4867, 0.6646, 0.6866, 0.9263, 0.9699, 0.6493, 0.7866, 0.977, 0.8297, 0.9244, 0.8803, 0.0557, 0.6903, 0.8541, 0.4562, 0.2542, 0.6303, 0.2462]])
print (np.array2string(model.predict([in0Max23323,in1Max23323,in0Glo60106,in0Con97705,in0Con35730,in0Sub37678,in1Sub37678,in0Dot68413,in1Dot68413,in0Con82033],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add60366.png')

LMax23323 = maximum_layer([[[[[0.8468], [0.0511]], [[0.6973], [0.9622]]]], [[[[0.0305], [0.2928]], [[0.8911], [0.345]]]]], Max23323), 
LRes24339 = reshape_layer(Max23323, [2, 2], Res24339), 
LFla22040 = flatten_layer(Res24339, Fla22040), 
LGlo60106 = global_average_pooling2D_layer([[[[1.1213, 1.6362]], [[1.1878, 1.5027]]]], Glo60106), 
LCon97705 = concatenate_layer([Glo60106,[[0.6756, 0.0352]]], 1, Con97705), 
LMul92655 = multiply_layer([Fla22040,Con97705], Mul92655), 
LReL82960 = relu_layer(Mul92655, 1.1092210774370914, 1.5693667886303118, 5.255855203644714, ReL82960), 
LCon35730 = concatenate_layer([ReL82960,[[0.7172, 0.9168, 0.2394, 0.8059, 0.7055, 0.9612, 0.0636, 0.6172, 0.5091, 0.4501, 0.3847, 0.8966, 0.1706, 0.5722, 0.2509, 0.7103, 0.9732, 0.4833, 0.6011, 0.4327, 0.4095, 0.4363, 0.4758, 0.4975, 0.7576, 0.5798, 0.1935, 0.085, 0.6881, 0.8528, 0.5817, 0.6126, 0.2285, 0.1589, 0.5266, 0.5399, 0.1026, 0.7965, 0.5558, 0.1849, 0.9316, 0.9413, 0.9074, 0.9562, 0.0341, 0.8287, 0.5546, 0.6504, 0.5958, 0.1713]]], 1, Con35730), 
LSub37678 = subtract_layer([[[[[0.8582, 0.6555, 0.5451], [0.4555, 0.1295, 0.0997], [0.3335, 0.3223, 0.9606]], [[0.9218, 0.7528, 0.3057], [0.1034, 0.0113, 0.2655], [0.5896, 0.0444, 0.4555]], [[0.7588, 0.9985, 0.6975], [0.9287, 0.5461, 0.1175], [0.6533, 0.9862, 0.3807]]], [[[0.3266, 0.6214, 0.6186], [0.3688, 0.8635, 0.6199], [0.4175, 0.043, 0.5972]], [[0.5406, 0.0914, 0.8831], [0.6689, 0.9527, 0.881], [0.2581, 0.5334, 0.3919]], [[0.6236, 0.1027, 0.2262], [0.9285, 0.8348, 0.6382], [0.8668, 0.5072, 0.1955]]]]], [[[[[0.1036, 0.5132, 0.408], [0.2581, 0.7685, 0.4844], [0.1897, 0.0185, 0.4686]], [[0.1799, 0.647, 0.2428], [0.5249, 0.2419, 0.6382], [0.078, 0.1861, 0.6301]], [[0.1196, 0.5328, 0.6685], [0.8089, 0.3631, 0.8689], [0.4598, 0.7824, 0.1255]]], [[[0.8107, 0.7972, 0.1562], [0.489, 0.7478, 0.1366], [0.7511, 0.199, 0.7853]], [[0.9883, 0.5523, 0.5879], [0.5787, 0.7087, 0.9349], [0.5909, 0.3772, 0.7131]], [[0.1783, 0.9392, 0.5984], [0.0988, 0.2505, 0.3414], [0.5565, 0.8562, 0.7282]]]]], Sub37678), 
LRes97728 = reshape_layer(Sub37678, [2, 3, 9], Res97728), 
LRes80929 = reshape_layer(Res97728, [2, 27], Res80929), 
LFla56568 = flatten_layer(Res80929, Fla56568), 
LDot68413 = dot_layer([[0.3584, 0.6754, 0.6837]], [[0.5013, 0.7143, 0.6313]], 1, 1, Dot68413), 
LCon82033 = concatenate_layer([Dot68413,[[0.8276, 0.8636, 0.9057, 0.8435, 0.9464, 0.931, 0.3649, 0.8201, 0.2778, 0.8654, 0.1748, 0.5887, 0.9767, 0.9571, 0.9142, 0.6498, 0.5709, 0.0651, 0.8588, 0.4699, 0.3398, 0.9561, 0.2299, 0.6584, 0.2603, 0.6577, 0.7666, 0.7288, 0.4814, 0.3844, 0.3772, 0.7664, 0.9816, 0.7933, 0.1499, 0.4867, 0.6646, 0.6866, 0.9263, 0.9699, 0.6493, 0.7866, 0.977, 0.8297, 0.9244, 0.8803, 0.0557, 0.6903, 0.8541, 0.4562, 0.2542, 0.6303, 0.2462]]], 1, Con82033), 
LMax42845 = maximum_layer([Fla56568,Con82033], Max42845), 
LThr87855 = thresholded_relu_layer(Max42845, 9.406443999665576, Thr87855), 
LAdd60366 = add_layer([Con35730,Thr87855], Add60366), 
exec_layers([LMax23323,LRes24339,LFla22040,LGlo60106,LCon97705,LMul92655,LReL82960,LCon35730,LSub37678,LRes97728,LRes80929,LFla56568,LDot68413,LCon82033,LMax42845,LThr87855,LAdd60366],["Max23323","Res24339","Fla22040","Glo60106","Con97705","Mul92655","ReL82960","Con35730","Sub37678","Res97728","Res80929","Fla56568","Dot68413","Con82033","Max42845","Thr87855","Add60366"],Add60366,"Add60366")

Actual (Unparsed): [[-6.7140371, -7.5271857, -7.3035632, -8.1952110, 0.7172000, 0.9168000, 0.2394000, 0.8059000, 0.7055000, 0.9612000, 0.0636000, 0.6172000, 0.5091000, 0.4501000, 0.3847000, 0.8966000, 0.1706000, 0.5722000, 0.2509000, 0.7103000, 0.9732000, 0.4833000, 0.6011000, 0.4327000, 0.4095000, 0.4363000, 0.4758000, 0.4975000, 0.7576000, 0.5798000, 0.1935000, 0.0850000, 0.6881000, 0.8528000, 0.5817000, 0.6126000, 0.2285000, 0.1589000, 0.5266000, 0.5399000, 0.1026000, 0.7965000, 0.5558000, 0.1849000, 0.9316000, 0.9413000, 0.9074000, 0.9562000, 0.0341000, 0.8287000, 0.5546000, 0.6504000, 0.5958000, 0.1713000]]

Expected (Unparsed): [[-6.714037160271263,-7.52718569801126,-7.303563171692391,-8.195211028164312,0.7172,0.9168,0.2394,0.8059,0.7055,0.9612,0.0636,0.6172,0.5091,0.4501,0.3847,0.8966,0.1706,0.5722,0.2509,0.7103,0.9732,0.4833,0.6011,0.4327,0.4095,0.4363,0.4758,0.4975,0.7576,0.5798,0.1935,0.085,0.6881,0.8528,0.5817,0.6126,0.2285,0.1589,0.5266,0.5399,0.1026,0.7965,0.5558,0.1849,0.9316,0.9413,0.9074,0.9562,0.0341,0.8287,0.5546,0.6504,0.5958,0.1713]]

Actual:   [[-6.714, -7.5271, -7.3035, -8.1952, 0.7172, 0.9168, 0.2394, 0.8059, 0.7055, 0.9612, 0.0636, 0.6172, 0.5091, 0.4501, 0.3847, 0.8966, 0.1706, 0.5722, 0.2509, 0.7103, 0.9732, 0.4833, 0.6011, 0.4327, 0.4095, 0.4363, 0.4758, 0.4975, 0.7576, 0.5798, 0.1935, 0.085, 0.6881, 0.8528, 0.5817, 0.6126, 0.2285, 0.1589, 0.5266, 0.5399, 0.1026, 0.7965, 0.5558, 0.1849, 0.9316, 0.9413, 0.9074, 0.9562, 0.0341, 0.8287, 0.5546, 0.6504, 0.5958, 0.1713]]

Expected: [[-6.714, -7.5271, -7.3035, -8.1952, 0.7172, 0.9168, 0.2394, 0.8059, 0.7055, 0.9612, 0.0636, 0.6172, 0.5091, 0.4501, 0.3847, 0.8966, 0.1706, 0.5722, 0.2509, 0.7103, 0.9732, 0.4833, 0.6011, 0.4327, 0.4095, 0.4363, 0.4758, 0.4975, 0.7576, 0.5798, 0.1935, 0.085, 0.6881, 0.8528, 0.5817, 0.6126, 0.2285, 0.1589, 0.5266, 0.5399, 0.1026, 0.7965, 0.5558, 0.1849, 0.9316, 0.9413, 0.9074, 0.9562, 0.0341, 0.8287, 0.5546, 0.6504, 0.5958, 0.1713]]