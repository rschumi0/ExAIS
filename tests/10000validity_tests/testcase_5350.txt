import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Fla77522 = tf.keras.layers.Input(shape=([3, 2, 3]))
in0Con90492 = tf.keras.layers.Input(shape=([18, 3]))
in0Per26739 = tf.keras.layers.Input(shape=([3, 4]))

Fla77522 = keras.layers.Flatten(name = 'Fla77522', )(in0Fla77522)
Res28392 = keras.layers.Reshape((18, 1), name = 'Res28392', )(Fla77522)
Con90492 = keras.layers.Concatenate(axis=2, name = 'Con90492', )([Res28392,in0Con90492])
Per26739 = keras.layers.Permute((1,2), name = 'Per26739',)(in0Per26739)
Zer61041 = keras.layers.ZeroPadding1D(padding=((15, 0)), name = 'Zer61041', )(Per26739)
Mul64284 = keras.layers.Multiply(name = 'Mul64284', )([Con90492,Zer61041])
model = tf.keras.models.Model(inputs=[in0Fla77522,in0Con90492,in0Per26739], outputs=Mul64284)
in0Fla77522 = tf.constant([[[[1.7562, 1.6013, 1.0801], [1.3448, 1.6832, 1.4263]], [[1.0576, 1.2625, 1.6555], [1.4577, 1.6068, 1.7376]], [[1.0792, 1.0628, 1.1103], [1.8762, 1.4864, 1.7701]]]])
in0Con90492 = tf.constant([[[0.701, 0.7448, 0.5461], [0.9943, 0.4992, 0.826], [0.7609, 0.2887, 0.6188], [0.5801, 0.248, 0.6661], [0.6227, 0.5807, 0.2807], [0.4471, 0.5998, 0.2952], [0.1719, 0.4221, 0.6861], [0.1604, 0.8035, 0.4863], [0.9896, 0.2653, 0.308], [0.1191, 0.1957, 0.7952], [0.1838, 0.5721, 0.0872], [0.0729, 0.097, 0.9533], [0.4444, 0.2423, 0.3721], [0.7475, 0.3114, 0.3862], [0.7085, 0.6951, 0.4086], [0.1423, 0.97, 0.3693], [0.555, 0.6864, 0.9923], [0.2351, 0.3186, 0.2916]]])
in0Per26739 = tf.constant([[[1.2911, 1.2041, 1.5977, 1.843], [1.1241, 1.9301, 1.5397, 1.2154], [1.2265, 1.9318, 1.2204, 1.2823]]])
print (np.array2string(model.predict([in0Fla77522,in0Con90492,in0Per26739],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul64284.png')

LFla77522 = flatten_layer([[[[1.7562, 1.6013, 1.0801], [1.3448, 1.6832, 1.4263]], [[1.0576, 1.2625, 1.6555], [1.4577, 1.6068, 1.7376]], [[1.0792, 1.0628, 1.1103], [1.8762, 1.4864, 1.7701]]]], Fla77522), 
LRes28392 = reshape_layer(Fla77522, [18, 1], Res28392), 
LCon90492 = concatenate_layer([Res28392,[[[0.701, 0.7448, 0.5461], [0.9943, 0.4992, 0.826], [0.7609, 0.2887, 0.6188], [0.5801, 0.248, 0.6661], [0.6227, 0.5807, 0.2807], [0.4471, 0.5998, 0.2952], [0.1719, 0.4221, 0.6861], [0.1604, 0.8035, 0.4863], [0.9896, 0.2653, 0.308], [0.1191, 0.1957, 0.7952], [0.1838, 0.5721, 0.0872], [0.0729, 0.097, 0.9533], [0.4444, 0.2423, 0.3721], [0.7475, 0.3114, 0.3862], [0.7085, 0.6951, 0.4086], [0.1423, 0.97, 0.3693], [0.555, 0.6864, 0.9923], [0.2351, 0.3186, 0.2916]]]], 2, Con90492), 
LPer26739 = permute_layer([[[1.2911, 1.2041, 1.5977, 1.843], [1.1241, 1.9301, 1.5397, 1.2154], [1.2265, 1.9318, 1.2204, 1.2823]]], 1,2, Per26739), 
LZer61041 = zero_padding1D_layer(Per26739, 15, 0, Zer61041), 
LMul64284 = multiply_layer([Con90492,Zer61041], Mul64284), 
exec_layers([LFla77522,LRes28392,LCon90492,LPer26739,LZer61041,LMul64284],["Fla77522","Res28392","Con90492","Per26739","Zer61041","Mul64284"],Mul64284,"Mul64284")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [2.4223618, 0.1713434, 1.5497690, 0.6806199], [1.6708622, 1.0712055, 1.0568501, 1.2060414], [2.1710277, 0.4541662, 0.3888194, 0.3739187]]]

Expected (Unparsed): [[[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[2.42236182,0.17134343,1.549769,0.6806199],[1.6708622400000002,1.0712055,1.05685008,1.20604142],[2.17102765,0.45416618,0.38881943999999996,0.37391868000000006]]]

Actual:   [[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [2.4224, 0.1714, 1.5498, 0.6807], [1.6709, 1.0713, 1.0569, 1.2061], [2.1711, 0.4542, 0.3889, 0.374]]]

Expected: [[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [2.4224, 0.1714, 1.5498, 0.6807], [1.6709, 1.0713, 1.0569, 1.2061], [2.1711, 0.4542, 0.3889, 0.374]]]