import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sep79988 = tf.keras.layers.Input(shape=([2, 2]))
in0Con1500 = tf.keras.layers.Input(shape=([2, 3, 3, 1]))
in0Ave31945 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in1Ave31945 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Con5915 = tf.keras.layers.Input(shape=([3, 4, 4, 1]))
in0Sub75828 = tf.keras.layers.Input(shape=([3, 2, 2, 3]))
in1Sub75828 = tf.keras.layers.Input(shape=([3, 2, 2, 3]))
in0Sub543 = tf.keras.layers.Input(shape=([2]))
in1Sub543 = tf.keras.layers.Input(shape=([2]))
in0Con48589 = tf.keras.layers.Input(shape=([142]))

Sep79988 = keras.layers.SeparableConv1D(3, (1),strides=(1), padding='valid', name = 'Sep79988', )(in0Sep79988)
Res64928 = keras.layers.Reshape((2, 3, 1), name = 'Res64928', )(Sep79988)
Res34181 = keras.layers.Reshape((2, 3, 1, 1), name = 'Res34181', )(Res64928)
Zer88508 = keras.layers.ZeroPadding3D(padding=((0, 0), (0, 0), (2, 0)), name = 'Zer88508', )(Res34181)
Con1500 = keras.layers.Concatenate(axis=4, name = 'Con1500', )([Zer88508,in0Con1500])
Ave31945 = keras.layers.Average(name = 'Ave31945', )([in0Ave31945,in1Ave31945])
Zer92491 = keras.layers.ZeroPadding3D(padding=((1, 0), (2, 0), (1, 0)), name = 'Zer92491', )(Ave31945)
Mul32961 = keras.layers.Multiply(name = 'Mul32961', )([Con1500,Zer92491])
Zer4089 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (1, 0)), name = 'Zer4089', )(Mul32961)
Con5915 = keras.layers.Concatenate(axis=4, name = 'Con5915', )([Zer4089,in0Con5915])
Sub75828 = keras.layers.Subtract(name = 'Sub75828', )([in0Sub75828,in1Sub75828])
Zer15458 = keras.layers.ZeroPadding3D(padding=((0, 0), (2, 0), (2, 0)), name = 'Zer15458', )(Sub75828)
Ave12674 = keras.layers.Average(name = 'Ave12674', )([Con5915,Zer15458])
Res69932 = keras.layers.Reshape((3, 4, 12), name = 'Res69932', )(Ave12674)
Res87662 = keras.layers.Reshape((3, 48), name = 'Res87662', )(Res69932)
Fla77224 = keras.layers.Flatten(name = 'Fla77224', )(Res87662)
Sub543 = keras.layers.Subtract(name = 'Sub543', )([in0Sub543,in1Sub543])
Con48589 = keras.layers.Concatenate(axis=1, name = 'Con48589', )([Sub543,in0Con48589])
Add83613 = keras.layers.Add(name = 'Add83613', )([Fla77224,Con48589])
model = tf.keras.models.Model(inputs=[in0Sep79988,in0Con1500,in0Ave31945,in1Ave31945,in0Con5915,in0Sub75828,in1Sub75828,in0Sub543,in1Sub543,in0Con48589], outputs=Add83613)
w = model.get_layer('Sep79988').get_weights() 
w[0] = np.array([[[0.8111], [0.5543]]])
w[1] = np.array([[[0.9083, 0.8585, 0.4351], [0.3628, 0.0446, 0.1034]]])
w[2] = np.array([0, 0, 0])
model.get_layer('Sep79988').set_weights(w) 
in0Sep79988 = tf.constant([[[0.032, 0.777], [0.2112, 0.8513]]])
in0Con1500 = tf.constant([[[[[0.8818], [0.6649], [0.522]], [[0.1314], [0.4302], [0.515]], [[0.4618], [0.8431], [0.4773]]], [[[0.1289], [0.3526], [0.9931]], [[0.7876], [0.8791], [0.8114]], [[0.6604], [0.192], [0.7048]]]]])
in0Ave31945 = tf.constant([[[[[0.3686, 0.6978], [0.9229, 0.3943]]]]])
in1Ave31945 = tf.constant([[[[[0.0446, 0.5404], [0.8739, 0.6564]]]]])
in0Con5915 = tf.constant([[[[[0.0948], [0.4458], [0.1188], [0.0727]], [[0.5318], [0.1424], [0.5141], [0.2516]], [[0.5986], [0.4873], [0.6763], [0.8669]], [[0.569], [0.4973], [0.0625], [0.422]]], [[[0.3477], [0.1343], [0.5489], [0.2552]], [[0.9549], [0.2975], [0.5144], [0.0398]], [[0.4141], [0.2198], [0.2201], [0.8448]], [[0.2139], [0.8419], [0.5551], [0.3811]]], [[[0.6389], [0.4649], [0.1159], [0.1695]], [[0.1733], [0.7425], [0.7552], [0.0213]], [[0.8699], [0.8616], [0.1923], [0.4001]], [[0.0449], [0.5843], [0.0119], [0.9451]]]]])
in0Sub75828 = tf.constant([[[[[0.4524, 0.2866, 0.9635], [0.2669, 0.3785, 0.8693]], [[0.6847, 0.1057, 0.5096], [0.1067, 0.4452, 0.3569]]], [[[0.6082, 0.5667, 0.6455], [0.9257, 0.2959, 0.4608]], [[0.8743, 0.7089, 0.3266], [0.1136, 0.3502, 0.6121]]], [[[0.0795, 0.1625, 0.9153], [0.2677, 0.7554, 0.404]], [[0.4734, 0.1223, 0.424], [0.1222, 0.7473, 0.9352]]]]])
in1Sub75828 = tf.constant([[[[[0.6338, 0.8107, 0.6336], [0.7563, 0.7727, 0.4298]], [[0.2281, 0.1394, 0.7456], [0.7285, 0.8075, 0.6832]]], [[[0.8224, 0.7062, 0.6656], [0.9948, 0.7006, 0.9875]], [[0.7216, 0.8191, 0.9277], [0.7406, 0.248, 0.3885]]], [[[0.8319, 0.7826, 0.8956], [0.0159, 0.0204, 0.6846]], [[0.4331, 0.5716, 0.3235], [0.0122, 0.2658, 0.7653]]]]])
in0Sub543 = tf.constant([[0.7851, 0.3224]])
in1Sub543 = tf.constant([[0.8476, 0.0906]])
in0Con48589 = tf.constant([[0.9598, 0.8583, 0.3718, 0.0821, 0.3126, 0.5472, 0.2845, 0.6254, 0.127, 0.7609, 0.3552, 0.521, 0.7754, 0.3486, 0.7066, 0.3016, 0.4347, 0.3443, 0.048, 0.2194, 0.6989, 0.9921, 0.1042, 0.8885, 0.7997, 0.6278, 0.1971, 0.6014, 0.8323, 0.7076, 0.6389, 0.5972, 0.5126, 0.4135, 0.5598, 0.6497, 0.0326, 0.5558, 0.1523, 0.0914, 0.5174, 0.9467, 0.0876, 0.7918, 0.4403, 0.0238, 0.0365, 0.6673, 0.1053, 0.2637, 0.808, 0.0191, 0.9683, 0.8488, 0.6103, 0.3622, 0.1341, 0.1211, 0.3331, 0.4431, 0.8431, 0.5901, 0.5526, 0.8232, 0.1378, 0.6523, 0.1681, 0.7479, 0.1872, 0.7176, 0.1934, 0.0196, 0.9404, 0.1444, 0.2473, 0.2439, 0.8782, 0.2379, 0.7135, 0.1286, 0.6349, 0.5801, 0.373, 0.4821, 0.1772, 0.1273, 0.5533, 0.1783, 0.0425, 0.8406, 0.4816, 0.634, 0.8603, 0.0893, 0.5819, 0.2797, 0.0158, 0.7122, 0.9155, 0.0953, 0.8448, 0.4093, 0.8265, 0.5288, 0.1967, 0.0922, 0.124, 0.0201, 0.5466, 0.9231, 0.8142, 0.9115, 0.0957, 0.0384, 0.4701, 0.742, 0.4582, 0.3706, 0.8257, 0.7939, 0.6024, 0.5567, 0.0689, 0.291, 0.6841, 0.6538, 0.6126, 0.8287, 0.2939, 0.271, 0.8337, 0.4607, 0.4237, 0.7676, 0.3778, 0.3608, 0.1512, 0.3711, 0.1548, 0.1347, 0.6386, 0.4245]])
print (np.array2string(model.predict([in0Sep79988,in0Con1500,in0Ave31945,in1Ave31945,in0Con5915,in0Sub75828,in1Sub75828,in0Sub543,in1Sub543,in0Con48589],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add83613.png')

LSep79988 = separable_conv1D_layer([[[0.032, 0.777], [0.2112, 0.8513]]], 1,[[[[0.8111], [0.5543]]],[[[0.9083, 0.8585, 0.4351], [0.3628, 0.0446, 0.1034]]]],[0, 0, 0], 1, false, Sep79988), 
LRes64928 = reshape_layer(Sep79988, [2, 3, 1], Res64928), 
LRes34181 = reshape_layer(Res64928, [2, 3, 1, 1], Res34181), 
LZer88508 = zero_padding3D_layer(Res34181, 0, 0, 0, 0, 2, 0, Zer88508), 
LCon1500 = concatenate_layer([Zer88508,[[[[[0.8818], [0.6649], [0.522]], [[0.1314], [0.4302], [0.515]], [[0.4618], [0.8431], [0.4773]]], [[[0.1289], [0.3526], [0.9931]], [[0.7876], [0.8791], [0.8114]], [[0.6604], [0.192], [0.7048]]]]]], 4, Con1500), 
LAve31945 = average_layer([[[[[[0.3686, 0.6978], [0.9229, 0.3943]]]]], [[[[[0.0446, 0.5404], [0.8739, 0.6564]]]]]], Ave31945), 
LZer92491 = zero_padding3D_layer(Ave31945, 1, 0, 2, 0, 1, 0, Zer92491), 
LMul32961 = multiply_layer([Con1500,Zer92491], Mul32961), 
LZer4089 = zero_padding3D_layer(Mul32961, 1, 0, 1, 0, 1, 0, Zer4089), 
LCon5915 = concatenate_layer([Zer4089,[[[[[0.0948], [0.4458], [0.1188], [0.0727]], [[0.5318], [0.1424], [0.5141], [0.2516]], [[0.5986], [0.4873], [0.6763], [0.8669]], [[0.569], [0.4973], [0.0625], [0.422]]], [[[0.3477], [0.1343], [0.5489], [0.2552]], [[0.9549], [0.2975], [0.5144], [0.0398]], [[0.4141], [0.2198], [0.2201], [0.8448]], [[0.2139], [0.8419], [0.5551], [0.3811]]], [[[0.6389], [0.4649], [0.1159], [0.1695]], [[0.1733], [0.7425], [0.7552], [0.0213]], [[0.8699], [0.8616], [0.1923], [0.4001]], [[0.0449], [0.5843], [0.0119], [0.9451]]]]]], 4, Con5915), 
LSub75828 = subtract_layer([[[[[0.4524, 0.2866, 0.9635], [0.2669, 0.3785, 0.8693]], [[0.6847, 0.1057, 0.5096], [0.1067, 0.4452, 0.3569]]], [[[0.6082, 0.5667, 0.6455], [0.9257, 0.2959, 0.4608]], [[0.8743, 0.7089, 0.3266], [0.1136, 0.3502, 0.6121]]], [[[0.0795, 0.1625, 0.9153], [0.2677, 0.7554, 0.404]], [[0.4734, 0.1223, 0.424], [0.1222, 0.7473, 0.9352]]]]], [[[[[0.6338, 0.8107, 0.6336], [0.7563, 0.7727, 0.4298]], [[0.2281, 0.1394, 0.7456], [0.7285, 0.8075, 0.6832]]], [[[0.8224, 0.7062, 0.6656], [0.9948, 0.7006, 0.9875]], [[0.7216, 0.8191, 0.9277], [0.7406, 0.248, 0.3885]]], [[[0.8319, 0.7826, 0.8956], [0.0159, 0.0204, 0.6846]], [[0.4331, 0.5716, 0.3235], [0.0122, 0.2658, 0.7653]]]]], Sub75828), 
LZer15458 = zero_padding3D_layer(Sub75828, 0, 0, 2, 0, 2, 0, Zer15458), 
LAve12674 = average_layer([Con5915,Zer15458], Ave12674), 
LRes69932 = reshape_layer(Ave12674, [3, 4, 12], Res69932), 
LRes87662 = reshape_layer(Res69932, [3, 48], Res87662), 
LFla77224 = flatten_layer(Res87662, Fla77224), 
LSub543 = subtract_layer([[0.7851, 0.3224]], [[0.8476, 0.0906]], Sub543), 
LCon48589 = concatenate_layer([Sub543,[[0.9598, 0.8583, 0.3718, 0.0821, 0.3126, 0.5472, 0.2845, 0.6254, 0.127, 0.7609, 0.3552, 0.521, 0.7754, 0.3486, 0.7066, 0.3016, 0.4347, 0.3443, 0.048, 0.2194, 0.6989, 0.9921, 0.1042, 0.8885, 0.7997, 0.6278, 0.1971, 0.6014, 0.8323, 0.7076, 0.6389, 0.5972, 0.5126, 0.4135, 0.5598, 0.6497, 0.0326, 0.5558, 0.1523, 0.0914, 0.5174, 0.9467, 0.0876, 0.7918, 0.4403, 0.0238, 0.0365, 0.6673, 0.1053, 0.2637, 0.808, 0.0191, 0.9683, 0.8488, 0.6103, 0.3622, 0.1341, 0.1211, 0.3331, 0.4431, 0.8431, 0.5901, 0.5526, 0.8232, 0.1378, 0.6523, 0.1681, 0.7479, 0.1872, 0.7176, 0.1934, 0.0196, 0.9404, 0.1444, 0.2473, 0.2439, 0.8782, 0.2379, 0.7135, 0.1286, 0.6349, 0.5801, 0.373, 0.4821, 0.1772, 0.1273, 0.5533, 0.1783, 0.0425, 0.8406, 0.4816, 0.634, 0.8603, 0.0893, 0.5819, 0.2797, 0.0158, 0.7122, 0.9155, 0.0953, 0.8448, 0.4093, 0.8265, 0.5288, 0.1967, 0.0922, 0.124, 0.0201, 0.5466, 0.9231, 0.8142, 0.9115, 0.0957, 0.0384, 0.4701, 0.742, 0.4582, 0.3706, 0.8257, 0.7939, 0.6024, 0.5567, 0.0689, 0.291, 0.6841, 0.6538, 0.6126, 0.8287, 0.2939, 0.271, 0.8337, 0.4607, 0.4237, 0.7676, 0.3778, 0.3608, 0.1512, 0.3711, 0.1548, 0.1347, 0.6386, 0.4245]]], 1, Con48589), 
LAdd83613 = add_layer([Fla77224,Con48589], Add83613), 
exec_layers([LSep79988,LRes64928,LRes34181,LZer88508,LCon1500,LAve31945,LZer92491,LMul32961,LZer4089,LCon5915,LSub75828,LZer15458,LAve12674,LRes69932,LRes87662,LFla77224,LSub543,LCon48589,LAdd83613],["Sep79988","Res64928","Res34181","Zer88508","Con1500","Ave31945","Zer92491","Mul32961","Zer4089","Con5915","Sub75828","Zer15458","Ave12674","Res69932","Res87662","Fla77224","Sub543","Con48589","Add83613"],Add83613,"Add83613")

Actual (Unparsed): [[-0.0625000, 0.2318000, 1.0072000, 0.8583000, 0.3718000, 0.3050000, 0.3126000, 0.5472000, 0.3439000, 0.6254000, 0.1270000, 0.7972500, 0.3552000, 0.5210000, 1.0413000, 0.3486000, 0.7066000, 0.3728000, 0.4347000, 0.3443000, 0.3050500, 0.2194000, 0.6989000, 1.1179000, 0.1042000, 0.8885000, 1.0990000, 0.6278000, 0.1971000, 0.8450500, 0.7416000, 0.4455500, 1.1420000, 0.3525000, 0.3155000, 1.0667000, 0.5598000, 0.6497000, 0.3171000, 0.5558000, 0.1523000, 0.3400500, 0.7457000, 0.9298500, 0.0008500, 0.4809000, 0.2591500, 0.0716500, 0.0365000, 0.6673000, 0.2791500, 0.2637000, 0.8080000, 0.0862500, 0.9683000, 0.8488000, 0.8847500, 0.3622000, 0.1341000, 0.2487000, 0.3331000, 0.4431000, 1.3205500, 0.5901000, 0.5526000, 0.9719500, 0.1378000, 0.6523000, 0.4253000, 0.7479000, 0.1872000, 0.7375000, 0.1934000, 0.0196000, 1.1474500, 0.1444000, 0.2473000, 0.3538000, 0.7711000, 0.1681500, 0.8135000, 0.0940500, 0.4325500, 0.7391500, 0.3730000, 0.4821000, 0.2841500, 0.1273000, 0.5533000, 0.5992500, 0.1188500, 0.7855000, 0.4586000, 0.3205000, 0.9114000, 0.3916500, 0.5819000, 0.2797000, 0.3352500, 0.7122000, 0.9155000, 0.3277500, 0.8448000, 0.4093000, 0.8844500, 0.5288000, 0.1967000, 0.1769500, 0.1240000, 0.0201000, 0.6332500, 0.9231000, 0.8142000, 1.2827500, 0.0957000, 0.0384000, 0.8477000, 0.7420000, 0.4582000, 0.3812500, 0.8257000, 0.7939000, 1.0373500, 0.5567000, 0.0689000, 0.7218000, 0.3079000, 0.3437500, 0.7186000, 0.9546000, 0.6614000, 0.3307500, 0.8337000, 0.4607000, 0.4461500, 0.7676000, 0.3778000, 0.6529500, 0.1713500, 0.2058836, 0.2110000, 0.2450982, 1.0644834, 0.9820000]]

Expected (Unparsed): [[-0.0625,0.2318,1.0072,0.8583,0.3718,0.305,0.3126,0.5472,0.3439,0.6254,0.127,0.79725,0.3552,0.521,1.0413000000000001,0.3486,0.7066,0.37279999999999996,0.4347,0.3443,0.30505,0.2194,0.6989,1.1179,0.1042,0.8885,1.099,0.6278,0.1971,0.8450500000000001,0.7416,0.44555,1.142,0.3525,0.3154999999999999,1.0667,0.5598,0.6497,0.3171,0.5558,0.1523,0.34005,0.7457,0.92985,0.0008500000000000035,0.48089999999999994,0.25915,0.07164999999999998,0.0365,0.6673,0.27915,0.2637,0.808,0.08625,0.9683,0.8488,0.8847499999999999,0.3622,0.1341,0.24869999999999998,0.3331,0.4431,1.32055,0.5901,0.5526,0.9719500000000001,0.1378,0.6523,0.4253,0.7479,0.1872,0.7375,0.1934,0.0196,1.14745,0.1444,0.2473,0.3538,0.7710999999999999,0.16814999999999997,0.8135,0.09404999999999997,0.43255,0.73915,0.373,0.4821,0.28415,0.1273,0.5533,0.59925,0.11884999999999998,0.7855,0.4586,0.3205,0.9114,0.39165,0.5819,0.2797,0.33525,0.7122,0.9155,0.32775,0.8448,0.4093,0.88445,0.5288,0.1967,0.17695,0.124,0.0201,0.63325,0.9231,0.8142,1.28275,0.0957,0.0384,0.8477,0.742,0.4582,0.38125,0.8257,0.7939,1.03735,0.5567,0.0689,0.7218,0.30790000000000006,0.34375000000000006,0.7186,0.9546,0.6614,0.33075000000000004,0.8337,0.4607,0.44615000000000005,0.7676,0.3778,0.65295,0.17135,0.2058836,0.21099999999999997,0.2450982393805896,1.0644833399999998,0.9820000000000001]]

Actual:   [[-0.0625, 0.2318, 1.0072, 0.8583, 0.3718, 0.305, 0.3126, 0.5472, 0.3439, 0.6254, 0.127, 0.7973, 0.3552, 0.521, 1.0413, 0.3486, 0.7066, 0.3728, 0.4347, 0.3443, 0.3051, 0.2194, 0.6989, 1.1179, 0.1042, 0.8885, 1.099, 0.6278, 0.1971, 0.8451, 0.7416, 0.4456, 1.142, 0.3525, 0.3155, 1.0667, 0.5598, 0.6497, 0.3171, 0.5558, 0.1523, 0.3401, 0.7457, 0.9299, 0.0009, 0.4809, 0.2592, 0.0717, 0.0365, 0.6673, 0.2792, 0.2637, 0.808, 0.0863, 0.9683, 0.8488, 0.8848, 0.3622, 0.1341, 0.2487, 0.3331, 0.4431, 1.3206, 0.5901, 0.5526, 0.972, 0.1378, 0.6523, 0.4253, 0.7479, 0.1872, 0.7375, 0.1934, 0.0196, 1.1475, 0.1444, 0.2473, 0.3538, 0.7711, 0.1682, 0.8135, 0.0941, 0.4326, 0.7392, 0.373, 0.4821, 0.2842, 0.1273, 0.5533, 0.5993, 0.1189, 0.7855, 0.4586, 0.3205, 0.9114, 0.3917, 0.5819, 0.2797, 0.3353, 0.7122, 0.9155, 0.3278, 0.8448, 0.4093, 0.8845, 0.5288, 0.1967, 0.177, 0.124, 0.0201, 0.6333, 0.9231, 0.8142, 1.2828, 0.0957, 0.0384, 0.8477, 0.742, 0.4582, 0.3813, 0.8257, 0.7939, 1.0374, 0.5567, 0.0689, 0.7218, 0.3079, 0.3438, 0.7186, 0.9546, 0.6614, 0.3308, 0.8337, 0.4607, 0.4462, 0.7676, 0.3778, 0.653, 0.1714, 0.2059, 0.211, 0.2451, 1.0645, 0.982]]

Expected: [[-0.0625, 0.2318, 1.0072, 0.8583, 0.3718, 0.305, 0.3126, 0.5472, 0.3439, 0.6254, 0.127, 0.7973, 0.3552, 0.521, 1.0414, 0.3486, 0.7066, 0.3728, 0.4347, 0.3443, 0.3051, 0.2194, 0.6989, 1.1179, 0.1042, 0.8885, 1.099, 0.6278, 0.1971, 0.8451, 0.7416, 0.4456, 1.142, 0.3525, 0.3155, 1.0667, 0.5598, 0.6497, 0.3171, 0.5558, 0.1523, 0.3401, 0.7457, 0.9299, 0.0009, 0.4809, 0.2592, 0.0717, 0.0365, 0.6673, 0.2792, 0.2637, 0.808, 0.0863, 0.9683, 0.8488, 0.8848, 0.3622, 0.1341, 0.2487, 0.3331, 0.4431, 1.3206, 0.5901, 0.5526, 0.972, 0.1378, 0.6523, 0.4253, 0.7479, 0.1872, 0.7375, 0.1934, 0.0196, 1.1475, 0.1444, 0.2473, 0.3538, 0.7711, 0.1682, 0.8135, 0.0941, 0.4326, 0.7392, 0.373, 0.4821, 0.2842, 0.1273, 0.5533, 0.5993, 0.1189, 0.7855, 0.4586, 0.3205, 0.9114, 0.3917, 0.5819, 0.2797, 0.3353, 0.7122, 0.9155, 0.3278, 0.8448, 0.4093, 0.8845, 0.5288, 0.1967, 0.177, 0.124, 0.0201, 0.6333, 0.9231, 0.8142, 1.2828, 0.0957, 0.0384, 0.8477, 0.742, 0.4582, 0.3813, 0.8257, 0.7939, 1.0374, 0.5567, 0.0689, 0.7218, 0.308, 0.3438, 0.7186, 0.9546, 0.6614, 0.3308, 0.8337, 0.4607, 0.4462, 0.7676, 0.3778, 0.653, 0.1714, 0.2059, 0.211, 0.2451, 1.0645, 0.9821]]