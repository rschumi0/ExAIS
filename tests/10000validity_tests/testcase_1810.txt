import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat62690 = tf.keras.layers.Input(shape=([2, 3]))
in0Sub95947 = tf.keras.layers.Input(shape=([3]))
in1Sub95947 = tf.keras.layers.Input(shape=([3]))
in0Con39284 = tf.keras.layers.Input(shape=([3, 1]))
in0Dot6536 = tf.keras.layers.Input(shape=([2, 2]))
in1Dot6536 = tf.keras.layers.Input(shape=([2, 2]))
in0Con74581 = tf.keras.layers.Input(shape=([6, 1]))
in0Dot85853 = tf.keras.layers.Input(shape=([3]))
in1Dot85853 = tf.keras.layers.Input(shape=([3]))
in0Con76360 = tf.keras.layers.Input(shape=([17]))

Bat62690 = keras.layers.BatchNormalization(axis=1, epsilon=0.7533663920398753,  name = 'Bat62690', )(in0Bat62690)
Zer9287 = keras.layers.ZeroPadding1D(padding=((4, 0)), name = 'Zer9287', )(Bat62690)
Sub95947 = keras.layers.Subtract(name = 'Sub95947', )([in0Sub95947,in1Sub95947])
Res56218 = keras.layers.Reshape((3, 1), name = 'Res56218', )(Sub95947)
Con39284 = keras.layers.Concatenate(axis=2, name = 'Con39284', )([Res56218,in0Con39284])
Dot6536 = keras.layers.Dot(axes=(1, 1), name = 'Dot6536', )([in0Dot6536,in1Dot6536])
Zer87217 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer87217', )(Dot6536)
Min77373 = keras.layers.Minimum(name = 'Min77373', )([Con39284,Zer87217])
Up_90533 = keras.layers.UpSampling1D(size=(2), name = 'Up_90533', )(Min77373)
Con74581 = keras.layers.Concatenate(axis=2, name = 'Con74581', )([Up_90533,in0Con74581])
Sub83323 = keras.layers.Subtract(name = 'Sub83323', )([Zer9287,Con74581])
Fla47519 = keras.layers.Flatten(name = 'Fla47519', )(Sub83323)
Dot85853 = keras.layers.Dot(axes=(1, 1), name = 'Dot85853', )([in0Dot85853,in1Dot85853])
Con76360 = keras.layers.Concatenate(axis=1, name = 'Con76360', )([Dot85853,in0Con76360])
Add37985 = keras.layers.Add(name = 'Add37985', )([Fla47519,Con76360])
model = tf.keras.models.Model(inputs=[in0Bat62690,in0Sub95947,in1Sub95947,in0Con39284,in0Dot6536,in1Dot6536,in0Con74581,in0Dot85853,in1Dot85853,in0Con76360], outputs=Add37985)
w = model.get_layer('Bat62690').get_weights() 
w[0] = np.array([0.3183, 0.1007])
w[1] = np.array([0.1296, 0.122])
w[2] = np.array([0.5204, 0.4208])
w[3] = np.array([0.6268, 0.4251])
model.get_layer('Bat62690').set_weights(w) 
in0Bat62690 = tf.constant([[[1.7412, 1.3972, 1.632], [1.6208, 1.696, 1.5261]]])
in0Sub95947 = tf.constant([[0.6553, 0.8664, 0.1637]])
in1Sub95947 = tf.constant([[0.9887, 0.2531, 0.9778]])
in0Con39284 = tf.constant([[[0.3057], [0.0408], [0.347]]])
in0Dot6536 = tf.constant([[[0.1914, 0.1028], [0.3013, 0.1727]]])
in1Dot6536 = tf.constant([[[0.2713, 0.3521], [0.6435, 0.8407]]])
in0Con74581 = tf.constant([[[0.4357], [0.2111], [0.732], [0.895], [0.3622], [0.5589]]])
in0Dot85853 = tf.constant([[0.8404, 0.1004, 0.0381]])
in1Dot85853 = tf.constant([[0.5429, 0.7869, 0.5875]])
in0Con76360 = tf.constant([[0.0286, 0.0937, 0.7296, 0.8299, 0.8955, 0.2689, 0.6611, 0.1168, 0.7623, 0.7276, 0.6336, 0.1315, 0.2316, 0.3625, 0.1254, 0.2858, 0.9945]])
print (np.array2string(model.predict([in0Bat62690,in0Sub95947,in1Sub95947,in0Con39284,in0Dot6536,in1Dot6536,in0Con74581,in0Dot85853,in1Dot85853,in0Con76360],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add37985.png')

LBat62690 = batch_normalization_layer([[[1.7412, 1.3972, 1.632], [1.6208, 1.696, 1.5261]]], 1, 0.7533663920398753, [0.3183, 0.1007], [0.1296, 0.122], [0.5204, 0.4208], [0.6268, 0.4251], Bat62690), 
LZer9287 = zero_padding1D_layer(Bat62690, 4, 0, Zer9287), 
LSub95947 = subtract_layer([[0.6553, 0.8664, 0.1637]], [[0.9887, 0.2531, 0.9778]], Sub95947), 
LRes56218 = reshape_layer(Sub95947, [3, 1], Res56218), 
LCon39284 = concatenate_layer([Res56218,[[[0.3057], [0.0408], [0.347]]]], 2, Con39284), 
LDot6536 = dot_layer([[[0.1914, 0.1028], [0.3013, 0.1727]]], [[[0.2713, 0.3521], [0.6435, 0.8407]]], 1, 1, Dot6536), 
LZer87217 = zero_padding1D_layer(Dot6536, 1, 0, Zer87217), 
LMin77373 = minimum_layer([Con39284,Zer87217], Min77373), 
LUp_90533 = up_sampling1D_layer(Min77373, 2, Up_90533), 
LCon74581 = concatenate_layer([Up_90533,[[[0.4357], [0.2111], [0.732], [0.895], [0.3622], [0.5589]]]], 2, Con74581), 
LSub83323 = subtract_layer(Zer9287,Con74581, Sub83323), 
LFla47519 = flatten_layer(Sub83323, Fla47519), 
LDot85853 = dot_layer([[0.8404, 0.1004, 0.0381]], [[0.5429, 0.7869, 0.5875]], 1, 1, Dot85853), 
LCon76360 = concatenate_layer([Dot85853,[[0.0286, 0.0937, 0.7296, 0.8299, 0.8955, 0.2689, 0.6611, 0.1168, 0.7623, 0.7276, 0.6336, 0.1315, 0.2316, 0.3625, 0.1254, 0.2858, 0.9945]]], 1, Con76360), 
LAdd37985 = add_layer([Fla47519,Con76360], Add37985), 
exec_layers([LBat62690,LZer9287,LSub95947,LRes56218,LCon39284,LDot6536,LZer87217,LMin77373,LUp_90533,LCon74581,LSub83323,LFla47519,LDot85853,LCon76360,LAdd37985],["Bat62690","Zer9287","Sub95947","Res56218","Con39284","Dot6536","Zer87217","Min77373","Up_90533","Con74581","Sub83323","Fla47519","Dot85853","Con76360","Add37985"],Add37985,"Add37985")

Actual (Unparsed): [[0.8910416, 0.0286000, -0.3420000, 1.0630000, 0.8299000, 0.6844000, 0.0230867, 0.6203000, -0.6152000, 0.5164867, 0.6868000, -0.2614000, 1.4059619, 0.4173742, 0.4310754, 1.1728146, 0.3447056, 0.6601300]]

Expected (Unparsed): [[0.8910416700000001,0.0286,-0.34199999999999997,1.0630000000000002,0.8299,0.6843999999999999,0.023086629999999997,0.6203000000000001,-0.6152,0.51648663,0.6868000000000001,-0.26139999999999997,1.4059618674963545,0.4173742121598982,0.4310753701744329,1.1728145963415075,0.34470554104557544,0.6601300194468904]]

Actual:   [[0.8911, 0.0286, -0.342, 1.063, 0.8299, 0.6844, 0.0231, 0.6203, -0.6152, 0.5165, 0.6868, -0.2614, 1.406, 0.4174, 0.4311, 1.1729, 0.3448, 0.6602]]

Expected: [[0.8911, 0.0286, -0.3419, 1.0631, 0.8299, 0.6844, 0.0231, 0.6204, -0.6152, 0.5165, 0.6869, -0.2613, 1.406, 0.4174, 0.4311, 1.1729, 0.3448, 0.6602]]