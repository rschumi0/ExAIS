import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot22937 = tf.keras.layers.Input(shape=([3, 2]))
in1Dot22937 = tf.keras.layers.Input(shape=([3, 2]))
in0Con74593 = tf.keras.layers.Input(shape=([2, 2, 3]))
in0Con63375 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Glo45419 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con72261 = tf.keras.layers.Input(shape=([15]))

Dot22937 = keras.layers.Dot(axes=(1, 1), name = 'Dot22937', )([in0Dot22937,in1Dot22937])
Res82332 = keras.layers.Reshape((2, 2, 1), name = 'Res82332', )(Dot22937)
Con74593 = keras.layers.Concatenate(axis=3, name = 'Con74593', )([Res82332,in0Con74593])
Con63375 = keras.layers.Conv2D(4, (2, 1),strides=(1, 1), padding='same', dilation_rate=(1, 1), name = 'Con63375', )(in0Con63375)
Zer36315 = keras.layers.ZeroPadding2D(padding=((0, 0), (1, 0)), name = 'Zer36315', )(Con63375)
Sub5689 = keras.layers.Subtract(name = 'Sub5689', )([Con74593,Zer36315])
Res23063 = keras.layers.Reshape((2, 8), name = 'Res23063', )(Sub5689)
Fla41757 = keras.layers.Flatten(name = 'Fla41757', )(Res23063)
Glo45419 = keras.layers.GlobalAveragePooling2D(name = 'Glo45419', )(in0Glo45419)
Con72261 = keras.layers.Concatenate(axis=1, name = 'Con72261', )([Glo45419,in0Con72261])
Min27555 = keras.layers.Minimum(name = 'Min27555', )([Fla41757,Con72261])
ReL29855 = keras.layers.ReLU(max_value=9.84495030741247, negative_slope=7.77366753602023, threshold=8.652055058800771, name = 'ReL29855', )(Min27555)
model = tf.keras.models.Model(inputs=[in0Dot22937,in1Dot22937,in0Con74593,in0Con63375,in0Glo45419,in0Con72261], outputs=ReL29855)
w = model.get_layer('Con63375').get_weights() 
w[0] = np.array([[[[0.6745, 0.2823, 0.6754, 0.2807]]], [[[0.6042, 0.5824, 0.725, 0.566]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con63375').set_weights(w) 
in0Dot22937 = tf.constant([[[0.1454, 0.8707], [0.9259, 0.6668], [0.8238, 0.2107]]])
in1Dot22937 = tf.constant([[[0.254, 0.7306], [0.8315, 0.1057], [0.2763, 0.0035]]])
in0Con74593 = tf.constant([[[[0.8318, 0.1195, 0.31], [0.064, 0.8291, 0.008]], [[0.1111, 0.2958, 0.2536], [0.9084, 0.8304, 0.84]]]])
in0Con63375 = tf.constant([[[[0.821]], [[0.2904]]]])
in0Glo45419 = tf.constant([[[[1.894]], [[1.2934]]]])
in0Con72261 = tf.constant([[0.0299, 0.511, 0.0007, 0.0178, 0.2226, 0.9368, 0.2832, 0.5744, 0.8525, 0.7596, 0.7282, 0.2086, 0.7643, 0.2875, 0.5634]])
print (np.array2string(model.predict([in0Dot22937,in1Dot22937,in0Con74593,in0Con63375,in0Glo45419,in0Con72261],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='ReL29855.png')

LDot22937 = dot_layer([[[0.1454, 0.8707], [0.9259, 0.6668], [0.8238, 0.2107]]], [[[0.254, 0.7306], [0.8315, 0.1057], [0.2763, 0.0035]]], 1, 1, Dot22937), 
LRes82332 = reshape_layer(Dot22937, [2, 2, 1], Res82332), 
LCon74593 = concatenate_layer([Res82332,[[[[0.8318, 0.1195, 0.31], [0.064, 0.8291, 0.008]], [[0.1111, 0.2958, 0.2536], [0.9084, 0.8304, 0.84]]]]], 3, Con74593), 
LCon63375 = conv2D_layer([[[[0.821]], [[0.2904]]]], 2, 1,[[[[0.6745, 0.2823, 0.6754, 0.2807]]], [[[0.6042, 0.5824, 0.725, 0.566]]]],[0, 0, 0, 0], 1, 1, true, 1, 1, Con63375), 
LZer36315 = zero_padding2D_layer(Con63375, 0, 0, 1, 0, Zer36315), 
LSub5689 = subtract_layer(Con74593,Zer36315, Sub5689), 
LRes23063 = reshape_layer(Sub5689, [2, 8], Res23063), 
LFla41757 = flatten_layer(Res23063, Fla41757), 
LGlo45419 = global_average_pooling2D_layer([[[[1.894]], [[1.2934]]]], Glo45419), 
LCon72261 = concatenate_layer([Glo45419,[[0.0299, 0.511, 0.0007, 0.0178, 0.2226, 0.9368, 0.2832, 0.5744, 0.8525, 0.7596, 0.7282, 0.2086, 0.7643, 0.2875, 0.5634]]], 1, Con72261), 
LMin27555 = minimum_layer([Fla41757,Con72261], Min27555), 
LReL29855 = relu_layer(Min27555, 9.84495030741247, 7.77366753602023, 8.652055058800771, ReL29855), 
exec_layers([LDot22937,LRes82332,LCon74593,LCon63375,LZer36315,LSub5689,LRes23063,LFla41757,LGlo45419,LCon72261,LMin27555,LReL29855],["Dot22937","Res82332","Con74593","Con63375","Zer36315","Sub5689","Res23063","Fla41757","Glo45419","Con72261","Min27555","ReL29855"],ReL29855,"ReL29855")

Actual (Unparsed): [[-59.2168583, -67.0257669, -66.3292463, -67.2527580, -71.3179507, -69.8771267, -66.7602446, -70.2652181, -62.7930048, -66.3945450, -64.9587487, -65.2867974, -65.6366125, -61.3167855, -65.0232702, -62.8785155]]

Expected (Unparsed): [[-59.2168582684408,-67.02576687113215,-66.32924625990474,-67.25275796318394,-71.31795083687717,-69.87712682349532,-66.76024481857132,-70.26521815777679,-62.79300489776913,-66.3945450672073,-64.95874867330437,-65.28679744332442,-65.63661248244533,-61.31678543267889,-65.02327011385333,-62.87851524066535]]

Actual:   [[-59.2168, -67.0257, -66.3292, -67.2527, -71.3179, -69.8771, -66.7602, -70.2652, -62.793, -66.3945, -64.9587, -65.2867, -65.6366, -61.3167, -65.0232, -62.8785]]

Expected: [[-59.2168, -67.0257, -66.3292, -67.2527, -71.3179, -69.8771, -66.7602, -70.2652, -62.793, -66.3945, -64.9587, -65.2867, -65.6366, -61.3167, -65.0232, -62.8785]]