import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul67505 = tf.keras.layers.Input(shape=([1, 1, 1]))
in1Mul67505 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Add1554 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Add1554 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con61553 = tf.keras.layers.Input(shape=([3, 2, 1]))
in0Lay19087 = tf.keras.layers.Input(shape=([3, 2, 2]))
in0Lea68735 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))

Mul67505 = keras.layers.Multiply(name = 'Mul67505', )([in0Mul67505,in1Mul67505])
Zer23502 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer23502', )(Mul67505)
Add1554 = keras.layers.Add(name = 'Add1554', )([in0Add1554,in1Add1554])
Add71856 = keras.layers.Add(name = 'Add71856', )([Zer23502,Add1554])
Zer67773 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer67773', )(Add71856)
Con61553 = keras.layers.Concatenate(axis=3, name = 'Con61553', )([Zer67773,in0Con61553])
Lay19087 = keras.layers.LayerNormalization(axis=2, epsilon=1.8737457238329611, name = 'Lay19087', )(in0Lay19087)
Max80352 = keras.layers.Maximum(name = 'Max80352', )([Con61553,Lay19087])
Res65254 = keras.layers.Reshape((3, 4), name = 'Res65254', )(Max80352)
Lea68735 = keras.layers.LeakyReLU(alpha=0.2364295856832487, name = 'Lea68735', input_shape=(1, 2, 2, 1))(in0Lea68735)
Res94053 = keras.layers.Reshape((1, 2, 2), name = 'Res94053', )(Lea68735)
Res87985 = keras.layers.Reshape((1, 4), name = 'Res87985', )(Res94053)
Dot89669 = keras.layers.Dot(axes=(2, 2), name = 'Dot89669', )([Res65254,Res87985])
model = tf.keras.models.Model(inputs=[in0Mul67505,in1Mul67505,in0Add1554,in1Add1554,in0Con61553,in0Lay19087,in0Lea68735], outputs=Dot89669)
in0Mul67505 = tf.constant([[[[0.1682]]]])
in1Mul67505 = tf.constant([[[[0.5468]]]])
in0Add1554 = tf.constant([[[[0.9014]], [[0.9415]]]])
in1Add1554 = tf.constant([[[[0.7284]], [[0.7565]]]])
in0Con61553 = tf.constant([[[[0.568], [0.3757]], [[0.9428], [0.2778]], [[0.3349], [0.6169]]]])
in0Lay19087 = tf.constant([[[[1.0812, 1.7163], [1.9935, 1.5798]], [[1.3827, 1.3249], [1.8666, 1.6906]], [[1.6144, 1.6708], [1.5789, 1.5529]]]])
in0Lea68735 = tf.constant([[[[[0.2304], [0.7294]], [[0.1196], [0.3622]]]]])
print (np.array2string(model.predict([in0Mul67505,in1Mul67505,in0Add1554,in1Add1554,in0Con61553,in0Lay19087,in0Lea68735],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot89669.png')

LMul67505 = multiply_layer([[[[[0.1682]]]], [[[[0.5468]]]]], Mul67505), 
LZer23502 = zero_padding2D_layer(Mul67505, 1, 0, 0, 0, Zer23502), 
LAdd1554 = add_layer([[[[[0.9014]], [[0.9415]]]], [[[[0.7284]], [[0.7565]]]]], Add1554), 
LAdd71856 = add_layer([Zer23502,Add1554], Add71856), 
LZer67773 = zero_padding2D_layer(Add71856, 1, 0, 1, 0, Zer67773), 
LCon61553 = concatenate_layer([Zer67773,[[[[0.568], [0.3757]], [[0.9428], [0.2778]], [[0.3349], [0.6169]]]]], 3, Con61553), 
LLay19087 = layer_normalization_layer([[[[1.0812, 1.7163], [1.9935, 1.5798]], [[1.3827, 1.3249], [1.8666, 1.6906]], [[1.6144, 1.6708], [1.5789, 1.5529]]]], 2, 1.8737457238329611, Lay19087), 
LMax80352 = maximum_layer([Con61553,Lay19087], Max80352), 
LRes65254 = reshape_layer(Max80352, [3, 4], Res65254), 
LLea68735 = leaky_relu_layer([[[[[0.2304], [0.7294]], [[0.1196], [0.3622]]]]], 0.2364295856832487, Lea68735), 
LRes94053 = reshape_layer(Lea68735, [1, 2, 2], Res94053), 
LRes87985 = reshape_layer(Res94053, [1, 4], Res87985), 
LDot89669 = dot_layer(Res65254,Res87985, 2, 2, Dot89669), 
exec_layers([LMul67505,LZer23502,LAdd1554,LAdd71856,LZer67773,LCon61553,LLay19087,LMax80352,LRes65254,LLea68735,LRes94053,LRes87985,LDot89669],["Mul67505","Zer23502","Add1554","Add71856","Zer67773","Con61553","Lay19087","Max80352","Res65254","Lea68735","Res94053","Res87985","Dot89669"],Dot89669,"Dot89669")

Actual (Unparsed): [[[0.5881887], [0.9832215], [0.6847852]]]

Expected (Unparsed): [[[0.5881886754685899],[0.9832215600000002],[0.6847852323589123]]]

Actual:   [[[0.5882], [0.9833], [0.6848]]]

Expected: [[[0.5882], [0.9833], [0.6848]]]