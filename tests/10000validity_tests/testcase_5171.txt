import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul53995 = tf.keras.layers.Input(shape=([1, 1, 1, 2]))
in1Mul53995 = tf.keras.layers.Input(shape=([1, 1, 1, 2]))
in0Bat71831 = tf.keras.layers.Input(shape=([1, 4, 2]))
in0Dot71219 = tf.keras.layers.Input(shape=([2, 2]))
in1Dot71219 = tf.keras.layers.Input(shape=([2, 2]))
in0Con7123 = tf.keras.layers.Input(shape=([2, 6]))

Mul53995 = keras.layers.Multiply(name = 'Mul53995', )([in0Mul53995,in1Mul53995])
Res3946 = keras.layers.Reshape((1, 1, 2), name = 'Res3946', )(Mul53995)
Zer39046 = keras.layers.ZeroPadding2D(padding=((0, 0), (3, 0)), name = 'Zer39046', )(Res3946)
Bat71831 = keras.layers.BatchNormalization(axis=2, epsilon=0.42834996602426134,  name = 'Bat71831', )(in0Bat71831)
Sub55740 = keras.layers.Subtract(name = 'Sub55740', )([Zer39046,Bat71831])
Res57331 = keras.layers.Reshape((1, 8), name = 'Res57331', )(Sub55740)
Zer86048 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer86048', )(Res57331)
Dot71219 = keras.layers.Dot(axes=(2, 2), name = 'Dot71219', )([in0Dot71219,in1Dot71219])
Lay18816 = keras.layers.LayerNormalization(axis=2, epsilon=1.5520067260505848, name = 'Lay18816', )(Dot71219)
Con7123 = keras.layers.Concatenate(axis=2, name = 'Con7123', )([Lay18816,in0Con7123])
Sub28370 = keras.layers.Subtract(name = 'Sub28370', )([Zer86048,Con7123])
Res81620 = keras.layers.Reshape((2, 8, 1), name = 'Res81620', )(Sub28370)
Ave12763 = keras.layers.AveragePooling2D(pool_size=(2, 5), strides=(1, 1), padding='same', name = 'Ave12763', )(Res81620)
Lea30447 = keras.layers.LeakyReLU(alpha=2.331708727966969, name = 'Lea30447', )(Ave12763)
model = tf.keras.models.Model(inputs=[in0Mul53995,in1Mul53995,in0Bat71831,in0Dot71219,in1Dot71219,in0Con7123], outputs=Lea30447)
w = model.get_layer('Bat71831').get_weights() 
w[0] = np.array([0.1343, 0.2128, 0.8601, 0.9367])
w[1] = np.array([0.3939, 0.0449, 0.1418, 0.2065])
w[2] = np.array([0.6698, 0.0935, 0.3418, 0.1632])
w[3] = np.array([0.8673, 0.8319, 0.0175, 0.3657])
model.get_layer('Bat71831').set_weights(w) 
in0Mul53995 = tf.constant([[[[[0.7673, 0.7825]]]]])
in1Mul53995 = tf.constant([[[[[0.8247, 0.9849]]]]])
in0Bat71831 = tf.constant([[[[1.3841, 1.5434], [1.6709, 1.6779], [1.0732, 1.9699], [1.7356, 1.8681]]]])
in0Dot71219 = tf.constant([[[0.138, 0.5345], [0.7967, 0.3159]]])
in1Dot71219 = tf.constant([[[0.1997, 0.0932], [0.0689, 0.477]]])
in0Con7123 = tf.constant([[[0.1562, 0.6935, 0.549, 0.619, 0.0509, 0.4762], [0.4729, 0.8394, 0.7974, 0.2381, 0.4165, 0.5002]]])
print (np.array2string(model.predict([in0Mul53995,in1Mul53995,in0Bat71831,in0Dot71219,in1Dot71219,in0Con7123],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Lea30447.png')

LMul53995 = multiply_layer([[[[[[0.7673, 0.7825]]]]], [[[[[0.8247, 0.9849]]]]]], Mul53995), 
LRes3946 = reshape_layer(Mul53995, [1, 1, 2], Res3946), 
LZer39046 = zero_padding2D_layer(Res3946, 0, 0, 3, 0, Zer39046), 
LBat71831 = batch_normalization_layer([[[[1.3841, 1.5434], [1.6709, 1.6779], [1.0732, 1.9699], [1.7356, 1.8681]]]], 2, 0.42834996602426134, [0.1343, 0.2128, 0.8601, 0.9367], [0.3939, 0.0449, 0.1418, 0.2065], [0.6698, 0.0935, 0.3418, 0.1632], [0.8673, 0.8319, 0.0175, 0.3657], Bat71831), 
LSub55740 = subtract_layer(Zer39046,Bat71831, Sub55740), 
LRes57331 = reshape_layer(Sub55740, [1, 8], Res57331), 
LZer86048 = zero_padding1D_layer(Res57331, 1, 0, Zer86048), 
LDot71219 = dot_layer([[[0.138, 0.5345], [0.7967, 0.3159]]], [[[0.1997, 0.0932], [0.0689, 0.477]]], 2, 2, Dot71219), 
LLay18816 = layer_normalization_layer(Dot71219, 2, 1.5520067260505848, Lay18816), 
LCon7123 = concatenate_layer([Lay18816,[[[0.1562, 0.6935, 0.549, 0.619, 0.0509, 0.4762], [0.4729, 0.8394, 0.7974, 0.2381, 0.4165, 0.5002]]]], 2, Con7123), 
LSub28370 = subtract_layer(Zer86048,Con7123, Sub28370), 
LRes81620 = reshape_layer(Sub28370, [2, 8, 1], Res81620), 
LAve12763 = average_pooling2D_layer(Res81620, 2, 5, 1, 1, true, Ave12763), 
LLea30447 = leaky_relu_layer(Ave12763, 2.331708727966969, Lea30447), 
exec_layers([LMul53995,LRes3946,LZer39046,LBat71831,LSub55740,LRes57331,LZer86048,LDot71219,LLay18816,LCon7123,LSub28370,LRes81620,LAve12763,LLea30447],["Mul53995","Res3946","Zer39046","Bat71831","Sub55740","Res57331","Zer86048","Dot71219","Lay18816","Con7123","Sub28370","Res81620","Ave12763","Lea30447"],Lea30447,"Lea30447")

Actual (Unparsed): [[[[-0.7570904], [-1.1152262], [-1.4588624], [-2.0883344], [-2.3483884], [-2.6355059], [-2.7469740], [-2.7181628]], [[-1.3927764], [-1.7351391], [-2.2654527], [-3.2008122], [-3.7321022], [-4.1571079], [-4.5058281], [-4.5455351]]]]

Expected (Unparsed): [[[[-0.757090390269782],[-1.115226200322111],[-1.458862470771866],[-2.088334411704493],[-2.348388440949291],[-2.635505947098445],[-2.746974026253282],[-2.71816285081408]],[[-1.3927764794367503],[-1.7351391741058382],[-2.2654527419822523],[-3.200812325281994],[-3.7321023469640866],[-4.157108000672509],[-4.50582818631236],[-4.5455352439205114]]]]

Actual:   [[[[-0.757], [-1.1152], [-1.4588], [-2.0883], [-2.3483], [-2.6355], [-2.7469], [-2.7181]], [[-1.3927], [-1.7351], [-2.2654], [-3.2008], [-3.7321], [-4.1571], [-4.5058], [-4.5455]]]]

Expected: [[[[-0.757], [-1.1152], [-1.4588], [-2.0883], [-2.3483], [-2.6355], [-2.7469], [-2.7181]], [[-1.3927], [-1.7351], [-2.2654], [-3.2008], [-3.7321], [-4.1571], [-4.5058], [-4.5455]]]]