import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con24570 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con44800 = tf.keras.layers.Input(shape=([3, 5, 2, 1]))
in0Sub67297 = tf.keras.layers.Input(shape=([3, 3, 2, 2]))
in1Sub67297 = tf.keras.layers.Input(shape=([3, 3, 2, 2]))

Con24570 = keras.layers.Conv2DTranspose(2, (1, 2),strides=(1, 1), padding='valid', name = 'Con24570', )(in0Con24570)
Res40657 = keras.layers.Reshape((1, 3, 2, 1), name = 'Res40657', )(Con24570)
Up_7951 = keras.layers.UpSampling3D(size=(2, 2, 1), name = 'Up_7951', )(Res40657)
Res21778 = keras.layers.Reshape((2, 6, 2), name = 'Res21778', )(Up_7951)
Sep56480 = keras.layers.SeparableConv2D(2, (2, 3),strides=(1, 1), padding='valid', name = 'Sep56480', )(Res21778)
Res87618 = keras.layers.Reshape((1, 4, 2, 1), name = 'Res87618', )(Sep56480)
Zer52597 = keras.layers.ZeroPadding3D(padding=((2, 0), (1, 0), (0, 0)), name = 'Zer52597', )(Res87618)
Con44800 = keras.layers.Concatenate(axis=4, name = 'Con44800', )([Zer52597,in0Con44800])
Sub67297 = keras.layers.Subtract(name = 'Sub67297', )([in0Sub67297,in1Sub67297])
Bat948 = keras.layers.BatchNormalization(axis=1, epsilon=0.15612818289412617,  name = 'Bat948', )(Sub67297)
Zer42324 = keras.layers.ZeroPadding3D(padding=((0, 0), (2, 0), (0, 0)), name = 'Zer42324', )(Bat948)
Sub43195 = keras.layers.Subtract(name = 'Sub43195', )([Con44800,Zer42324])
PRe856 = keras.layers.PReLU(name = 'PRe856', )(Sub43195)
model = tf.keras.models.Model(inputs=[in0Con24570,in0Con44800,in0Sub67297,in1Sub67297], outputs=PRe856)
w = model.get_layer('Con24570').get_weights() 
w[0] = np.array([[[[0.4967], [0.4296]], [[0.9191], [0.4416]]]])
w[1] = np.array([0, 0])
model.get_layer('Con24570').set_weights(w) 
w = model.get_layer('Sep56480').get_weights() 
w[0] = np.array([[[[0.9778], [0.5768]], [[0.3954], [0.6672]], [[0.0386], [0.7978]]], [[[0.9854], [0.9661]], [[0.424], [0.7342]], [[0.8505], [0.2097]]]])
w[1] = np.array([[[[0.2245, 0.0112], [0.0372, 0.7534]]]])
w[2] = np.array([0, 0])
model.get_layer('Sep56480').set_weights(w) 
w = model.get_layer('Bat948').get_weights() 
w[0] = np.array([0.1021, 0.6191, 0.321])
w[1] = np.array([0.4659, 0.9377, 0.3593])
w[2] = np.array([0.0353, 0.1519, 0.7709])
w[3] = np.array([0.8365, 0.0214, 0.7374])
model.get_layer('Bat948').set_weights(w) 
w = model.get_layer('PRe856').get_weights() 
w[0] = np.array([[[[0.7036, 0.032], [0.9154, 0.6529]], [[0.3579, 0.1293], [0.8521, 0.7037]], [[0.1717, 0.1874], [0.3526, 0.1704]], [[0.7777, 0.7492], [0.3146, 0.9393]], [[0.638, 0.7768], [0.5048, 0.5342]]], [[[0.3866, 0.0708], [0.9838, 0.5431]], [[0.755, 0.148], [0.4546, 0.2272]], [[0.5687, 0.5775], [0.5173, 0.7045]], [[0.1167, 0.6934], [0.3968, 0.4063]], [[0.7911, 0.546], [0.5659, 0.3416]]], [[[0.2691, 0.9313], [0.8312, 0.0732]], [[0.6678, 0.3495], [0.8713, 0.2077]], [[0.04, 0.7802], [0.9188, 0.6336]], [[0.2988, 0.2357], [0.2657, 0.7017]], [[0.1612, 0.155], [0.5381, 0.0378]]]])
model.get_layer('PRe856').set_weights(w) 
in0Con24570 = tf.constant([[[[0.9881], [0.9267]]]])
in0Con44800 = tf.constant([[[[[0.767], [0.6264]], [[0.4213], [0.7719]], [[0.621], [0.8274]], [[0.5677], [0.8409]], [[0.6552], [0.2871]]], [[[0.1428], [0.7032]], [[0.6432], [0.6524]], [[0.561], [0.5003]], [[0.9332], [0.379]], [[0.0177], [0.9673]]], [[[0.7676], [0.5624]], [[0.2261], [0.1088]], [[0.2394], [0.9093]], [[0.4506], [0.1884]], [[0.6916], [0.3233]]]]])
in0Sub67297 = tf.constant([[[[[0.6465, 0.4575], [0.136, 0.3897]], [[0.4603, 0.5953], [0.8008, 0.8535]], [[0.3201, 0.1578], [0.1702, 0.5509]]], [[[0.1335, 0.7489], [0.2266, 0.1448]], [[0.2265, 0.0608], [0.9666, 0.9283]], [[0.0521, 0.7273], [0.4222, 0.8699]]], [[[0.635, 0.368], [0.4571, 0.7157]], [[0.0299, 0.3275], [0.6783, 0.5153]], [[0.0828, 0.0364], [0.7045, 0.8768]]]]])
in1Sub67297 = tf.constant([[[[[0.8183, 0.6242], [0.4608, 0.9781]], [[0.8542, 0.4005], [0.1333, 0.859]], [[0.3416, 0.0867], [0.9093, 0.8056]]], [[[0.0659, 0.2295], [0.6545, 0.6967]], [[0.5077, 0.0545], [0.2311, 0.031]], [[0.86, 0.1309], [0.2527, 0.9776]]], [[[0.2232, 0.6082], [0.6846, 0.2001]], [[0.4617, 0.4593], [0.8512, 0.3932]], [[0.4926, 0.1192], [0.0924, 0.4396]]]]])
print (np.array2string(model.predict([in0Con24570,in0Con44800,in0Sub67297,in1Sub67297],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='PRe856.png')

LCon24570 = conv2D_transpose_layer([[[[0.9881], [0.9267]]]], 1, 2,[[[[0.4967], [0.4296]], [[0.9191], [0.4416]]]],[0, 0], 1, 1, false, Con24570), 
LRes40657 = reshape_layer(Con24570, [1, 3, 2, 1], Res40657), 
LUp_7951 = up_sampling3D_layer(Res40657, 2, 2, 1, Up_7951), 
LRes21778 = reshape_layer(Up_7951, [2, 6, 2], Res21778), 
LSep56480 = separable_conv2D_layer(Res21778, 2, 3,[[[[[0.9778], [0.5768]], [[0.3954], [0.6672]], [[0.0386], [0.7978]]], [[[0.9854], [0.9661]], [[0.424], [0.7342]], [[0.8505], [0.2097]]]],[[[[0.2245, 0.0112], [0.0372, 0.7534]]]]],[0, 0], 1, 1, false, Sep56480), 
LRes87618 = reshape_layer(Sep56480, [1, 4, 2, 1], Res87618), 
LZer52597 = zero_padding3D_layer(Res87618, 2, 0, 1, 0, 0, 0, Zer52597), 
LCon44800 = concatenate_layer([Zer52597,[[[[[0.767], [0.6264]], [[0.4213], [0.7719]], [[0.621], [0.8274]], [[0.5677], [0.8409]], [[0.6552], [0.2871]]], [[[0.1428], [0.7032]], [[0.6432], [0.6524]], [[0.561], [0.5003]], [[0.9332], [0.379]], [[0.0177], [0.9673]]], [[[0.7676], [0.5624]], [[0.2261], [0.1088]], [[0.2394], [0.9093]], [[0.4506], [0.1884]], [[0.6916], [0.3233]]]]]], 4, Con44800), 
LSub67297 = subtract_layer([[[[[0.6465, 0.4575], [0.136, 0.3897]], [[0.4603, 0.5953], [0.8008, 0.8535]], [[0.3201, 0.1578], [0.1702, 0.5509]]], [[[0.1335, 0.7489], [0.2266, 0.1448]], [[0.2265, 0.0608], [0.9666, 0.9283]], [[0.0521, 0.7273], [0.4222, 0.8699]]], [[[0.635, 0.368], [0.4571, 0.7157]], [[0.0299, 0.3275], [0.6783, 0.5153]], [[0.0828, 0.0364], [0.7045, 0.8768]]]]], [[[[[0.8183, 0.6242], [0.4608, 0.9781]], [[0.8542, 0.4005], [0.1333, 0.859]], [[0.3416, 0.0867], [0.9093, 0.8056]]], [[[0.0659, 0.2295], [0.6545, 0.6967]], [[0.5077, 0.0545], [0.2311, 0.031]], [[0.86, 0.1309], [0.2527, 0.9776]]], [[[0.2232, 0.6082], [0.6846, 0.2001]], [[0.4617, 0.4593], [0.8512, 0.3932]], [[0.4926, 0.1192], [0.0924, 0.4396]]]]], Sub67297), 
LBat948 = batch_normalization_layer(Sub67297, 1, 0.15612818289412617, [0.1021, 0.6191, 0.321], [0.4659, 0.9377, 0.3593], [0.0353, 0.1519, 0.7709], [0.8365, 0.0214, 0.7374], Bat948), 
LZer42324 = zero_padding3D_layer(Bat948, 0, 0, 2, 0, 0, 0, Zer42324), 
LSub43195 = subtract_layer(Con44800,Zer42324, Sub43195), 
LPRe856 = prelu_layer(Sub43195, [[[[0.7036, 0.032], [0.9154, 0.6529]], [[0.3579, 0.1293], [0.8521, 0.7037]], [[0.1717, 0.1874], [0.3526, 0.1704]], [[0.7777, 0.7492], [0.3146, 0.9393]], [[0.638, 0.7768], [0.5048, 0.5342]]], [[[0.3866, 0.0708], [0.9838, 0.5431]], [[0.755, 0.148], [0.4546, 0.2272]], [[0.5687, 0.5775], [0.5173, 0.7045]], [[0.1167, 0.6934], [0.3968, 0.4063]], [[0.7911, 0.546], [0.5659, 0.3416]]], [[[0.2691, 0.9313], [0.8312, 0.0732]], [[0.6678, 0.3495], [0.8713, 0.2077]], [[0.04, 0.7802], [0.9188, 0.6336]], [[0.2988, 0.2357], [0.2657, 0.7017]], [[0.1612, 0.155], [0.5381, 0.0378]]]], PRe856), 
exec_layers([LCon24570,LRes40657,LUp_7951,LRes21778,LSep56480,LRes87618,LZer52597,LCon44800,LSub67297,LBat948,LZer42324,LSub43195,LPRe856],["Con24570","Res40657","Up_7951","Res21778","Sep56480","Res87618","Zer52597","Con44800","Sub67297","Bat948","Zer42324","Sub43195","PRe856"],PRe856,"PRe856")

Actual (Unparsed): [[[[[0.0000000, 0.7670000], [0.0000000, 0.6264000]], [[0.0000000, 0.4213000], [0.0000000, 0.7719000]], [[-0.0763510, 0.1758006], [-0.1512645, 0.4254158]], [[-0.3281243, 0.0854547], [-0.1669541, 0.3791811]], [[-0.2935305, 0.1856313], [-0.1951257, -0.0796392]]], [[[0.0000000, 0.1428000], [0.0000000, 0.7032000]], [[0.0000000, 0.6432000], [0.0000000, 0.6524000]], [[-0.4628270, -0.5293876], [-0.0443673, 0.5967330]], [[-0.0351642, 0.2094383], [-0.7123419, -0.6720033]], [[0.4725883, -0.8589284], [-0.5452790, 0.4110449]]], [[[0.0000000, 0.7676000], [0.0000000, 0.5624000]], [[0.6575084, 0.2261000], [1.6039300, 0.1088000]], [[0.6029777, 0.2234563], [2.0245779, 0.6366966]], [[1.1807277, 0.3978451], [2.1739768, 0.0494240]], [[1.0560347, 0.6222053], [1.4537006, 0.0773201]]]]]

Expected (Unparsed): [[[[[0,0.767],[0,0.6264]],[[0,0.4213],[0,0.7719]],[[-0.07635099251861306,0.1758006418120654],[-0.15126452527877912,0.4254157935553722]],[[-0.3281242754569069,0.08545469124245336],[-0.16695408620831037,0.3791811197323379]],[[-0.2935305458502854,0.1856312723917231],[-0.19512574931027638,-0.07963920738494286]]],[[[0,0.1428],[0,0.7032]],[[0,0.6432],[0,0.6524]],[[-0.46282697220443436,-0.529387596295512],[-0.04436735032537635,0.596733037065849]],[[-0.0351642472295813,0.2094382924080529],[-0.7123418664553431,-0.6720032424471091]],[[0.4725882764646232,-0.858928391157673],[-0.5452789846858339,0.41104492245281965]]],[[[0,0.7676],[0,0.5624]],[[0.6575083679345586,0.2261],[1.6039300349223455,0.1088]],[[0.6029776657211436,0.2234562959132128],[2.024577916656447,0.636696530854162]],[[1.180727667069966,0.39784507795555063],[2.173976817537209,0.04942396873552815]],[[1.0560346805674206,0.6222053207606664],[1.4537006221626219,0.07732014236597673]]]]]

Actual:   [[[[[0, 0.767], [0, 0.6264]], [[0, 0.4213], [0, 0.7719]], [[-0.0763, 0.1759], [-0.1512, 0.4255]], [[-0.3281, 0.0855], [-0.1669, 0.3792]], [[-0.2935, 0.1857], [-0.1951, -0.0796]]], [[[0, 0.1428], [0, 0.7032]], [[0, 0.6432], [0, 0.6524]], [[-0.4628, -0.5293], [-0.0443, 0.5968]], [[-0.0351, 0.2095], [-0.7123, -0.672]], [[0.4726, -0.8589], [-0.5452, 0.4111]]], [[[0, 0.7676], [0, 0.5624]], [[0.6576, 0.2261], [1.604, 0.1088]], [[0.603, 0.2235], [2.0246, 0.6367]], [[1.1808, 0.3979], [2.174, 0.0495]], [[1.0561, 0.6223], [1.4538, 0.0774]]]]]

Expected: [[[[[0, 0.767], [0, 0.6264]], [[0, 0.4213], [0, 0.7719]], [[-0.0763, 0.1759], [-0.1512, 0.4255]], [[-0.3281, 0.0855], [-0.1669, 0.3792]], [[-0.2935, 0.1857], [-0.1951, -0.0796]]], [[[0, 0.1428], [0, 0.7032]], [[0, 0.6432], [0, 0.6524]], [[-0.4628, -0.5293], [-0.0443, 0.5968]], [[-0.0351, 0.2095], [-0.7123, -0.672]], [[0.4726, -0.8589], [-0.5452, 0.4111]]], [[[0, 0.7676], [0, 0.5624]], [[0.6576, 0.2261], [1.604, 0.1088]], [[0.603, 0.2235], [2.0246, 0.6367]], [[1.1808, 0.3979], [2.174, 0.0495]], [[1.0561, 0.6223], [1.4538, 0.0774]]]]]