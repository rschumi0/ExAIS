import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub66459 = tf.keras.layers.Input(shape=([3]))
in1Sub66459 = tf.keras.layers.Input(shape=([3]))
in0Max52505 = tf.keras.layers.Input(shape=([1, 1]))
in1Max52505 = tf.keras.layers.Input(shape=([1, 1]))

Sub66459 = keras.layers.Subtract(name = 'Sub66459', )([in0Sub66459,in1Sub66459])
Res84475 = keras.layers.Reshape((3, 1), name = 'Res84475', )(Sub66459)
Max52505 = keras.layers.Maximum(name = 'Max52505', )([in0Max52505,in1Max52505])
Zer84095 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer84095', )(Max52505)
Mul9198 = keras.layers.Multiply(name = 'Mul9198', )([Res84475,Zer84095])
Bat88900 = keras.layers.BatchNormalization(axis=1, epsilon=0.45684785730029787,  name = 'Bat88900', )(Mul9198)
model = tf.keras.models.Model(inputs=[in0Sub66459,in1Sub66459,in0Max52505,in1Max52505], outputs=Bat88900)
w = model.get_layer('Bat88900').get_weights() 
w[0] = np.array([0.1435, 0.0063, 0.9641])
w[1] = np.array([0.8995, 0.6938, 0.0917])
w[2] = np.array([0.69, 0.213, 0.6739])
w[3] = np.array([0.6837, 0.5063, 0.879])
model.get_layer('Bat88900').set_weights(w) 
in0Sub66459 = tf.constant([[0.9939, 0.7557, 0.8887]])
in1Sub66459 = tf.constant([[0.4249, 0.4203, 0.0555]])
in0Max52505 = tf.constant([[[0.286]]])
in1Max52505 = tf.constant([[[0.3465]]])
print (np.array2string(model.predict([in0Sub66459,in1Sub66459,in0Max52505,in1Max52505],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat88900.png')

LSub66459 = subtract_layer([[0.9939, 0.7557, 0.8887]], [[0.4249, 0.4203, 0.0555]], Sub66459), 
LRes84475 = reshape_layer(Sub66459, [3, 1], Res84475), 
LMax52505 = maximum_layer([[[[0.286]]], [[[0.3465]]]], Max52505), 
LZer84095 = zero_padding1D_layer(Max52505, 2, 0, Zer84095), 
LMul9198 = multiply_layer([Res84475,Zer84095], Mul9198), 
LBat88900 = batch_normalization_layer(Mul9198, 1, 0.45684785730029787, [0.1435, 0.0063, 0.9641], [0.8995, 0.6938, 0.0917], [0.69, 0.213, 0.6739], [0.6837, 0.5063, 0.879], Bat88900), 
exec_layers([LSub66459,LRes84475,LMax52505,LZer84095,LMul9198,LBat88900],["Sub66459","Res84475","Max52505","Zer84095","Mul9198","Bat88900"],Bat88900,"Bat88900")

Actual (Unparsed): [[[0.8067862], [0.6924327], [-0.2296110]]]

Expected (Unparsed): [[[0.8067862312232285],[0.6924326689644403],[-0.22961098824779774]]]

Actual:   [[[0.8068], [0.6925], [-0.2296]]]

Expected: [[[0.8068], [0.6925], [-0.2296]]]