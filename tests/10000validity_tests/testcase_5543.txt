import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub25256 = tf.keras.layers.Input(shape=([2, 2]))
in1Sub25256 = tf.keras.layers.Input(shape=([2, 2]))
in0Den57281 = tf.keras.layers.Input(shape=([4, 5, 5]))
in0Con8272 = tf.keras.layers.Input(shape=([1]))

Sub25256 = keras.layers.Subtract(name = 'Sub25256', )([in0Sub25256,in1Sub25256])
Fla45475 = keras.layers.Flatten(name = 'Fla45475', )(Sub25256)
Den57281 = keras.layers.Dense(1,name = 'Den57281', )(in0Den57281)
Res44990 = keras.layers.Reshape((4, 5), name = 'Res44990', )(Den57281)
Sim45693 = keras.layers.SimpleRNN(3,name = 'Sim45693', )(Res44990)
Con8272 = keras.layers.Concatenate(axis=1, name = 'Con8272', )([Sim45693,in0Con8272])
Ave99860 = keras.layers.Average(name = 'Ave99860', )([Fla45475,Con8272])
Thr41629 = keras.layers.ThresholdedReLU(theta=0.3253549225521311, name = 'Thr41629', )(Ave99860)
Res67802 = keras.layers.Reshape((4, 1), name = 'Res67802', )(Thr41629)
Zer36885 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer36885', )(Res67802)
model = tf.keras.models.Model(inputs=[in0Sub25256,in1Sub25256,in0Den57281,in0Con8272], outputs=Zer36885)
w = model.get_layer('Den57281').get_weights() 
w[0] = np.array([[0.1185], [0.363], [0.0595], [0.5927], [0.2325]])
w[1] = np.array([0.9516])
model.get_layer('Den57281').set_weights(w) 
w = model.get_layer('Sim45693').get_weights() 
w[0] = np.array([[3, 6, 4], [9, 1, 4], [8, 10, 5], [9, 9, 9], [6, 3, 7]])
w[1] = np.array([[5, 7, 10], [1, 3, 1], [9, 9, 6]])
w[2] = np.array([8, 9, 2])
model.get_layer('Sim45693').set_weights(w) 
in0Sub25256 = tf.constant([[[0.7852, 0.4548], [0.6981, 0.4495]]])
in1Sub25256 = tf.constant([[[0.1926, 0.7354], [0.4891, 0.0103]]])
in0Den57281 = tf.constant([[[[0.1514, 0.5322, 0.4063, 0.0034, 0.5299], [0.7404, 0.9065, 0.0312, 0.9414, 0.1594], [0.8548, 0.8624, 0.0081, 0.5074, 0.1431], [0.4872, 0.1657, 0.9136, 0.6182, 0.7485], [0.0656, 0.8931, 0.4362, 0.2156, 0.1049]], [[0.0385, 0.7631, 0.6454, 0.9957, 0.054], [0.9503, 0.722, 0.5695, 0.2986, 0.9267], [0.7589, 0.2066, 0.7061, 0.5691, 0.703], [0.377, 0.807, 0.2422, 0.09, 0.7867], [0.5883, 0.5284, 0.5647, 0.5323, 0.0976]], [[0.4109, 0.202, 0.4855, 0.0232, 0.8154], [0.146, 0.8515, 0.9608, 0.4714, 0.0131], [0.4769, 0.7199, 0.5083, 0.1024, 0.0167], [0.8116, 0.0679, 0.6984, 0.5148, 0.2133], [0.4853, 0.6578, 0.299, 0.6112, 0.2667]], [[0.0309, 0.3468, 0.5841, 0.1749, 0.6814], [0.4409, 0.6102, 0.2236, 0.7459, 0.4981], [0.3555, 0.2768, 0.2966, 0.4325, 0.4329], [0.2512, 0.7592, 0.7887, 0.7083, 0.627], [0.479, 0.1733, 0.2742, 0.0882, 0.3213]]]])
in0Con8272 = tf.constant([[0.6406]])
print (np.array2string(model.predict([in0Sub25256,in1Sub25256,in0Den57281,in0Con8272],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Zer36885.png')

LSub25256 = subtract_layer([[[0.7852, 0.4548], [0.6981, 0.4495]]], [[[0.1926, 0.7354], [0.4891, 0.0103]]], Sub25256), 
LFla45475 = flatten_layer(Sub25256, Fla45475), 
LDen57281 = dense_layer([[[[0.1514, 0.5322, 0.4063, 0.0034, 0.5299], [0.7404, 0.9065, 0.0312, 0.9414, 0.1594], [0.8548, 0.8624, 0.0081, 0.5074, 0.1431], [0.4872, 0.1657, 0.9136, 0.6182, 0.7485], [0.0656, 0.8931, 0.4362, 0.2156, 0.1049]], [[0.0385, 0.7631, 0.6454, 0.9957, 0.054], [0.9503, 0.722, 0.5695, 0.2986, 0.9267], [0.7589, 0.2066, 0.7061, 0.5691, 0.703], [0.377, 0.807, 0.2422, 0.09, 0.7867], [0.5883, 0.5284, 0.5647, 0.5323, 0.0976]], [[0.4109, 0.202, 0.4855, 0.0232, 0.8154], [0.146, 0.8515, 0.9608, 0.4714, 0.0131], [0.4769, 0.7199, 0.5083, 0.1024, 0.0167], [0.8116, 0.0679, 0.6984, 0.5148, 0.2133], [0.4853, 0.6578, 0.299, 0.6112, 0.2667]], [[0.0309, 0.3468, 0.5841, 0.1749, 0.6814], [0.4409, 0.6102, 0.2236, 0.7459, 0.4981], [0.3555, 0.2768, 0.2966, 0.4325, 0.4329], [0.2512, 0.7592, 0.7887, 0.7083, 0.627], [0.479, 0.1733, 0.2742, 0.0882, 0.3213]]]], [[0.1185], [0.363], [0.0595], [0.5927], [0.2325]],[0.9516], Den57281), 
LRes44990 = reshape_layer(Den57281, [4, 5], Res44990), 
LSim45693 = simple_rnn_layer(Res44990,[[3, 6, 4], [9, 1, 4], [8, 10, 5], [9, 9, 9], [6, 3, 7]],[[5, 7, 10], [1, 3, 1], [9, 9, 6]],[8, 9, 2], Sim45693), 
LCon8272 = concatenate_layer([Sim45693,[[0.6406]]], 1, Con8272), 
LAve99860 = average_layer([Fla45475,Con8272], Ave99860), 
LThr41629 = thresholded_relu_layer(Ave99860, 0.3253549225521311, Thr41629), 
LRes67802 = reshape_layer(Thr41629, [4, 1], Res67802), 
LZer36885 = zero_padding1D_layer(Res67802, 1, 1, Zer36885), 
exec_layers([LSub25256,LFla45475,LDen57281,LRes44990,LSim45693,LCon8272,LAve99860,LThr41629,LRes67802,LZer36885],["Sub25256","Fla45475","Den57281","Res44990","Sim45693","Con8272","Ave99860","Thr41629","Res67802","Zer36885"],Zer36885,"Zer36885")

Actual (Unparsed): [[[0.0000000], [0.7963000], [0.3597000], [0.6045000], [0.5399000], [0.0000000]]]

Expected (Unparsed): [[[0],[0.7963],[0.35969999999999996],[0.6045],[0.5399],[0]]]

Actual:   [[[0], [0.7963], [0.3597], [0.6045], [0.5399], [0]]]

Expected: [[[0], [0.7963], [0.3597], [0.6045], [0.5399], [0]]]