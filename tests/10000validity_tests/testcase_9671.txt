import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add62067 = tf.keras.layers.Input(shape=([1, 1]))
in1Add62067 = tf.keras.layers.Input(shape=([1, 1]))
in0Dot47795 = tf.keras.layers.Input(shape=([3, 2]))
in1Dot47795 = tf.keras.layers.Input(shape=([3, 2]))

Add62067 = keras.layers.Add(name = 'Add62067', )([in0Add62067,in1Add62067])
Res8093 = keras.layers.Reshape((1, 1, 1), name = 'Res8093', )(Add62067)
Zer82496 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer82496', )(Res8093)
Dot47795 = keras.layers.Dot(axes=(1, 1), name = 'Dot47795', )([in0Dot47795,in1Dot47795])
Res56479 = keras.layers.Reshape((2, 2, 1), name = 'Res56479', )(Dot47795)
PRe33810 = keras.layers.PReLU(name = 'PRe33810', )(Res56479)
Min71551 = keras.layers.Minimum(name = 'Min71551', )([Zer82496,PRe33810])
Con56405 = keras.layers.Conv2D(2, (2, 2),strides=(4, 1), padding='same', dilation_rate=(1, 1), name = 'Con56405', )(Min71551)
model = tf.keras.models.Model(inputs=[in0Add62067,in1Add62067,in0Dot47795,in1Dot47795], outputs=Con56405)
w = model.get_layer('PRe33810').get_weights() 
w[0] = np.array([[[0.0584], [0.0649]], [[0.7736], [0.6814]]])
model.get_layer('PRe33810').set_weights(w) 
w = model.get_layer('Con56405').get_weights() 
w[0] = np.array([[[[0.9951, 0.2308]], [[0.2701, 0.3583]]], [[[0.0055, 0.6149]], [[0.6443, 0.1593]]]])
w[1] = np.array([0, 0])
model.get_layer('Con56405').set_weights(w) 
in0Add62067 = tf.constant([[[0.2877]]])
in1Add62067 = tf.constant([[[0.9535]]])
in0Dot47795 = tf.constant([[[0.9936, 0.9418], [0.9367, 0.1326], [0.8687, 0.2488]]])
in1Dot47795 = tf.constant([[[0.1112, 0.8188], [0.6863, 0.16], [0.7713, 0.6316]]])
print (np.array2string(model.predict([in0Add62067,in1Add62067,in0Dot47795,in1Dot47795],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Con56405.png')

LAdd62067 = add_layer([[[[0.2877]]], [[[0.9535]]]], Add62067), 
LRes8093 = reshape_layer(Add62067, [1, 1, 1], Res8093), 
LZer82496 = zero_padding2D_layer(Res8093, 1, 0, 1, 0, Zer82496), 
LDot47795 = dot_layer([[[0.9936, 0.9418], [0.9367, 0.1326], [0.8687, 0.2488]]], [[[0.1112, 0.8188], [0.6863, 0.16], [0.7713, 0.6316]]], 1, 1, Dot47795), 
LRes56479 = reshape_layer(Dot47795, [2, 2, 1], Res56479), 
LPRe33810 = prelu_layer(Res56479, [[[0.0584], [0.0649]], [[0.7736], [0.6814]]], PRe33810), 
LMin71551 = minimum_layer([Zer82496,PRe33810], Min71551), 
LCon56405 = conv2D_layer(Min71551, 2, 2,[[[[0.9951, 0.2308]], [[0.2701, 0.3583]]], [[[0.0055, 0.6149]], [[0.6443, 0.1593]]]],[0, 0], 4, 1, true, 1, 1, Con56405), 
exec_layers([LAdd62067,LRes8093,LZer82496,LDot47795,LRes56479,LPRe33810,LMin71551,LCon56405],["Add62067","Res8093","Zer82496","Dot47795","Res56479","PRe33810","Min71551","Con56405"],Con56405,"Con56405")

Actual (Unparsed): [[[[0.6117654, 0.1512560], [0.0052223, 0.5838499]]]]

Expected (Unparsed): [[[[0.611765375656,0.15125597445599998],[0.005222271559999999,0.583849960408]]]]

Actual:   [[[[0.6118, 0.1513], [0.0053, 0.5839]]]]

Expected: [[[[0.6118, 0.1513], [0.0053, 0.5839]]]]