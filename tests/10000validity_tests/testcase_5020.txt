import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ReL41337 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Sub77977 = tf.keras.layers.Input(shape=([3, 3, 2, 3]))
in1Sub77977 = tf.keras.layers.Input(shape=([3, 3, 2, 3]))
in0Bat23141 = tf.keras.layers.Input(shape=([4, 3]))
in0Con25143 = tf.keras.layers.Input(shape=([4, 15]))
in0Max2656 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Max2656 = tf.keras.layers.Input(shape=([2, 1, 1]))

ReL41337 = keras.layers.ReLU(max_value=1.4835143370088635, negative_slope=6.066451440838442, threshold=9.230980422764054, name = 'ReL41337', input_shape=(1, 1, 1))(in0ReL41337)
Zer8794 = keras.layers.ZeroPadding2D(padding=((3, 0), (17, 0)), name = 'Zer8794', )(ReL41337)
Sub77977 = keras.layers.Subtract(name = 'Sub77977', )([in0Sub77977,in1Sub77977])
Res84529 = keras.layers.Reshape((3, 3, 6), name = 'Res84529', )(Sub77977)
Res50341 = keras.layers.Reshape((3, 18), name = 'Res50341', )(Res84529)
Zer80607 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer80607', )(Res50341)
Bat23141 = keras.layers.BatchNormalization(axis=1, epsilon=0.10808186509476951,  name = 'Bat23141', )(in0Bat23141)
Con25143 = keras.layers.Concatenate(axis=2, name = 'Con25143', )([Bat23141,in0Con25143])
Sub15647 = keras.layers.Subtract(name = 'Sub15647', )([Zer80607,Con25143])
Res97686 = keras.layers.Reshape((4, 18, 1), name = 'Res97686', )(Sub15647)
Max2656 = keras.layers.Maximum(name = 'Max2656', )([in0Max2656,in1Max2656])
Zer26736 = keras.layers.ZeroPadding2D(padding=((2, 0), (17, 0)), name = 'Zer26736', )(Max2656)
Min17605 = keras.layers.Minimum(name = 'Min17605', )([Res97686,Zer26736])
Min69057 = keras.layers.Minimum(name = 'Min69057', )([Zer8794,Min17605])
model = tf.keras.models.Model(inputs=[in0ReL41337,in0Sub77977,in1Sub77977,in0Bat23141,in0Con25143,in0Max2656,in1Max2656], outputs=Min69057)
w = model.get_layer('Bat23141').get_weights() 
w[0] = np.array([0.6054, 0.3293, 0.6243, 0.0687])
w[1] = np.array([0.0214, 0.573, 0.424, 0.0823])
w[2] = np.array([0.7481, 0.5473, 0.9097, 0.5973])
w[3] = np.array([0.9503, 0.7348, 0.3455, 0.3961])
model.get_layer('Bat23141').set_weights(w) 
in0ReL41337 = tf.constant([[[[0.3251]]]])
in0Sub77977 = tf.constant([[[[[0.1702, 0.9169, 0.9028], [0.8616, 0.83, 0.6643]], [[0.4569, 0.2357, 0.7047], [0.6829, 0.0562, 0.3158]], [[0.4059, 0.9536, 0.9878], [0.3256, 0.9692, 0.0967]]], [[[0.0991, 0.1695, 0.504], [0.9444, 0.9129, 0.1727]], [[0.4912, 0.603, 0.0615], [0.4574, 0.9123, 0.7349]], [[0.0494, 0.7373, 0.6474], [0.0572, 0.4384, 0.5268]]], [[[0.7417, 0.4686, 0.0349], [0.634, 0.2062, 0.7948]], [[0.5597, 0.336, 0.9931], [0.8731, 0.576, 0.8188]], [[0.6664, 0.5825, 0.167], [0.3027, 0.0715, 0.473]]]]])
in1Sub77977 = tf.constant([[[[[0.9601, 0.7767, 0.0058], [0.8465, 0.6239, 0.4117]], [[0.4841, 0.4953, 0.883], [0.5387, 0.7023, 0.8234]], [[0.4353, 0.5381, 0.2128], [0.7377, 0.891, 0.1128]]], [[[0.1407, 0.5263, 0.0005], [0.1933, 0.4967, 0.9199]], [[0.9898, 0.1591, 0.7691], [0.6722, 0.7782, 0.1505]], [[0.0158, 0.2857, 0.221], [0.9926, 0.6186, 0.9646]]], [[[0.2863, 0.6569, 0.7113], [0.4767, 0.2552, 0.2443]], [[0.0474, 0.3756, 0.6148], [0.1902, 0.7335, 0.947]], [[0.3052, 0.7641, 0.8256], [0.3231, 0.3759, 0.9649]]]]])
in0Bat23141 = tf.constant([[[1.253, 1.4382, 1.9077], [1.5959, 1.9213, 1.8859], [1.2679, 1.6473, 1.1256], [1.2843, 1.3753, 1.1083]]])
in0Con25143 = tf.constant([[[0.2477, 0.1076, 0.8313, 0.0909, 0.8209, 0.7552, 0.6705, 0.7011, 0.4745, 0.3222, 0.4794, 0.1477, 0.2375, 0.3643, 0.4415], [0.988, 0.2355, 0.9633, 0.0403, 0.4051, 0.0794, 0.3431, 0.6432, 0.7844, 0.1435, 0.022, 0.5083, 0.7803, 0.9389, 0.6229], [0.3604, 0.7356, 0.5503, 0.6347, 0.3301, 0.999, 0.8918, 0.8727, 0.2324, 0.1605, 0.3593, 0.1222, 0.8716, 0.4727, 0.3093], [0.4631, 0.3042, 0.7596, 0.6794, 0.0751, 0.7637, 0.926, 0.9781, 0.8992, 0.259, 0.7787, 0.8204, 0.3927, 0.6938, 0.2441]]])
in0Max2656 = tf.constant([[[[0.6032]], [[0.453]]]])
in1Max2656 = tf.constant([[[[0.6784]], [[0.9852]]]])
print (np.array2string(model.predict([in0ReL41337,in0Sub77977,in1Sub77977,in0Bat23141,in0Con25143,in0Max2656,in1Max2656],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min69057.png')

LReL41337 = relu_layer([[[[0.3251]]]], 1.4835143370088635, 6.066451440838442, 9.230980422764054, ReL41337), 
LZer8794 = zero_padding2D_layer(ReL41337, 3, 0, 17, 0, Zer8794), 
LSub77977 = subtract_layer([[[[[0.1702, 0.9169, 0.9028], [0.8616, 0.83, 0.6643]], [[0.4569, 0.2357, 0.7047], [0.6829, 0.0562, 0.3158]], [[0.4059, 0.9536, 0.9878], [0.3256, 0.9692, 0.0967]]], [[[0.0991, 0.1695, 0.504], [0.9444, 0.9129, 0.1727]], [[0.4912, 0.603, 0.0615], [0.4574, 0.9123, 0.7349]], [[0.0494, 0.7373, 0.6474], [0.0572, 0.4384, 0.5268]]], [[[0.7417, 0.4686, 0.0349], [0.634, 0.2062, 0.7948]], [[0.5597, 0.336, 0.9931], [0.8731, 0.576, 0.8188]], [[0.6664, 0.5825, 0.167], [0.3027, 0.0715, 0.473]]]]], [[[[[0.9601, 0.7767, 0.0058], [0.8465, 0.6239, 0.4117]], [[0.4841, 0.4953, 0.883], [0.5387, 0.7023, 0.8234]], [[0.4353, 0.5381, 0.2128], [0.7377, 0.891, 0.1128]]], [[[0.1407, 0.5263, 0.0005], [0.1933, 0.4967, 0.9199]], [[0.9898, 0.1591, 0.7691], [0.6722, 0.7782, 0.1505]], [[0.0158, 0.2857, 0.221], [0.9926, 0.6186, 0.9646]]], [[[0.2863, 0.6569, 0.7113], [0.4767, 0.2552, 0.2443]], [[0.0474, 0.3756, 0.6148], [0.1902, 0.7335, 0.947]], [[0.3052, 0.7641, 0.8256], [0.3231, 0.3759, 0.9649]]]]], Sub77977), 
LRes84529 = reshape_layer(Sub77977, [3, 3, 6], Res84529), 
LRes50341 = reshape_layer(Res84529, [3, 18], Res50341), 
LZer80607 = zero_padding1D_layer(Res50341, 1, 0, Zer80607), 
LBat23141 = batch_normalization_layer([[[1.253, 1.4382, 1.9077], [1.5959, 1.9213, 1.8859], [1.2679, 1.6473, 1.1256], [1.2843, 1.3753, 1.1083]]], 1, 0.10808186509476951, [0.6054, 0.3293, 0.6243, 0.0687], [0.0214, 0.573, 0.424, 0.0823], [0.7481, 0.5473, 0.9097, 0.5973], [0.9503, 0.7348, 0.3455, 0.3961], Bat23141), 
LCon25143 = concatenate_layer([Bat23141,[[[0.2477, 0.1076, 0.8313, 0.0909, 0.8209, 0.7552, 0.6705, 0.7011, 0.4745, 0.3222, 0.4794, 0.1477, 0.2375, 0.3643, 0.4415], [0.988, 0.2355, 0.9633, 0.0403, 0.4051, 0.0794, 0.3431, 0.6432, 0.7844, 0.1435, 0.022, 0.5083, 0.7803, 0.9389, 0.6229], [0.3604, 0.7356, 0.5503, 0.6347, 0.3301, 0.999, 0.8918, 0.8727, 0.2324, 0.1605, 0.3593, 0.1222, 0.8716, 0.4727, 0.3093], [0.4631, 0.3042, 0.7596, 0.6794, 0.0751, 0.7637, 0.926, 0.9781, 0.8992, 0.259, 0.7787, 0.8204, 0.3927, 0.6938, 0.2441]]]], 2, Con25143), 
LSub15647 = subtract_layer(Zer80607,Con25143, Sub15647), 
LRes97686 = reshape_layer(Sub15647, [4, 18, 1], Res97686), 
LMax2656 = maximum_layer([[[[[0.6032]], [[0.453]]]], [[[[0.6784]], [[0.9852]]]]], Max2656), 
LZer26736 = zero_padding2D_layer(Max2656, 2, 0, 17, 0, Zer26736), 
LMin17605 = minimum_layer([Res97686,Zer26736], Min17605), 
LMin69057 = minimum_layer([Zer8794,Min17605], Min69057), 
exec_layers([LReL41337,LZer8794,LSub77977,LRes84529,LRes50341,LZer80607,LBat23141,LCon25143,LSub15647,LRes97686,LMax2656,LZer26736,LMin17605,LMin69057],["ReL41337","Zer8794","Sub77977","Res84529","Res50341","Zer80607","Bat23141","Con25143","Sub15647","Res97686","Max2656","Zer26736","Min17605","Min69057"],Min69057,"Min69057")

Actual (Unparsed): [[[[-0.3185164], [-0.4275002], [-0.7037849], [-0.2477000], [-0.1076000], [-0.8313000], [-0.0909000], [-0.8209000], [-0.7552000], [-0.6705000], [-0.7011000], [-0.4745000], [-0.3222000], [-0.4794000], [-0.1477000], [-0.2375000], [-0.3643000], [-0.4415000]], [[-1.7390129], [-0.9256278], [-0.1561304], [-0.9729000], [-0.0294000], [-0.7107000], [-0.0675000], [-0.6647000], [-0.2577000], [-0.1989000], [-1.2893000], [-1.2920000], [-0.1729000], [0.0000000], [0.0000000], [-1.1924000], [-0.8607000], [-0.6390000]], [[-0.7976405], [-1.4645328], [-0.1206327], [0.0000000], [-0.3194000], [-1.2975000], [-1.1333000], [0.0000000], [-1.7066000], [-1.1066000], [-0.7386000], [0.0000000], [-0.1269000], [0.0000000], [0.0000000], [-1.8070000], [-0.6529000], [-0.7471001]], [[0.0000000], [-0.3458736], [-0.8081406], [-0.3058000], [-0.3532000], [-0.2091000], [-0.1671000], [-0.1147000], [-0.3854000], [-0.2431000], [-1.1356000], [-1.0274001], [0.0000000], [-0.9603000], [-1.4790000], [-0.4131000], [-0.9982000], [-54.0270911]]]]

Expected (Unparsed): [[[[-0.3185163781774522],[-0.42750024278126314],[-0.7037849319361728],[-0.2477],[-0.1076],[-0.8313],[-0.0909],[-0.8209],[-0.7552],[-0.6705],[-0.7011],[-0.4745],[-0.3222],[-0.4794],[-0.1477],[-0.2375],[-0.3643],[-0.4415]],[[-1.739012899930339],[-0.925627698363805],[-0.15613039085137514],[-0.9729],[-0.029400000000000037],[-0.7107000000000001],[-0.0675],[-0.6647000000000001],[-0.25770000000000004],[-0.19890000000000002],[-1.2893],[-1.292],[-0.17290000000000003],[0],[0],[-1.1924000000000001],[-0.8607],[-0.639]],[[-0.7976405122664432],[-1.4645327801444121],[-0.1206327375720967],[0],[-0.31939999999999996],[-1.2975],[-1.1333],[0],[-1.7066],[-1.1066],[-0.7386],[0],[-0.1269],[0],[0],[-1.807],[-0.6529],[-0.7471]],[[0],[-0.34587360639679104],[-0.8081406335074038],[-0.3058],[-0.3532],[-0.20910000000000006],[-0.16710000000000003],[-0.11469999999999997],[-0.3854000000000001],[-0.2431000000000001],[-1.1356000000000002],[-1.0274],[0],[-0.9602999999999999],[-1.479],[-0.41309999999999997],[-0.9982],[-54.02709112261187]]]]

Actual:   [[[[-0.3185], [-0.4275], [-0.7037], [-0.2477], [-0.1076], [-0.8313], [-0.0909], [-0.8209], [-0.7552], [-0.6705], [-0.7011], [-0.4745], [-0.3222], [-0.4794], [-0.1477], [-0.2375], [-0.3643], [-0.4415]], [[-1.739], [-0.9256], [-0.1561], [-0.9729], [-0.0294], [-0.7107], [-0.0675], [-0.6647], [-0.2577], [-0.1989], [-1.2893], [-1.292], [-0.1729], [0], [0], [-1.1924], [-0.8607], [-0.639]], [[-0.7976], [-1.4645], [-0.1206], [0], [-0.3194], [-1.2975], [-1.1333], [0], [-1.7066], [-1.1066], [-0.7386], [0], [-0.1269], [0], [0], [-1.807], [-0.6529], [-0.7471]], [[0], [-0.3458], [-0.8081], [-0.3058], [-0.3532], [-0.2091], [-0.1671], [-0.1147], [-0.3854], [-0.2431], [-1.1356], [-1.0274], [0], [-0.9603], [-1.479], [-0.4131], [-0.9982], [-54.027]]]]

Expected: [[[[-0.3185], [-0.4275], [-0.7037], [-0.2477], [-0.1076], [-0.8313], [-0.0909], [-0.8209], [-0.7552], [-0.6705], [-0.7011], [-0.4745], [-0.3222], [-0.4794], [-0.1477], [-0.2375], [-0.3643], [-0.4415]], [[-1.739], [-0.9256], [-0.1561], [-0.9729], [-0.0294], [-0.7107], [-0.0675], [-0.6647], [-0.2577], [-0.1989], [-1.2893], [-1.292], [-0.1729], [0], [0], [-1.1924], [-0.8607], [-0.639]], [[-0.7976], [-1.4645], [-0.1206], [0], [-0.3193], [-1.2975], [-1.1333], [0], [-1.7066], [-1.1066], [-0.7386], [0], [-0.1269], [0], [0], [-1.807], [-0.6529], [-0.7471]], [[0], [-0.3458], [-0.8081], [-0.3058], [-0.3532], [-0.2091], [-0.1671], [-0.1146], [-0.3854], [-0.2431], [-1.1356], [-1.0274], [0], [-0.9602], [-1.479], [-0.413], [-0.9982], [-54.027]]]]