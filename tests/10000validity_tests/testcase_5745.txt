import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con39677 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in0Min14617 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))
in1Min14617 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))
in0Con99953 = tf.keras.layers.Input(shape=([3, 5, 3, 2]))

Con39677 = keras.layers.Conv3DTranspose(4, (2, 1, 2),strides=(1, 5, 1), padding='valid', name = 'Con39677', )(in0Con39677)
Min14617 = keras.layers.Minimum(name = 'Min14617', )([in0Min14617,in1Min14617])
Zer66196 = keras.layers.ZeroPadding3D(padding=((1, 0), (4, 0), (2, 0)), name = 'Zer66196', )(Min14617)
Con99953 = keras.layers.Concatenate(axis=4, name = 'Con99953', )([Zer66196,in0Con99953])
Ave4452 = keras.layers.Average(name = 'Ave4452', )([Con39677,Con99953])
Res15569 = keras.layers.Reshape((3, 5, 12), name = 'Res15569', )(Ave4452)
Res69467 = keras.layers.Reshape((3, 60), name = 'Res69467', )(Res15569)
Zer30919 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer30919', )(Res69467)
Sof72207 = keras.layers.Softmax(axis=1, name = 'Sof72207', )(Zer30919)
model = tf.keras.models.Model(inputs=[in0Con39677,in0Min14617,in1Min14617,in0Con99953], outputs=Sof72207)
w = model.get_layer('Con39677').get_weights() 
w[0] = np.array([[[[[0.2828], [0.7732], [0.9001], [0.3283]], [[0.5652], [0.8514], [0.4709], [0.7203]]]], [[[[0.9938], [0.9407], [0.5009], [0.8359]], [[0.9846], [0.264], [0.8267], [0.6425]]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con39677').set_weights(w) 
in0Con39677 = tf.constant([[[[[0.3925], [0.6643]]], [[[0.1764], [0.2845]]]]])
in0Min14617 = tf.constant([[[[[0.5548, 0.6747]]], [[[0.7821, 0.4061]]]]])
in1Min14617 = tf.constant([[[[[0.4116, 0.667]]], [[[0.7376, 0.07]]]]])
in0Con99953 = tf.constant([[[[[0.0906, 0.9301], [0.5721, 0.7492], [0.6264, 0.2456]], [[0.9357, 0.9382], [0.1937, 0.8582], [0.5257, 0.5877]], [[0.7611, 0.9799], [0.4479, 0.1022], [0.7256, 0.641]], [[0.4111, 0.4142], [0.2993, 0.549], [0.9914, 0.6125]], [[0.9797, 0.6099], [0.0139, 0.3858], [0.4274, 0.9343]]], [[[0.423, 0.3279], [0.8023, 0.0427], [0.1305, 0.0583]], [[0.3685, 0.1589], [0.9799, 0.7994], [0.9679, 0.9309]], [[0.1469, 0.5226], [0.7844, 0.6583], [0.0068, 0.0253]], [[0.672, 0.1183], [0.7435, 0.3344], [0.2051, 0.3829]], [[0.7495, 0.6433], [0.523, 0.5963], [0.1697, 0.5868]]], [[[0.989, 0.5446], [0.783, 0.032], [0.6591, 0.9901]], [[0.7785, 0.7216], [0.5675, 0.1645], [0.888, 0.0444]], [[0.872, 0.522], [0.7626, 0.9273], [0.9788, 0.8351]], [[0.4451, 0.3449], [0.8636, 0.9865], [0.2844, 0.2225]], [[0.9436, 0.3546], [0.6597, 0.5755], [0.0174, 0.5218]]]]])
print (np.array2string(model.predict([in0Con39677,in0Min14617,in1Min14617,in0Con99953],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sof72207.png')

LCon39677 = conv3D_transpose_layer([[[[[0.3925], [0.6643]]], [[[0.1764], [0.2845]]]]], 2, 1, 2,[[[[[0.2828], [0.7732], [0.9001], [0.3283]], [[0.5652], [0.8514], [0.4709], [0.7203]]]], [[[[0.9938], [0.9407], [0.5009], [0.8359]], [[0.9846], [0.264], [0.8267], [0.6425]]]]],[0, 0, 0, 0], 1, 5, 1, false, Con39677), 
LMin14617 = minimum_layer([[[[[[0.5548, 0.6747]]], [[[0.7821, 0.4061]]]]], [[[[[0.4116, 0.667]]], [[[0.7376, 0.07]]]]]], Min14617), 
LZer66196 = zero_padding3D_layer(Min14617, 1, 0, 4, 0, 2, 0, Zer66196), 
LCon99953 = concatenate_layer([Zer66196,[[[[[0.0906, 0.9301], [0.5721, 0.7492], [0.6264, 0.2456]], [[0.9357, 0.9382], [0.1937, 0.8582], [0.5257, 0.5877]], [[0.7611, 0.9799], [0.4479, 0.1022], [0.7256, 0.641]], [[0.4111, 0.4142], [0.2993, 0.549], [0.9914, 0.6125]], [[0.9797, 0.6099], [0.0139, 0.3858], [0.4274, 0.9343]]], [[[0.423, 0.3279], [0.8023, 0.0427], [0.1305, 0.0583]], [[0.3685, 0.1589], [0.9799, 0.7994], [0.9679, 0.9309]], [[0.1469, 0.5226], [0.7844, 0.6583], [0.0068, 0.0253]], [[0.672, 0.1183], [0.7435, 0.3344], [0.2051, 0.3829]], [[0.7495, 0.6433], [0.523, 0.5963], [0.1697, 0.5868]]], [[[0.989, 0.5446], [0.783, 0.032], [0.6591, 0.9901]], [[0.7785, 0.7216], [0.5675, 0.1645], [0.888, 0.0444]], [[0.872, 0.522], [0.7626, 0.9273], [0.9788, 0.8351]], [[0.4451, 0.3449], [0.8636, 0.9865], [0.2844, 0.2225]], [[0.9436, 0.3546], [0.6597, 0.5755], [0.0174, 0.5218]]]]]], 4, Con99953), 
LAve4452 = average_layer([Con39677,Con99953], Ave4452), 
LRes15569 = reshape_layer(Ave4452, [3, 5, 12], Res15569), 
LRes69467 = reshape_layer(Res15569, [3, 60], Res69467), 
LZer30919 = zero_padding1D_layer(Res69467, 1, 0, Zer30919), 
LSof72207 = softmax_layer(Zer30919, 1, Sof72207), 
exec_layers([LCon39677,LMin14617,LZer66196,LCon99953,LAve4452,LRes15569,LRes69467,LZer30919,LSof72207],["Con39677","Min14617","Zer66196","Con99953","Ave4452","Res15569","Res69467","Zer30919","Sof72207"],Sof72207,"Sof72207")

Actual (Unparsed): [[[0.2275455, 0.2203612, 0.1838901, 0.1804906, 0.1876036, 0.1841571, 0.1401468, 0.1727893, 0.2057694, 0.2175192, 0.1765146, 0.1771206, 0.2500000, 0.2500000, 0.1895825, 0.1954758, 0.2500000, 0.2500000, 0.1975492, 0.1955807, 0.2500000, 0.2500000, 0.1824141, 0.2017446, 0.2500000, 0.2500000, 0.1966254, 0.1912382, 0.2500000, 0.2500000, 0.1924769, 0.1987249, 0.2500000, 0.2500000, 0.1971573, 0.2037164, 0.2500000, 0.2500000, 0.2050526, 0.2232515, 0.2500000, 0.2500000, 0.1941097, 0.1947233, 0.2500000, 0.2500000, 0.2039798, 0.2133561, 0.2500000, 0.2500000, 0.1757600, 0.2028419, 0.2500000, 0.2500000, 0.2129195, 0.2043507, 0.2139264, 0.2256590, 0.2306516, 0.1910396], [0.2405312, 0.2564692, 0.2295872, 0.3064816, 0.2302542, 0.2813768, 0.2759232, 0.3228140, 0.2482627, 0.2886110, 0.2823120, 0.2543925, 0.2500000, 0.2500000, 0.3026795, 0.3124788, 0.2500000, 0.2500000, 0.2176390, 0.3003874, 0.2500000, 0.2500000, 0.2372535, 0.2706571, 0.2500000, 0.2500000, 0.2876805, 0.3121457, 0.2500000, 0.2500000, 0.2407902, 0.2091437, 0.2500000, 0.2500000, 0.2833838, 0.2806839, 0.2500000, 0.2500000, 0.2518457, 0.2746230, 0.2500000, 0.2500000, 0.2254444, 0.2562310, 0.2500000, 0.2500000, 0.3348628, 0.2898062, 0.2500000, 0.2500000, 0.2868529, 0.2751666, 0.2500000, 0.2500000, 0.2144044, 0.2478286, 0.2139264, 0.2256590, 0.2856046, 0.3047923], [0.2835324, 0.2837452, 0.2713824, 0.2579151, 0.3464466, 0.3189817, 0.3444768, 0.2951220, 0.3092626, 0.2680266, 0.2651319, 0.2500972, 0.2500000, 0.2500000, 0.2279382, 0.2116400, 0.2500000, 0.2500000, 0.3224466, 0.2916846, 0.2500000, 0.2500000, 0.2959615, 0.3213249, 0.2500000, 0.2500000, 0.2116112, 0.2483453, 0.2500000, 0.2500000, 0.2849108, 0.2761852, 0.2500000, 0.2500000, 0.1978288, 0.2063098, 0.2500000, 0.2500000, 0.2869381, 0.2368552, 0.2500000, 0.2500000, 0.2815116, 0.2301611, 0.2500000, 0.2500000, 0.2260081, 0.2583751, 0.2500000, 0.2500000, 0.2556654, 0.2798005, 0.2500000, 0.2500000, 0.2765562, 0.2753347, 0.2628101, 0.3149850, 0.2510767, 0.2561801], [0.2483908, 0.2394244, 0.3151403, 0.2551127, 0.2356956, 0.2154844, 0.2394533, 0.2092747, 0.2367052, 0.2258432, 0.2760416, 0.3183898, 0.2500000, 0.2500000, 0.2797998, 0.2804054, 0.2500000, 0.2500000, 0.2623652, 0.2123473, 0.2500000, 0.2500000, 0.2843709, 0.2062734, 0.2500000, 0.2500000, 0.3040829, 0.2482708, 0.2500000, 0.2500000, 0.2818221, 0.3159461, 0.2500000, 0.2500000, 0.3216301, 0.3092899, 0.2500000, 0.2500000, 0.2561636, 0.2652703, 0.2500000, 0.2500000, 0.2989343, 0.3188846, 0.2500000, 0.2500000, 0.2351493, 0.2384626, 0.2500000, 0.2500000, 0.2817217, 0.2421910, 0.2500000, 0.2500000, 0.2961198, 0.2724860, 0.3093372, 0.2336969, 0.2326670, 0.2479881]]]

Expected (Unparsed): [[[0.22754552240178444,0.22036120207913842,0.1838901224602749,0.18049063853552408,0.1876036208072809,0.18415708227996805,0.14014677191327024,0.17278926136758926,0.20576943157662164,0.21751919137987832,0.1765145648544383,0.17712056019025585,0.25,0.25,0.1895825259206938,0.1954757983923955,0.25,0.25,0.19754918204347113,0.1955806961704621,0.25,0.25,0.18241409166547465,0.20174462044444205,0.25,0.25,0.19662541294829117,0.1912382488977386,0.25,0.25,0.1924768872071655,0.19872494661997292,0.25,0.25,0.1971573354065977,0.20371643294953395,0.25,0.25,0.20505259034466566,0.22325154312490703,0.25,0.25,0.19410973544956792,0.19472326847145646,0.25,0.25,0.2039797727758924,0.2133560723579048,0.25,0.25,0.17576002520963005,0.20284188332898045,0.25,0.25,0.21291950195542841,0.20435065423884244,0.21392635530812035,0.22565902138671481,0.23065162416185025,0.19103957069945587],[0.24053120143885448,0.2564691867228631,0.22958722983099678,0.3064816203537567,0.23025418642719286,0.2813768098728343,0.27592320500404244,0.3228140399036932,0.2482626995111662,0.28861095157510475,0.2823119960657637,0.2543924813857092,0.25,0.25,0.30267947965775166,0.31247878484411795,0.25,0.25,0.21763896724129717,0.3003874262717958,0.25,0.25,0.2372535336524749,0.2706570827562971,0.25,0.25,0.2876804920123352,0.3121456878770601,0.25,0.25,0.24079021568288952,0.20914372412140855,0.25,0.25,0.28338377287034405,0.2806838627180106,0.25,0.25,0.2518456713182533,0.27462296809053477,0.25,0.25,0.22544441813580682,0.25623100851468344,0.25,0.25,0.3348627799658421,0.28980621375433563,0.25,0.25,0.286852908805868,0.2751666119064069,0.25,0.25,0.2144044466997982,0.24782860827065548,0.21392635530812035,0.22565902138671481,0.28560463280843623,0.3047923067052171],[0.28353243529734223,0.28374519724945135,0.2713823911336959,0.2579150706905274,0.3464466009925878,0.3189817166134275,0.34447677073747307,0.2951219481782423,0.30926263512513374,0.26802662775378144,0.2651318696118021,0.25009720986099787,0.25,0.25,0.22793817336010436,0.21163997044176158,0.25,0.25,0.3224466113548431,0.2916845944235223,0.25,0.25,0.29596148617771145,0.3213248619378038,0.25,0.25,0.21161116464361324,0.2483452778170632,0.25,0.25,0.28491078040945506,0.27618520985049366,0.25,0.25,0.19782881120898926,0.2063098143807083,0.25,0.25,0.2869380918078597,0.23685523502470077,0.25,0.25,0.2815115975358785,0.23016108068415095,0.25,0.25,0.22600809921595263,0.2583751170907014,0.25,0.25,0.25566540337203764,0.2798004794245786,0.25,0.25,0.2765562315008822,0.27533468982486886,0.26281012722189506,0.3149850272100528,0.2510766953576534,0.25618006676628263],[0.2483908408620188,0.23942441394854705,0.31514025657503236,0.255112670420192,0.23569559177293836,0.2154843912337701,0.23945325234521428,0.2092747505504752,0.23670523378707845,0.2258432292912354,0.2760415694679958,0.31838974856303703,0.25,0.25,0.2797998210614501,0.2804054463217251,0.25,0.25,0.26236523936038864,0.21234728313421983,0.25,0.25,0.284370888504339,0.2062734348614572,0.25,0.25,0.3040829303957604,0.2482707854081381,0.25,0.25,0.2818221167004899,0.315946119408125,0.25,0.25,0.321630080514069,0.3092898899517473,0.25,0.25,0.2561636465292214,0.2652702537598575,0.25,0.25,0.29893424887874676,0.3188846423297091,0.25,0.25,0.2351493480423129,0.23846259679705817,0.25,0.25,0.28172166261246423,0.24219102534003417,0.25,0.25,0.2961198198438913,0.2724860476656333,0.30933716216186424,0.23369693001651756,0.23266704767206003,0.24798805582904446]]]

Actual:   [[[0.2276, 0.2204, 0.1839, 0.1805, 0.1877, 0.1842, 0.1402, 0.1728, 0.2058, 0.2176, 0.1766, 0.1772, 0.25, 0.25, 0.1896, 0.1955, 0.25, 0.25, 0.1976, 0.1956, 0.25, 0.25, 0.1825, 0.2018, 0.25, 0.25, 0.1967, 0.1913, 0.25, 0.25, 0.1925, 0.1988, 0.25, 0.25, 0.1972, 0.2038, 0.25, 0.25, 0.2051, 0.2233, 0.25, 0.25, 0.1942, 0.1948, 0.25, 0.25, 0.204, 0.2134, 0.25, 0.25, 0.1758, 0.2029, 0.25, 0.25, 0.213, 0.2044, 0.214, 0.2257, 0.2307, 0.1911], [0.2406, 0.2565, 0.2296, 0.3065, 0.2303, 0.2814, 0.276, 0.3229, 0.2483, 0.2887, 0.2824, 0.2544, 0.25, 0.25, 0.3027, 0.3125, 0.25, 0.25, 0.2177, 0.3004, 0.25, 0.25, 0.2373, 0.2707, 0.25, 0.25, 0.2877, 0.3122, 0.25, 0.25, 0.2408, 0.2092, 0.25, 0.25, 0.2834, 0.2807, 0.25, 0.25, 0.2519, 0.2747, 0.25, 0.25, 0.2255, 0.2563, 0.25, 0.25, 0.3349, 0.2899, 0.25, 0.25, 0.2869, 0.2752, 0.25, 0.25, 0.2145, 0.2479, 0.214, 0.2257, 0.2857, 0.3048], [0.2836, 0.2838, 0.2714, 0.258, 0.3465, 0.319, 0.3445, 0.2952, 0.3093, 0.2681, 0.2652, 0.2501, 0.25, 0.25, 0.228, 0.2117, 0.25, 0.25, 0.3225, 0.2917, 0.25, 0.25, 0.296, 0.3214, 0.25, 0.25, 0.2117, 0.2484, 0.25, 0.25, 0.285, 0.2762, 0.25, 0.25, 0.1979, 0.2064, 0.25, 0.25, 0.287, 0.2369, 0.25, 0.25, 0.2816, 0.2302, 0.25, 0.25, 0.2261, 0.2584, 0.25, 0.25, 0.2557, 0.2799, 0.25, 0.25, 0.2766, 0.2754, 0.2629, 0.315, 0.2511, 0.2562], [0.2484, 0.2395, 0.3152, 0.2552, 0.2357, 0.2155, 0.2395, 0.2093, 0.2368, 0.2259, 0.2761, 0.3184, 0.25, 0.25, 0.2798, 0.2805, 0.25, 0.25, 0.2624, 0.2124, 0.25, 0.25, 0.2844, 0.2063, 0.25, 0.25, 0.3041, 0.2483, 0.25, 0.25, 0.2819, 0.316, 0.25, 0.25, 0.3217, 0.3093, 0.25, 0.25, 0.2562, 0.2653, 0.25, 0.25, 0.299, 0.3189, 0.25, 0.25, 0.2352, 0.2385, 0.25, 0.25, 0.2818, 0.2422, 0.25, 0.25, 0.2962, 0.2725, 0.3094, 0.2337, 0.2327, 0.248]]]

Expected: [[[0.2276, 0.2204, 0.1839, 0.1805, 0.1877, 0.1842, 0.1402, 0.1728, 0.2058, 0.2176, 0.1766, 0.1772, 0.25, 0.25, 0.1896, 0.1955, 0.25, 0.25, 0.1976, 0.1956, 0.25, 0.25, 0.1825, 0.2018, 0.25, 0.25, 0.1967, 0.1913, 0.25, 0.25, 0.1925, 0.1988, 0.25, 0.25, 0.1972, 0.2038, 0.25, 0.25, 0.2051, 0.2233, 0.25, 0.25, 0.1942, 0.1948, 0.25, 0.25, 0.204, 0.2134, 0.25, 0.25, 0.1758, 0.2029, 0.25, 0.25, 0.213, 0.2044, 0.214, 0.2257, 0.2307, 0.1911], [0.2406, 0.2565, 0.2296, 0.3065, 0.2303, 0.2814, 0.276, 0.3229, 0.2483, 0.2887, 0.2824, 0.2544, 0.25, 0.25, 0.3027, 0.3125, 0.25, 0.25, 0.2177, 0.3004, 0.25, 0.25, 0.2373, 0.2707, 0.25, 0.25, 0.2877, 0.3122, 0.25, 0.25, 0.2408, 0.2092, 0.25, 0.25, 0.2834, 0.2807, 0.25, 0.25, 0.2519, 0.2747, 0.25, 0.25, 0.2255, 0.2563, 0.25, 0.25, 0.3349, 0.2899, 0.25, 0.25, 0.2869, 0.2752, 0.25, 0.25, 0.2145, 0.2479, 0.214, 0.2257, 0.2857, 0.3048], [0.2836, 0.2838, 0.2714, 0.258, 0.3465, 0.319, 0.3445, 0.2952, 0.3093, 0.2681, 0.2652, 0.2501, 0.25, 0.25, 0.228, 0.2117, 0.25, 0.25, 0.3225, 0.2917, 0.25, 0.25, 0.296, 0.3214, 0.25, 0.25, 0.2117, 0.2484, 0.25, 0.25, 0.285, 0.2762, 0.25, 0.25, 0.1979, 0.2064, 0.25, 0.25, 0.287, 0.2369, 0.25, 0.25, 0.2816, 0.2302, 0.25, 0.25, 0.2261, 0.2584, 0.25, 0.25, 0.2557, 0.2799, 0.25, 0.25, 0.2766, 0.2754, 0.2629, 0.315, 0.2511, 0.2562], [0.2484, 0.2395, 0.3152, 0.2552, 0.2357, 0.2155, 0.2395, 0.2093, 0.2368, 0.2259, 0.2761, 0.3184, 0.25, 0.25, 0.2798, 0.2805, 0.25, 0.25, 0.2624, 0.2124, 0.25, 0.25, 0.2844, 0.2063, 0.25, 0.25, 0.3041, 0.2483, 0.25, 0.25, 0.2819, 0.316, 0.25, 0.25, 0.3217, 0.3093, 0.25, 0.25, 0.2562, 0.2653, 0.25, 0.25, 0.299, 0.3189, 0.25, 0.25, 0.2352, 0.2385, 0.25, 0.25, 0.2818, 0.2422, 0.25, 0.25, 0.2962, 0.2725, 0.3094, 0.2337, 0.2327, 0.248]]]