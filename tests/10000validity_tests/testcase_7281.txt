import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Den11630 = tf.keras.layers.Input(shape=([5, 2, 4]))
in0Add75628 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Add75628 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con38907 = tf.keras.layers.Input(shape=([7, 4, 3]))

Den11630 = keras.layers.Dense(4,name = 'Den11630', )(in0Den11630)
ReL43801 = keras.layers.ReLU(max_value=2.194193753032771, negative_slope=8.765956292601471, threshold=8.920779911304207, name = 'ReL43801', )(Den11630)
Zer31764 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer31764', )(ReL43801)
Mas30571 = keras.layers.Masking(mask_value=2, name = 'Mas30571', )(Zer31764)
Add75628 = keras.layers.Add(name = 'Add75628', )([in0Add75628,in1Add75628])
Zer22962 = keras.layers.ZeroPadding2D(padding=((5, 0), (3, 0)), name = 'Zer22962', )(Add75628)
Con38907 = keras.layers.Concatenate(axis=3, name = 'Con38907', )([Zer22962,in0Con38907])
Max1517 = keras.layers.Maximum(name = 'Max1517', )([Mas30571,Con38907])
model = tf.keras.models.Model(inputs=[in0Den11630,in0Add75628,in1Add75628,in0Con38907], outputs=Max1517)
w = model.get_layer('Den11630').get_weights() 
w[0] = np.array([[0.8459, 0.8321, 0.6392, 0.2222], [0.9169, 0.7152, 0.7984, 0.9767], [0.2809, 0.0405, 0.3773, 0.2558], [0.731, 0.3141, 0.8802, 0.985]])
w[1] = np.array([0.4648, 0.1714, 0.1726, 0.5366])
model.get_layer('Den11630').set_weights(w) 
in0Den11630 = tf.constant([[[[0.6019, 0.4552, 0.1634, 0.0469], [0.5991, 0.903, 0.083, 0.4551]], [[0.7956, 0.349, 0.7934, 0.7525], [0.9885, 0.8825, 0.6328, 0.2232]], [[0.3355, 0.7208, 0.3538, 0.572], [0.7814, 0.1205, 0.6108, 0.1919]], [[0.2045, 0.8796, 0.9416, 0.1124], [0.0911, 0.1403, 0.9348, 0.5369]], [[0.8543, 0.2, 0.2896, 0.711], [0.8821, 0.9563, 0.6419, 0.1018]]]])
in0Add75628 = tf.constant([[[[0.0179]], [[0.4235]]]])
in1Add75628 = tf.constant([[[[0.3574]], [[0.5129]]]])
in0Con38907 = tf.constant([[[[0.8942, 0.9817, 0.5261], [0.5217, 0.9678, 0.3601], [0.5216, 0.5843, 0.5926], [0.0646, 0.8327, 0.7698]], [[0.6318, 0.0071, 0.7828], [0.3796, 0.6703, 0.7636], [0.9553, 0.7348, 0.029], [0.9294, 0.0843, 0.7566]], [[0.3625, 0.5179, 0.3498], [0.3174, 0.57, 0.533], [0.2974, 0.0648, 0.4231], [0.9951, 0.7903, 0.7085]], [[0.2667, 0.3786, 0.3692], [0.0821, 0.3866, 0.6359], [0.1496, 0.6451, 0.1526], [0.7197, 0.9174, 0.4721]], [[0.8436, 0.796, 0.3953], [0.1947, 0.1413, 0.1407], [0.7489, 0.8031, 0.6399], [0.0533, 0.2785, 0.6977]], [[0.3569, 0.9868, 0.8971], [0.8837, 0.1603, 0.4951], [0.4346, 0.7468, 0.2226], [0.526, 0.0296, 0.4173]], [[0.1059, 0.0539, 0.8693], [0.3308, 0.8424, 0.0367], [0.3198, 0.2315, 0.4263], [0.2065, 0.0549, 0.5245]]]])
print (np.array2string(model.predict([in0Den11630,in0Add75628,in1Add75628,in0Con38907],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max1517.png')

LDen11630 = dense_layer([[[[0.6019, 0.4552, 0.1634, 0.0469], [0.5991, 0.903, 0.083, 0.4551]], [[0.7956, 0.349, 0.7934, 0.7525], [0.9885, 0.8825, 0.6328, 0.2232]], [[0.3355, 0.7208, 0.3538, 0.572], [0.7814, 0.1205, 0.6108, 0.1919]], [[0.2045, 0.8796, 0.9416, 0.1124], [0.0911, 0.1403, 0.9348, 0.5369]], [[0.8543, 0.2, 0.2896, 0.711], [0.8821, 0.9563, 0.6419, 0.1018]]]], [[0.8459, 0.8321, 0.6392, 0.2222], [0.9169, 0.7152, 0.7984, 0.9767], [0.2809, 0.0405, 0.3773, 0.2558], [0.731, 0.3141, 0.8802, 0.985]],[0.4648, 0.1714, 0.1726, 0.5366], Den11630), 
LReL43801 = relu_layer(Den11630, 2.194193753032771, 8.765956292601471, 8.920779911304207, ReL43801), 
LZer31764 = zero_padding2D_layer(ReL43801, 1, 1, 1, 1, Zer31764), 
LMas30571 = masking_layer(Zer31764, 2, Mas30571), 
LAdd75628 = add_layer([[[[[0.0179]], [[0.4235]]]], [[[[0.3574]], [[0.5129]]]]], Add75628), 
LZer22962 = zero_padding2D_layer(Add75628, 5, 0, 3, 0, Zer22962), 
LCon38907 = concatenate_layer([Zer22962,[[[[0.8942, 0.9817, 0.5261], [0.5217, 0.9678, 0.3601], [0.5216, 0.5843, 0.5926], [0.0646, 0.8327, 0.7698]], [[0.6318, 0.0071, 0.7828], [0.3796, 0.6703, 0.7636], [0.9553, 0.7348, 0.029], [0.9294, 0.0843, 0.7566]], [[0.3625, 0.5179, 0.3498], [0.3174, 0.57, 0.533], [0.2974, 0.0648, 0.4231], [0.9951, 0.7903, 0.7085]], [[0.2667, 0.3786, 0.3692], [0.0821, 0.3866, 0.6359], [0.1496, 0.6451, 0.1526], [0.7197, 0.9174, 0.4721]], [[0.8436, 0.796, 0.3953], [0.1947, 0.1413, 0.1407], [0.7489, 0.8031, 0.6399], [0.0533, 0.2785, 0.6977]], [[0.3569, 0.9868, 0.8971], [0.8837, 0.1603, 0.4951], [0.4346, 0.7468, 0.2226], [0.526, 0.0296, 0.4173]], [[0.1059, 0.0539, 0.8693], [0.3308, 0.8424, 0.0367], [0.3198, 0.2315, 0.4263], [0.2065, 0.0549, 0.5245]]]]], 3, Con38907), 
LMax1517 = maximum_layer([Mas30571,Con38907], Max1517), 
exec_layers([LDen11630,LReL43801,LZer31764,LMas30571,LAdd75628,LZer22962,LCon38907,LMax1517],["Den11630","ReL43801","Zer31764","Mas30571","Add75628","Zer22962","Con38907","Max1517"],Max1517,"Max1517")

Actual (Unparsed): [[[[0.0000000, 0.8942000, 0.9817000, 0.5261000], [0.0000000, 0.5217000, 0.9678000, 0.3601000], [0.0000000, 0.5216000, 0.5843000, 0.5926000], [0.0000000, 0.0646000, 0.8327000, 0.7698000]], [[0.0000000, 0.6318000, 0.0071000, 0.7828000], [0.0000000, 0.3796000, 0.6703000, 0.7636000], [0.0000000, 0.9553000, 0.7348000, 0.0290000], [0.0000000, 0.9294000, 0.0843000, 0.7566000]], [[0.0000000, 0.3625000, 0.5179000, 0.3498000], [0.0000000, 0.3174000, 0.5700000, 0.5330000], [0.0000000, 0.2974000, 0.0648000, 0.4231000], [0.0000000, 0.9951000, 0.7903000, 0.7085000]], [[0.0000000, 0.2667000, 0.3786000, 0.3692000], [0.0000000, 0.0821000, 0.3866000, 0.6359000], [0.0000000, 0.1496000, 0.6451000, 0.1526000], [0.0000000, 0.7197000, 0.9174000, 0.4721000]], [[0.0000000, 0.8436000, 0.7960000, 0.3953000], [0.0000000, 0.1947000, 0.1413000, 0.1407000], [0.0000000, 0.7489000, 0.8031000, 0.6399000], [0.0000000, 0.0533000, 0.2785000, 0.6977000]], [[0.0000000, 0.3569000, 0.9868000, 0.8971000], [0.0000000, 0.8837000, 0.1603000, 0.4951000], [0.0000000, 0.4346000, 0.7468000, 0.2226000], [0.3753000, 0.5260000, 0.0296000, 0.4173000]], [[0.0000000, 0.1059000, 0.0539000, 0.8693000], [0.0000000, 0.3308000, 0.8424000, 0.0367000], [0.0000000, 0.3198000, 0.2315000, 0.4263000], [0.9364000, 0.2065000, 0.0549000, 0.5245000]]]]

Expected (Unparsed): [[[[0,0.8942,0.9817,0.5261],[0,0.5217,0.9678,0.3601],[0,0.5216,0.5843,0.5926],[0,0.0646,0.8327,0.7698]],[[0,0.6318,0.0071,0.7828],[0,0.3796,0.6703,0.7636],[0,0.9553,0.7348,0.029],[0,0.9294,0.0843,0.7566]],[[0,0.3625,0.5179,0.3498],[0,0.3174,0.57,0.533],[0,0.2974,0.0648,0.4231],[0,0.9951,0.7903,0.7085]],[[0,0.2667,0.3786,0.3692],[0,0.0821,0.3866,0.6359],[0,0.1496,0.6451,0.1526],[0,0.7197,0.9174,0.4721]],[[0,0.8436,0.796,0.3953],[0,0.1947,0.1413,0.1407],[0,0.7489,0.8031,0.6399],[0,0.0533,0.2785,0.6977]],[[0,0.3569,0.9868,0.8971],[0,0.8837,0.1603,0.4951],[0,0.4346,0.7468,0.2226],[0.37529999999999997,0.526,0.0296,0.4173]],[[0,0.1059,0.0539,0.8693],[0,0.3308,0.8424,0.0367],[0,0.3198,0.2315,0.4263],[0.9364,0.2065,0.0549,0.5245]]]]

Actual:   [[[[0, 0.8942, 0.9817, 0.5261], [0, 0.5217, 0.9678, 0.3601], [0, 0.5216, 0.5843, 0.5926], [0, 0.0646, 0.8327, 0.7698]], [[0, 0.6318, 0.0071, 0.7828], [0, 0.3796, 0.6703, 0.7636], [0, 0.9553, 0.7348, 0.029], [0, 0.9294, 0.0843, 0.7566]], [[0, 0.3625, 0.5179, 0.3498], [0, 0.3174, 0.57, 0.533], [0, 0.2974, 0.0648, 0.4231], [0, 0.9951, 0.7903, 0.7085]], [[0, 0.2667, 0.3786, 0.3692], [0, 0.0821, 0.3866, 0.6359], [0, 0.1496, 0.6451, 0.1526], [0, 0.7197, 0.9174, 0.4721]], [[0, 0.8436, 0.796, 0.3953], [0, 0.1947, 0.1413, 0.1407], [0, 0.7489, 0.8031, 0.6399], [0, 0.0533, 0.2785, 0.6977]], [[0, 0.3569, 0.9868, 0.8971], [0, 0.8837, 0.1603, 0.4951], [0, 0.4346, 0.7468, 0.2226], [0.3753, 0.526, 0.0296, 0.4173]], [[0, 0.1059, 0.0539, 0.8693], [0, 0.3308, 0.8424, 0.0367], [0, 0.3198, 0.2315, 0.4263], [0.9364, 0.2065, 0.0549, 0.5245]]]]

Expected: [[[[0, 0.8942, 0.9817, 0.5261], [0, 0.5217, 0.9678, 0.3601], [0, 0.5216, 0.5843, 0.5926], [0, 0.0646, 0.8327, 0.7698]], [[0, 0.6318, 0.0071, 0.7828], [0, 0.3796, 0.6703, 0.7636], [0, 0.9553, 0.7348, 0.029], [0, 0.9294, 0.0843, 0.7566]], [[0, 0.3625, 0.5179, 0.3498], [0, 0.3174, 0.57, 0.533], [0, 0.2974, 0.0648, 0.4231], [0, 0.9951, 0.7903, 0.7085]], [[0, 0.2667, 0.3786, 0.3692], [0, 0.0821, 0.3866, 0.6359], [0, 0.1496, 0.6451, 0.1526], [0, 0.7197, 0.9174, 0.4721]], [[0, 0.8436, 0.796, 0.3953], [0, 0.1947, 0.1413, 0.1407], [0, 0.7489, 0.8031, 0.6399], [0, 0.0533, 0.2785, 0.6977]], [[0, 0.3569, 0.9868, 0.8971], [0, 0.8837, 0.1603, 0.4951], [0, 0.4346, 0.7468, 0.2226], [0.3753, 0.526, 0.0296, 0.4173]], [[0, 0.1059, 0.0539, 0.8693], [0, 0.3308, 0.8424, 0.0367], [0, 0.3198, 0.2315, 0.4263], [0.9364, 0.2065, 0.0549, 0.5245]]]]