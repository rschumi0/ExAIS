import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add78854 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in1Add78854 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in0Up_71793 = tf.keras.layers.Input(shape=([3, 4]))
in0Con37449 = tf.keras.layers.Input(shape=([6, 4]))
in0Mul36455 = tf.keras.layers.Input(shape=([2, 1]))
in1Mul36455 = tf.keras.layers.Input(shape=([2, 1]))
in0Con81864 = tf.keras.layers.Input(shape=([47]))

Add78854 = keras.layers.Add(name = 'Add78854', )([in0Add78854,in1Add78854])
Res37695 = keras.layers.Reshape((1, 2, 4), name = 'Res37695', )(Add78854)
Res91002 = keras.layers.Reshape((1, 8), name = 'Res91002', )(Res37695)
Zer70599 = keras.layers.ZeroPadding1D(padding=((5, 0)), name = 'Zer70599', )(Res91002)
Up_71793 = keras.layers.UpSampling1D(size=(2), name = 'Up_71793', )(in0Up_71793)
Con37449 = keras.layers.Concatenate(axis=2, name = 'Con37449', )([Up_71793,in0Con37449])
Max66502 = keras.layers.Maximum(name = 'Max66502', )([Zer70599,Con37449])
Fla68579 = keras.layers.Flatten(name = 'Fla68579', )(Max66502)
Mul36455 = keras.layers.Multiply(name = 'Mul36455', )([in0Mul36455,in1Mul36455])
GRU53745 = keras.layers.GRU(1,reset_after=True, recurrent_activation='sigmoid', name = 'GRU53745', )(Mul36455)
Con81864 = keras.layers.Concatenate(axis=1, name = 'Con81864', )([GRU53745,in0Con81864])
Sub62935 = keras.layers.Subtract(name = 'Sub62935', )([Fla68579,Con81864])
model = tf.keras.models.Model(inputs=[in0Add78854,in1Add78854,in0Up_71793,in0Con37449,in0Mul36455,in1Mul36455,in0Con81864], outputs=Sub62935)
w = model.get_layer('GRU53745').get_weights() 
w[0] = np.array([[1, 10, 10]])
w[1] = np.array([[5, 7, 10]])
w[2] = np.array([[6, 4, 8], [7, 9, 8]])
model.get_layer('GRU53745').set_weights(w) 
in0Add78854 = tf.constant([[[[[0.8934, 0.1543], [0.3312, 0.6873]], [[0.8992, 0.3075], [0.0292, 0.2428]]]]])
in1Add78854 = tf.constant([[[[[0.4314, 0.799], [0.161, 0.1846]], [[0.4161, 0.0413], [0.533, 0.5256]]]]])
in0Up_71793 = tf.constant([[[1.4045, 1.2174, 1.8713, 1.5821], [1.4759, 1.8629, 1.2878, 1.4564], [1.5543, 1.2279, 1.4414, 1.2201]]])
in0Con37449 = tf.constant([[[0.2789, 0.6525, 0.8859, 0.1129], [0.1678, 0.0095, 0.3146, 0.6468], [0.9547, 0.0885, 0.7561, 0.3273], [0.8165, 0.6848, 0.5933, 0.6813], [0.1449, 0.9269, 0.2316, 0.9414], [0.6917, 0.4499, 0.6683, 0.3771]]])
in0Mul36455 = tf.constant([[[0.6318], [0.5299]]])
in1Mul36455 = tf.constant([[[0.564], [0.1675]]])
in0Con81864 = tf.constant([[0.2341, 0.5869, 0.3204, 0.5065, 0.4762, 0.6492, 0.4563, 0.9865, 0.8979, 0.1769, 0.2936, 0.3731, 0.4463, 0.8683, 0.3643, 0.1407, 0.5293, 0.5401, 0.7641, 0.9555, 0.4151, 0.8595, 0.246, 0.8498, 0.591, 0.4088, 0.8367, 0.9468, 0.8895, 0.1391, 0.7278, 0.1455, 0.5536, 0.0144, 0.1344, 0.6252, 0.1826, 0.0542, 0.6649, 0.6382, 0.6786, 0.0386, 0.4975, 0.8164, 0.8955, 0.8595, 0.324]])
print (np.array2string(model.predict([in0Add78854,in1Add78854,in0Up_71793,in0Con37449,in0Mul36455,in1Mul36455,in0Con81864],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub62935.png')

LAdd78854 = add_layer([[[[[[0.8934, 0.1543], [0.3312, 0.6873]], [[0.8992, 0.3075], [0.0292, 0.2428]]]]], [[[[[0.4314, 0.799], [0.161, 0.1846]], [[0.4161, 0.0413], [0.533, 0.5256]]]]]], Add78854), 
LRes37695 = reshape_layer(Add78854, [1, 2, 4], Res37695), 
LRes91002 = reshape_layer(Res37695, [1, 8], Res91002), 
LZer70599 = zero_padding1D_layer(Res91002, 5, 0, Zer70599), 
LUp_71793 = up_sampling1D_layer([[[1.4045, 1.2174, 1.8713, 1.5821], [1.4759, 1.8629, 1.2878, 1.4564], [1.5543, 1.2279, 1.4414, 1.2201]]], 2, Up_71793), 
LCon37449 = concatenate_layer([Up_71793,[[[0.2789, 0.6525, 0.8859, 0.1129], [0.1678, 0.0095, 0.3146, 0.6468], [0.9547, 0.0885, 0.7561, 0.3273], [0.8165, 0.6848, 0.5933, 0.6813], [0.1449, 0.9269, 0.2316, 0.9414], [0.6917, 0.4499, 0.6683, 0.3771]]]], 2, Con37449), 
LMax66502 = maximum_layer([Zer70599,Con37449], Max66502), 
LFla68579 = flatten_layer(Max66502, Fla68579), 
LMul36455 = multiply_layer([[[[0.6318], [0.5299]]], [[[0.564], [0.1675]]]], Mul36455), 
LGRU53745 = gru_layer(Mul36455,[[1, 10, 10]],[[5, 7, 10]],[[6, 4, 8], [7, 9, 8]], true, GRU53745), 
LCon81864 = concatenate_layer([GRU53745,[[0.2341, 0.5869, 0.3204, 0.5065, 0.4762, 0.6492, 0.4563, 0.9865, 0.8979, 0.1769, 0.2936, 0.3731, 0.4463, 0.8683, 0.3643, 0.1407, 0.5293, 0.5401, 0.7641, 0.9555, 0.4151, 0.8595, 0.246, 0.8498, 0.591, 0.4088, 0.8367, 0.9468, 0.8895, 0.1391, 0.7278, 0.1455, 0.5536, 0.0144, 0.1344, 0.6252, 0.1826, 0.0542, 0.6649, 0.6382, 0.6786, 0.0386, 0.4975, 0.8164, 0.8955, 0.8595, 0.324]]], 1, Con81864), 
LSub62935 = subtract_layer(Fla68579,Con81864, Sub62935), 
exec_layers([LAdd78854,LRes37695,LRes91002,LZer70599,LUp_71793,LCon37449,LMax66502,LFla68579,LMul36455,LGRU53745,LCon81864,LSub62935],["Add78854","Res37695","Res91002","Zer70599","Up_71793","Con37449","Max66502","Fla68579","Mul36455","GRU53745","Con81864","Sub62935"],Sub62935,"Sub62935")

Actual (Unparsed): [[1.4044964, 0.9833000, 1.2844000, 1.2617000, -0.2276000, 0.1763000, 0.2367000, -0.3434000, 0.4180000, 0.3195000, 1.6944000, 1.2885000, -0.2053000, -0.4368000, -0.5537000, 0.2825000, 1.3352001, 1.3336000, 0.7477000, 0.6923000, -0.0008000, -0.3266000, -0.1034000, 0.0813000, 0.6261001, 1.2719000, 0.8789999, 0.6197000, -0.1303000, -0.2047000, 0.4542000, -0.0465000, 1.4087999, 0.6743000, 1.4270001, 1.0857000, -0.4803000, 0.7443000, 0.1774000, 0.2765000, 0.9161000, 0.5493000, 1.4028000, 0.7226000, 0.4989000, -0.4456000, -0.1912000, 0.4444000]]

Expected (Unparsed): [[1.4044963489058795,0.9833000000000001,1.2844,1.2617,-0.22759999999999997,0.17629999999999996,0.23670000000000002,-0.3434,0.41800000000000004,0.3195,1.6944,1.2885,-0.20529999999999998,-0.43679999999999997,-0.5537,0.28250000000000003,1.3352,1.3336000000000001,0.7477,0.6922999999999999,-0.0008000000000000229,-0.3266,-0.10340000000000005,0.08129999999999998,0.6261,1.2719,0.879,0.6196999999999999,-0.13029999999999997,-0.2047,0.45420000000000005,-0.046499999999999986,1.4088,0.6743,1.427,1.0856999999999999,-0.48029999999999995,0.7443,0.1774,0.27649999999999997,0.9161,0.5493,1.4028,0.7225999999999999,0.4989000000000001,-0.44559999999999994,-0.19120000000000004,0.44439999999999996]]

Actual:   [[1.4045, 0.9833, 1.2844, 1.2617, -0.2276, 0.1763, 0.2367, -0.3434, 0.418, 0.3195, 1.6944, 1.2885, -0.2053, -0.4368, -0.5537, 0.2825, 1.3353, 1.3336, 0.7477, 0.6923, -0.0008, -0.3266, -0.1034, 0.0813, 0.6262, 1.2719, 0.879, 0.6197, -0.1303, -0.2047, 0.4542, -0.0465, 1.4088, 0.6743, 1.4271, 1.0857, -0.4803, 0.7443, 0.1774, 0.2765, 0.9161, 0.5493, 1.4028, 0.7226, 0.4989, -0.4456, -0.1912, 0.4444]]

Expected: [[1.4045, 0.9834, 1.2844, 1.2617, -0.2275, 0.1763, 0.2368, -0.3434, 0.4181, 0.3195, 1.6944, 1.2885, -0.2052, -0.4367, -0.5537, 0.2826, 1.3352, 1.3337, 0.7477, 0.6923, -0.0008, -0.3266, -0.1034, 0.0813, 0.6261, 1.2719, 0.879, 0.6197, -0.1302, -0.2047, 0.4543, -0.0464, 1.4088, 0.6743, 1.427, 1.0857, -0.4802, 0.7443, 0.1774, 0.2765, 0.9161, 0.5493, 1.4028, 0.7226, 0.499, -0.4455, -0.1912, 0.4444]]