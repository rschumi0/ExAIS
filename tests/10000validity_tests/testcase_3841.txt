import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add4929 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Add4929 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con4433 = tf.keras.layers.Input(shape=([5, 4]))
in0Glo60026 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con10684 = tf.keras.layers.Input(shape=([3, 4, 1]))
in0Mas93179 = tf.keras.layers.Input(shape=([3, 4, 2]))

Add4929 = keras.layers.Add(name = 'Add4929', )([in0Add4929,in1Add4929])
Res45874 = keras.layers.Reshape((2, 4), name = 'Res45874', )(Add4929)
Zer89210 = keras.layers.ZeroPadding1D(padding=((3, 0)), name = 'Zer89210', )(Res45874)
Con4433 = keras.layers.Concatenate(axis=2, name = 'Con4433', )([Zer89210,in0Con4433])
Glo60026 = keras.layers.GlobalAveragePooling2D(name = 'Glo60026', )(in0Glo60026)
Res20014 = keras.layers.Reshape((2, 1), name = 'Res20014', )(Glo60026)
Res96904 = keras.layers.Reshape((2, 1, 1), name = 'Res96904', )(Res20014)
Zer38990 = keras.layers.ZeroPadding2D(padding=((1, 0), (3, 0)), name = 'Zer38990', )(Res96904)
Con10684 = keras.layers.Concatenate(axis=3, name = 'Con10684', )([Zer38990,in0Con10684])
Mas93179 = keras.layers.Masking(mask_value=1, name = 'Mas93179', )(in0Mas93179)
Sub88668 = keras.layers.Subtract(name = 'Sub88668', )([Con10684,Mas93179])
Res71777 = keras.layers.Reshape((3, 8), name = 'Res71777', )(Sub88668)
Zer73574 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer73574', )(Res71777)
Min33409 = keras.layers.Minimum(name = 'Min33409', )([Con4433,Zer73574])
model = tf.keras.models.Model(inputs=[in0Add4929,in1Add4929,in0Con4433,in0Glo60026,in0Con10684,in0Mas93179], outputs=Min33409)
in0Add4929 = tf.constant([[[[0.0582, 0.1932], [0.1986, 0.9313]], [[0.8564, 0.7241], [0.9243, 0.991]]]])
in1Add4929 = tf.constant([[[[0.0636, 0.6305], [0.8597, 0.5902]], [[0.53, 0.1796], [0.1366, 0.3284]]]])
in0Con4433 = tf.constant([[[0.4571, 0.6905, 0.6205, 0.856], [0.0867, 0.7743, 0.1387, 0.0164], [0.5604, 0.9149, 0.7493, 0.2585], [0.9877, 0.8421, 0.4647, 0.5916], [0.2729, 0.9797, 0.8871, 0.6627]]])
in0Glo60026 = tf.constant([[[[1.2825, 1.9118], [1.8439, 1.7313]], [[1.3086, 1.4645], [1.5885, 1.6652]]]])
in0Con10684 = tf.constant([[[[0.4785], [0.4256], [0.6854], [0.7957]], [[0.8091], [0.0702], [0.3626], [0.6319]], [[0.1592], [0.9569], [0.6838], [0.5135]]]])
in0Mas93179 = tf.constant([[[[1.7953, 1.8217], [1.9143, 1.2534], [1.7776, 1.7766], [1.3799, 1.1807]], [[1.756, 1.5685], [1.1535, 1.0277], [1.6059, 1.2409], [1.7014, 1.9367]], [[1.0218, 1.2554], [1.5175, 1.4781], [1.8118, 1.2926], [1.868, 1.0614]]]])
print (np.array2string(model.predict([in0Add4929,in1Add4929,in0Con4433,in0Glo60026,in0Con10684,in0Mas93179],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min33409.png')

LAdd4929 = add_layer([[[[[0.0582, 0.1932], [0.1986, 0.9313]], [[0.8564, 0.7241], [0.9243, 0.991]]]], [[[[0.0636, 0.6305], [0.8597, 0.5902]], [[0.53, 0.1796], [0.1366, 0.3284]]]]], Add4929), 
LRes45874 = reshape_layer(Add4929, [2, 4], Res45874), 
LZer89210 = zero_padding1D_layer(Res45874, 3, 0, Zer89210), 
LCon4433 = concatenate_layer([Zer89210,[[[0.4571, 0.6905, 0.6205, 0.856], [0.0867, 0.7743, 0.1387, 0.0164], [0.5604, 0.9149, 0.7493, 0.2585], [0.9877, 0.8421, 0.4647, 0.5916], [0.2729, 0.9797, 0.8871, 0.6627]]]], 2, Con4433), 
LGlo60026 = global_average_pooling2D_layer([[[[1.2825, 1.9118], [1.8439, 1.7313]], [[1.3086, 1.4645], [1.5885, 1.6652]]]], Glo60026), 
LRes20014 = reshape_layer(Glo60026, [2, 1], Res20014), 
LRes96904 = reshape_layer(Res20014, [2, 1, 1], Res96904), 
LZer38990 = zero_padding2D_layer(Res96904, 1, 0, 3, 0, Zer38990), 
LCon10684 = concatenate_layer([Zer38990,[[[[0.4785], [0.4256], [0.6854], [0.7957]], [[0.8091], [0.0702], [0.3626], [0.6319]], [[0.1592], [0.9569], [0.6838], [0.5135]]]]], 3, Con10684), 
LMas93179 = masking_layer([[[[1.7953, 1.8217], [1.9143, 1.2534], [1.7776, 1.7766], [1.3799, 1.1807]], [[1.756, 1.5685], [1.1535, 1.0277], [1.6059, 1.2409], [1.7014, 1.9367]], [[1.0218, 1.2554], [1.5175, 1.4781], [1.8118, 1.2926], [1.868, 1.0614]]]], 1, Mas93179), 
LSub88668 = subtract_layer(Con10684,Mas93179, Sub88668), 
LRes71777 = reshape_layer(Sub88668, [3, 8], Res71777), 
LZer73574 = zero_padding1D_layer(Res71777, 1, 1, Zer73574), 
LMin33409 = minimum_layer([Con4433,Zer73574], Min33409), 
exec_layers([LAdd4929,LRes45874,LZer89210,LCon4433,LGlo60026,LRes20014,LRes96904,LZer38990,LCon10684,LMas93179,LSub88668,LRes71777,LZer73574,LMin33409],["Add4929","Res45874","Zer89210","Con4433","Glo60026","Res20014","Res96904","Zer38990","Con10684","Mas93179","Sub88668","Res71777","Zer73574","Min33409"],Min33409,"Min33409")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [-1.7953000, -1.3432000, -1.9143000, -0.8278000, -1.7776000, -1.0912000, -1.3799000, -0.3849999], [-1.7560000, -0.7594001, -1.1535000, -0.9574999, -1.6059000, -0.8783000, -0.1955251, -1.3048000], [-1.0218000, -1.0961999, -1.5175000, -0.5211999, -1.8118000, -0.6088001, -0.1748000, -0.5479001], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000]]]

Expected (Unparsed): [[[0,0,0,0,0,0,0,0],[-1.7953,-1.3432000000000002,-1.9143,-0.8278000000000001,-1.7776,-1.0912,-1.3799,-0.3850000000000001],[-1.756,-0.7594,-1.1535,-0.9575,-1.6059,-0.8782999999999999,-0.19552499999999995,-1.3048000000000002],[-1.0218,-1.0962,-1.5175,-0.5212,-1.8118,-0.6088,-0.17480000000000007,-0.5478999999999999],[0,0,0,0,0,0,0,0]]]

Actual:   [[[0, 0, 0, 0, 0, 0, 0, 0], [-1.7953, -1.3432, -1.9143, -0.8278, -1.7776, -1.0912, -1.3799, -0.3849], [-1.756, -0.7594, -1.1535, -0.9574, -1.6059, -0.8783, -0.1955, -1.3048], [-1.0218, -1.0961, -1.5175, -0.5211, -1.8118, -0.6088, -0.1748, -0.5479], [0, 0, 0, 0, 0, 0, 0, 0]]]

Expected: [[[0, 0, 0, 0, 0, 0, 0, 0], [-1.7953, -1.3432, -1.9143, -0.8278, -1.7776, -1.0912, -1.3799, -0.385], [-1.756, -0.7594, -1.1535, -0.9575, -1.6059, -0.8782, -0.1955, -1.3048], [-1.0218, -1.0962, -1.5175, -0.5212, -1.8118, -0.6088, -0.1748, -0.5478], [0, 0, 0, 0, 0, 0, 0, 0]]]