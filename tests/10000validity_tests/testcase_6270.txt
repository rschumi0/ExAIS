import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add8 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in1Add8 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Con45301 = tf.keras.layers.Input(shape=([3, 5, 3]))
in0Bat58597 = tf.keras.layers.Input(shape=([3, 3, 4]))

Add8 = keras.layers.Add(name = 'Add8', )([in0Add8,in1Add8])
Res56198 = keras.layers.Reshape((1, 1, 4), name = 'Res56198', )(Add8)
Res42936 = keras.layers.Reshape((1, 4), name = 'Res42936', )(Res56198)
Max56633 = keras.layers.MaxPool1D(pool_size=(1), strides=(1), padding='valid', name = 'Max56633', )(Res42936)
Res66694 = keras.layers.Reshape((1, 4, 1), name = 'Res66694', )(Max56633)
Zer44208 = keras.layers.ZeroPadding2D(padding=((2, 0), (1, 0)), name = 'Zer44208', )(Res66694)
Con45301 = keras.layers.Concatenate(axis=3, name = 'Con45301', )([Zer44208,in0Con45301])
Bat58597 = keras.layers.BatchNormalization(axis=2, epsilon=0.6499387704791059,  name = 'Bat58597', )(in0Bat58597)
Zer1764 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer1764', )(Bat58597)
Sub92684 = keras.layers.Subtract(name = 'Sub92684', )([Con45301,Zer1764])
Cro9453 = keras.layers.Cropping2D(cropping=((1, 0), (1, 1)), name = 'Cro9453', )(Sub92684)
Res12703 = keras.layers.Reshape((2, 3, 4, 1), name = 'Res12703', )(Cro9453)
PRe77810 = keras.layers.PReLU(name = 'PRe77810', )(Res12703)
model = tf.keras.models.Model(inputs=[in0Add8,in1Add8,in0Con45301,in0Bat58597], outputs=PRe77810)
w = model.get_layer('Bat58597').get_weights() 
w[0] = np.array([0.0472, 0.6425, 0.0397])
w[1] = np.array([0.4164, 0.1245, 0.1549])
w[2] = np.array([0.6665, 0.183, 0.1711])
w[3] = np.array([0.94, 0.5669, 0.9219])
model.get_layer('Bat58597').set_weights(w) 
w = model.get_layer('PRe77810').get_weights() 
w[0] = np.array([[[[0.5658], [0.7442], [0.3439], [0.9179]], [[0.2002], [0.06], [0.5135], [0.6808]], [[0.1204], [0.768], [0.21], [0.006]]], [[[0.8431], [0.6993], [0.8678], [0.7703]], [[0.5595], [0.5967], [0.911], [0.0617]], [[0.069], [0.6453], [0.5969], [0.1437]]]])
model.get_layer('PRe77810').set_weights(w) 
in0Add8 = tf.constant([[[[[0.2196, 0.836], [0.4466, 0.3043]]]]])
in1Add8 = tf.constant([[[[[0.5035, 0.9006], [0.6634, 0.0695]]]]])
in0Con45301 = tf.constant([[[[0.6166, 0.3009, 0.9038], [0.9477, 0.8927, 0.004], [0.762, 0.2562, 0.7009], [0.2081, 0.5558, 0.1669], [0.3518, 0.5464, 0.8533]], [[0.8291, 0.8227, 0.8762], [0.8127, 0.8775, 0.6803], [0.6428, 0.5366, 0.7666], [0.3115, 0.4273, 0.3036], [0.8647, 0.0409, 0.4161]], [[0.0761, 0.0671, 0.2937], [0.8341, 0.2715, 0.6349], [0.8219, 0.2197, 0.1658], [0.944, 0.1534, 0.789], [0.4526, 0.8377, 0.848]]]])
in0Bat58597 = tf.constant([[[[1.2584, 1.2694, 1.9452, 1.587], [1.2855, 1.3692, 1.6157, 1.6263], [1.8348, 1.0828, 1.5277, 1.5584]], [[1.4615, 1.924, 1.9513, 1.1594], [1.3762, 1.1424, 1.5076, 1.2138], [1.575, 1.4278, 1.6794, 1.7336]], [[1.3473, 1.3059, 1.5093, 1.4124], [1.8568, 1.7568, 1.4585, 1.272], [1.3633, 1.0719, 1.0369, 1.3266]]]])
print (np.array2string(model.predict([in0Add8,in1Add8,in0Con45301,in0Bat58597],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='PRe77810.png')

LAdd8 = add_layer([[[[[[0.2196, 0.836], [0.4466, 0.3043]]]]], [[[[[0.5035, 0.9006], [0.6634, 0.0695]]]]]], Add8), 
LRes56198 = reshape_layer(Add8, [1, 1, 4], Res56198), 
LRes42936 = reshape_layer(Res56198, [1, 4], Res42936), 
LMax56633 = max_pool1D_layer(Res42936, 1, 1, false, Max56633), 
LRes66694 = reshape_layer(Max56633, [1, 4, 1], Res66694), 
LZer44208 = zero_padding2D_layer(Res66694, 2, 0, 1, 0, Zer44208), 
LCon45301 = concatenate_layer([Zer44208,[[[[0.6166, 0.3009, 0.9038], [0.9477, 0.8927, 0.004], [0.762, 0.2562, 0.7009], [0.2081, 0.5558, 0.1669], [0.3518, 0.5464, 0.8533]], [[0.8291, 0.8227, 0.8762], [0.8127, 0.8775, 0.6803], [0.6428, 0.5366, 0.7666], [0.3115, 0.4273, 0.3036], [0.8647, 0.0409, 0.4161]], [[0.0761, 0.0671, 0.2937], [0.8341, 0.2715, 0.6349], [0.8219, 0.2197, 0.1658], [0.944, 0.1534, 0.789], [0.4526, 0.8377, 0.848]]]]], 3, Con45301), 
LBat58597 = batch_normalization_layer([[[[1.2584, 1.2694, 1.9452, 1.587], [1.2855, 1.3692, 1.6157, 1.6263], [1.8348, 1.0828, 1.5277, 1.5584]], [[1.4615, 1.924, 1.9513, 1.1594], [1.3762, 1.1424, 1.5076, 1.2138], [1.575, 1.4278, 1.6794, 1.7336]], [[1.3473, 1.3059, 1.5093, 1.4124], [1.8568, 1.7568, 1.4585, 1.272], [1.3633, 1.0719, 1.0369, 1.3266]]]], 2, 0.6499387704791059, [0.0472, 0.6425, 0.0397], [0.4164, 0.1245, 0.1549], [0.6665, 0.183, 0.1711], [0.94, 0.5669, 0.9219], Bat58597), 
LZer1764 = zero_padding2D_layer(Bat58597, 0, 0, 2, 0, Zer1764), 
LSub92684 = subtract_layer(Con45301,Zer1764, Sub92684), 
LCro9453 = cropping2D_layer(Sub92684, 1, 0, 1, 1, Cro9453), 
LRes12703 = reshape_layer(Cro9453, [2, 3, 4, 1], Res12703), 
LPRe77810 = prelu_layer(Res12703, [[[[0.5658], [0.7442], [0.3439], [0.9179]], [[0.2002], [0.06], [0.5135], [0.6808]], [[0.1204], [0.768], [0.21], [0.006]]], [[[0.8431], [0.6993], [0.8678], [0.7703]], [[0.5595], [0.5967], [0.911], [0.0617]], [[0.069], [0.6453], [0.5969], [0.1437]]]], PRe77810), 
exec_layers([LAdd8,LRes56198,LRes42936,LMax56633,LRes66694,LZer44208,LCon45301,LBat58597,LZer1764,LSub92684,LCro9453,LRes12703,LPRe77810],["Add8","Res56198","Res42936","Max56633","Res66694","Zer44208","Con45301","Bat58597","Zer1764","Sub92684","Cro9453","Res12703","PRe77810"],PRe77810,"PRe77810")

Actual (Unparsed): [[[[[0.0000000], [0.8127000], [0.8775000], [0.6803000]], [[-0.0893210], [0.1793283], [0.0721064], [0.3317494]], [[-0.0986649], [-0.2855423], [-0.0984290], [-0.0025277]]], [[[0.7231000], [0.8341000], [0.2715000], [0.6349000]], [[1.2947158], [0.3815655], [-0.2079342], [-0.0171848]], [[0.0105998], [-0.0626945], [-0.4261935], [0.0302149]]]]]

Expected (Unparsed): [[[[[0],[0.8127],[0.8775],[0.6803]],[[-0.08932103994922648],[0.17932830982757936],[0.0721063955995816],[0.3317493947626352]],[[-0.09866492008773904],[-0.28554233022615283],[-0.09842902681701028],[-0.00252771986460547]]],[[[0.7231],[0.8341],[0.2715],[0.6349]],[[1.2947157799845852],[0.3815654960666037],[-0.2079342253716382],[-0.017184751401404255]],[[0.010599762421317438],[-0.06269445109005159],[-0.42619345876243725],[0.03021492488757016]]]]]

Actual:   [[[[[0], [0.8127], [0.8775], [0.6803]], [[-0.0893], [0.1794], [0.0722], [0.3318]], [[-0.0986], [-0.2855], [-0.0984], [-0.0025]]], [[[0.7231], [0.8341], [0.2715], [0.6349]], [[1.2948], [0.3816], [-0.2079], [-0.0171]], [[0.0106], [-0.0626], [-0.4261], [0.0303]]]]]

Expected: [[[[[0], [0.8127], [0.8775], [0.6803]], [[-0.0893], [0.1794], [0.0722], [0.3318]], [[-0.0986], [-0.2855], [-0.0984], [-0.0025]]], [[[0.7231], [0.8341], [0.2715], [0.6349]], [[1.2948], [0.3816], [-0.2079], [-0.0171]], [[0.0106], [-0.0626], [-0.4261], [0.0303]]]]]