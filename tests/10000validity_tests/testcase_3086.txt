import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul29379 = tf.keras.layers.Input(shape=([1, 2, 1]))
in1Mul29379 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con98997 = tf.keras.layers.Input(shape=([3, 4, 3]))
in0Ave59872 = tf.keras.layers.Input(shape=([2, 2]))

Mul29379 = keras.layers.Multiply(name = 'Mul29379', )([in0Mul29379,in1Mul29379])
Zer57852 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer57852', )(Mul29379)
Con98997 = keras.layers.Concatenate(axis=3, name = 'Con98997', )([Zer57852,in0Con98997])
Ave59872 = keras.layers.AveragePooling1D(pool_size=(2), name = 'Ave59872', )(in0Ave59872)
Res96852 = keras.layers.Reshape((1, 2, 1), name = 'Res96852', )(Ave59872)
Con46331 = keras.layers.Conv2DTranspose(4, (1, 2),strides=(1, 1), padding='valid', name = 'Con46331', )(Res96852)
Zer51481 = keras.layers.ZeroPadding2D(padding=((2, 0), (1, 0)), name = 'Zer51481', )(Con46331)
Sub14383 = keras.layers.Subtract(name = 'Sub14383', )([Con98997,Zer51481])
model = tf.keras.models.Model(inputs=[in0Mul29379,in1Mul29379,in0Con98997,in0Ave59872], outputs=Sub14383)
w = model.get_layer('Con46331').get_weights() 
w[0] = np.array([[[[0.0682], [0.657], [0.9679], [0.0355]], [[0.9774], [0.2717], [0.0522], [0.4671]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con46331').set_weights(w) 
in0Mul29379 = tf.constant([[[[0.5633], [0.5218]]]])
in1Mul29379 = tf.constant([[[[0.0245], [0.9128]]]])
in0Con98997 = tf.constant([[[[0.6862, 0.4599, 0.8775], [0.6579, 0.884, 0.7229], [0.6183, 0.1448, 0.9454], [0.8029, 0.5962, 0.6887]], [[0.003, 0.5604, 0.7041], [0.2011, 0.7132, 0.5523], [0.3769, 0.2659, 0.0865], [0.3977, 0.9753, 0.8004]], [[0.7639, 0.7885, 0.9771], [0.3652, 0.2034, 0.5261], [0.205, 0.1964, 0.9023], [0.2991, 0.3748, 0.3828]]]])
in0Ave59872 = tf.constant([[[1.4192, 1.318], [1.0532, 1.2473]]])
print (np.array2string(model.predict([in0Mul29379,in1Mul29379,in0Con98997,in0Ave59872],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub14383.png')

LMul29379 = multiply_layer([[[[[0.5633], [0.5218]]]], [[[[0.0245], [0.9128]]]]], Mul29379), 
LZer57852 = zero_padding2D_layer(Mul29379, 1, 1, 1, 1, Zer57852), 
LCon98997 = concatenate_layer([Zer57852,[[[[0.6862, 0.4599, 0.8775], [0.6579, 0.884, 0.7229], [0.6183, 0.1448, 0.9454], [0.8029, 0.5962, 0.6887]], [[0.003, 0.5604, 0.7041], [0.2011, 0.7132, 0.5523], [0.3769, 0.2659, 0.0865], [0.3977, 0.9753, 0.8004]], [[0.7639, 0.7885, 0.9771], [0.3652, 0.2034, 0.5261], [0.205, 0.1964, 0.9023], [0.2991, 0.3748, 0.3828]]]]], 3, Con98997), 
LAve59872 = average_pooling1D_layer([[[1.4192, 1.318], [1.0532, 1.2473]]], 2, Ave59872), 
LRes96852 = reshape_layer(Ave59872, [1, 2, 1], Res96852), 
LCon46331 = conv2D_transpose_layer(Res96852, 1, 2,[[[[0.0682], [0.657], [0.9679], [0.0355]], [[0.9774], [0.2717], [0.0522], [0.4671]]]],[0, 0, 0, 0], 1, 1, false, Con46331), 
LZer51481 = zero_padding2D_layer(Con46331, 2, 0, 1, 0, Zer51481), 
LSub14383 = subtract_layer(Con98997,Zer51481, Sub14383), 
exec_layers([LMul29379,LZer57852,LCon98997,LAve59872,LRes96852,LCon46331,LZer51481,LSub14383],["Mul29379","Zer57852","Con98997","Ave59872","Res96852","Con46331","Zer51481","Sub14383"],Sub14383,"Sub14383")

Actual (Unparsed): [[[[0.0000000, 0.6862000, 0.4599000, 0.8775000], [0.0000000, 0.6579000, 0.8840000, 0.7229000], [0.0000000, 0.6183000, 0.1448000, 0.9454000], [0.0000000, 0.8029000, 0.5962000, 0.6887000]], [[0.0000000, 0.0030000, 0.5604000, 0.7041000], [0.0138008, 0.2011000, 0.7132000, 0.5523000], [0.4762990, 0.3769000, 0.2659000, 0.0865000], [0.0000000, 0.3977000, 0.9753000, 0.8004000]], [[0.0000000, 0.7639000, 0.7885000, 0.9771000], [-0.0843088, -0.4469834, -0.9931180, 0.4822149], [-1.2957386, -0.9735766, -1.1096066, 0.2793369], [-1.2536621, -0.0493960, 0.3078457, -0.2163258]]]]

Expected (Unparsed): [[[[0,0.6862,0.4599,0.8775],[0,0.6579,0.884,0.7229],[0,0.6183,0.1448,0.9454],[0,0.8029,0.5962,0.6887]],[[0,0.003,0.5604,0.7041],[0.013800850000000002,0.2011,0.7132,0.5523],[0.47629904,0.3769,0.2659,0.0865],[0,0.3977,0.9753,0.8004]],[[0,0.7639,0.7885,0.9771],[-0.08430884,-0.4469834,-0.9931179799999998,0.4822149],[-1.29573861,-0.9735765900000001,-1.1096065750000002,0.2793369050000001],[-1.25366211,-0.04939600500000002,0.30784567,-0.2163258150000001]]]]

Actual:   [[[[0, 0.6862, 0.4599, 0.8775], [0, 0.6579, 0.884, 0.7229], [0, 0.6183, 0.1448, 0.9454], [0, 0.8029, 0.5962, 0.6887]], [[0, 0.003, 0.5604, 0.7041], [0.0139, 0.2011, 0.7132, 0.5523], [0.4763, 0.3769, 0.2659, 0.0865], [0, 0.3977, 0.9753, 0.8004]], [[0, 0.7639, 0.7885, 0.9771], [-0.0843, -0.4469, -0.9931, 0.4823], [-1.2957, -0.9735, -1.1096, 0.2794], [-1.2536, -0.0493, 0.3079, -0.2163]]]]

Expected: [[[[0, 0.6862, 0.4599, 0.8775], [0, 0.6579, 0.884, 0.7229], [0, 0.6183, 0.1448, 0.9454], [0, 0.8029, 0.5962, 0.6887]], [[0, 0.003, 0.5604, 0.7041], [0.0139, 0.2011, 0.7132, 0.5523], [0.4763, 0.3769, 0.2659, 0.0865], [0, 0.3977, 0.9753, 0.8004]], [[0, 0.7639, 0.7885, 0.9771], [-0.0843, -0.4469, -0.9931, 0.4823], [-1.2957, -0.9735, -1.1096, 0.2794], [-1.2536, -0.0493, 0.3079, -0.2163]]]]