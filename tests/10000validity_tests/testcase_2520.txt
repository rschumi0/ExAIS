import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo30879 = tf.keras.layers.Input(shape=([1, 2]))
in0Con9938 = tf.keras.layers.Input(shape=([2, 1]))
in0Dot27446 = tf.keras.layers.Input(shape=([2, 3]))
in1Dot27446 = tf.keras.layers.Input(shape=([2, 3]))
in0Mul33464 = tf.keras.layers.Input(shape=([2, 1]))
in1Mul33464 = tf.keras.layers.Input(shape=([2, 1]))
in0Con96287 = tf.keras.layers.Input(shape=([2, 1]))

Glo30879 = keras.layers.GlobalAveragePooling1D(name = 'Glo30879', )(in0Glo30879)
Res19492 = keras.layers.Reshape((2, 1), name = 'Res19492', )(Glo30879)
Con9938 = keras.layers.Concatenate(axis=2, name = 'Con9938', )([Res19492,in0Con9938])
Dot27446 = keras.layers.Dot(axes=(2, 2), name = 'Dot27446', )([in0Dot27446,in1Dot27446])
Mul33464 = keras.layers.Multiply(name = 'Mul33464', )([in0Mul33464,in1Mul33464])
Bat94259 = keras.layers.BatchNormalization(axis=1, epsilon=0.9757100339269107,  name = 'Bat94259', )(Mul33464)
Con96287 = keras.layers.Concatenate(axis=2, name = 'Con96287', )([Bat94259,in0Con96287])
Mul74814 = keras.layers.Multiply(name = 'Mul74814', )([Dot27446,Con96287])
Sub75701 = keras.layers.Subtract(name = 'Sub75701', )([Con9938,Mul74814])
model = tf.keras.models.Model(inputs=[in0Glo30879,in0Con9938,in0Dot27446,in1Dot27446,in0Mul33464,in1Mul33464,in0Con96287], outputs=Sub75701)
w = model.get_layer('Bat94259').get_weights() 
w[0] = np.array([0.1122, 0.7813])
w[1] = np.array([0.511, 0.6794])
w[2] = np.array([0.042, 0.8448])
w[3] = np.array([0.5669, 0.5587])
model.get_layer('Bat94259').set_weights(w) 
in0Glo30879 = tf.constant([[[1.6736, 1.1324]]])
in0Con9938 = tf.constant([[[0.1893], [0.3161]]])
in0Dot27446 = tf.constant([[[0.1549, 0.5498, 0.765], [0.8981, 0.9335, 0.6946]]])
in1Dot27446 = tf.constant([[[0.8574, 0.3456, 0.5967], [0.3833, 0.0527, 0.0599]]])
in0Mul33464 = tf.constant([[[0.3187], [0.8682]]])
in1Mul33464 = tf.constant([[[0.4418], [0.8653]]])
in0Con96287 = tf.constant([[[0.4499], [0.4244]]])
print (np.array2string(model.predict([in0Glo30879,in0Con9938,in0Dot27446,in1Dot27446,in0Mul33464,in1Mul33464,in0Con96287],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub75701.png')

LGlo30879 = global_average_pooling1D_layer([[[1.6736, 1.1324]]], Glo30879), 
LRes19492 = reshape_layer(Glo30879, [2, 1], Res19492), 
LCon9938 = concatenate_layer([Res19492,[[[0.1893], [0.3161]]]], 2, Con9938), 
LDot27446 = dot_layer([[[0.1549, 0.5498, 0.765], [0.8981, 0.9335, 0.6946]]], [[[0.8574, 0.3456, 0.5967], [0.3833, 0.0527, 0.0599]]], 2, 2, Dot27446), 
LMul33464 = multiply_layer([[[[0.3187], [0.8682]]], [[[0.4418], [0.8653]]]], Mul33464), 
LBat94259 = batch_normalization_layer(Mul33464, 1, 0.9757100339269107, [0.1122, 0.7813], [0.511, 0.6794], [0.042, 0.8448], [0.5669, 0.5587], Bat94259), 
LCon96287 = concatenate_layer([Bat94259,[[[0.4499], [0.4244]]]], 2, Con96287), 
LMul74814 = multiply_layer([Dot27446,Con96287], Mul74814), 
LSub75701 = subtract_layer(Con9938,Mul74814, Sub75701), 
exec_layers([LGlo30879,LRes19492,LCon9938,LDot27446,LMul33464,LBat94259,LCon96287,LMul74814,LSub75701],["Glo30879","Res19492","Con9938","Dot27446","Mul33464","Bat94259","Con96287","Mul74814","Sub75701"],Sub75701,"Sub75701")

Actual (Unparsed): [[[1.2684233, 0.1289364], [0.1973897, 0.1314674]]]

Expected (Unparsed): [[[1.2684233414418795,0.128936408613],[0.19738968403902368,0.13146744523200002]]]

Actual:   [[[1.2685, 0.129], [0.1974, 0.1315]]]

Expected: [[[1.2685, 0.129], [0.1974, 0.1315]]]