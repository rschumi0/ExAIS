import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sim60210 = tf.keras.layers.Input(shape=([3, 1]))

Sim60210 = keras.layers.SimpleRNN(1,name = 'Sim60210', )(in0Sim60210)
Bat79628 = keras.layers.BatchNormalization(axis=1, epsilon=0.4932135190274194,  name = 'Bat79628', )(Sim60210)
Den32432 = keras.layers.Dense(4,name = 'Den32432', )(Bat79628)
ReL53310 = keras.layers.ReLU(max_value=3.162887761497459, negative_slope=8.87949573447075, threshold=3.9942369177955808, name = 'ReL53310', )(Den32432)
Den73397 = keras.layers.Dense(4,name = 'Den73397', )(ReL53310)
model = tf.keras.models.Model(inputs=[in0Sim60210], outputs=Den73397)
w = model.get_layer('Sim60210').get_weights() 
w[0] = np.array([[7]])
w[1] = np.array([[10]])
w[2] = np.array([2])
model.get_layer('Sim60210').set_weights(w) 
w = model.get_layer('Bat79628').get_weights() 
w[0] = np.array([0.9124])
w[1] = np.array([0.0791])
w[2] = np.array([0.9099])
w[3] = np.array([0.8741])
model.get_layer('Bat79628').set_weights(w) 
w = model.get_layer('Den32432').get_weights() 
w[0] = np.array([[0.2864, 0.6155, 0.771, 0.0531]])
w[1] = np.array([0.5886, 0.5051, 0.8055, 0.0581])
model.get_layer('Den32432').set_weights(w) 
w = model.get_layer('Den73397').get_weights() 
w[0] = np.array([[0.444, 0.9087, 0.7901, 0.9628], [0.0965, 0.1142, 0.5334, 0.8326], [0.0268, 0.5744, 0.8102, 0.395], [0.1861, 0.7305, 0.6028, 0.9536]])
w[1] = np.array([0.0357, 0.7523, 0.6099, 0.6908])
model.get_layer('Den73397').set_weights(w) 
in0Sim60210 = tf.constant([[[1], [1], [10]]])
print (np.array2string(model.predict([in0Sim60210],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Den73397.png')

LSim60210 = simple_rnn_layer([[[1], [1], [10]]],[[7]],[[10]],[2], Sim60210), 
LBat79628 = batch_normalization_layer(Sim60210, 1, 0.4932135190274194, [0.9124], [0.0791], [0.9099], [0.8741], Bat79628), 
LDen32432 = dense_layer(Bat79628, [[0.2864, 0.6155, 0.771, 0.0531]],[0.5886, 0.5051, 0.8055, 0.0581], Den32432), 
LReL53310 = relu_layer(Den32432, 3.162887761497459, 8.87949573447075, 3.9942369177955808, ReL53310), 
LDen73397 = dense_layer(ReL53310, [[0.444, 0.9087, 0.7901, 0.9628], [0.0965, 0.1142, 0.5334, 0.8326], [0.0268, 0.5744, 0.8102, 0.395], [0.1861, 0.7305, 0.6028, 0.9536]],[0.0357, 0.7523, 0.6099, 0.6908], Den73397), 
exec_layers([LSim60210,LBat79628,LDen32432,LReL53310,LDen73397],["Sim60210","Bat79628","Den32432","ReL53310","Den73397"],Den73397,"Den73397")

Actual (Unparsed): [[-23.3559282, -70.9831548, -82.2104910, -97.2165376]]

Expected (Unparsed): [[-23.355928188352628,-70.983154758197,-82.21049099431501,-97.21653755637075]]

Actual:   [[-23.3559, -70.9831, -82.2104, -97.2165]]

Expected: [[-23.3559, -70.9831, -82.2104, -97.2165]]