import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0PRe46670 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Glo838 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con76731 = tf.keras.layers.Input(shape=([2]))
in0Sub70720 = tf.keras.layers.Input(shape=([3]))
in1Sub70720 = tf.keras.layers.Input(shape=([3]))

PRe46670 = keras.layers.PReLU(name = 'PRe46670', input_shape=(1, 1, 1))(in0PRe46670)
Res14273 = keras.layers.Reshape((1, 1), name = 'Res14273', )(PRe46670)
Glo838 = keras.layers.GlobalAveragePooling2D(name = 'Glo838', )(in0Glo838)
Res74435 = keras.layers.Reshape((2, 1), name = 'Res74435', )(Glo838)
Res26290 = keras.layers.Reshape((2, 1, 1), name = 'Res26290', )(Res74435)
Res62082 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res62082', )(Res26290)
Glo10401 = keras.layers.GlobalAveragePooling3D(name = 'Glo10401', )(Res62082)
Bat41034 = keras.layers.BatchNormalization(axis=1, epsilon=0.8994668019808046,  name = 'Bat41034', )(Glo10401)
Res88556 = keras.layers.Reshape((1, 1), name = 'Res88556', )(Bat41034)
Max2744 = keras.layers.Maximum(name = 'Max2744', )([Res14273,Res88556])
Bat54762 = keras.layers.BatchNormalization(axis=2, epsilon=0.4228230930618263,  name = 'Bat54762', )(Max2744)
Fla95822 = keras.layers.Flatten(name = 'Fla95822', )(Bat54762)
Con76731 = keras.layers.Concatenate(axis=1, name = 'Con76731', )([Fla95822,in0Con76731])
Sub70720 = keras.layers.Subtract(name = 'Sub70720', )([in0Sub70720,in1Sub70720])
Ave92310 = keras.layers.Average(name = 'Ave92310', )([Con76731,Sub70720])
model = tf.keras.models.Model(inputs=[in0PRe46670,in0Glo838,in0Con76731,in0Sub70720,in1Sub70720], outputs=Ave92310)
w = model.get_layer('PRe46670').get_weights() 
w[0] = np.array([[[0.8679]]])
model.get_layer('PRe46670').set_weights(w) 
w = model.get_layer('Bat41034').get_weights() 
w[0] = np.array([0.5551])
w[1] = np.array([0.1732])
w[2] = np.array([0.2874])
w[3] = np.array([0.38])
model.get_layer('Bat41034').set_weights(w) 
w = model.get_layer('Bat54762').get_weights() 
w[0] = np.array([0.3159])
w[1] = np.array([0.672])
w[2] = np.array([0.0826])
w[3] = np.array([0.0344])
model.get_layer('Bat54762').set_weights(w) 
in0PRe46670 = tf.constant([[[[0.3095]]]])
in0Glo838 = tf.constant([[[[1.8407, 1.7607]], [[1.4414, 1.4469]]]])
in0Con76731 = tf.constant([[0.9956, 0.0758]])
in0Sub70720 = tf.constant([[0.9671, 0.5101, 0.495]])
in1Sub70720 = tf.constant([[0.2689, 0.3851, 0.8569]])
print (np.array2string(model.predict([in0PRe46670,in0Glo838,in0Con76731,in0Sub70720,in1Sub70720],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave92310.png')

LPRe46670 = prelu_layer([[[[0.3095]]]], [[[0.8679]]], PRe46670), 
LRes14273 = reshape_layer(PRe46670, [1, 1], Res14273), 
LGlo838 = global_average_pooling2D_layer([[[[1.8407, 1.7607]], [[1.4414, 1.4469]]]], Glo838), 
LRes74435 = reshape_layer(Glo838, [2, 1], Res74435), 
LRes26290 = reshape_layer(Res74435, [2, 1, 1], Res26290), 
LRes62082 = reshape_layer(Res26290, [2, 1, 1, 1], Res62082), 
LGlo10401 = global_average_pooling3D_layer(Res62082, Glo10401), 
LBat41034 = batch_normalization_layer(Glo10401, 1, 0.8994668019808046, [0.5551], [0.1732], [0.2874], [0.38], Bat41034), 
LRes88556 = reshape_layer(Bat41034, [1, 1], Res88556), 
LMax2744 = maximum_layer([Res14273,Res88556], Max2744), 
LBat54762 = batch_normalization_layer(Max2744, 2, 0.4228230930618263, [0.3159], [0.672], [0.0826], [0.0344], Bat54762), 
LFla95822 = flatten_layer(Bat54762, Fla95822), 
LCon76731 = concatenate_layer([Fla95822,[[0.9956, 0.0758]]], 1, Con76731), 
LSub70720 = subtract_layer([[0.9671, 0.5101, 0.495]], [[0.2689, 0.3851, 0.8569]], Sub70720), 
LAve92310 = average_layer([Con76731,Sub70720], Ave92310), 
exec_layers([LPRe46670,LRes14273,LGlo838,LRes74435,LRes26290,LRes62082,LGlo10401,LBat41034,LRes88556,LMax2744,LBat54762,LFla95822,LCon76731,LSub70720,LAve92310],["PRe46670","Res14273","Glo838","Res74435","Res26290","Res62082","Glo10401","Bat41034","Res88556","Max2744","Bat54762","Fla95822","Con76731","Sub70720","Ave92310"],Ave92310,"Ave92310")

Actual (Unparsed): [[0.8593022, 0.5603000, -0.1430500]]

Expected (Unparsed): [[0.8593021580545666,0.5603,-0.14305]]

Actual:   [[0.8594, 0.5603, -0.143]]

Expected: [[0.8594, 0.5603, -0.143]]