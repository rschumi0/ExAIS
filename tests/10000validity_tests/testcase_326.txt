import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub17081 = tf.keras.layers.Input(shape=([2, 3, 3, 2]))
in1Sub17081 = tf.keras.layers.Input(shape=([2, 3, 3, 2]))
in0Ave43967 = tf.keras.layers.Input(shape=([1, 2, 2]))
in1Ave43967 = tf.keras.layers.Input(shape=([1, 2, 2]))
in0Con58948 = tf.keras.layers.Input(shape=([116]))

Sub17081 = keras.layers.Subtract(name = 'Sub17081', )([in0Sub17081,in1Sub17081])
Res88227 = keras.layers.Reshape((2, 3, 6), name = 'Res88227', )(Sub17081)
Zer47238 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer47238', )(Res88227)
Res53994 = keras.layers.Reshape((4, 30), name = 'Res53994', )(Zer47238)
Fla22466 = keras.layers.Flatten(name = 'Fla22466', )(Res53994)
Ave43967 = keras.layers.Average(name = 'Ave43967', )([in0Ave43967,in1Ave43967])
Res10847 = keras.layers.Reshape((1, 4), name = 'Res10847', )(Ave43967)
Glo96458 = keras.layers.GlobalMaxPool1D(name = 'Glo96458', )(Res10847)
ReL38790 = keras.layers.ReLU(max_value=7.243742031395075, negative_slope=9.456996463349896, threshold=0.5916320638539296, name = 'ReL38790', )(Glo96458)
Con58948 = keras.layers.Concatenate(axis=1, name = 'Con58948', )([ReL38790,in0Con58948])
Mul46379 = keras.layers.Multiply(name = 'Mul46379', )([Fla22466,Con58948])
model = tf.keras.models.Model(inputs=[in0Sub17081,in1Sub17081,in0Ave43967,in1Ave43967,in0Con58948], outputs=Mul46379)
in0Sub17081 = tf.constant([[[[[0.1222, 0.3502], [0.07, 0.0616], [0.0604, 0.0708]], [[0.3564, 0.8362], [0.5681, 0.8621], [0.4728, 0.2816]], [[0.7057, 0.1938], [0.5722, 0.3148], [0.2271, 0.3227]]], [[[0.4036, 0.1344], [0.9746, 0.1769], [0.0978, 0.0778]], [[0.0317, 0.5595], [0.9001, 0.2871], [0.506, 0.9782]], [[0.5276, 0.8698], [0.1175, 0.18], [0.6398, 0.1613]]]]])
in1Sub17081 = tf.constant([[[[[0.341, 0.7772], [0.5061, 0.6372], [0.7182, 0.1878]], [[0.332, 0.0046], [0.0898, 0.4796], [0.8601, 0.0087]], [[0.9265, 0.6109], [0.8028, 0.5307], [0.6383, 0.9856]]], [[[0.3813, 0.6266], [0.7292, 0.2084], [0.7487, 0.2554]], [[0.9285, 0.4142], [0.3553, 0.583], [0.9799, 0.5727]], [[0.3787, 0.9091], [0.5985, 0.7246], [0.1856, 0.4652]]]]])
in0Ave43967 = tf.constant([[[[0.2149, 0.1923], [0.4192, 0.5538]]]])
in1Ave43967 = tf.constant([[[[0.5173, 0.4255], [0.7103, 0.7641]]]])
in0Con58948 = tf.constant([[0.8984, 0.6648, 0.1235, 0.4869, 0.4975, 0.3513, 0.7568, 0.3971, 0.1995, 0.6322, 0.3498, 0.346, 0.9228, 0.0343, 0.8205, 0.5628, 0.5808, 0.176, 0.5434, 0.4266, 0.4812, 0.6737, 0.9241, 0.9425, 0.2655, 0.3207, 0.749, 0.8094, 0.8804, 0.4803, 0.8666, 0.6795, 0.5508, 0.867, 0.5567, 0.8954, 0.103, 0.2764, 0.1532, 0.3307, 0.2695, 0.3693, 0.1009, 0.9576, 0.806, 0.316, 0.6449, 0.4176, 0.3423, 0.961, 0.7807, 0.1813, 0.899, 0.184, 0.9242, 0.8501, 0.9107, 0.3, 0.0014, 0.7725, 0.4145, 0.6672, 0.3012, 0.4284, 0.7858, 0.1526, 0.4892, 0.9679, 0.0338, 0.7431, 0.6362, 0.8814, 0.2046, 0.3845, 0.9792, 0.0281, 0.8827, 0.079, 0.4057, 0.1477, 0.13, 0.3805, 0.3266, 0.5461, 0.4575, 0.6885, 0.6856, 0.8567, 0.5828, 0.1605, 0.3446, 0.653, 0.7985, 0.638, 0.9788, 0.2172, 0.7456, 0.7126, 0.9159, 0.9527, 0.2704, 0.9477, 0.0634, 0.7694, 0.8248, 0.3117, 0.1824, 0.2687, 0.5663, 0.0838, 0.2852, 0.708, 0.9106, 0.8448, 0.8614, 0.5333]])
print (np.array2string(model.predict([in0Sub17081,in1Sub17081,in0Ave43967,in1Ave43967,in0Con58948],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul46379.png')

LSub17081 = subtract_layer([[[[[0.1222, 0.3502], [0.07, 0.0616], [0.0604, 0.0708]], [[0.3564, 0.8362], [0.5681, 0.8621], [0.4728, 0.2816]], [[0.7057, 0.1938], [0.5722, 0.3148], [0.2271, 0.3227]]], [[[0.4036, 0.1344], [0.9746, 0.1769], [0.0978, 0.0778]], [[0.0317, 0.5595], [0.9001, 0.2871], [0.506, 0.9782]], [[0.5276, 0.8698], [0.1175, 0.18], [0.6398, 0.1613]]]]], [[[[[0.341, 0.7772], [0.5061, 0.6372], [0.7182, 0.1878]], [[0.332, 0.0046], [0.0898, 0.4796], [0.8601, 0.0087]], [[0.9265, 0.6109], [0.8028, 0.5307], [0.6383, 0.9856]]], [[[0.3813, 0.6266], [0.7292, 0.2084], [0.7487, 0.2554]], [[0.9285, 0.4142], [0.3553, 0.583], [0.9799, 0.5727]], [[0.3787, 0.9091], [0.5985, 0.7246], [0.1856, 0.4652]]]]], Sub17081), 
LRes88227 = reshape_layer(Sub17081, [2, 3, 6], Res88227), 
LZer47238 = zero_padding2D_layer(Res88227, 1, 1, 1, 1, Zer47238), 
LRes53994 = reshape_layer(Zer47238, [4, 30], Res53994), 
LFla22466 = flatten_layer(Res53994, Fla22466), 
LAve43967 = average_layer([[[[[0.2149, 0.1923], [0.4192, 0.5538]]]], [[[[0.5173, 0.4255], [0.7103, 0.7641]]]]], Ave43967), 
LRes10847 = reshape_layer(Ave43967, [1, 4], Res10847), 
LGlo96458 = global_max_pool1D_layer(Res10847, Glo96458), 
LReL38790 = relu_layer(Glo96458, 7.243742031395075, 9.456996463349896, 0.5916320638539296, ReL38790), 
LCon58948 = concatenate_layer([ReL38790,[[0.8984, 0.6648, 0.1235, 0.4869, 0.4975, 0.3513, 0.7568, 0.3971, 0.1995, 0.6322, 0.3498, 0.346, 0.9228, 0.0343, 0.8205, 0.5628, 0.5808, 0.176, 0.5434, 0.4266, 0.4812, 0.6737, 0.9241, 0.9425, 0.2655, 0.3207, 0.749, 0.8094, 0.8804, 0.4803, 0.8666, 0.6795, 0.5508, 0.867, 0.5567, 0.8954, 0.103, 0.2764, 0.1532, 0.3307, 0.2695, 0.3693, 0.1009, 0.9576, 0.806, 0.316, 0.6449, 0.4176, 0.3423, 0.961, 0.7807, 0.1813, 0.899, 0.184, 0.9242, 0.8501, 0.9107, 0.3, 0.0014, 0.7725, 0.4145, 0.6672, 0.3012, 0.4284, 0.7858, 0.1526, 0.4892, 0.9679, 0.0338, 0.7431, 0.6362, 0.8814, 0.2046, 0.3845, 0.9792, 0.0281, 0.8827, 0.079, 0.4057, 0.1477, 0.13, 0.3805, 0.3266, 0.5461, 0.4575, 0.6885, 0.6856, 0.8567, 0.5828, 0.1605, 0.3446, 0.653, 0.7985, 0.638, 0.9788, 0.2172, 0.7456, 0.7126, 0.9159, 0.9527, 0.2704, 0.9477, 0.0634, 0.7694, 0.8248, 0.3117, 0.1824, 0.2687, 0.5663, 0.0838, 0.2852, 0.708, 0.9106, 0.8448, 0.8614, 0.5333]]], 1, Con58948), 
LMul46379 = multiply_layer([Fla22466,Con58948], Mul46379), 
exec_layers([LSub17081,LRes88227,LZer47238,LRes53994,LFla22466,LAve43967,LRes10847,LGlo96458,LReL38790,LCon58948,LMul46379],["Sub17081","Res88227","Zer47238","Res53994","Fla22466","Ave43967","Res10847","Glo96458","ReL38790","Con58948","Mul46379"],Mul46379,"Mul46379")

Actual (Unparsed): [[-0.0000000, -0.0000000, -0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, -0.1205150, -0.3702090, -0.2427769, -0.5153922, -0.0677534, -0.0323388, 0.0037381, 0.2750101, 0.1289018, 0.1412573, -0.0390786, 0.2613290, -0.1779648, -0.1318036, -0.1487139, -0.0901599, -0.1407538, -0.6370469, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0067168, -0.2108585, 0.1928353, -0.0048069, -0.3184203, -0.1718990, -0.0303118, 0.1079724, 0.3466018, -0.2608063, -0.0969599, 0.1559147, 0.1458029, -0.0011043, -0.4245787, -0.0430234, 0.1842689, -0.0448860, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000]]

Expected (Unparsed): [[-0.0,-0.0,-0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.12051504,-0.370209,-0.24277686999999998,-0.51539224,-0.06775339999999999,-0.032338799999999994,0.0037380799999999965,0.27501012,0.12890185,0.14125725,-0.03907857,0.26132904,-0.1779648,-0.13180360000000002,-0.14871393999999996,-0.09015983999999998,-0.14075376,-0.6370469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0067167600000000134,-0.21085848000000004,0.19283532000000006,-0.0048069,-0.31842028000000006,-0.17189904000000003,-0.03031184,0.10797242999999998,0.34660176,-0.26080625999999996,-0.09695994,0.15591475,0.14580287999999997,-0.00110433,-0.42457870000000003,-0.043023399999999996,0.18426894000000002,-0.04488603,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]

Actual:   [[-0, -0, -0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0.1205, -0.3702, -0.2427, -0.5153, -0.0677, -0.0323, 0.0038, 0.2751, 0.129, 0.1413, -0.039, 0.2614, -0.1779, -0.1318, -0.1487, -0.0901, -0.1407, -0.637, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0068, -0.2108, 0.1929, -0.0048, -0.3184, -0.1718, -0.0303, 0.108, 0.3467, -0.2608, -0.0969, 0.156, 0.1459, -0.0011, -0.4245, -0.043, 0.1843, -0.0448, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]

Expected: [[-0, -0, -0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0.1205, -0.3702, -0.2427, -0.5153, -0.0677, -0.0323, 0.0038, 0.2751, 0.129, 0.1413, -0.039, 0.2614, -0.1779, -0.1318, -0.1487, -0.0901, -0.1407, -0.637, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0068, -0.2108, 0.1929, -0.0048, -0.3184, -0.1718, -0.0303, 0.108, 0.3467, -0.2608, -0.0969, 0.156, 0.1459, -0.0011, -0.4245, -0.043, 0.1843, -0.0448, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]