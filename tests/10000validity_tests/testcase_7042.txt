import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Up_809 = tf.keras.layers.Input(shape=([2, 3, 2]))
in0Max57884 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in1Max57884 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in0Con60928 = tf.keras.layers.Input(shape=([45]))

Up_809 = keras.layers.UpSampling2D(size=(2, 2), name = 'Up_809', )(in0Up_809)
Res49900 = keras.layers.Reshape((4, 12), name = 'Res49900', )(Up_809)
Fla12061 = keras.layers.Flatten(name = 'Fla12061', )(Res49900)
Max57884 = keras.layers.Maximum(name = 'Max57884', )([in0Max57884,in1Max57884])
Res67198 = keras.layers.Reshape((2, 2, 1), name = 'Res67198', )(Max57884)
Res7417 = keras.layers.Reshape((2, 2), name = 'Res7417', )(Res67198)
Sim71750 = keras.layers.SimpleRNN(3,name = 'Sim71750', )(Res7417)
Con60928 = keras.layers.Concatenate(axis=1, name = 'Con60928', )([Sim71750,in0Con60928])
Ave12359 = keras.layers.Average(name = 'Ave12359', )([Fla12061,Con60928])
model = tf.keras.models.Model(inputs=[in0Up_809,in0Max57884,in1Max57884,in0Con60928], outputs=Ave12359)
w = model.get_layer('Sim71750').get_weights() 
w[0] = np.array([[4, 1, 1], [4, 2, 8]])
w[1] = np.array([[5, 4, 2], [5, 8, 3], [4, 1, 1]])
w[2] = np.array([8, 2, 9])
model.get_layer('Sim71750').set_weights(w) 
in0Up_809 = tf.constant([[[[1.9168, 1.7749], [1.4783, 1.3115], [1.5297, 1.8561]], [[1.6562, 1.6699], [1.6489, 1.4589], [1.7406, 1.4425]]]])
in0Max57884 = tf.constant([[[[[0.4301]], [[0.4381]]], [[[0.8666]], [[0.54]]]]])
in1Max57884 = tf.constant([[[[[0.5241]], [[0.7423]]], [[[0.8024]], [[0.2508]]]]])
in0Con60928 = tf.constant([[0.8775, 0.7221, 0.4065, 0.7098, 0.0359, 0.6205, 0.8132, 0.1893, 0.013, 0.2316, 0.1339, 0.2308, 0.2033, 0.501, 0.1071, 0.7634, 0.5851, 0.0252, 0.8798, 0.9633, 0.4947, 0.0052, 0.8337, 0.0521, 0.6338, 0.2585, 0.5778, 0.57, 0.5434, 0.3278, 0.8919, 0.2972, 0.5772, 0.0025, 0.7209, 0.4125, 0.4837, 0.3719, 0.4131, 0.9221, 0.0713, 0.8675, 0.2717, 0.8733, 0.0666]])
print (np.array2string(model.predict([in0Up_809,in0Max57884,in1Max57884,in0Con60928],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave12359.png')

LUp_809 = up_sampling2D_layer([[[[1.9168, 1.7749], [1.4783, 1.3115], [1.5297, 1.8561]], [[1.6562, 1.6699], [1.6489, 1.4589], [1.7406, 1.4425]]]], 2, 2, Up_809), 
LRes49900 = reshape_layer(Up_809, [4, 12], Res49900), 
LFla12061 = flatten_layer(Res49900, Fla12061), 
LMax57884 = maximum_layer([[[[[[0.4301]], [[0.4381]]], [[[0.8666]], [[0.54]]]]], [[[[[0.5241]], [[0.7423]]], [[[0.8024]], [[0.2508]]]]]], Max57884), 
LRes67198 = reshape_layer(Max57884, [2, 2, 1], Res67198), 
LRes7417 = reshape_layer(Res67198, [2, 2], Res7417), 
LSim71750 = simple_rnn_layer(Res7417,[[4, 1, 1], [4, 2, 8]],[[5, 4, 2], [5, 8, 3], [4, 1, 1]],[8, 2, 9], Sim71750), 
LCon60928 = concatenate_layer([Sim71750,[[0.8775, 0.7221, 0.4065, 0.7098, 0.0359, 0.6205, 0.8132, 0.1893, 0.013, 0.2316, 0.1339, 0.2308, 0.2033, 0.501, 0.1071, 0.7634, 0.5851, 0.0252, 0.8798, 0.9633, 0.4947, 0.0052, 0.8337, 0.0521, 0.6338, 0.2585, 0.5778, 0.57, 0.5434, 0.3278, 0.8919, 0.2972, 0.5772, 0.0025, 0.7209, 0.4125, 0.4837, 0.3719, 0.4131, 0.9221, 0.0713, 0.8675, 0.2717, 0.8733, 0.0666]]], 1, Con60928), 
LAve12359 = average_layer([Fla12061,Con60928], Ave12359), 
exec_layers([LUp_809,LRes49900,LFla12061,LMax57884,LRes67198,LRes7417,LSim71750,LCon60928,LAve12359],["Up_809","Res49900","Fla12061","Max57884","Res67198","Res7417","Sim71750","Con60928","Ave12359"],Ave12359,"Ave12359")

Actual (Unparsed): [[1.4584000, 1.3874500, 1.4584000, 1.3262000, 1.1002000, 0.8590000, 1.0940500, 0.6737000, 1.0751000, 1.3346500, 0.8595000, 0.9345500, 1.0742000, 0.9544000, 1.0738000, 0.9891000, 0.9896500, 0.7093000, 1.1208500, 0.9483000, 0.7774500, 1.3679500, 1.2465000, 1.1754000, 0.8307000, 1.2518000, 0.8541500, 1.1518500, 0.9537000, 1.0183500, 1.1094500, 1.0011500, 1.0342000, 1.1672000, 1.0189000, 1.0098500, 0.8293500, 1.1954000, 1.0343500, 1.0768000, 1.0104000, 0.9360000, 1.2855000, 0.7651000, 1.3040500, 0.8571000, 1.3069500, 0.7545500]]

Expected (Unparsed): [[1.4584000000000001,1.387449999999998,1.4584000000000001,1.3262,1.1002,0.859,1.09405,0.6737000000000001,1.0751,1.3346500000000001,0.8595,0.93455,1.0742,0.9543999999999999,1.0738,0.9891,0.9896499999999999,0.7093,1.12085,0.9483,0.77745,1.36795,1.2465000000000002,1.1754,0.8307,1.2518,0.85415,1.15185,0.9537,1.01835,1.10945,1.00115,1.0342,1.1672,1.0189,1.00985,0.8293499999999999,1.1954,1.0343499999999999,1.0768,1.0104,0.936,1.2855,0.7651,1.30405,0.8571,1.30695,0.7545499999999999]]

Actual:   [[1.4584, 1.3875, 1.4584, 1.3262, 1.1002, 0.859, 1.0941, 0.6737, 1.0751, 1.3347, 0.8595, 0.9346, 1.0742, 0.9544, 1.0738, 0.9891, 0.9897, 0.7093, 1.1209, 0.9483, 0.7775, 1.368, 1.2465, 1.1754, 0.8307, 1.2518, 0.8542, 1.1519, 0.9537, 1.0184, 1.1095, 1.0012, 1.0342, 1.1672, 1.0189, 1.0099, 0.8294, 1.1954, 1.0344, 1.0768, 1.0104, 0.936, 1.2855, 0.7651, 1.3041, 0.8571, 1.307, 0.7546]]

Expected: [[1.4585, 1.3875, 1.4585, 1.3262, 1.1002, 0.859, 1.0941, 0.6738, 1.0751, 1.3347, 0.8595, 0.9346, 1.0742, 0.9544, 1.0738, 0.9891, 0.9897, 0.7093, 1.1209, 0.9483, 0.7775, 1.368, 1.2466, 1.1754, 0.8307, 1.2518, 0.8542, 1.1519, 0.9537, 1.0184, 1.1095, 1.0012, 1.0342, 1.1672, 1.0189, 1.0099, 0.8294, 1.1954, 1.0344, 1.0768, 1.0104, 0.936, 1.2855, 0.7651, 1.3041, 0.8571, 1.307, 0.7546]]