import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer77891 = tf.keras.layers.Input(shape=([4, 4]))
in0Con31113 = tf.keras.layers.Input(shape=([6, 6, 2]))
in0Zer80613 = tf.keras.layers.Input(shape=([3, 3, 3]))
in0Ave80790 = tf.keras.layers.Input(shape=([2, 2]))
in1Ave80790 = tf.keras.layers.Input(shape=([2, 2]))
in0Con61461 = tf.keras.layers.Input(shape=([2, 2]))
in0Cro17401 = tf.keras.layers.Input(shape=([4, 4]))
in0Max89783 = tf.keras.layers.Input(shape=([1, 2]))
in1Max89783 = tf.keras.layers.Input(shape=([1, 2]))
in0Con96833 = tf.keras.layers.Input(shape=([5]))
in0Con99349 = tf.keras.layers.Input(shape=([100]))

Zer77891 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer77891', )(in0Zer77891)
Res43480 = keras.layers.Reshape((6, 4, 1), name = 'Res43480', )(Zer77891)
Zer16738 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer16738', )(Res43480)
Con31113 = keras.layers.Concatenate(axis=3, name = 'Con31113', )([Zer16738,in0Con31113])
Zer80613 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer80613', )(in0Zer80613)
Zer84107 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer84107', )(Zer80613)
Ave40325 = keras.layers.Average(name = 'Ave40325', )([Con31113,Zer84107])
Res6775 = keras.layers.Reshape((6, 18), name = 'Res6775', )(Ave40325)
Fla11041 = keras.layers.Flatten(name = 'Fla11041', )(Res6775)
Ave80790 = keras.layers.Average(name = 'Ave80790', )([in0Ave80790,in1Ave80790])
Con61461 = keras.layers.Concatenate(axis=2, name = 'Con61461', )([Ave80790,in0Con61461])
Cro17401 = keras.layers.Cropping1D(cropping=((3, 0)), name = 'Cro17401', )(in0Cro17401)
Zer86237 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer86237', )(Cro17401)
Ave54788 = keras.layers.Average(name = 'Ave54788', )([Con61461,Zer86237])
Fla50749 = keras.layers.Flatten(name = 'Fla50749', )(Ave54788)
Max89783 = keras.layers.Maximum(name = 'Max89783', )([in0Max89783,in1Max89783])
GRU53919 = keras.layers.GRU(3,reset_after=False, recurrent_activation='sigmoid', name = 'GRU53919', )(Max89783)
Con96833 = keras.layers.Concatenate(axis=1, name = 'Con96833', )([GRU53919,in0Con96833])
Add38038 = keras.layers.Add(name = 'Add38038', )([Fla50749,Con96833])
Con99349 = keras.layers.Concatenate(axis=1, name = 'Con99349', )([Add38038,in0Con99349])
Max25516 = keras.layers.Maximum(name = 'Max25516', )([Fla11041,Con99349])
model = tf.keras.models.Model(inputs=[in0Zer77891,in0Con31113,in0Zer80613,in0Ave80790,in1Ave80790,in0Con61461,in0Cro17401,in0Max89783,in1Max89783,in0Con96833,in0Con99349], outputs=Max25516)
w = model.get_layer('GRU53919').get_weights() 
w[0] = np.array([[1, 4, 3, 5, 1, 9, 7, 1, 8], [5, 10, 2, 1, 8, 2, 9, 7, 3]])
w[1] = np.array([[8, 6, 3, 10, 8, 3, 6, 1, 6], [1, 3, 3, 8, 10, 8, 7, 6, 5], [10, 8, 1, 4, 2, 3, 9, 10, 9]])
w[2] = np.array([3, 8, 7, 10, 1, 10, 4, 4, 4])
model.get_layer('GRU53919').set_weights(w) 
in0Zer77891 = tf.constant([[[1.2982, 1.6453, 1.7642, 1.3821], [1.7799, 1.9512, 1.6704, 1.7968], [1.5083, 1.9429, 1.8854, 1.6809], [1.2148, 1.562, 1.0256, 1.0163]]])
in0Con31113 = tf.constant([[[[0.1002, 0.0073], [0.6545, 0.6453], [0.1749, 0.4042], [0.7462, 0.0835], [0.7945, 0.278], [0.2637, 0.5232]], [[0.1818, 0.9012], [0.2319, 0.8072], [0.5526, 0.048], [0.9736, 0.4717], [0.2359, 0.9314], [0.2981, 0.5284]], [[0.4919, 0.9276], [0.3047, 0.7202], [0.7572, 0.6398], [0.3402, 0.2105], [0.02, 0.583], [0.9539, 0.8515]], [[0.907, 0.6616], [0.3985, 0.0156], [0.8508, 0.6538], [0.3403, 0.4746], [0.4002, 0.1176], [0.9652, 0.9603]], [[0.3296, 0.4892], [0.5899, 0.8536], [0.7162, 0.6579], [0.2234, 0.913], [0.557, 0.971], [0.2618, 0.0747]], [[0.8205, 0.4452], [0.6467, 0.1386], [0.0493, 0.9451], [0.3653, 0.5829], [0.7602, 0.2253], [0.1344, 0.848]]]])
in0Zer80613 = tf.constant([[[[1.6492, 1.6649, 1.9311], [1.5384, 1.3817, 1.5706], [1.3139, 1.2415, 1.654]], [[1.3659, 1.9772, 1.2507], [1.9646, 1.705, 1.5294], [1.326, 1.7798, 1.6854]], [[1.308, 1.3047, 1.8818], [1.8733, 1.9164, 1.9925], [1.3777, 1.7106, 1.3771]]]])
in0Ave80790 = tf.constant([[[0.3671, 0.3286], [0.342, 0.41]]])
in1Ave80790 = tf.constant([[[0.4722, 0.2839], [0.3665, 0.7548]]])
in0Con61461 = tf.constant([[[0.7008, 0.4976], [0.6143, 0.0422]]])
in0Cro17401 = tf.constant([[[1.0484, 1.7485, 1.141, 1.7742], [1.7731, 1.758, 1.042, 1.7987], [1.9615, 1.2824, 1.5243, 1.8023], [1.7215, 1.1446, 1.9079, 1.037]]])
in0Max89783 = tf.constant([[[0.8447, 0.4982]]])
in1Max89783 = tf.constant([[[0.5716, 0.1927]]])
in0Con96833 = tf.constant([[0.4948, 0.0829, 0.6184, 0.6814, 0.437]])
in0Con99349 = tf.constant([[0.9648, 0.5128, 0.9415, 0.1166, 0.4173, 0.7575, 0.0303, 0.8096, 0.5516, 0.2833, 0.1147, 0.416, 0.8115, 0.2955, 0.824, 0.9362, 0.8547, 0.9103, 0.5778, 0.9981, 0.3505, 0.2213, 0.3728, 0.7889, 0.7237, 0.6893, 0.2596, 0.0239, 0.7411, 0.3947, 0.9636, 0.2358, 0.2409, 0.5367, 0.7087, 0.8493, 0.3641, 0.3218, 0.068, 0.0852, 0.3637, 0.043, 0.583, 0.7305, 0.4388, 0.7193, 0.9681, 0.2039, 0.0689, 0.1395, 0.9489, 0.1496, 0.0103, 0.5315, 0.1711, 0.9994, 0.4534, 0.3688, 0.1596, 0.5588, 0.8416, 0.0132, 0.0078, 0.6904, 0.501, 0.996, 0.3347, 0.5976, 0.5435, 0.7414, 0.0586, 0.0439, 0.4701, 0.4491, 0.7066, 0.0801, 0.5225, 0.6694, 0.3022, 0.5018, 0.1111, 0.8278, 0.3574, 0.3057, 0.5813, 0.5867, 0.1313, 0.8757, 0.1696, 0.4674, 0.1121, 0.493, 0.2514, 0.5972, 0.6296, 0.0325, 0.8817, 0.7974, 0.6107, 0.388]])
print (np.array2string(model.predict([in0Zer77891,in0Con31113,in0Zer80613,in0Ave80790,in1Ave80790,in0Con61461,in0Cro17401,in0Max89783,in1Max89783,in0Con96833,in0Con99349],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max25516.png')

LZer77891 = zero_padding1D_layer([[[1.2982, 1.6453, 1.7642, 1.3821], [1.7799, 1.9512, 1.6704, 1.7968], [1.5083, 1.9429, 1.8854, 1.6809], [1.2148, 1.562, 1.0256, 1.0163]]], 1, 1, Zer77891), 
LRes43480 = reshape_layer(Zer77891, [6, 4, 1], Res43480), 
LZer16738 = zero_padding2D_layer(Res43480, 0, 0, 2, 0, Zer16738), 
LCon31113 = concatenate_layer([Zer16738,[[[[0.1002, 0.0073], [0.6545, 0.6453], [0.1749, 0.4042], [0.7462, 0.0835], [0.7945, 0.278], [0.2637, 0.5232]], [[0.1818, 0.9012], [0.2319, 0.8072], [0.5526, 0.048], [0.9736, 0.4717], [0.2359, 0.9314], [0.2981, 0.5284]], [[0.4919, 0.9276], [0.3047, 0.7202], [0.7572, 0.6398], [0.3402, 0.2105], [0.02, 0.583], [0.9539, 0.8515]], [[0.907, 0.6616], [0.3985, 0.0156], [0.8508, 0.6538], [0.3403, 0.4746], [0.4002, 0.1176], [0.9652, 0.9603]], [[0.3296, 0.4892], [0.5899, 0.8536], [0.7162, 0.6579], [0.2234, 0.913], [0.557, 0.971], [0.2618, 0.0747]], [[0.8205, 0.4452], [0.6467, 0.1386], [0.0493, 0.9451], [0.3653, 0.5829], [0.7602, 0.2253], [0.1344, 0.848]]]]], 3, Con31113), 
LZer80613 = zero_padding2D_layer([[[[1.6492, 1.6649, 1.9311], [1.5384, 1.3817, 1.5706], [1.3139, 1.2415, 1.654]], [[1.3659, 1.9772, 1.2507], [1.9646, 1.705, 1.5294], [1.326, 1.7798, 1.6854]], [[1.308, 1.3047, 1.8818], [1.8733, 1.9164, 1.9925], [1.3777, 1.7106, 1.3771]]]], 1, 1, 1, 1, Zer80613), 
LZer84107 = zero_padding2D_layer(Zer80613, 1, 0, 1, 0, Zer84107), 
LAve40325 = average_layer([Con31113,Zer84107], Ave40325), 
LRes6775 = reshape_layer(Ave40325, [6, 18], Res6775), 
LFla11041 = flatten_layer(Res6775, Fla11041), 
LAve80790 = average_layer([[[[0.3671, 0.3286], [0.342, 0.41]]], [[[0.4722, 0.2839], [0.3665, 0.7548]]]], Ave80790), 
LCon61461 = concatenate_layer([Ave80790,[[[0.7008, 0.4976], [0.6143, 0.0422]]]], 2, Con61461), 
LCro17401 = cropping1D_layer([[[1.0484, 1.7485, 1.141, 1.7742], [1.7731, 1.758, 1.042, 1.7987], [1.9615, 1.2824, 1.5243, 1.8023], [1.7215, 1.1446, 1.9079, 1.037]]], 3, 0, Cro17401), 
LZer86237 = zero_padding1D_layer(Cro17401, 1, 0, Zer86237), 
LAve54788 = average_layer([Con61461,Zer86237], Ave54788), 
LFla50749 = flatten_layer(Ave54788, Fla50749), 
LMax89783 = maximum_layer([[[[0.8447, 0.4982]]], [[[0.5716, 0.1927]]]], Max89783), 
LGRU53919 = gru_layer(Max89783,[[1, 4, 3, 5, 1, 9, 7, 1, 8], [5, 10, 2, 1, 8, 2, 9, 7, 3]],[[8, 6, 3, 10, 8, 3, 6, 1, 6], [1, 3, 3, 8, 10, 8, 7, 6, 5], [10, 8, 1, 4, 2, 3, 9, 10, 9]],[3, 8, 7, 10, 1, 10, 4, 4, 4], false, GRU53919), 
LCon96833 = concatenate_layer([GRU53919,[[0.4948, 0.0829, 0.6184, 0.6814, 0.437]]], 1, Con96833), 
LAdd38038 = add_layer([Fla50749,Con96833], Add38038), 
LCon99349 = concatenate_layer([Add38038,[[0.9648, 0.5128, 0.9415, 0.1166, 0.4173, 0.7575, 0.0303, 0.8096, 0.5516, 0.2833, 0.1147, 0.416, 0.8115, 0.2955, 0.824, 0.9362, 0.8547, 0.9103, 0.5778, 0.9981, 0.3505, 0.2213, 0.3728, 0.7889, 0.7237, 0.6893, 0.2596, 0.0239, 0.7411, 0.3947, 0.9636, 0.2358, 0.2409, 0.5367, 0.7087, 0.8493, 0.3641, 0.3218, 0.068, 0.0852, 0.3637, 0.043, 0.583, 0.7305, 0.4388, 0.7193, 0.9681, 0.2039, 0.0689, 0.1395, 0.9489, 0.1496, 0.0103, 0.5315, 0.1711, 0.9994, 0.4534, 0.3688, 0.1596, 0.5588, 0.8416, 0.0132, 0.0078, 0.6904, 0.501, 0.996, 0.3347, 0.5976, 0.5435, 0.7414, 0.0586, 0.0439, 0.4701, 0.4491, 0.7066, 0.0801, 0.5225, 0.6694, 0.3022, 0.5018, 0.1111, 0.8278, 0.3574, 0.3057, 0.5813, 0.5867, 0.1313, 0.8757, 0.1696, 0.4674, 0.1121, 0.493, 0.2514, 0.5972, 0.6296, 0.0325, 0.8817, 0.7974, 0.6107, 0.388]]], 1, Con99349), 
LMax25516 = maximum_layer([Fla11041,Con99349], Max25516), 
exec_layers([LZer77891,LRes43480,LZer16738,LCon31113,LZer80613,LZer84107,LAve40325,LRes6775,LFla11041,LAve80790,LCon61461,LCro17401,LZer86237,LAve54788,LFla50749,LMax89783,LGRU53919,LCon96833,LAdd38038,LCon99349,LMax25516],["Zer77891","Res43480","Zer16738","Con31113","Zer80613","Zer84107","Ave40325","Res6775","Fla11041","Ave80790","Con61461","Cro17401","Zer86237","Ave54788","Fla50749","Max89783","GRU53919","Con96833","Add38038","Con99349","Max25516"],Max25516,"Max25516")

Actual (Unparsed): [[0.2115938, 0.1531251, 0.3504267, 0.7436000, 1.1207750, 1.4819000, 1.9425000, 0.9766000, 0.9648000, 0.5128000, 0.9415000, 0.1166000, 0.4173000, 0.7575000, 0.1390000, 0.8096000, 0.5516000, 0.2833000, 0.1147000, 0.4160000, 0.8115000, 0.2955000, 0.8240000, 0.9362000, 0.8547000, 0.9103000, 0.5778000, 0.9981000, 0.4868000, 0.2358500, 0.8821000, 0.7889000, 0.7237000, 0.6910500, 0.2596000, 0.2642000, 0.7411000, 0.3947000, 0.9636000, 0.2358000, 0.2409000, 0.5367000, 1.7145500, 1.2110500, 1.2854500, 1.7448000, 0.8609500, 0.8905500, 1.4921500, 0.6307500, 1.1185000, 0.8984000, 0.4769500, 0.7193000, 0.9681000, 0.4535000, 0.3308000, 0.1395000, 0.9489000, 0.1496000, 1.4371000, 1.4140000, 0.9522500, 1.9537500, 1.0226500, 1.0020000, 1.6057000, 1.0900000, 0.9015000, 0.8404500, 0.4826000, 0.6904000, 0.5010000, 0.9960000, 0.3347000, 0.5976000, 0.5435000, 0.7414000, 1.2614000, 1.0104500, 1.2698500, 1.7176500, 1.0699000, 1.4527500, 1.2016500, 1.1338000, 1.1740500, 0.5081500, 0.1309000, 0.8278000, 0.3574000, 0.4102500, 0.5813000, 0.5867000, 0.3233500, 0.8757000, 0.1696000, 0.4674000, 0.4725500, 0.4930000, 0.2514000, 0.5972000, 0.6296000, 0.3801000, 0.8817000, 0.7974000, 0.6107000, 0.4240000]]

Expected (Unparsed): [[0.21159377097656745,0.1531250784503266,0.35042670855294183,0.7436,1.120775,1.4819,1.9425,0.9765999999999999,0.9648,0.5128,0.9415,0.1166,0.4173,0.7575,0.139,0.8096,0.5516,0.2833,0.1147,0.416,0.8115,0.2955,0.824,0.9362,0.8547,0.9103,0.5778,0.9981,0.4868,0.23585,0.8821,0.7889,0.7237,0.69105,0.2596,0.2642,0.7411,0.3947,0.9636,0.2358,0.2409,0.5367,1.71455,1.21105,1.28545,1.7448000000000001,0.86095,0.89055,1.49215,0.63075,1.1185,0.8984,0.47695,0.7193,0.9681,0.4535,0.3308,0.1395,0.9489,0.1496,1.4371,1.4140000000000001,0.95225,1.9537499999999999,1.02265,1.002,1.6057000000000001,1.09,0.9015,0.84045,0.4826,0.6904,0.501,0.996,0.3347,0.5976,0.5435,0.7414,1.2614,1.01045,1.26985,1.71765,1.0699,1.45275,1.2016499999999999,1.1338,1.17405,0.50815,0.1309,0.8278,0.3574,0.41025,0.5813,0.5867,0.32335,0.8757,0.1696,0.4674,0.47255,0.493,0.2514,0.5972,0.6296,0.3801,0.8817,0.7974,0.6107,0.424]]

Actual:   [[0.2116, 0.1532, 0.3505, 0.7436, 1.1208, 1.4819, 1.9425, 0.9766, 0.9648, 0.5128, 0.9415, 0.1166, 0.4173, 0.7575, 0.139, 0.8096, 0.5516, 0.2833, 0.1147, 0.416, 0.8115, 0.2955, 0.824, 0.9362, 0.8547, 0.9103, 0.5778, 0.9981, 0.4868, 0.2359, 0.8821, 0.7889, 0.7237, 0.6911, 0.2596, 0.2642, 0.7411, 0.3947, 0.9636, 0.2358, 0.2409, 0.5367, 1.7146, 1.2111, 1.2855, 1.7448, 0.861, 0.8906, 1.4922, 0.6308, 1.1185, 0.8984, 0.477, 0.7193, 0.9681, 0.4535, 0.3308, 0.1395, 0.9489, 0.1496, 1.4371, 1.414, 0.9523, 1.9538, 1.0227, 1.002, 1.6057, 1.09, 0.9015, 0.8405, 0.4826, 0.6904, 0.501, 0.996, 0.3347, 0.5976, 0.5435, 0.7414, 1.2614, 1.0105, 1.2699, 1.7177, 1.0699, 1.4528, 1.2017, 1.1338, 1.1741, 0.5082, 0.1309, 0.8278, 0.3574, 0.4103, 0.5813, 0.5867, 0.3234, 0.8757, 0.1696, 0.4674, 0.4726, 0.493, 0.2514, 0.5972, 0.6296, 0.3801, 0.8817, 0.7974, 0.6107, 0.424]]

Expected: [[0.2116, 0.1532, 0.3505, 0.7436, 1.1208, 1.4819, 1.9425, 0.9766, 0.9648, 0.5128, 0.9415, 0.1166, 0.4173, 0.7575, 0.139, 0.8096, 0.5516, 0.2833, 0.1147, 0.416, 0.8115, 0.2955, 0.824, 0.9362, 0.8547, 0.9103, 0.5778, 0.9981, 0.4868, 0.2359, 0.8821, 0.7889, 0.7237, 0.6911, 0.2596, 0.2642, 0.7411, 0.3947, 0.9636, 0.2358, 0.2409, 0.5367, 1.7146, 1.2111, 1.2855, 1.7449, 0.861, 0.8906, 1.4922, 0.6308, 1.1185, 0.8984, 0.477, 0.7193, 0.9681, 0.4535, 0.3308, 0.1395, 0.9489, 0.1496, 1.4371, 1.4141, 0.9523, 1.9538, 1.0227, 1.002, 1.6058, 1.09, 0.9015, 0.8405, 0.4826, 0.6904, 0.501, 0.996, 0.3347, 0.5976, 0.5435, 0.7414, 1.2614, 1.0105, 1.2699, 1.7177, 1.0699, 1.4528, 1.2017, 1.1338, 1.1741, 0.5082, 0.1309, 0.8278, 0.3574, 0.4103, 0.5813, 0.5867, 0.3234, 0.8757, 0.1696, 0.4674, 0.4726, 0.493, 0.2514, 0.5972, 0.6296, 0.3801, 0.8817, 0.7974, 0.6107, 0.424]]