import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sep27459 = tf.keras.layers.Input(shape=([1, 1]))
in0Min16186 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in1Min16186 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0Con65682 = tf.keras.layers.Input(shape=([2]))

Sep27459 = keras.layers.SeparableConv1D(4, (1),strides=(1), padding='same', name = 'Sep27459', )(in0Sep27459)
Fla43567 = keras.layers.Flatten(name = 'Fla43567', )(Sep27459)
Min16186 = keras.layers.Minimum(name = 'Min16186', )([in0Min16186,in1Min16186])
Res2830 = keras.layers.Reshape((1, 2, 1), name = 'Res2830', )(Min16186)
Res27449 = keras.layers.Reshape((1, 2), name = 'Res27449', )(Res2830)
Glo16680 = keras.layers.GlobalAveragePooling1D(name = 'Glo16680', )(Res27449)
Con65682 = keras.layers.Concatenate(axis=1, name = 'Con65682', )([Glo16680,in0Con65682])
Mul64448 = keras.layers.Multiply(name = 'Mul64448', )([Fla43567,Con65682])
Lay55918 = keras.layers.LayerNormalization(axis=1, epsilon=2.2991683072544484, name = 'Lay55918', )(Mul64448)
model = tf.keras.models.Model(inputs=[in0Sep27459,in0Min16186,in1Min16186,in0Con65682], outputs=Lay55918)
w = model.get_layer('Sep27459').get_weights() 
w[0] = np.array([[[0.7044]]])
w[1] = np.array([[[0.1678, 0.9858, 0.8343, 0.6911]]])
w[2] = np.array([0, 0, 0, 0])
model.get_layer('Sep27459').set_weights(w) 
in0Sep27459 = tf.constant([[[0.9707]]])
in0Min16186 = tf.constant([[[[[0.4187]], [[0.6236]]]]])
in1Min16186 = tf.constant([[[[[0.8465]], [[0.6492]]]]])
in0Con65682 = tf.constant([[0.1711, 0.7733]])
print (np.array2string(model.predict([in0Sep27459,in0Min16186,in1Min16186,in0Con65682],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Lay55918.png')

LSep27459 = separable_conv1D_layer([[[0.9707]]], 1,[[[[0.7044]]],[[[0.1678, 0.9858, 0.8343, 0.6911]]]],[0, 0, 0, 0], 1, true, Sep27459), 
LFla43567 = flatten_layer(Sep27459, Fla43567), 
LMin16186 = minimum_layer([[[[[[0.4187]], [[0.6236]]]]], [[[[[0.8465]], [[0.6492]]]]]], Min16186), 
LRes2830 = reshape_layer(Min16186, [1, 2, 1], Res2830), 
LRes27449 = reshape_layer(Res2830, [1, 2], Res27449), 
LGlo16680 = global_average_pooling1D_layer(Res27449, Glo16680), 
LCon65682 = concatenate_layer([Glo16680,[[0.1711, 0.7733]]], 1, Con65682), 
LMul64448 = multiply_layer([Fla43567,Con65682], Mul64448), 
LLay55918 = layer_normalization_layer(Mul64448, 1, 2.2991683072544484, Lay55918), 
exec_layers([LSep27459,LFla43567,LMin16186,LRes2830,LRes27449,LGlo16680,LCon65682,LMul64448,LLay55918],["Sep27459","Fla43567","Min16186","Res2830","Res27449","Glo16680","Con65682","Mul64448","Lay55918"],Lay55918,"Lay55918")

Actual (Unparsed): [[-0.1211922, 0.1229469, -0.0886885, 0.0869339]]

Expected (Unparsed): [[-0.12119224209305361,0.1229468526328798,-0.08868851890476655,0.08693390836494028]]

Actual:   [[-0.1211, 0.123, -0.0886, 0.087]]

Expected: [[-0.1211, 0.123, -0.0886, 0.087]]