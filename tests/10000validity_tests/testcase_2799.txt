import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer88858 = tf.keras.layers.Input(shape=([1, 4, 1, 1]))
in0Glo93251 = tf.keras.layers.Input(shape=([2, 2]))
in0Glo15563 = tf.keras.layers.Input(shape=([2, 1]))
in0Con90449 = tf.keras.layers.Input(shape=([1]))
in0Max97646 = tf.keras.layers.Input(shape=([2, 2]))
in1Max97646 = tf.keras.layers.Input(shape=([2, 2]))
in0Add35098 = tf.keras.layers.Input(shape=([1, 2, 1]))
in1Add35098 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con62987 = tf.keras.layers.Input(shape=([3, 16]))

Zer88858 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer88858', )(in0Zer88858)
Mas24571 = keras.layers.Masking(mask_value=1, name = 'Mas24571', )(Zer88858)
Res88218 = keras.layers.Reshape((3, 6, 3), name = 'Res88218', )(Mas24571)
Res44481 = keras.layers.Reshape((3, 18), name = 'Res44481', )(Res88218)
Glo93251 = keras.layers.GlobalAveragePooling1D(name = 'Glo93251', )(in0Glo93251)
Glo15563 = keras.layers.GlobalAveragePooling1D(name = 'Glo15563', )(in0Glo15563)
Con90449 = keras.layers.Concatenate(axis=1, name = 'Con90449', )([Glo15563,in0Con90449])
Min69640 = keras.layers.Minimum(name = 'Min69640', )([Glo93251,Con90449])
Res82415 = keras.layers.Reshape((2, 1), name = 'Res82415', )(Min69640)
Max97646 = keras.layers.Maximum(name = 'Max97646', )([in0Max97646,in1Max97646])
Res65034 = keras.layers.Reshape((2, 2, 1), name = 'Res65034', )(Max97646)
Add35098 = keras.layers.Add(name = 'Add35098', )([in0Add35098,in1Add35098])
Zer40402 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer40402', )(Add35098)
Max21152 = keras.layers.Maximum(name = 'Max21152', )([Res65034,Zer40402])
Max41644 = keras.layers.MaxPool2D(pool_size=(1, 1), strides=(1, 1), padding='same', name = 'Max41644', )(Max21152)
Res73256 = keras.layers.Reshape((2, 2), name = 'Res73256', )(Max41644)
Dot34084 = keras.layers.Dot(axes=(1, 1), name = 'Dot34084', )([Res82415,Res73256])
Zer81759 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer81759', )(Dot34084)
Con62987 = keras.layers.Concatenate(axis=2, name = 'Con62987', )([Zer81759,in0Con62987])
Min96713 = keras.layers.Minimum(name = 'Min96713', )([Res44481,Con62987])
model = tf.keras.models.Model(inputs=[in0Zer88858,in0Glo93251,in0Glo15563,in0Con90449,in0Max97646,in1Max97646,in0Add35098,in1Add35098,in0Con62987], outputs=Min96713)
in0Zer88858 = tf.constant([[[[[1.2947]], [[1.5221]], [[1.2388]], [[1.7148]]]]])
in0Glo93251 = tf.constant([[[1.4522, 1.9012], [1.9545, 1.3494]]])
in0Glo15563 = tf.constant([[[1.9897], [1.2869]]])
in0Con90449 = tf.constant([[0.6495]])
in0Max97646 = tf.constant([[[0.6903, 0.8731], [0.6971, 0.3225]]])
in1Max97646 = tf.constant([[[0.7509, 0.9333], [0.0746, 0.4689]]])
in0Add35098 = tf.constant([[[[0.8363], [0.1438]]]])
in1Add35098 = tf.constant([[[[0.5988], [0.1939]]]])
in0Con62987 = tf.constant([[[0.8099, 0.5668, 0.5463, 0.4537, 0.8336, 0.6998, 0.4485, 0.2627, 0.2421, 0.2855, 0.6907, 0.2755, 0.4498, 0.2216, 0.8534, 0.4955], [0.4765, 0.565, 0.3607, 0.137, 0.3559, 0.9236, 0.1567, 0.3067, 0.9792, 0.5098, 0.7313, 0.6355, 0.8681, 0.0035, 0.5877, 0.4487], [0.4106, 0.665, 0.6014, 0.8084, 0.0348, 0.5898, 0.497, 0.1648, 0.6438, 0.6024, 0.841, 0.4145, 0.3908, 0.0497, 0.5352, 0.8778]]])
print (np.array2string(model.predict([in0Zer88858,in0Glo93251,in0Glo15563,in0Con90449,in0Max97646,in1Max97646,in0Add35098,in1Add35098,in0Con62987],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min96713.png')

LZer88858 = zero_padding3D_layer([[[[[1.2947]], [[1.5221]], [[1.2388]], [[1.7148]]]]], 1, 1, 1, 1, 1, 1, Zer88858), 
LMas24571 = masking_layer(Zer88858, 1, Mas24571), 
LRes88218 = reshape_layer(Mas24571, [3, 6, 3], Res88218), 
LRes44481 = reshape_layer(Res88218, [3, 18], Res44481), 
LGlo93251 = global_average_pooling1D_layer([[[1.4522, 1.9012], [1.9545, 1.3494]]], Glo93251), 
LGlo15563 = global_average_pooling1D_layer([[[1.9897], [1.2869]]], Glo15563), 
LCon90449 = concatenate_layer([Glo15563,[[0.6495]]], 1, Con90449), 
LMin69640 = minimum_layer([Glo93251,Con90449], Min69640), 
LRes82415 = reshape_layer(Min69640, [2, 1], Res82415), 
LMax97646 = maximum_layer([[[[0.6903, 0.8731], [0.6971, 0.3225]]], [[[0.7509, 0.9333], [0.0746, 0.4689]]]], Max97646), 
LRes65034 = reshape_layer(Max97646, [2, 2, 1], Res65034), 
LAdd35098 = add_layer([[[[[0.8363], [0.1438]]]], [[[[0.5988], [0.1939]]]]], Add35098), 
LZer40402 = zero_padding2D_layer(Add35098, 1, 0, 0, 0, Zer40402), 
LMax21152 = maximum_layer([Res65034,Zer40402], Max21152), 
LMax41644 = max_pool2D_layer(Max21152, 1, 1, 1, 1, true, Max41644), 
LRes73256 = reshape_layer(Max41644, [2, 2], Res73256), 
LDot34084 = dot_layer(Res82415,Res73256, 1, 1, Dot34084), 
LZer81759 = zero_padding1D_layer(Dot34084, 2, 0, Zer81759), 
LCon62987 = concatenate_layer([Zer81759,[[[0.8099, 0.5668, 0.5463, 0.4537, 0.8336, 0.6998, 0.4485, 0.2627, 0.2421, 0.2855, 0.6907, 0.2755, 0.4498, 0.2216, 0.8534, 0.4955], [0.4765, 0.565, 0.3607, 0.137, 0.3559, 0.9236, 0.1567, 0.3067, 0.9792, 0.5098, 0.7313, 0.6355, 0.8681, 0.0035, 0.5877, 0.4487], [0.4106, 0.665, 0.6014, 0.8084, 0.0348, 0.5898, 0.497, 0.1648, 0.6438, 0.6024, 0.841, 0.4145, 0.3908, 0.0497, 0.5352, 0.8778]]]], 2, Con62987), 
LMin96713 = minimum_layer([Res44481,Con62987], Min96713), 
exec_layers([LZer88858,LMas24571,LRes88218,LRes44481,LGlo93251,LGlo15563,LCon90449,LMin69640,LRes82415,LMax97646,LRes65034,LAdd35098,LZer40402,LMax21152,LMax41644,LRes73256,LDot34084,LZer81759,LCon62987,LMin96713],["Zer88858","Mas24571","Res88218","Res44481","Glo93251","Glo15563","Con90449","Min69640","Res82415","Max97646","Res65034","Add35098","Zer40402","Max21152","Max41644","Res73256","Dot34084","Zer81759","Con62987","Min96713"],Min96713,"Min96713")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.3607000, 0.0000000, 0.0000000, 0.9236000, 0.0000000, 0.0000000, 0.9792000, 0.0000000, 0.0000000, 0.6355000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000]]]

Expected (Unparsed): [[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0.3607,0,0,0.9236,0,0,0.9792,0,0,0.6355,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]]

Actual:   [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0.3607, 0, 0, 0.9236, 0, 0, 0.9792, 0, 0, 0.6355, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]

Expected: [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0.3607, 0, 0, 0.9236, 0, 0, 0.9792, 0, 0, 0.6355, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]