import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con63012 = tf.keras.layers.Input(shape=([2, 1, 1, 1]))

Con63012 = keras.layers.Conv3D(4, (1, 1, 1),strides=(1, 1, 1), padding='valid', dilation_rate=(1, 1, 1), name = 'Con63012', )(in0Con63012)
Bat88861 = keras.layers.BatchNormalization(axis=2, epsilon=0.6616518892437584,  name = 'Bat88861', )(Con63012)
model = tf.keras.models.Model(inputs=[in0Con63012], outputs=Bat88861)
w = model.get_layer('Con63012').get_weights() 
w[0] = np.array([[[[[0.9491, 0.6603, 0.442, 0.0526]]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con63012').set_weights(w) 
w = model.get_layer('Bat88861').get_weights() 
w[0] = np.array([0.8002])
w[1] = np.array([0.5222])
w[2] = np.array([0.6222])
w[3] = np.array([0.7818])
model.get_layer('Bat88861').set_weights(w) 
in0Con63012 = tf.constant([[[[[0.6987]]], [[[0.4898]]]]])
print (np.array2string(model.predict([in0Con63012],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat88861.png')

LCon63012 = conv3D_layer([[[[[0.6987]]], [[[0.4898]]]]], 1, 1, 1,[[[[[0.9491, 0.6603, 0.442, 0.0526]]]]],[0, 0, 0, 0], 1, 1, 1, false, 1, 1, 1, Con63012), 
LBat88861 = batch_normalization_layer(Con63012, 2, 0.6616518892437584, [0.8002], [0.5222], [0.6222], [0.7818], Bat88861), 
exec_layers([LCon63012,LBat88861],["Con63012","Bat88861"],Bat88861,"Bat88861")

Actual (Unparsed): [[[[[0.5494650, 0.4150693, 0.3134814, 0.1322706]]], [[[0.4174121, 0.3231985, 0.2519838, 0.1249521]]]]]

Expected (Unparsed): [[[[[0.5494649432402664,0.4150692590528565,0.31348138558294114,0.13227058425822724]]],[[[0.417412085614151,0.32319853743182186,0.25198379515965275,0.12495209272821595]]]]]

Actual:   [[[[[0.5495, 0.4151, 0.3135, 0.1323]]], [[[0.4175, 0.3232, 0.252, 0.125]]]]]

Expected: [[[[[0.5495, 0.4151, 0.3135, 0.1323]]], [[[0.4175, 0.3232, 0.252, 0.125]]]]]