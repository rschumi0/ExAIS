import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con84972 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Bat66120 = tf.keras.layers.Input(shape=([3]))
in0Con4032 = tf.keras.layers.Input(shape=([3, 3, 3, 2]))

Con84972 = keras.layers.Conv3DTranspose(3, (2, 2, 2),strides=(1, 1, 1), padding='valid', name = 'Con84972', )(in0Con84972)
Bat66120 = keras.layers.BatchNormalization(axis=1, epsilon=0.6183697463793649,  name = 'Bat66120', )(in0Bat66120)
Res62534 = keras.layers.Reshape((3, 1), name = 'Res62534', )(Bat66120)
Res24825 = keras.layers.Reshape((3, 1, 1), name = 'Res24825', )(Res62534)
Res11375 = keras.layers.Reshape((3, 1, 1, 1), name = 'Res11375', )(Res24825)
Up_12964 = keras.layers.UpSampling3D(size=(1, 1, 2), name = 'Up_12964', )(Res11375)
Lay70459 = keras.layers.LayerNormalization(axis=1, epsilon=2.515414804063817, name = 'Lay70459', )(Up_12964)
Zer46417 = keras.layers.ZeroPadding3D(padding=((0, 0), (2, 0), (1, 0)), name = 'Zer46417', )(Lay70459)
Con4032 = keras.layers.Concatenate(axis=4, name = 'Con4032', )([Zer46417,in0Con4032])
Add8563 = keras.layers.Add(name = 'Add8563', )([Con84972,Con4032])
model = tf.keras.models.Model(inputs=[in0Con84972,in0Bat66120,in0Con4032], outputs=Add8563)
w = model.get_layer('Con84972').get_weights() 
w[0] = np.array([[[[[0.1724, 0.6806], [0.129, 0.9695], [0.5357, 0.7988]], [[0.3738, 0.8134], [0.1381, 0.9564], [0.0147, 0.899]]], [[[0.6412, 0.2385], [0.0715, 0.5008], [0.6216, 0.7917]], [[0.9495, 0.0346], [0.0955, 0.0872], [0.2358, 0.1572]]]], [[[[0.6883, 0.0952], [0.7469, 0.6203], [0.3426, 0.8711]], [[0.3635, 0.9481], [0.871, 0.133], [0.9894, 0.0999]]], [[[0.1076, 0.7725], [0.3121, 0.1556], [0.8886, 0.8777]], [[0.9069, 0.7215], [0.6024, 0.7759], [0.6301, 0.1881]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con84972').set_weights(w) 
w = model.get_layer('Bat66120').get_weights() 
w[0] = np.array([0.4801, 0.2793, 0.2577])
w[1] = np.array([0.7095, 0.6083, 0.1573])
w[2] = np.array([0.4912, 0.526, 0.5049])
w[3] = np.array([0.8606, 0.9766, 0.3024])
model.get_layer('Bat66120').set_weights(w) 
in0Con84972 = tf.constant([[[[[0.4105, 0.1995], [0.5752, 0.1915]], [[0.2058, 0.3887], [0.4494, 0.8513]]], [[[0.1551, 0.7927], [0.4932, 0.1544]], [[0.2457, 0.6057], [0.0512, 0.9702]]]]])
in0Bat66120 = tf.constant([[1.4159, 1.7507, 1.7261]])
in0Con4032 = tf.constant([[[[[0.1748, 0.4422], [0.1706, 0.2361], [0.5205, 0.9024]], [[0.6228, 0.7401], [0.202, 0.5262], [0.0035, 0.0329]], [[0.0289, 0.5041], [0.772, 0.5228], [0.6165, 0.5757]]], [[[0.8157, 0.5034], [0.2527, 0.6189], [0.4352, 0.8839]], [[0.1639, 0.3786], [0.759, 0.7326], [0.171, 0.9454]], [[0.2567, 0.4979], [0.7773, 0.1199], [0.5821, 0.4447]]], [[[0.0549, 0.8517], [0.3228, 0.5329], [0.3114, 0.5313]], [[0.3582, 0.6976], [0.4046, 0.0306], [0.4359, 0.2463]], [[0.7525, 0.0362], [0.2655, 0.88], [0.5336, 0.402]]]]])
print (np.array2string(model.predict([in0Con84972,in0Bat66120,in0Con4032],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add8563.png')

LCon84972 = conv3D_transpose_layer([[[[[0.4105, 0.1995], [0.5752, 0.1915]], [[0.2058, 0.3887], [0.4494, 0.8513]]], [[[0.1551, 0.7927], [0.4932, 0.1544]], [[0.2457, 0.6057], [0.0512, 0.9702]]]]], 2, 2, 2,[[[[[0.1724, 0.6806], [0.129, 0.9695], [0.5357, 0.7988]], [[0.3738, 0.8134], [0.1381, 0.9564], [0.0147, 0.899]]], [[[0.6412, 0.2385], [0.0715, 0.5008], [0.6216, 0.7917]], [[0.9495, 0.0346], [0.0955, 0.0872], [0.2358, 0.1572]]]], [[[[0.6883, 0.0952], [0.7469, 0.6203], [0.3426, 0.8711]], [[0.3635, 0.9481], [0.871, 0.133], [0.9894, 0.0999]]], [[[0.1076, 0.7725], [0.3121, 0.1556], [0.8886, 0.8777]], [[0.9069, 0.7215], [0.6024, 0.7759], [0.6301, 0.1881]]]]],[0, 0, 0], 1, 1, 1, false, Con84972), 
LBat66120 = batch_normalization_layer([[1.4159, 1.7507, 1.7261]], 1, 0.6183697463793649, [0.4801, 0.2793, 0.2577], [0.7095, 0.6083, 0.1573], [0.4912, 0.526, 0.5049], [0.8606, 0.9766, 0.3024], Bat66120), 
LRes62534 = reshape_layer(Bat66120, [3, 1], Res62534), 
LRes24825 = reshape_layer(Res62534, [3, 1, 1], Res24825), 
LRes11375 = reshape_layer(Res24825, [3, 1, 1, 1], Res11375), 
LUp_12964 = up_sampling3D_layer(Res11375, 1, 1, 2, Up_12964), 
LLay70459 = layer_normalization_layer(Up_12964, 1, 2.515414804063817, Lay70459), 
LZer46417 = zero_padding3D_layer(Lay70459, 0, 0, 2, 0, 1, 0, Zer46417), 
LCon4032 = concatenate_layer([Zer46417,[[[[[0.1748, 0.4422], [0.1706, 0.2361], [0.5205, 0.9024]], [[0.6228, 0.7401], [0.202, 0.5262], [0.0035, 0.0329]], [[0.0289, 0.5041], [0.772, 0.5228], [0.6165, 0.5757]]], [[[0.8157, 0.5034], [0.2527, 0.6189], [0.4352, 0.8839]], [[0.1639, 0.3786], [0.759, 0.7326], [0.171, 0.9454]], [[0.2567, 0.4979], [0.7773, 0.1199], [0.5821, 0.4447]]], [[[0.0549, 0.8517], [0.3228, 0.5329], [0.3114, 0.5313]], [[0.3582, 0.6976], [0.4046, 0.0306], [0.4359, 0.2463]], [[0.7525, 0.0362], [0.2655, 0.88], [0.5336, 0.402]]]]]], 4, Con4032), 
LAdd8563 = add_layer([Con84972,Con4032], Add8563), 
exec_layers([LCon84972,LBat66120,LRes62534,LRes24825,LRes11375,LUp_12964,LLay70459,LZer46417,LCon4032,LAdd8563],["Con84972","Bat66120","Res62534","Res24825","Res11375","Up_12964","Lay70459","Zer46417","Con4032","Add8563"],Add8563,"Add8563")

Actual (Unparsed): [[[[[0.2065499, 0.4211697, 0.8214654], [0.5452176, 0.6779519, 0.8825897], [0.3707759, 0.7830857, 1.0830140]], [[0.6108225, 1.1554532, 1.5739516], [1.8611314, 1.6791108, 2.4367408], [1.4132115, 0.9513759, 0.9705608]], [[0.2246639, 0.2382757, 0.9397591], [0.8630315, 1.2840117, 1.5857526], [0.6191454, 0.7336511, 0.8154929]]], [[[0.8677904, 2.0345828, 1.5341176], [1.6453745, 2.1780545, 2.5113171], [0.7005935, 1.1774478, 1.6181894]], [[1.1200471, 1.7448772, 2.6670205], [3.3411707, 4.2220209, 4.7865221], [2.9122255, 2.1662699, 2.8870666]], [[0.6244171, 0.7023140, 1.6541957], [1.7327689, 2.0414046, 2.4222973], [1.1451828, 1.6028332, 1.0525849]]], [[[0.1822204, 0.6624560, 1.5953582], [1.1621062, 1.0274666, 1.0690148], [0.3256648, 0.7615124, 1.0346967]], [[0.8558275, 1.0891799, 2.1429768], [1.6761157, 2.2256597, 2.0174971], [1.4971405, 1.0264344, 0.7336882]], [[0.4943406, 0.9234299, 0.7861519], [1.2106158, 1.0504150, 2.0457886], [0.5422219, 1.3172210, 0.6167557]]]]]

Expected (Unparsed): [[[[[0.2065499,0.42116975,0.8214654499999999],[0.54521758,0.6779518999999999,0.8825896900000001],[0.37077586000000007,0.78308572,1.08301394]],[[0.6108224899999999,1.1554532000000002,1.57395157],[1.8611314,1.67911076,2.4367407500000002],[1.41321144,0.9513758599999999,0.9705608400000001]],[[0.22466391000000002,0.23827566,0.9397590699999999],[0.863031518240303,1.2840116799999999,1.5857525300000002],[0.619145348240303,0.73365106,0.81549288]]],[[[0.86779041,2.03458285,1.5341175799999998],[1.6453745400000002,2.17805452,2.51131715],[0.70059347,1.17744778,1.61818937]],[[1.1200470999999999,1.7448771399999998,2.6670204999999996],[3.3411706700000003,4.2220208800000005,4.7865221],[2.9122254400000003,2.16626991,2.88706658]],[[0.6244171199999999,0.70231401,1.65419568],[1.7327688960451189,2.04140462,2.4222972599999997],[1.1451827560451187,1.60283327,1.05258487]]],[[[0.18222037,0.6624559999999999,1.59535823],[1.16210616,1.0274666,1.06901483],[0.32566484,0.7615124000000001,1.03469664]],[[0.8558274599999999,1.08917987,2.14297674],[1.67611568,2.2256596699999998,2.0174971299999997],[1.4971405000000002,1.02643444,0.73368822]],[[0.49434057,0.92342989,0.7861519100000001],[1.2106158057145784,1.0504149500000002,2.0457886],[0.5422218857145782,1.31722106,0.61675574]]]]]

Actual:   [[[[[0.2066, 0.4212, 0.8215], [0.5453, 0.678, 0.8826], [0.3708, 0.7831, 1.0831]], [[0.6109, 1.1555, 1.574], [1.8612, 1.6792, 2.4368], [1.4133, 0.9514, 0.9706]], [[0.2247, 0.2383, 0.9398], [0.8631, 1.2841, 1.5858], [0.6192, 0.7337, 0.8155]]], [[[0.8678, 2.0346, 1.5342], [1.6454, 2.1781, 2.5114], [0.7006, 1.1775, 1.6182]], [[1.1201, 1.7449, 2.6671], [3.3412, 4.2221, 4.7866], [2.9123, 2.1663, 2.8871]], [[0.6245, 0.7024, 1.6542], [1.7328, 2.0415, 2.4223], [1.1452, 1.6029, 1.0526]]], [[[0.1823, 0.6625, 1.5954], [1.1622, 1.0275, 1.0691], [0.3257, 0.7616, 1.0347]], [[0.8559, 1.0892, 2.143], [1.6762, 2.2257, 2.0175], [1.4972, 1.0265, 0.7337]], [[0.4944, 0.9235, 0.7862], [1.2107, 1.0505, 2.0458], [0.5423, 1.3173, 0.6168]]]]]

Expected: [[[[[0.2066, 0.4212, 0.8215], [0.5453, 0.678, 0.8826], [0.3708, 0.7831, 1.0831]], [[0.6109, 1.1555, 1.574], [1.8612, 1.6792, 2.4368], [1.4133, 0.9514, 0.9706]], [[0.2247, 0.2383, 0.9398], [0.8631, 1.2841, 1.5858], [0.6192, 0.7337, 0.8155]]], [[[0.8678, 2.0346, 1.5342], [1.6454, 2.1781, 2.5114], [0.7006, 1.1775, 1.6182]], [[1.1201, 1.7449, 2.6671], [3.3412, 4.2221, 4.7866], [2.9123, 2.1663, 2.8871]], [[0.6245, 0.7024, 1.6542], [1.7328, 2.0415, 2.4223], [1.1452, 1.6029, 1.0526]]], [[[0.1823, 0.6625, 1.5954], [1.1622, 1.0275, 1.0691], [0.3257, 0.7616, 1.0347]], [[0.8559, 1.0892, 2.143], [1.6762, 2.2257, 2.0175], [1.4972, 1.0265, 0.7337]], [[0.4944, 0.9235, 0.7862], [1.2107, 1.0505, 2.0458], [0.5423, 1.3173, 0.6168]]]]]