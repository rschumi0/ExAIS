import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sim64404 = tf.keras.layers.Input(shape=([1, 2]))
in0Glo60067 = tf.keras.layers.Input(shape=([1, 2]))
in0Con89986 = tf.keras.layers.Input(shape=([4, 2]))
in0Up_44718 = tf.keras.layers.Input(shape=([2, 3]))

Sim64404 = keras.layers.SimpleRNN(3,name = 'Sim64404', )(in0Sim64404)
Lea99647 = keras.layers.LeakyReLU(alpha=9.001405691054073, name = 'Lea99647', )(Sim64404)
Res8679 = keras.layers.Reshape((3, 1), name = 'Res8679', )(Lea99647)
Res67515 = keras.layers.Reshape((3, 1, 1), name = 'Res67515', )(Res8679)
Glo60067 = keras.layers.GlobalMaxPool1D(name = 'Glo60067', )(in0Glo60067)
Res84390 = keras.layers.Reshape((2, 1), name = 'Res84390', )(Glo60067)
Res7115 = keras.layers.Reshape((2, 1, 1), name = 'Res7115', )(Res84390)
Max97267 = keras.layers.MaxPool2D(pool_size=(2, 1), name = 'Max97267', )(Res7115)
Zer39526 = keras.layers.ZeroPadding2D(padding=((2, 0), (0, 0)), name = 'Zer39526', )(Max97267)
Min53838 = keras.layers.Minimum(name = 'Min53838', )([Res67515,Zer39526])
Res43073 = keras.layers.Reshape((3, 1), name = 'Res43073', )(Min53838)
Zer32681 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer32681', )(Res43073)
Con89986 = keras.layers.Concatenate(axis=2, name = 'Con89986', )([Zer32681,in0Con89986])
Up_44718 = keras.layers.UpSampling1D(size=(2), name = 'Up_44718', )(in0Up_44718)
Dot17275 = keras.layers.Dot(axes=(1, 1), name = 'Dot17275', )([Con89986,Up_44718])
model = tf.keras.models.Model(inputs=[in0Sim64404,in0Glo60067,in0Con89986,in0Up_44718], outputs=Dot17275)
w = model.get_layer('Sim64404').get_weights() 
w[0] = np.array([[10, 3, 3], [1, 4, 10]])
w[1] = np.array([[1, 6, 10], [3, 9, 8], [6, 2, 9]])
w[2] = np.array([8, 2, 6])
model.get_layer('Sim64404').set_weights(w) 
in0Sim64404 = tf.constant([[[3, 2]]])
in0Glo60067 = tf.constant([[[1.9714, 1.6161]]])
in0Con89986 = tf.constant([[[0.676, 0.5836], [0.608, 0.7863], [0.1205, 0.3855], [0.5356, 0.1973]]])
in0Up_44718 = tf.constant([[[1.3605, 1.7549, 1.9645], [1.54, 1.7476, 1.5086]]])
print (np.array2string(model.predict([in0Sim64404,in0Glo60067,in0Con89986,in0Up_44718],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot17275.png')

LSim64404 = simple_rnn_layer([[[3, 2]]],[[10, 3, 3], [1, 4, 10]],[[1, 6, 10], [3, 9, 8], [6, 2, 9]],[8, 2, 6], Sim64404), 
LLea99647 = leaky_relu_layer(Sim64404, 9.001405691054073, Lea99647), 
LRes8679 = reshape_layer(Lea99647, [3, 1], Res8679), 
LRes67515 = reshape_layer(Res8679, [3, 1, 1], Res67515), 
LGlo60067 = global_max_pool1D_layer([[[1.9714, 1.6161]]], Glo60067), 
LRes84390 = reshape_layer(Glo60067, [2, 1], Res84390), 
LRes7115 = reshape_layer(Res84390, [2, 1, 1], Res7115), 
LMax97267 = max_pool2D_layer(Res7115, 2, 1, Max97267), 
LZer39526 = zero_padding2D_layer(Max97267, 2, 0, 0, 0, Zer39526), 
LMin53838 = minimum_layer([Res67515,Zer39526], Min53838), 
LRes43073 = reshape_layer(Min53838, [3, 1], Res43073), 
LZer32681 = zero_padding1D_layer(Res43073, 1, 0, Zer32681), 
LCon89986 = concatenate_layer([Zer32681,[[[0.676, 0.5836], [0.608, 0.7863], [0.1205, 0.3855], [0.5356, 0.1973]]]], 2, Con89986), 
LUp_44718 = up_sampling1D_layer([[[1.3605, 1.7549, 1.9645], [1.54, 1.7476, 1.5086]]], 2, Up_44718), 
LDot17275 = dot_layer(Con89986,Up_44718, 1, 1, Dot17275), 
exec_layers([LSim64404,LLea99647,LRes8679,LRes67515,LGlo60067,LRes84390,LRes7115,LMax97267,LZer39526,LMin53838,LRes43073,LZer32681,LCon89986,LUp_44718,LDot17275],["Sim64404","Lea99647","Res8679","Res67515","Glo60067","Res84390","Res7115","Max97267","Zer39526","Min53838","Res43073","Zer32681","Con89986","Up_44718","Dot17275"],Dot17275,"Dot17275")

Actual (Unparsed): [[[1.5400000, 1.7476000, 1.5086000], [2.7572759, 3.3998919, 3.5122104], [2.7612609, 3.4225387, 3.5703806]]]

Expected (Unparsed): [[[1.54,1.7476,1.5086],[2.757276,3.3998919599999997,3.5122104600000004],[2.76126095,3.42253879,3.5703806299999994]]]

Actual:   [[[1.54, 1.7476, 1.5086], [2.7573, 3.3999, 3.5123], [2.7613, 3.4226, 3.5704]]]

Expected: [[[1.54, 1.7476, 1.5086], [2.7573, 3.3999, 3.5123], [2.7613, 3.4226, 3.5704]]]