import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot41975 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot41975 = tf.keras.layers.Input(shape=([3, 3]))
in0Con43456 = tf.keras.layers.Input(shape=([4, 4, 3]))
in0Up_34454 = tf.keras.layers.Input(shape=([2, 1, 4]))
in0Ave72167 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in1Ave72167 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))

Dot41975 = keras.layers.Dot(axes=(1, 1), name = 'Dot41975', )([in0Dot41975,in1Dot41975])
Res73796 = keras.layers.Reshape((3, 3, 1), name = 'Res73796', )(Dot41975)
Zer82876 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer82876', )(Res73796)
Con43456 = keras.layers.Concatenate(axis=3, name = 'Con43456', )([Zer82876,in0Con43456])
Up_34454 = keras.layers.UpSampling2D(size=(1, 2), name = 'Up_34454', )(in0Up_34454)
Zer94523 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer94523', )(Up_34454)
Mul54781 = keras.layers.Multiply(name = 'Mul54781', )([Con43456,Zer94523])
Bat73618 = keras.layers.BatchNormalization(axis=2, epsilon=0.5641946873513092,  name = 'Bat73618', )(Mul54781)
Ave72167 = keras.layers.Average(name = 'Ave72167', )([in0Ave72167,in1Ave72167])
Res67726 = keras.layers.Reshape((1, 1, 4), name = 'Res67726', )(Ave72167)
Max38840 = keras.layers.MaxPool2D(pool_size=(1, 1), strides=(1, 1), padding='valid', name = 'Max38840', )(Res67726)
Zer60384 = keras.layers.ZeroPadding2D(padding=((3, 0), (3, 0)), name = 'Zer60384', )(Max38840)
Ave59033 = keras.layers.Average(name = 'Ave59033', )([Bat73618,Zer60384])
model = tf.keras.models.Model(inputs=[in0Dot41975,in1Dot41975,in0Con43456,in0Up_34454,in0Ave72167,in1Ave72167], outputs=Ave59033)
w = model.get_layer('Bat73618').get_weights() 
w[0] = np.array([0.931, 0.5325, 0.7933, 0.5419])
w[1] = np.array([0.0883, 0.5957, 0.6359, 0.5123])
w[2] = np.array([0.2003, 0.7456, 0.4316, 0.4476])
w[3] = np.array([0.4622, 0.8953, 0.1228, 0.7344])
model.get_layer('Bat73618').set_weights(w) 
in0Dot41975 = tf.constant([[[0.243, 0.9208, 0.9698], [0.4655, 0.4482, 0.6638], [0.3029, 0.7108, 0.3662]]])
in1Dot41975 = tf.constant([[[0.5766, 0.8226, 0.3161], [0.1136, 0.1937, 0.9683], [0.2815, 0.1646, 0.3332]]])
in0Con43456 = tf.constant([[[[0.1765, 0.2392, 0.6292], [0.4613, 0.5083, 0.4296], [0.3187, 0.176, 0.3707], [0.3309, 0.3869, 0.2158]], [[0.7018, 0.2168, 0.4042], [0.0158, 0.0639, 0.0345], [0.2039, 0.2427, 0.3851], [0.7632, 0.4197, 0.8577]], [[0.6771, 0.5198, 0.8682], [0.0867, 0.8462, 0.7717], [0.4215, 0.5378, 0.6259], [0.1889, 0.2594, 0.3276]], [[0.4772, 0.991, 0.0312], [0.355, 0.0269, 0.1257], [0.5122, 0.7993, 0.2432], [0.2568, 0.7958, 0.5049]]]])
in0Up_34454 = tf.constant([[[[1.4363, 1.0165, 1.4422, 1.5384]], [[1.9436, 1.391, 1.4481, 1.2114]]]])
in0Ave72167 = tf.constant([[[[[0.1373, 0.4237], [0.0891, 0.5343]]]]])
in1Ave72167 = tf.constant([[[[[0.7315, 0.3047], [0.3379, 0.9179]]]]])
print (np.array2string(model.predict([in0Dot41975,in1Dot41975,in0Con43456,in0Up_34454,in0Ave72167,in1Ave72167],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave59033.png')

LDot41975 = dot_layer([[[0.243, 0.9208, 0.9698], [0.4655, 0.4482, 0.6638], [0.3029, 0.7108, 0.3662]]], [[[0.5766, 0.8226, 0.3161], [0.1136, 0.1937, 0.9683], [0.2815, 0.1646, 0.3332]]], 1, 1, Dot41975), 
LRes73796 = reshape_layer(Dot41975, [3, 3, 1], Res73796), 
LZer82876 = zero_padding2D_layer(Res73796, 1, 0, 1, 0, Zer82876), 
LCon43456 = concatenate_layer([Zer82876,[[[[0.1765, 0.2392, 0.6292], [0.4613, 0.5083, 0.4296], [0.3187, 0.176, 0.3707], [0.3309, 0.3869, 0.2158]], [[0.7018, 0.2168, 0.4042], [0.0158, 0.0639, 0.0345], [0.2039, 0.2427, 0.3851], [0.7632, 0.4197, 0.8577]], [[0.6771, 0.5198, 0.8682], [0.0867, 0.8462, 0.7717], [0.4215, 0.5378, 0.6259], [0.1889, 0.2594, 0.3276]], [[0.4772, 0.991, 0.0312], [0.355, 0.0269, 0.1257], [0.5122, 0.7993, 0.2432], [0.2568, 0.7958, 0.5049]]]]], 3, Con43456), 
LUp_34454 = up_sampling2D_layer([[[[1.4363, 1.0165, 1.4422, 1.5384]], [[1.9436, 1.391, 1.4481, 1.2114]]]], 1, 2, Up_34454), 
LZer94523 = zero_padding2D_layer(Up_34454, 1, 1, 1, 1, Zer94523), 
LMul54781 = multiply_layer([Con43456,Zer94523], Mul54781), 
LBat73618 = batch_normalization_layer(Mul54781, 2, 0.5641946873513092, [0.931, 0.5325, 0.7933, 0.5419], [0.0883, 0.5957, 0.6359, 0.5123], [0.2003, 0.7456, 0.4316, 0.4476], [0.4622, 0.8953, 0.1228, 0.7344], Bat73618), 
LAve72167 = average_layer([[[[[[0.1373, 0.4237], [0.0891, 0.5343]]]]], [[[[[0.7315, 0.3047], [0.3379, 0.9179]]]]]], Ave72167), 
LRes67726 = reshape_layer(Ave72167, [1, 1, 4], Res67726), 
LMax38840 = max_pool2D_layer(Res67726, 1, 1, 1, 1, false, Max38840), 
LZer60384 = zero_padding2D_layer(Max38840, 3, 0, 3, 0, Zer60384), 
LAve59033 = average_layer([Bat73618,Zer60384], Ave59033), 
exec_layers([LDot41975,LRes73796,LZer82876,LCon43456,LUp_34454,LZer94523,LMul54781,LBat73618,LAve72167,LRes67726,LMax38840,LZer60384,LAve59033],["Dot41975","Res73796","Zer82876","Con43456","Up_34454","Zer94523","Mul54781","Bat73618","Ave72167","Res67726","Max38840","Zer60384","Ave59033"],Ave59033,"Ave59033")

Actual (Unparsed): [[[[-0.0478830, -0.0478830, -0.0478830, -0.0478830], [0.1335286, 0.1335286, 0.1335286, 0.1335286], [0.1114062, 0.1114062, 0.1114062, 0.1114062], [0.1497253, 0.1497253, 0.1497253, 0.1497253]], [[-0.0478830, -0.0478830, -0.0478830, -0.0478830], [0.2216103, 0.1370681, 0.1538388, 0.1452256], [0.3450467, 0.2105933, 0.2789105, 0.3949196], [0.1497253, 0.1497253, 0.1497253, 0.1497253]], [[-0.0478830, -0.0478830, -0.0478830, -0.0478830], [0.4684694, 0.1601073, 0.4035883, 0.3395557], [1.0054944, 0.3919854, 0.4840982, 0.4742530], [0.1497253, 0.1497253, 0.1497253, 0.1497253]], [[-0.0478830, -0.0478830, -0.0478830, -0.0478830], [0.1335286, 0.1335286, 0.1335286, 0.1335286], [0.1114062, 0.1114062, 0.1114062, 0.1114062], [0.3669253, 0.3318253, 0.2564753, 0.5127753]]]]

Expected (Unparsed): [[[[-0.04788296989321448,-0.04788296989321448,-0.04788296989321448,-0.04788296989321448],[0.1335285507563686,0.1335285507563686,0.1335285507563686,0.1335285507563686],[0.1114061798301634,0.1114061798301634,0.1114061798301634,0.1114061798301634],[0.14972530301911863,0.14972530301911863,0.14972530301911863,0.14972530301911863]],[[-0.04788296989321448,-0.04788296989321448,-0.04788296989321448,-0.04788296989321448],[0.22161026964858138,0.13706813967786433,0.15383877444592958,0.1452256109150541],[0.34504669939820204,0.21059332217033502,0.2789105093733917,0.39491955954927005],[0.14972530301911863,0.14972530301911863,0.14972530301911863,0.14972530301911863]],[[-0.04788296989321448,-0.04788296989321448,-0.04788296989321448,-0.04788296989321448],[0.4684694038641277,0.16010730274449517,0.403588344570449,0.33955568740969394],[1.0054944203809848,0.3919853834919018,0.48409822292635046,0.47425297387897236],[0.14972530301911863,0.14972530301911863,0.14972530301911863,0.14972530301911863]],[[-0.04788296989321448,-0.04788296989321448,-0.04788296989321448,-0.04788296989321448],[0.1335285507563686,0.1335285507563686,0.1335285507563686,0.1335285507563686],[0.1114061798301634,0.1114061798301634,0.1114061798301634,0.1114061798301634],[0.36692530301911863,0.3318253030191186,0.25647530301911864,0.5127753030191187]]]]

Actual:   [[[[-0.0478, -0.0478, -0.0478, -0.0478], [0.1336, 0.1336, 0.1336, 0.1336], [0.1115, 0.1115, 0.1115, 0.1115], [0.1498, 0.1498, 0.1498, 0.1498]], [[-0.0478, -0.0478, -0.0478, -0.0478], [0.2217, 0.1371, 0.1539, 0.1453], [0.3451, 0.2106, 0.279, 0.395], [0.1498, 0.1498, 0.1498, 0.1498]], [[-0.0478, -0.0478, -0.0478, -0.0478], [0.4685, 0.1602, 0.4036, 0.3396], [1.0055, 0.392, 0.4841, 0.4743], [0.1498, 0.1498, 0.1498, 0.1498]], [[-0.0478, -0.0478, -0.0478, -0.0478], [0.1336, 0.1336, 0.1336, 0.1336], [0.1115, 0.1115, 0.1115, 0.1115], [0.367, 0.3319, 0.2565, 0.5128]]]]

Expected: [[[[-0.0478, -0.0478, -0.0478, -0.0478], [0.1336, 0.1336, 0.1336, 0.1336], [0.1115, 0.1115, 0.1115, 0.1115], [0.1498, 0.1498, 0.1498, 0.1498]], [[-0.0478, -0.0478, -0.0478, -0.0478], [0.2217, 0.1371, 0.1539, 0.1453], [0.3451, 0.2106, 0.279, 0.395], [0.1498, 0.1498, 0.1498, 0.1498]], [[-0.0478, -0.0478, -0.0478, -0.0478], [0.4685, 0.1602, 0.4036, 0.3396], [1.0055, 0.392, 0.4841, 0.4743], [0.1498, 0.1498, 0.1498, 0.1498]], [[-0.0478, -0.0478, -0.0478, -0.0478], [0.1336, 0.1336, 0.1336, 0.1336], [0.1115, 0.1115, 0.1115, 0.1115], [0.367, 0.3319, 0.2565, 0.5128]]]]