import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max63151 = tf.keras.layers.Input(shape=([2, 1]))
in1Max63151 = tf.keras.layers.Input(shape=([2, 1]))

Max63151 = keras.layers.Maximum(name = 'Max63151', )([in0Max63151,in1Max63151])
Lea65197 = keras.layers.LeakyReLU(alpha=9.989142371111427, name = 'Lea65197', )(Max63151)
Zer2267 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer2267', )(Lea65197)
model = tf.keras.models.Model(inputs=[in0Max63151,in1Max63151], outputs=Zer2267)
in0Max63151 = tf.constant([[[0.9778], [0.2911]]])
in1Max63151 = tf.constant([[[0.049], [0.8925]]])
print (np.array2string(model.predict([in0Max63151,in1Max63151],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Zer2267.png')

LMax63151 = maximum_layer([[[[0.9778], [0.2911]]], [[[0.049], [0.8925]]]], Max63151), 
LLea65197 = leaky_relu_layer(Max63151, 9.989142371111427, Lea65197), 
LZer2267 = zero_padding1D_layer(Lea65197, 1, 1, Zer2267), 
exec_layers([LMax63151,LLea65197,LZer2267],["Max63151","Lea65197","Zer2267"],Zer2267,"Zer2267")

Actual (Unparsed): [[[0.0000000], [0.9778000], [0.8925000], [0.0000000]]]

Expected (Unparsed): [[[0],[0.9778],[0.8925],[0]]]

Actual:   [[[0], [0.9778], [0.8925], [0]]]

Expected: [[[0], [0.9778], [0.8925], [0]]]