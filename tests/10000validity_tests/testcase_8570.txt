import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer72868 = tf.keras.layers.Input(shape=([2, 3, 2, 3]))

Zer72868 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer72868', )(in0Zer72868)
Zer67855 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer67855', )(Zer72868)
Res15179 = keras.layers.Reshape((6, 7, 18), name = 'Res15179', )(Zer67855)
Glo17369 = keras.layers.GlobalMaxPool2D(name = 'Glo17369', )(Res15179)
Bat22363 = keras.layers.BatchNormalization(axis=1, epsilon=0.7062834178845491,  name = 'Bat22363', )(Glo17369)
model = tf.keras.models.Model(inputs=[in0Zer72868], outputs=Bat22363)
w = model.get_layer('Bat22363').get_weights() 
w[0] = np.array([0.4464, 0.2117, 0.8153, 0.4388, 0.9107, 0.7921, 0.0503, 0.0782, 0.6807, 0.7919, 0.8283, 0.6688, 0.0946, 0.0407, 0.9419, 0.3073, 0.9456, 0.7429])
w[1] = np.array([0.0631, 0.2143, 0.3163, 0.8042, 0.6165, 0.0103, 0.4667, 0.1439, 0.6188, 0.8788, 0.2865, 0.0311, 0.5461, 0.5863, 0.0892, 0.5709, 0.507, 0.487])
w[2] = np.array([0.9428, 0.9526, 0.8744, 0.7129, 0.3077, 0.9682, 0.0514, 0.7186, 0.4816, 0.6134, 0.2382, 0.2323, 0.2431, 0.288, 0.9017, 0.4513, 0.126, 0.2285])
w[3] = np.array([0.1506, 0.0101, 0.9573, 0.3274, 0.3695, 0.8511, 0.6503, 0.4174, 0.2776, 0.6294, 0.7535, 0.4354, 0.0406, 0.698, 0.9287, 0.6165, 0.1894, 0.033])
model.get_layer('Bat22363').set_weights(w) 
in0Zer72868 = tf.constant([[[[[1.1238, 1.073, 1.2404], [1.7287, 1.9719, 1.9423]], [[1.9039, 1.4171, 1.6906], [1.4626, 1.1433, 1.0767]], [[1.3689, 1.8807, 1.0897], [1.2627, 1.0655, 1.5539]]], [[[1.9737, 1.2118, 1.7803], [1.7911, 1.762, 1.6591]], [[1.9287, 1.6086, 1.7461], [1.5919, 1.2024, 1.055]], [[1.3961, 1.8074, 1.787], [1.9787, 1.9548, 1.5661]]]]])
print (np.array2string(model.predict([in0Zer72868],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat22363.png')

LZer72868 = zero_padding3D_layer([[[[[1.1238, 1.073, 1.2404], [1.7287, 1.9719, 1.9423]], [[1.9039, 1.4171, 1.6906], [1.4626, 1.1433, 1.0767]], [[1.3689, 1.8807, 1.0897], [1.2627, 1.0655, 1.5539]]], [[[1.9737, 1.2118, 1.7803], [1.7911, 1.762, 1.6591]], [[1.9287, 1.6086, 1.7461], [1.5919, 1.2024, 1.055]], [[1.3961, 1.8074, 1.787], [1.9787, 1.9548, 1.5661]]]]], 1, 1, 1, 1, 1, 1, Zer72868), 
LZer67855 = zero_padding3D_layer(Zer72868, 1, 1, 1, 1, 1, 1, Zer67855), 
LRes15179 = reshape_layer(Zer67855, [6, 7, 18], Res15179), 
LGlo17369 = global_max_pool2D_layer(Res15179, Glo17369), 
LBat22363 = batch_normalization_layer(Glo17369, 1, 0.7062834178845491, [0.4464, 0.2117, 0.8153, 0.4388, 0.9107, 0.7921, 0.0503, 0.0782, 0.6807, 0.7919, 0.8283, 0.6688, 0.0946, 0.0407, 0.9419, 0.3073, 0.9456, 0.7429], [0.0631, 0.2143, 0.3163, 0.8042, 0.6165, 0.0103, 0.4667, 0.1439, 0.6188, 0.8788, 0.2865, 0.0311, 0.5461, 0.5863, 0.0892, 0.5709, 0.507, 0.487], [0.9428, 0.9526, 0.8744, 0.7129, 0.3077, 0.9682, 0.0514, 0.7186, 0.4816, 0.6134, 0.2382, 0.2323, 0.2431, 0.288, 0.9017, 0.4513, 0.126, 0.2285], [0.1506, 0.0101, 0.9573, 0.3274, 0.3695, 0.8511, 0.6503, 0.4174, 0.2776, 0.6294, 0.7535, 0.4354, 0.0406, 0.698, 0.9287, 0.6165, 0.1894, 0.033], Bat22363), 
exec_layers([LZer72868,LZer67855,LRes15179,LGlo17369,LBat22363],["Zer72868","Zer67855","Res15179","Glo17369","Bat22363"],Bat22363,"Bat22363")

Actual (Unparsed): [[-0.3915560, -0.0239641, -0.2364202, 0.4965184, 0.3463280, -0.6042360, 0.5497168, 0.2296291, 1.5146340, 1.8143062, 1.4750498, 1.1014345, 0.5194897, 0.5764086, -0.5750173, 0.4503177, 0.3811072, 0.2895709]]

Expected (Unparsed): [[-0.3915559620301615,-0.023964134063688913,-0.2364201529679797,0.49651844706484427,0.3463279550937456,-0.6042359846919679,0.5497167828028064,0.22962910074425885,1.514633993795072,1.814306191182164,1.475049838906208,1.1014345097316036,0.5194897051604399,0.576408560177671,-0.575017311432442,0.45031771128408443,0.38110724383600153,0.2895709388860713]]

Actual:   [[-0.3915, -0.0239, -0.2364, 0.4966, 0.3464, -0.6042, 0.5498, 0.2297, 1.5147, 1.8144, 1.4751, 1.1015, 0.5195, 0.5765, -0.575, 0.4504, 0.3812, 0.2896]]

Expected: [[-0.3915, -0.0239, -0.2364, 0.4966, 0.3464, -0.6042, 0.5498, 0.2297, 1.5147, 1.8144, 1.4751, 1.1015, 0.5195, 0.5765, -0.575, 0.4504, 0.3812, 0.2896]]