import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo25548 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con16800 = tf.keras.layers.Input(shape=([4, 2]))
in0Bat60591 = tf.keras.layers.Input(shape=([2, 1, 3]))
in0Con69675 = tf.keras.layers.Input(shape=([4, 3]))
in0Min67376 = tf.keras.layers.Input(shape=([1, 2, 1, 2]))
in1Min67376 = tf.keras.layers.Input(shape=([1, 2, 1, 2]))
in0Add77409 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Add77409 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con53544 = tf.keras.layers.Input(shape=([2, 3, 1]))

Glo25548 = keras.layers.GlobalMaxPool2D(name = 'Glo25548', )(in0Glo25548)
Res91926 = keras.layers.Reshape((2, 1), name = 'Res91926', )(Glo25548)
Zer22921 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer22921', )(Res91926)
Con16800 = keras.layers.Concatenate(axis=2, name = 'Con16800', )([Zer22921,in0Con16800])
Bat60591 = keras.layers.BatchNormalization(axis=2, epsilon=0.5306100987604745,  name = 'Bat60591', )(in0Bat60591)
Res87170 = keras.layers.Reshape((2, 3), name = 'Res87170', )(Bat60591)
Zer88861 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer88861', )(Res87170)
Sub86107 = keras.layers.Subtract(name = 'Sub86107', )([Con16800,Zer88861])
Con69675 = keras.layers.Concatenate(axis=2, name = 'Con69675', )([Sub86107,in0Con69675])
Min67376 = keras.layers.Minimum(name = 'Min67376', )([in0Min67376,in1Min67376])
Res52001 = keras.layers.Reshape((1, 2, 2), name = 'Res52001', )(Min67376)
Zer3104 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer3104', )(Res52001)
Add77409 = keras.layers.Add(name = 'Add77409', )([in0Add77409,in1Add77409])
Zer93113 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer93113', )(Add77409)
Con53544 = keras.layers.Concatenate(axis=3, name = 'Con53544', )([Zer93113,in0Con53544])
Sub62111 = keras.layers.Subtract(name = 'Sub62111', )([Zer3104,Con53544])
ELU94014 = keras.layers.ELU(alpha=-3.6258692138704918, name = 'ELU94014', )(Sub62111)
Res8964 = keras.layers.Reshape((2, 6), name = 'Res8964', )(ELU94014)
Dot83222 = keras.layers.Dot(axes=(2, 2), name = 'Dot83222', )([Con69675,Res8964])
model = tf.keras.models.Model(inputs=[in0Glo25548,in0Con16800,in0Bat60591,in0Con69675,in0Min67376,in1Min67376,in0Add77409,in1Add77409,in0Con53544], outputs=Dot83222)
w = model.get_layer('Bat60591').get_weights() 
w[0] = np.array([0.1219])
w[1] = np.array([0.804])
w[2] = np.array([0.0582])
w[3] = np.array([0.0057])
model.get_layer('Bat60591').set_weights(w) 
in0Glo25548 = tf.constant([[[[1.5668, 1.52]], [[1.6195, 1.5961]]]])
in0Con16800 = tf.constant([[[0.4886, 0.2358], [0.8647, 0.9051], [0.0866, 0.1341], [0.1883, 0.4973]]])
in0Bat60591 = tf.constant([[[[1.0185, 1.6354, 1.5793]], [[1.6494, 1.6929, 1.6361]]]])
in0Con69675 = tf.constant([[[0.9696, 0.6667, 0.5823], [0.2367, 0.036, 0.8198], [0.8657, 0.4312, 0.2016], [0.5765, 0.9759, 0.8561]]])
in0Min67376 = tf.constant([[[[[0.9244, 0.1118]], [[0.2944, 0.4912]]]]])
in1Min67376 = tf.constant([[[[[0.2451, 0.1816]], [[0.6185, 0.6889]]]]])
in0Add77409 = tf.constant([[[[0.5251]], [[0.784]]]])
in1Add77409 = tf.constant([[[[0.7678]], [[0.0276]]]])
in0Con53544 = tf.constant([[[[0.02], [0.9935], [0.9472]], [[0.9043], [0.4632], [0.3676]]]])
print (np.array2string(model.predict([in0Glo25548,in0Con16800,in0Bat60591,in0Con69675,in0Min67376,in1Min67376,in0Add77409,in1Add77409,in0Con53544],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot83222.png')

LGlo25548 = global_max_pool2D_layer([[[[1.5668, 1.52]], [[1.6195, 1.5961]]]], Glo25548), 
LRes91926 = reshape_layer(Glo25548, [2, 1], Res91926), 
LZer22921 = zero_padding1D_layer(Res91926, 2, 0, Zer22921), 
LCon16800 = concatenate_layer([Zer22921,[[[0.4886, 0.2358], [0.8647, 0.9051], [0.0866, 0.1341], [0.1883, 0.4973]]]], 2, Con16800), 
LBat60591 = batch_normalization_layer([[[[1.0185, 1.6354, 1.5793]], [[1.6494, 1.6929, 1.6361]]]], 2, 0.5306100987604745, [0.1219], [0.804], [0.0582], [0.0057], Bat60591), 
LRes87170 = reshape_layer(Bat60591, [2, 3], Res87170), 
LZer88861 = zero_padding1D_layer(Res87170, 1, 1, Zer88861), 
LSub86107 = subtract_layer(Con16800,Zer88861, Sub86107), 
LCon69675 = concatenate_layer([Sub86107,[[[0.9696, 0.6667, 0.5823], [0.2367, 0.036, 0.8198], [0.8657, 0.4312, 0.2016], [0.5765, 0.9759, 0.8561]]]], 2, Con69675), 
LMin67376 = minimum_layer([[[[[[0.9244, 0.1118]], [[0.2944, 0.4912]]]]], [[[[[0.2451, 0.1816]], [[0.6185, 0.6889]]]]]], Min67376), 
LRes52001 = reshape_layer(Min67376, [1, 2, 2], Res52001), 
LZer3104 = zero_padding2D_layer(Res52001, 1, 0, 1, 0, Zer3104), 
LAdd77409 = add_layer([[[[[0.5251]], [[0.784]]]], [[[[0.7678]], [[0.0276]]]]], Add77409), 
LZer93113 = zero_padding2D_layer(Add77409, 0, 0, 2, 0, Zer93113), 
LCon53544 = concatenate_layer([Zer93113,[[[[0.02], [0.9935], [0.9472]], [[0.9043], [0.4632], [0.3676]]]]], 3, Con53544), 
LSub62111 = subtract_layer(Zer3104,Con53544, Sub62111), 
LELU94014 = elu_layer(Sub62111, -3.6258692138704918, ELU94014), 
LRes8964 = reshape_layer(ELU94014, [2, 6], Res8964), 
LDot83222 = dot_layer(Con69675,Res8964, 2, 2, Dot83222), 
exec_layers([LGlo25548,LRes91926,LZer22921,LCon16800,LBat60591,LRes87170,LZer88861,LSub86107,LCon69675,LMin67376,LRes52001,LZer3104,LAdd77409,LZer93113,LCon53544,LSub62111,LELU94014,LRes8964,LDot83222],["Glo25548","Res91926","Zer22921","Con16800","Bat60591","Res87170","Zer88861","Sub86107","Con69675","Min67376","Res52001","Zer3104","Add77409","Zer93113","Con53544","Sub62111","ELU94014","Res8964","Dot83222"],Dot83222,"Dot83222")

Actual (Unparsed): [[[5.2953305, 3.2020185], [2.4403486, -0.0645043], [3.4874256, -0.7776197], [5.7973547, 2.6822984]]]

Expected (Unparsed): [[[5.2953304322329275,3.2020185073544916],[2.4403485625145915,-0.06450427695470805],[3.487425652427637,-0.7776196828595743],[5.79735474438061,2.6822984425228062]]]

Actual:   [[[5.2954, 3.2021], [2.4404, -0.0645], [3.4875, -0.7776], [5.7974, 2.6823]]]

Expected: [[[5.2954, 3.2021], [2.4404, -0.0645], [3.4875, -0.7776], [5.7974, 2.6823]]]