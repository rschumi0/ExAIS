import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub43833 = tf.keras.layers.Input(shape=([2]))
in1Sub43833 = tf.keras.layers.Input(shape=([2]))

Sub43833 = keras.layers.Subtract(name = 'Sub43833', )([in0Sub43833,in1Sub43833])
Lea66401 = keras.layers.LeakyReLU(alpha=0.967319770439934, name = 'Lea66401', )(Sub43833)
Res64986 = keras.layers.Reshape((2, 1), name = 'Res64986', )(Lea66401)
Glo61900 = keras.layers.GlobalMaxPool1D(name = 'Glo61900', )(Res64986)
model = tf.keras.models.Model(inputs=[in0Sub43833,in1Sub43833], outputs=Glo61900)
in0Sub43833 = tf.constant([[0.0718, 0.2713]])
in1Sub43833 = tf.constant([[0.1012, 0.9515]])
print (np.array2string(model.predict([in0Sub43833,in1Sub43833],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Glo61900.png')

LSub43833 = subtract_layer([[0.0718, 0.2713]], [[0.1012, 0.9515]], Sub43833), 
LLea66401 = leaky_relu_layer(Sub43833, 0.967319770439934, Lea66401), 
LRes64986 = reshape_layer(Lea66401, [2, 1], Res64986), 
LGlo61900 = global_max_pool1D_layer(Res64986, Glo61900), 
exec_layers([LSub43833,LLea66401,LRes64986,LGlo61900],["Sub43833","Lea66401","Res64986","Glo61900"],Glo61900,"Glo61900")

Actual (Unparsed): [[-0.0284392]]

Expected (Unparsed): [[-0.028439201250934056]]

Actual:   [[-0.0284]]

Expected: [[-0.0284]]