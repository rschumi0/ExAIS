import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add26093 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in1Add26093 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0GRU82033 = tf.keras.layers.Input(shape=([2, 1]))

Add26093 = keras.layers.Add(name = 'Add26093', )([in0Add26093,in1Add26093])
Res24186 = keras.layers.Reshape((1, 2, 1), name = 'Res24186', )(Add26093)
GRU82033 = keras.layers.GRU(2,reset_after=False, recurrent_activation='sigmoid', name = 'GRU82033', )(in0GRU82033)
Res2535 = keras.layers.Reshape((1, 2, 1), name = 'Res2535', )(GRU82033)
Ave65181 = keras.layers.Average(name = 'Ave65181', )([Res24186,Res2535])
Bat72088 = keras.layers.BatchNormalization(axis=1, epsilon=0.16701169932201645,  name = 'Bat72088', )(Ave65181)
model = tf.keras.models.Model(inputs=[in0Add26093,in1Add26093,in0GRU82033], outputs=Bat72088)
w = model.get_layer('GRU82033').get_weights() 
w[0] = np.array([[2, 4, 2, 9, 5, 9]])
w[1] = np.array([[10, 2, 2, 8, 10, 4], [8, 10, 2, 8, 6, 7]])
w[2] = np.array([6, 9, 3, 6, 1, 2])
model.get_layer('GRU82033').set_weights(w) 
w = model.get_layer('Bat72088').get_weights() 
w[0] = np.array([0.6052])
w[1] = np.array([0.8866])
w[2] = np.array([0.6529])
w[3] = np.array([0.3713])
model.get_layer('Bat72088').set_weights(w) 
in0Add26093 = tf.constant([[[[[0.1926]], [[0.3223]]]]])
in1Add26093 = tf.constant([[[[[0.0214]], [[0.0626]]]]])
in0GRU82033 = tf.constant([[[9], [10]]])
print (np.array2string(model.predict([in0Add26093,in1Add26093,in0GRU82033],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat72088.png')

LAdd26093 = add_layer([[[[[[0.1926]], [[0.3223]]]]], [[[[[0.0214]], [[0.0626]]]]]], Add26093), 
LRes24186 = reshape_layer(Add26093, [1, 2, 1], Res24186), 
LGRU82033 = gru_layer([[[9], [10]]],[[2, 4, 2, 9, 5, 9]],[[10, 2, 2, 8, 10, 4], [8, 10, 2, 8, 6, 7]],[6, 9, 3, 6, 1, 2], false, GRU82033), 
LRes2535 = reshape_layer(GRU82033, [1, 2, 1], Res2535), 
LAve65181 = average_layer([Res24186,Res2535], Ave65181), 
LBat72088 = batch_normalization_layer(Ave65181, 1, 0.16701169932201645, [0.6052], [0.8866], [0.6529], [0.3713], Bat72088), 
exec_layers([LAdd26093,LRes24186,LGRU82033,LRes2535,LAve65181,LBat72088],["Add26093","Res24186","GRU82033","Res2535","Ave65181","Bat72088"],Bat72088,"Bat72088")

Actual (Unparsed): [[[[0.4363071], [0.5067917]]]]

Expected (Unparsed): [[[[0.4363070947437164],[0.5067916683762682]]]]

Actual:   [[[[0.4364], [0.5068]]]]

Expected: [[[[0.4364], [0.5068]]]]