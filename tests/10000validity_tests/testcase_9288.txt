import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul91545 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))
in1Mul91545 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))
in0Zer29875 = tf.keras.layers.Input(shape=([1, 2]))
in0Con82803 = tf.keras.layers.Input(shape=([3]))

Mul91545 = keras.layers.Multiply(name = 'Mul91545', )([in0Mul91545,in1Mul91545])
Res22516 = keras.layers.Reshape((2, 1, 2), name = 'Res22516', )(Mul91545)
Res2951 = keras.layers.Reshape((2, 2), name = 'Res2951', )(Res22516)
Fla45368 = keras.layers.Flatten(name = 'Fla45368', )(Res2951)
Zer29875 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer29875', )(in0Zer29875)
Res31870 = keras.layers.Reshape((3, 2, 1), name = 'Res31870', )(Zer29875)
PRe14224 = keras.layers.PReLU(name = 'PRe14224', )(Res31870)
Res22801 = keras.layers.Reshape((3, 2, 1, 1), name = 'Res22801', )(PRe14224)
Glo70820 = keras.layers.GlobalAveragePooling3D(name = 'Glo70820', )(Res22801)
Con82803 = keras.layers.Concatenate(axis=1, name = 'Con82803', )([Glo70820,in0Con82803])
Add85042 = keras.layers.Add(name = 'Add85042', )([Fla45368,Con82803])
model = tf.keras.models.Model(inputs=[in0Mul91545,in1Mul91545,in0Zer29875,in0Con82803], outputs=Add85042)
w = model.get_layer('PRe14224').get_weights() 
w[0] = np.array([[[0.9344], [0.6223]], [[0.607], [0.4927]], [[0.3608], [0.5945]]])
model.get_layer('PRe14224').set_weights(w) 
in0Mul91545 = tf.constant([[[[[0.7668, 0.1821]]], [[[0.5848, 0.52]]]]])
in1Mul91545 = tf.constant([[[[[0.2353, 0.6827]]], [[[0.0383, 0.9082]]]]])
in0Zer29875 = tf.constant([[[1.2494, 1.1253]]])
in0Con82803 = tf.constant([[0.8823, 0.4996, 0.1541]])
print (np.array2string(model.predict([in0Mul91545,in1Mul91545,in0Zer29875,in0Con82803],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add85042.png')

LMul91545 = multiply_layer([[[[[[0.7668, 0.1821]]], [[[0.5848, 0.52]]]]], [[[[[0.2353, 0.6827]]], [[[0.0383, 0.9082]]]]]], Mul91545), 
LRes22516 = reshape_layer(Mul91545, [2, 1, 2], Res22516), 
LRes2951 = reshape_layer(Res22516, [2, 2], Res2951), 
LFla45368 = flatten_layer(Res2951, Fla45368), 
LZer29875 = zero_padding1D_layer([[[1.2494, 1.1253]]], 1, 1, Zer29875), 
LRes31870 = reshape_layer(Zer29875, [3, 2, 1], Res31870), 
LPRe14224 = prelu_layer(Res31870, [[[0.9344], [0.6223]], [[0.607], [0.4927]], [[0.3608], [0.5945]]], PRe14224), 
LRes22801 = reshape_layer(PRe14224, [3, 2, 1, 1], Res22801), 
LGlo70820 = global_average_pooling3D_layer(Res22801, Glo70820), 
LCon82803 = concatenate_layer([Glo70820,[[0.8823, 0.4996, 0.1541]]], 1, Con82803), 
LAdd85042 = add_layer([Fla45368,Con82803], Add85042), 
exec_layers([LMul91545,LRes22516,LRes2951,LFla45368,LZer29875,LRes31870,LPRe14224,LRes22801,LGlo70820,LCon82803,LAdd85042],["Mul91545","Res22516","Res2951","Fla45368","Zer29875","Res31870","PRe14224","Res22801","Glo70820","Con82803","Add85042"],Add85042,"Add85042")

Actual (Unparsed): [[0.5762114, 1.0066197, 0.5219978, 0.6263640]]

Expected (Unparsed): [[0.5762113733333334,1.00661967,0.5219978399999999,0.626364]]

Actual:   [[0.5763, 1.0067, 0.522, 0.6264]]

Expected: [[0.5763, 1.0067, 0.522, 0.6264]]