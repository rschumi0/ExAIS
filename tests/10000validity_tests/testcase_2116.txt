import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add66282 = tf.keras.layers.Input(shape=([1, 1]))
in1Add66282 = tf.keras.layers.Input(shape=([1, 1]))
in0Up_81290 = tf.keras.layers.Input(shape=([3, 3, 1]))
in0Con40486 = tf.keras.layers.Input(shape=([6, 6, 3]))

Add66282 = keras.layers.Add(name = 'Add66282', )([in0Add66282,in1Add66282])
Res1135 = keras.layers.Reshape((1, 1, 1), name = 'Res1135', )(Add66282)
Con64445 = keras.layers.Conv2D(4, (1, 1),strides=(1, 1), padding='valid', dilation_rate=(1, 1), name = 'Con64445', )(Res1135)
Zer38596 = keras.layers.ZeroPadding2D(padding=((5, 0), (5, 0)), name = 'Zer38596', )(Con64445)
Up_81290 = keras.layers.UpSampling2D(size=(2, 2), name = 'Up_81290', )(in0Up_81290)
Con40486 = keras.layers.Concatenate(axis=3, name = 'Con40486', )([Up_81290,in0Con40486])
Ave9705 = keras.layers.Average(name = 'Ave9705', )([Zer38596,Con40486])
model = tf.keras.models.Model(inputs=[in0Add66282,in1Add66282,in0Up_81290,in0Con40486], outputs=Ave9705)
w = model.get_layer('Con64445').get_weights() 
w[0] = np.array([[[[0.9133, 0.1853, 0.5419, 0.6387]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con64445').set_weights(w) 
in0Add66282 = tf.constant([[[0.7923]]])
in1Add66282 = tf.constant([[[0.4247]]])
in0Up_81290 = tf.constant([[[[1.213], [1.1201], [1.3341]], [[1.4407], [1.497], [1.4427]], [[1.3057], [1.7043], [1.083]]]])
in0Con40486 = tf.constant([[[[0.2701, 0.669, 0.2792], [0.7141, 0.0132, 0.5521], [0.3305, 0.9267, 0.198], [0.2382, 0.5839, 0.0445], [0.4883, 0.4292, 0.6507], [0.2207, 0.1283, 0.7796]], [[0.0655, 0.4546, 0.0963], [0.9874, 0.538, 0.4845], [0.7734, 0.8817, 0.4792], [0.6087, 0.9822, 0.8937], [0.4151, 0.4877, 0.2446], [0.6729, 0.4713, 0.0565]], [[0.5014, 0.6344, 0.5826], [0.91, 0.3394, 0.9126], [0.465, 0.9079, 0.9765], [0.5325, 0.6704, 0.2929], [0.8752, 0.6116, 0.2379], [0.3157, 0.8689, 0.0547]], [[0.5562, 0.2146, 0.118], [0.5157, 0.0523, 0.4122], [0.0408, 0.3661, 0.2374], [0.9608, 0.6083, 0.032], [0.4539, 0.5918, 0.0326], [0.3378, 0.396, 0.2069]], [[0.9347, 0.4329, 0.1004], [0.2868, 0.5325, 0.466], [0.6451, 0.4852, 0.2555], [0.4175, 0.2341, 0.6295], [0.4632, 0.4093, 0.6934], [0.4527, 0.6197, 0.363]], [[0.6619, 0.6449, 0.3622], [0.1006, 0.9183, 0.2329], [0.3879, 0.8492, 0.3555], [0.8695, 0.9811, 0.6412], [0.0847, 0.3476, 0.3037], [0.2866, 0.0351, 0.5399]]]])
print (np.array2string(model.predict([in0Add66282,in1Add66282,in0Up_81290,in0Con40486],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave9705.png')

LAdd66282 = add_layer([[[[0.7923]]], [[[0.4247]]]], Add66282), 
LRes1135 = reshape_layer(Add66282, [1, 1, 1], Res1135), 
LCon64445 = conv2D_layer(Res1135, 1, 1,[[[[0.9133, 0.1853, 0.5419, 0.6387]]]],[0, 0, 0, 0], 1, 1, false, 1, 1, Con64445), 
LZer38596 = zero_padding2D_layer(Con64445, 5, 0, 5, 0, Zer38596), 
LUp_81290 = up_sampling2D_layer([[[[1.213], [1.1201], [1.3341]], [[1.4407], [1.497], [1.4427]], [[1.3057], [1.7043], [1.083]]]], 2, 2, Up_81290), 
LCon40486 = concatenate_layer([Up_81290,[[[[0.2701, 0.669, 0.2792], [0.7141, 0.0132, 0.5521], [0.3305, 0.9267, 0.198], [0.2382, 0.5839, 0.0445], [0.4883, 0.4292, 0.6507], [0.2207, 0.1283, 0.7796]], [[0.0655, 0.4546, 0.0963], [0.9874, 0.538, 0.4845], [0.7734, 0.8817, 0.4792], [0.6087, 0.9822, 0.8937], [0.4151, 0.4877, 0.2446], [0.6729, 0.4713, 0.0565]], [[0.5014, 0.6344, 0.5826], [0.91, 0.3394, 0.9126], [0.465, 0.9079, 0.9765], [0.5325, 0.6704, 0.2929], [0.8752, 0.6116, 0.2379], [0.3157, 0.8689, 0.0547]], [[0.5562, 0.2146, 0.118], [0.5157, 0.0523, 0.4122], [0.0408, 0.3661, 0.2374], [0.9608, 0.6083, 0.032], [0.4539, 0.5918, 0.0326], [0.3378, 0.396, 0.2069]], [[0.9347, 0.4329, 0.1004], [0.2868, 0.5325, 0.466], [0.6451, 0.4852, 0.2555], [0.4175, 0.2341, 0.6295], [0.4632, 0.4093, 0.6934], [0.4527, 0.6197, 0.363]], [[0.6619, 0.6449, 0.3622], [0.1006, 0.9183, 0.2329], [0.3879, 0.8492, 0.3555], [0.8695, 0.9811, 0.6412], [0.0847, 0.3476, 0.3037], [0.2866, 0.0351, 0.5399]]]]], 3, Con40486), 
LAve9705 = average_layer([Zer38596,Con40486], Ave9705), 
exec_layers([LAdd66282,LRes1135,LCon64445,LZer38596,LUp_81290,LCon40486,LAve9705],["Add66282","Res1135","Con64445","Zer38596","Up_81290","Con40486","Ave9705"],Ave9705,"Ave9705")

Actual (Unparsed): [[[[0.6065000, 0.1350500, 0.3345000, 0.1396000], [0.6065000, 0.3570500, 0.0066000, 0.2760500], [0.5600500, 0.1652500, 0.4633500, 0.0990000], [0.5600500, 0.1191000, 0.2919500, 0.0222500], [0.6670500, 0.2441500, 0.2146000, 0.3253500], [0.6670500, 0.1103500, 0.0641500, 0.3898000]], [[0.6065000, 0.0327500, 0.2273000, 0.0481500], [0.6065000, 0.4937000, 0.2690000, 0.2422500], [0.5600500, 0.3867000, 0.4408500, 0.2396000], [0.5600500, 0.3043500, 0.4911000, 0.4468500], [0.6670500, 0.2075500, 0.2438500, 0.1223000], [0.6670500, 0.3364500, 0.2356500, 0.0282500]], [[0.7203500, 0.2507000, 0.3172000, 0.2913000], [0.7203500, 0.4550000, 0.1697000, 0.4563000], [0.7485000, 0.2325000, 0.4539500, 0.4882500], [0.7485000, 0.2662500, 0.3352000, 0.1464500], [0.7213500, 0.4376000, 0.3058000, 0.1189500], [0.7213500, 0.1578500, 0.4344500, 0.0273500]], [[0.7203500, 0.2781000, 0.1073000, 0.0590000], [0.7203500, 0.2578500, 0.0261500, 0.2061000], [0.7485000, 0.0204000, 0.1830500, 0.1187000], [0.7485000, 0.4804000, 0.3041500, 0.0160000], [0.7213500, 0.2269500, 0.2959000, 0.0163000], [0.7213500, 0.1689000, 0.1980000, 0.1034500]], [[0.6528500, 0.4673500, 0.2164500, 0.0502000], [0.6528500, 0.1434000, 0.2662500, 0.2330000], [0.8521500, 0.3225500, 0.2426000, 0.1277500], [0.8521500, 0.2087500, 0.1170500, 0.3147500], [0.5415000, 0.2316000, 0.2046500, 0.3467000], [0.5415000, 0.2263500, 0.3098500, 0.1815000]], [[0.6528500, 0.3309500, 0.3224500, 0.1811000], [0.6528500, 0.0503000, 0.4591500, 0.1164500], [0.8521500, 0.1939500, 0.4246000, 0.1777500], [0.8521500, 0.4347500, 0.4905500, 0.3206000], [0.5415000, 0.0423500, 0.1738000, 0.1518500], [1.0972430, 0.2560550, 0.3472961, 0.6585989]]]]

Expected (Unparsed): [[[[0.6065,0.13505,0.3345,0.1396],[0.6065,0.35705,0.0066,0.27605],[0.56005,0.16525,0.46335,0.099],[0.56005,0.1191,0.29195,0.02225],[0.66705,0.24415,0.2146,0.32535],[0.66705,0.11035,0.06415,0.3898]],[[0.6065,0.03275,0.2273,0.04815],[0.6065,0.4937,0.269,0.24225],[0.56005,0.3867,0.44085,0.2396],[0.56005,0.30435,0.4911,0.44685],[0.66705,0.20755,0.24385,0.1223],[0.66705,0.33645,0.23565,0.02825]],[[0.72035,0.2507,0.3172,0.2913],[0.72035,0.455,0.1697,0.4563],[0.7485,0.2325,0.45395,0.48825],[0.7485,0.26625,0.3352,0.14645],[0.72135,0.4376,0.3058,0.11895],[0.72135,0.15785,0.43445,0.02735]],[[0.72035,0.2781,0.1073,0.059],[0.72035,0.25785,0.02615,0.2061],[0.7485,0.0204,0.18305,0.1187],[0.7485,0.4804,0.30415,0.016],[0.72135,0.22695,0.2959,0.0163],[0.72135,0.1689,0.198,0.10345]],[[0.65285,0.46735,0.21645,0.0502],[0.65285,0.1434,0.26625,0.233],[0.85215,0.32255,0.2426,0.12775],[0.85215,0.20875,0.11705,0.31475],[0.5415,0.2316,0.20465,0.3467],[0.5415,0.22635,0.30985,0.1815]],[[0.65285,0.33095,0.32245,0.1811],[0.65285,0.0503,0.45915,0.11645],[0.85215,0.19395,0.4246,0.17775],[0.85215,0.43475,0.49055,0.3206],[0.5415,0.04235,0.1738,0.15185],[1.0972430499999999,0.25605505,0.3472961500000001,0.65859895]]]]

Actual:   [[[[0.6065, 0.1351, 0.3345, 0.1396], [0.6065, 0.3571, 0.0066, 0.2761], [0.5601, 0.1653, 0.4634, 0.099], [0.5601, 0.1191, 0.292, 0.0223], [0.6671, 0.2442, 0.2146, 0.3254], [0.6671, 0.1104, 0.0642, 0.3898]], [[0.6065, 0.0328, 0.2273, 0.0482], [0.6065, 0.4937, 0.269, 0.2423], [0.5601, 0.3867, 0.4409, 0.2396], [0.5601, 0.3044, 0.4911, 0.4469], [0.6671, 0.2076, 0.2439, 0.1223], [0.6671, 0.3365, 0.2357, 0.0283]], [[0.7204, 0.2507, 0.3172, 0.2913], [0.7204, 0.455, 0.1697, 0.4563], [0.7485, 0.2325, 0.454, 0.4883], [0.7485, 0.2663, 0.3352, 0.1465], [0.7214, 0.4376, 0.3058, 0.119], [0.7214, 0.1579, 0.4345, 0.0274]], [[0.7204, 0.2781, 0.1073, 0.059], [0.7204, 0.2579, 0.0262, 0.2061], [0.7485, 0.0204, 0.1831, 0.1187], [0.7485, 0.4804, 0.3042, 0.016], [0.7214, 0.227, 0.2959, 0.0163], [0.7214, 0.1689, 0.198, 0.1035]], [[0.6529, 0.4674, 0.2165, 0.0502], [0.6529, 0.1434, 0.2663, 0.233], [0.8522, 0.3226, 0.2426, 0.1278], [0.8522, 0.2088, 0.1171, 0.3148], [0.5415, 0.2316, 0.2047, 0.3467], [0.5415, 0.2264, 0.3099, 0.1815]], [[0.6529, 0.331, 0.3225, 0.1811], [0.6529, 0.0503, 0.4592, 0.1165], [0.8522, 0.194, 0.4246, 0.1778], [0.8522, 0.4348, 0.4906, 0.3206], [0.5415, 0.0424, 0.1738, 0.1519], [1.0973, 0.2561, 0.3473, 0.6586]]]]

Expected: [[[[0.6065, 0.1351, 0.3345, 0.1396], [0.6065, 0.3571, 0.0066, 0.2761], [0.5601, 0.1653, 0.4634, 0.099], [0.5601, 0.1191, 0.292, 0.0223], [0.6671, 0.2442, 0.2146, 0.3254], [0.6671, 0.1104, 0.0642, 0.3898]], [[0.6065, 0.0328, 0.2273, 0.0482], [0.6065, 0.4937, 0.269, 0.2423], [0.5601, 0.3867, 0.4409, 0.2396], [0.5601, 0.3044, 0.4911, 0.4469], [0.6671, 0.2076, 0.2439, 0.1223], [0.6671, 0.3365, 0.2357, 0.0283]], [[0.7204, 0.2507, 0.3172, 0.2913], [0.7204, 0.455, 0.1697, 0.4563], [0.7485, 0.2325, 0.454, 0.4883], [0.7485, 0.2663, 0.3352, 0.1465], [0.7214, 0.4376, 0.3058, 0.119], [0.7214, 0.1579, 0.4345, 0.0274]], [[0.7204, 0.2781, 0.1073, 0.059], [0.7204, 0.2579, 0.0262, 0.2061], [0.7485, 0.0204, 0.1831, 0.1187], [0.7485, 0.4804, 0.3042, 0.016], [0.7214, 0.227, 0.2959, 0.0163], [0.7214, 0.1689, 0.198, 0.1035]], [[0.6529, 0.4674, 0.2165, 0.0502], [0.6529, 0.1434, 0.2663, 0.233], [0.8522, 0.3226, 0.2426, 0.1278], [0.8522, 0.2088, 0.1171, 0.3148], [0.5415, 0.2316, 0.2047, 0.3467], [0.5415, 0.2264, 0.3099, 0.1815]], [[0.6529, 0.331, 0.3225, 0.1811], [0.6529, 0.0503, 0.4592, 0.1165], [0.8522, 0.194, 0.4246, 0.1778], [0.8522, 0.4348, 0.4906, 0.3206], [0.5415, 0.0424, 0.1738, 0.1519], [1.0973, 0.2561, 0.3473, 0.6586]]]]