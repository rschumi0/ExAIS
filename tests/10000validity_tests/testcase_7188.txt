import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Lea48571 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in0GRU26841 = tf.keras.layers.Input(shape=([1, 3]))
in0Con27691 = tf.keras.layers.Input(shape=([2]))
in0Con46306 = tf.keras.layers.Input(shape=([4, 3, 5, 1]))
in0Sub62588 = tf.keras.layers.Input(shape=([3, 2, 3, 2]))
in1Sub62588 = tf.keras.layers.Input(shape=([3, 2, 3, 2]))

Lea48571 = keras.layers.LeakyReLU(alpha=9.65455480736136, name = 'Lea48571', input_shape=(2, 2, 1, 1))(in0Lea48571)
Res99014 = keras.layers.Reshape((2, 2, 1), name = 'Res99014', )(Lea48571)
Res28185 = keras.layers.Reshape((2, 2), name = 'Res28185', )(Res99014)
Fla53140 = keras.layers.Flatten(name = 'Fla53140', )(Res28185)
GRU26841 = keras.layers.GRU(2,reset_after=False, recurrent_activation='sigmoid', name = 'GRU26841', )(in0GRU26841)
Bat82944 = keras.layers.BatchNormalization(axis=1, epsilon=0.8780111993971106,  name = 'Bat82944', )(GRU26841)
Con27691 = keras.layers.Concatenate(axis=1, name = 'Con27691', )([Bat82944,in0Con27691])
Mul47472 = keras.layers.Multiply(name = 'Mul47472', )([Fla53140,Con27691])
Res89050 = keras.layers.Reshape((4, 1), name = 'Res89050', )(Mul47472)
Res40610 = keras.layers.Reshape((4, 1, 1), name = 'Res40610', )(Res89050)
Res39742 = keras.layers.Reshape((4, 1, 1, 1), name = 'Res39742', )(Res40610)
Zer72222 = keras.layers.ZeroPadding3D(padding=((0, 0), (2, 0), (4, 0)), name = 'Zer72222', )(Res39742)
Con46306 = keras.layers.Concatenate(axis=4, name = 'Con46306', )([Zer72222,in0Con46306])
Sub62588 = keras.layers.Subtract(name = 'Sub62588', )([in0Sub62588,in1Sub62588])
Lay27083 = keras.layers.LayerNormalization(axis=1, epsilon=1.2095658912226657, name = 'Lay27083', )(Sub62588)
Zer78852 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (2, 0)), name = 'Zer78852', )(Lay27083)
Ave92614 = keras.layers.Average(name = 'Ave92614', )([Con46306,Zer78852])
model = tf.keras.models.Model(inputs=[in0Lea48571,in0GRU26841,in0Con27691,in0Con46306,in0Sub62588,in1Sub62588], outputs=Ave92614)
w = model.get_layer('GRU26841').get_weights() 
w[0] = np.array([[2, 7, 2, 8, 6, 6], [9, 8, 7, 8, 4, 2], [5, 1, 5, 9, 7, 10]])
w[1] = np.array([[9, 7, 5, 3, 10, 8], [2, 5, 3, 1, 3, 2]])
w[2] = np.array([3, 7, 3, 1, 10, 8])
model.get_layer('GRU26841').set_weights(w) 
w = model.get_layer('Bat82944').get_weights() 
w[0] = np.array([0.2835, 0.8552])
w[1] = np.array([0.4755, 0.7049])
w[2] = np.array([0.212, 0.3168])
w[3] = np.array([0.2439, 0.0384])
model.get_layer('Bat82944').set_weights(w) 
in0Lea48571 = tf.constant([[[[[0.8664]], [[0.4545]]], [[[0.0268]], [[0.5255]]]]])
in0GRU26841 = tf.constant([[[3, 10, 4]]])
in0Con27691 = tf.constant([[0.4833, 0.2821]])
in0Con46306 = tf.constant([[[[[0.0637], [0.7261], [0.257], [0.5935], [0.7581]], [[0.4575], [0.9405], [0.744], [0.7162], [0.3552]], [[0.4797], [0.112], [0.8804], [0.5932], [0.3068]]], [[[0.0463], [0.5005], [0.0172], [0.6454], [0.1877]], [[0.6043], [0.6774], [0.8872], [0.591], [0.9691]], [[0.7212], [0.9428], [0.1518], [0.2679], [0.6852]]], [[[0.7967], [0.9243], [0.9366], [0.8802], [0.0063]], [[0.8307], [0.703], [0.0055], [0.4256], [0.4745]], [[0.6537], [0.3448], [0.0035], [0.2486], [0.1743]]], [[[0.8989], [0.1108], [0.7022], [0.0915], [0.592]], [[0.4843], [0.1717], [0.8711], [0.2526], [0.5385]], [[0.0162], [0.781], [0.4136], [0.4953], [0.4042]]]]])
in0Sub62588 = tf.constant([[[[[0.3082, 0.0111], [0.7695, 0.4649], [0.1848, 0.1228]], [[0.1399, 0.4608], [0.2547, 0.5288], [0.2585, 0.4262]]], [[[0.3807, 0.2658], [0.4649, 0.2496], [0.1921, 0.1711]], [[0.5677, 0.3143], [0.32, 0.9714], [0.7142, 0.1055]]], [[[0.0923, 0.5835], [0.0065, 0.7514], [0.3603, 0.3739]], [[0.4676, 0.3721], [0.2781, 0.7266], [0.3142, 0.0329]]]]])
in1Sub62588 = tf.constant([[[[[0.6698, 0.7691], [0.01, 0.4357], [0.082, 0.5209]], [[0.2383, 0.2181], [0.7431, 0.0447], [0.7588, 0.8775]]], [[[0.4282, 0.4037], [0.0974, 0.888], [0.6633, 0.3603]], [[0.1519, 0.5365], [0.794, 0.7854], [0.0935, 0.3692]]], [[[0.1898, 0.6901], [0.3914, 0.9081], [0.2585, 0.6439]], [[0.3974, 0.4767], [0.0063, 0.0908], [0.6869, 0.5552]]]]])
print (np.array2string(model.predict([in0Lea48571,in0GRU26841,in0Con27691,in0Con46306,in0Sub62588,in1Sub62588],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave92614.png')

LLea48571 = leaky_relu_layer([[[[[0.8664]], [[0.4545]]], [[[0.0268]], [[0.5255]]]]], 9.65455480736136, Lea48571), 
LRes99014 = reshape_layer(Lea48571, [2, 2, 1], Res99014), 
LRes28185 = reshape_layer(Res99014, [2, 2], Res28185), 
LFla53140 = flatten_layer(Res28185, Fla53140), 
LGRU26841 = gru_layer([[[3, 10, 4]]],[[2, 7, 2, 8, 6, 6], [9, 8, 7, 8, 4, 2], [5, 1, 5, 9, 7, 10]],[[9, 7, 5, 3, 10, 8], [2, 5, 3, 1, 3, 2]],[3, 7, 3, 1, 10, 8], false, GRU26841), 
LBat82944 = batch_normalization_layer(GRU26841, 1, 0.8780111993971106, [0.2835, 0.8552], [0.4755, 0.7049], [0.212, 0.3168], [0.2439, 0.0384], Bat82944), 
LCon27691 = concatenate_layer([Bat82944,[[0.4833, 0.2821]]], 1, Con27691), 
LMul47472 = multiply_layer([Fla53140,Con27691], Mul47472), 
LRes89050 = reshape_layer(Mul47472, [4, 1], Res89050), 
LRes40610 = reshape_layer(Res89050, [4, 1, 1], Res40610), 
LRes39742 = reshape_layer(Res40610, [4, 1, 1, 1], Res39742), 
LZer72222 = zero_padding3D_layer(Res39742, 0, 0, 2, 0, 4, 0, Zer72222), 
LCon46306 = concatenate_layer([Zer72222,[[[[[0.0637], [0.7261], [0.257], [0.5935], [0.7581]], [[0.4575], [0.9405], [0.744], [0.7162], [0.3552]], [[0.4797], [0.112], [0.8804], [0.5932], [0.3068]]], [[[0.0463], [0.5005], [0.0172], [0.6454], [0.1877]], [[0.6043], [0.6774], [0.8872], [0.591], [0.9691]], [[0.7212], [0.9428], [0.1518], [0.2679], [0.6852]]], [[[0.7967], [0.9243], [0.9366], [0.8802], [0.0063]], [[0.8307], [0.703], [0.0055], [0.4256], [0.4745]], [[0.6537], [0.3448], [0.0035], [0.2486], [0.1743]]], [[[0.8989], [0.1108], [0.7022], [0.0915], [0.592]], [[0.4843], [0.1717], [0.8711], [0.2526], [0.5385]], [[0.0162], [0.781], [0.4136], [0.4953], [0.4042]]]]]], 4, Con46306), 
LSub62588 = subtract_layer([[[[[0.3082, 0.0111], [0.7695, 0.4649], [0.1848, 0.1228]], [[0.1399, 0.4608], [0.2547, 0.5288], [0.2585, 0.4262]]], [[[0.3807, 0.2658], [0.4649, 0.2496], [0.1921, 0.1711]], [[0.5677, 0.3143], [0.32, 0.9714], [0.7142, 0.1055]]], [[[0.0923, 0.5835], [0.0065, 0.7514], [0.3603, 0.3739]], [[0.4676, 0.3721], [0.2781, 0.7266], [0.3142, 0.0329]]]]], [[[[[0.6698, 0.7691], [0.01, 0.4357], [0.082, 0.5209]], [[0.2383, 0.2181], [0.7431, 0.0447], [0.7588, 0.8775]]], [[[0.4282, 0.4037], [0.0974, 0.888], [0.6633, 0.3603]], [[0.1519, 0.5365], [0.794, 0.7854], [0.0935, 0.3692]]], [[[0.1898, 0.6901], [0.3914, 0.9081], [0.2585, 0.6439]], [[0.3974, 0.4767], [0.0063, 0.0908], [0.6869, 0.5552]]]]], Sub62588), 
LLay27083 = layer_normalization_layer(Sub62588, 1, 1.2095658912226657, Lay27083), 
LZer78852 = zero_padding3D_layer(Lay27083, 1, 0, 1, 0, 2, 0, Zer78852), 
LAve92614 = average_layer([Con46306,Zer78852], Ave92614), 
exec_layers([LLea48571,LRes99014,LRes28185,LFla53140,LGRU26841,LBat82944,LCon27691,LMul47472,LRes89050,LRes40610,LRes39742,LZer72222,LCon46306,LSub62588,LLay27083,LZer78852,LAve92614],["Lea48571","Res99014","Res28185","Fla53140","GRU26841","Bat82944","Con27691","Mul47472","Res89050","Res40610","Res39742","Zer72222","Con46306","Sub62588","Lay27083","Zer78852","Ave92614"],Ave92614,"Ave92614")

Actual (Unparsed): [[[[[0.0000000, 0.0318500], [0.0000000, 0.3630500], [0.0000000, 0.1285000], [0.0000000, 0.2967500], [0.0000000, 0.3790500]], [[0.0000000, 0.2287500], [0.0000000, 0.4702500], [0.0000000, 0.3720000], [0.0000000, 0.3581000], [0.0000000, 0.1776000]], [[0.0000000, 0.2398500], [0.0000000, 0.0560000], [0.0000000, 0.4402000], [0.0000000, 0.2966000], [0.1814057, 0.1534000]]], [[[0.0000000, 0.0231500], [0.0000000, 0.2502500], [0.0000000, 0.0086000], [0.0000000, 0.3227000], [0.0000000, 0.0938500]], [[0.0000000, 0.3021500], [0.0000000, 0.3387000], [-0.0869420, 0.2577044], [0.2137561, 0.4208069], [0.0846178, 0.4336357]], [[0.0000000, 0.3606000], [0.0000000, 0.4714000], [-0.1015677, 0.1970474], [-0.1117089, 0.1558224], [-0.0763128, 0.3250164]]], [[[0.0000000, 0.3983500], [0.0000000, 0.4621500], [0.0000000, 0.4683000], [0.0000000, 0.4401000], [0.0000000, 0.0031500]], [[0.0000000, 0.4153500], [0.0000000, 0.3515000], [0.0547485, 0.0888336], [0.0501417, 0.0440651], [-0.1687941, 0.2810182]], [[0.0000000, 0.3268500], [0.0000000, 0.1724000], [0.1278968, -0.0851354], [-0.1054788, 0.0125625], [0.2980595, 0.1544380]]], [[[0.0000000, 0.4494500], [0.0000000, 0.0554000], [0.0000000, 0.3511000], [0.0000000, 0.0457500], [0.0000000, 0.2960000]], [[0.0000000, 0.2421500], [0.0000000, 0.0858500], [0.0321935, 0.5353620], [-0.2638978, 0.1697280], [0.0841763, 0.2763961]], [[0.0000000, 0.0081000], [0.0000000, 0.3905000], [-0.0263291, 0.1725380], [0.2171877, 0.3375151], [-0.0452751, 0.1523956]]]]]

Expected (Unparsed): [[[[[0,0.03185],[0,0.36305],[0,0.1285],[0,0.29675],[0,0.37905]],[[0,0.22875],[0,0.47025],[0,0.372],[0,0.3581],[0,0.1776]],[[0,0.23985],[0,0.056],[0,0.4402],[0,0.2966],[0.18140568016621575,0.1534]]],[[[0,0.02315],[0,0.25025],[0,0.0086],[0,0.3227],[0,0.09385]],[[0,0.30215],[0,0.3387],[-0.08694195953624152,0.2577043621959634],[0.21375606853765985,0.4208068835296595],[0.08461777265202483,0.433635686271911]],[[0,0.3606],[0,0.4714],[-0.10156774558019493,0.19704741059399475],[-0.11170886481751745,0.15582240081182816],[-0.07631276904130975,0.3250164542487054]]],[[[0,0.39835],[0,0.46215],[0,0.4683],[0,0.4401],[0,0.00315]],[[0,0.41535],[0,0.3515],[0.054748473654696546,0.08883364257885705],[0.05014168647550938,0.044065142073066554],[-0.16879406127282173,0.2810181800801999]],[[0,0.32685],[0,0.1724],[0.1278968184678553,-0.08513545514774924],[-0.10547878095472796,0.012562509787115567],[0.29805953150438924,0.15443797696593187]]],[[[0,0.44945],[0,0.0554],[0,0.3511],[0,0.04575],[0,0.296]],[[0,0.24215],[0,0.08585],[0.032193485881545005,0.5353619952251796],[-0.2638977550131692,0.16972797439727388],[0.08417628862079687,0.276396133647889]],[[0,0.0081],[0,0.3905],[-0.02632907288766035,0.1725380445537545],[0.2171876457722454,0.33751508940105623],[-0.04527513717390287,0.1523955687853627]]]]]

Actual:   [[[[[0, 0.0319], [0, 0.3631], [0, 0.1285], [0, 0.2968], [0, 0.3791]], [[0, 0.2288], [0, 0.4703], [0, 0.372], [0, 0.3581], [0, 0.1776]], [[0, 0.2399], [0, 0.056], [0, 0.4402], [0, 0.2966], [0.1815, 0.1534]]], [[[0, 0.0232], [0, 0.2503], [0, 0.0086], [0, 0.3227], [0, 0.0939]], [[0, 0.3022], [0, 0.3387], [-0.0869, 0.2578], [0.2138, 0.4209], [0.0847, 0.4337]], [[0, 0.3606], [0, 0.4714], [-0.1015, 0.1971], [-0.1117, 0.1559], [-0.0763, 0.3251]]], [[[0, 0.3984], [0, 0.4622], [0, 0.4683], [0, 0.4401], [0, 0.0032]], [[0, 0.4154], [0, 0.3515], [0.0548, 0.0889], [0.0502, 0.0441], [-0.1687, 0.2811]], [[0, 0.3269], [0, 0.1724], [0.1279, -0.0851], [-0.1054, 0.0126], [0.2981, 0.1545]]], [[[0, 0.4495], [0, 0.0554], [0, 0.3511], [0, 0.0458], [0, 0.296]], [[0, 0.2422], [0, 0.0859], [0.0322, 0.5354], [-0.2638, 0.1698], [0.0842, 0.2764]], [[0, 0.0081], [0, 0.3905], [-0.0263, 0.1726], [0.2172, 0.3376], [-0.0452, 0.1524]]]]]

Expected: [[[[[0, 0.0319], [0, 0.3631], [0, 0.1285], [0, 0.2968], [0, 0.3791]], [[0, 0.2288], [0, 0.4703], [0, 0.372], [0, 0.3581], [0, 0.1776]], [[0, 0.2399], [0, 0.056], [0, 0.4402], [0, 0.2966], [0.1815, 0.1534]]], [[[0, 0.0232], [0, 0.2503], [0, 0.0086], [0, 0.3227], [0, 0.0939]], [[0, 0.3022], [0, 0.3387], [-0.0869, 0.2578], [0.2138, 0.4209], [0.0847, 0.4337]], [[0, 0.3606], [0, 0.4714], [-0.1015, 0.1971], [-0.1117, 0.1559], [-0.0763, 0.3251]]], [[[0, 0.3984], [0, 0.4622], [0, 0.4683], [0, 0.4401], [0, 0.0032]], [[0, 0.4154], [0, 0.3515], [0.0548, 0.0889], [0.0502, 0.0441], [-0.1687, 0.2811]], [[0, 0.3269], [0, 0.1724], [0.1279, -0.0851], [-0.1054, 0.0126], [0.2981, 0.1545]]], [[[0, 0.4495], [0, 0.0554], [0, 0.3511], [0, 0.0458], [0, 0.296]], [[0, 0.2422], [0, 0.0859], [0.0322, 0.5354], [-0.2638, 0.1698], [0.0842, 0.2764]], [[0, 0.0081], [0, 0.3905], [-0.0263, 0.1726], [0.2172, 0.3376], [-0.0452, 0.1524]]]]]