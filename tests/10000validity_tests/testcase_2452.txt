import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ELU38638 = tf.keras.layers.Input(shape=([2, 2, 1]))

ELU38638 = keras.layers.ELU(alpha=1.1517184974808377, name = 'ELU38638', input_shape=(2, 2, 1))(in0ELU38638)
Bat69593 = keras.layers.BatchNormalization(axis=3, epsilon=0.963593698762657,  name = 'Bat69593', )(ELU38638)
model = tf.keras.models.Model(inputs=[in0ELU38638], outputs=Bat69593)
w = model.get_layer('Bat69593').get_weights() 
w[0] = np.array([0.4089])
w[1] = np.array([0.4648])
w[2] = np.array([0.3187])
w[3] = np.array([0.3102])
model.get_layer('Bat69593').set_weights(w) 
in0ELU38638 = tf.constant([[[[0.5161], [0.2435]], [[0.2027], [0.9351]]]])
print (np.array2string(model.predict([in0ELU38638],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat69593.png')

LELU38638 = elu_layer([[[[0.5161], [0.2435]], [[0.2027], [0.9351]]]], 1.1517184974808377, ELU38638), 
LBat69593 = batch_normalization_layer(ELU38638, 3, 0.963593698762657, [0.4089], [0.4648], [0.3187], [0.3102], Bat69593), 
exec_layers([LELU38638,LBat69593],["ELU38638","Bat69593"],Bat69593,"Bat69593")

Actual (Unparsed): [[[[0.5363179], [0.4375551]], [[0.4227733], [0.6881213]]]]

Expected (Unparsed): [[[[0.5363178929411623],[0.4375550884033667]],[[0.42277327466476783],[0.6881213232468717]]]]

Actual:   [[[[0.5364], [0.4376]], [[0.4228], [0.6882]]]]

Expected: [[[[0.5364], [0.4376]], [[0.4228], [0.6882]]]]