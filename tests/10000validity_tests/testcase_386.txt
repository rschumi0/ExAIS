import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave60356 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in1Ave60356 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Glo30150 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con91452 = tf.keras.layers.Input(shape=([2]))
in0Con42916 = tf.keras.layers.Input(shape=([4, 1]))
in0Min55609 = tf.keras.layers.Input(shape=([1, 2]))
in1Min55609 = tf.keras.layers.Input(shape=([1, 2]))

Ave60356 = keras.layers.Average(name = 'Ave60356', )([in0Ave60356,in1Ave60356])
Res91857 = keras.layers.Reshape((1, 1, 4), name = 'Res91857', )(Ave60356)
Res90148 = keras.layers.Reshape((1, 4), name = 'Res90148', )(Res91857)
Ave26146 = keras.layers.AveragePooling1D(pool_size=(1), name = 'Ave26146', )(Res90148)
Fla30412 = keras.layers.Flatten(name = 'Fla30412', )(Ave26146)
Glo30150 = keras.layers.GlobalMaxPool2D(name = 'Glo30150', )(in0Glo30150)
Con91452 = keras.layers.Concatenate(axis=1, name = 'Con91452', )([Glo30150,in0Con91452])
Ave49023 = keras.layers.Average(name = 'Ave49023', )([Fla30412,Con91452])
Res2372 = keras.layers.Reshape((4, 1), name = 'Res2372', )(Ave49023)
Con42916 = keras.layers.Concatenate(axis=2, name = 'Con42916', )([Res2372,in0Con42916])
Min55609 = keras.layers.Minimum(name = 'Min55609', )([in0Min55609,in1Min55609])
Max52769 = keras.layers.MaxPool1D(pool_size=(1), name = 'Max52769', )(Min55609)
Zer75670 = keras.layers.ZeroPadding1D(padding=((3, 0)), name = 'Zer75670', )(Max52769)
Max69400 = keras.layers.Maximum(name = 'Max69400', )([Con42916,Zer75670])
model = tf.keras.models.Model(inputs=[in0Ave60356,in1Ave60356,in0Glo30150,in0Con91452,in0Con42916,in0Min55609,in1Min55609], outputs=Max69400)
in0Ave60356 = tf.constant([[[[[0.1083, 0.3114], [0.3285, 0.1009]]]]])
in1Ave60356 = tf.constant([[[[[0.4429, 0.1667], [0.889, 0.0846]]]]])
in0Glo30150 = tf.constant([[[[1.3839, 1.5374]]]])
in0Con91452 = tf.constant([[0.7369, 0.7894]])
in0Con42916 = tf.constant([[[0.3538], [0.5058], [0.6951], [0.7175]]])
in0Min55609 = tf.constant([[[0.2101, 0.098]]])
in1Min55609 = tf.constant([[[0.4441, 0.4468]]])
print (np.array2string(model.predict([in0Ave60356,in1Ave60356,in0Glo30150,in0Con91452,in0Con42916,in0Min55609,in1Min55609],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max69400.png')

LAve60356 = average_layer([[[[[[0.1083, 0.3114], [0.3285, 0.1009]]]]], [[[[[0.4429, 0.1667], [0.889, 0.0846]]]]]], Ave60356), 
LRes91857 = reshape_layer(Ave60356, [1, 1, 4], Res91857), 
LRes90148 = reshape_layer(Res91857, [1, 4], Res90148), 
LAve26146 = average_pooling1D_layer(Res90148, 1, Ave26146), 
LFla30412 = flatten_layer(Ave26146, Fla30412), 
LGlo30150 = global_max_pool2D_layer([[[[1.3839, 1.5374]]]], Glo30150), 
LCon91452 = concatenate_layer([Glo30150,[[0.7369, 0.7894]]], 1, Con91452), 
LAve49023 = average_layer([Fla30412,Con91452], Ave49023), 
LRes2372 = reshape_layer(Ave49023, [4, 1], Res2372), 
LCon42916 = concatenate_layer([Res2372,[[[0.3538], [0.5058], [0.6951], [0.7175]]]], 2, Con42916), 
LMin55609 = minimum_layer([[[[0.2101, 0.098]]], [[[0.4441, 0.4468]]]], Min55609), 
LMax52769 = max_pool1D_layer(Min55609, 1, Max52769), 
LZer75670 = zero_padding1D_layer(Max52769, 3, 0, Zer75670), 
LMax69400 = maximum_layer([Con42916,Zer75670], Max69400), 
exec_layers([LAve60356,LRes91857,LRes90148,LAve26146,LFla30412,LGlo30150,LCon91452,LAve49023,LRes2372,LCon42916,LMin55609,LMax52769,LZer75670,LMax69400],["Ave60356","Res91857","Res90148","Ave26146","Fla30412","Glo30150","Con91452","Ave49023","Res2372","Con42916","Min55609","Max52769","Zer75670","Max69400"],Max69400,"Max69400")

Actual (Unparsed): [[[0.8297500, 0.3538000], [0.8882250, 0.5058000], [0.6728250, 0.6951000], [0.4410750, 0.7175000]]]

Expected (Unparsed): [[[0.82975,0.3538],[0.888225,0.5058],[0.672825,0.6951],[0.441075,0.7175]]]

Actual:   [[[0.8298, 0.3538], [0.8883, 0.5058], [0.6729, 0.6951], [0.4411, 0.7175]]]

Expected: [[[0.8298, 0.3538], [0.8883, 0.5058], [0.6729, 0.6951], [0.4411, 0.7175]]]