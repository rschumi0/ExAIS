import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat51876 = tf.keras.layers.Input(shape=([2, 3, 2]))

Bat51876 = keras.layers.BatchNormalization(axis=1, epsilon=0.8589198134509779,  name = 'Bat51876', )(in0Bat51876)
Lay70203 = keras.layers.LayerNormalization(axis=1, epsilon=1.853055180482063, name = 'Lay70203', )(Bat51876)
Res44777 = keras.layers.Reshape((2, 3, 2, 1), name = 'Res44777', )(Lay70203)
Up_84419 = keras.layers.UpSampling3D(size=(2, 2, 2), name = 'Up_84419', )(Res44777)
model = tf.keras.models.Model(inputs=[in0Bat51876], outputs=Up_84419)
w = model.get_layer('Bat51876').get_weights() 
w[0] = np.array([0.7572, 0.1761])
w[1] = np.array([0.0193, 0.2111])
w[2] = np.array([0.0338, 0.9076])
w[3] = np.array([0.9119, 0.8761])
model.get_layer('Bat51876').set_weights(w) 
in0Bat51876 = tf.constant([[[[1.1834, 1.291], [1.4681, 1.4424], [1.383, 1.1204]], [[1.3161, 1.2003], [1.0888, 1.0954], [1.1336, 1.7498]]]])
print (np.array2string(model.predict([in0Bat51876],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Up_84419.png')

LBat51876 = batch_normalization_layer([[[[1.1834, 1.291], [1.4681, 1.4424], [1.383, 1.1204]], [[1.3161, 1.2003], [1.0888, 1.0954], [1.1336, 1.7498]]]], 1, 0.8589198134509779, [0.7572, 0.1761], [0.0193, 0.2111], [0.0338, 0.9076], [0.9119, 0.8761], Bat51876), 
LLay70203 = layer_normalization_layer(Bat51876, 1, 1.853055180482063, Lay70203), 
LRes44777 = reshape_layer(Lay70203, [2, 3, 2, 1], Res44777), 
LUp_84419 = up_sampling3D_layer(Res44777, 2, 2, 2, Up_84419), 
exec_layers([LBat51876,LLay70203,LRes44777,LUp_84419],["Bat51876","Lay70203","Res44777","Up_84419"],Up_84419,"Up_84419")

Actual (Unparsed): [[[[[0.1481077], [0.1481077], [0.1751828], [0.1751828]], [[0.1481077], [0.1481077], [0.1751828], [0.1751828]], [[0.2152565], [0.2152565], [0.2099429], [0.2099429]], [[0.2152565], [0.2152565], [0.2099429], [0.2099429]], [[0.1965289], [0.1965289], [0.1145363], [0.1145363]], [[0.1965289], [0.1965289], [0.1145363], [0.1145363]]], [[[0.1481077], [0.1481077], [0.1751828], [0.1751828]], [[0.1481077], [0.1481077], [0.1751828], [0.1751828]], [[0.2152565], [0.2152565], [0.2099429], [0.2099429]], [[0.2152565], [0.2152565], [0.2099429], [0.2099429]], [[0.1965289], [0.1965289], [0.1145363], [0.1145363]], [[0.1965289], [0.1965289], [0.1145363], [0.1145363]]], [[[-0.1481077], [-0.1481077], [-0.1751828], [-0.1751828]], [[-0.1481077], [-0.1481077], [-0.1751828], [-0.1751828]], [[-0.2152565], [-0.2152565], [-0.2099429], [-0.2099429]], [[-0.2152565], [-0.2152565], [-0.2099429], [-0.2099429]], [[-0.1965289], [-0.1965289], [-0.1145363], [-0.1145363]], [[-0.1965289], [-0.1965289], [-0.1145363], [-0.1145363]]], [[[-0.1481077], [-0.1481077], [-0.1751828], [-0.1751828]], [[-0.1481077], [-0.1481077], [-0.1751828], [-0.1751828]], [[-0.2152565], [-0.2152565], [-0.2099429], [-0.2099429]], [[-0.2152565], [-0.2152565], [-0.2099429], [-0.2099429]], [[-0.1965289], [-0.1965289], [-0.1145363], [-0.1145363]], [[-0.1965289], [-0.1965289], [-0.1145363], [-0.1145363]]]]]

Expected (Unparsed): [[[[[0.1481077151745285],[0.1481077151745285],[0.17518279280551788],[0.17518279280551788]],[[0.1481077151745285],[0.1481077151745285],[0.17518279280551788],[0.17518279280551788]],[[0.21525655610486777],[0.21525655610486777],[0.20994288757578772],[0.20994288757578772]],[[0.21525655610486777],[0.21525655610486777],[0.20994288757578772],[0.20994288757578772]],[[0.19652893816223824],[0.19652893816223824],[0.1145363420489132],[0.1145363420489132]],[[0.19652893816223824],[0.19652893816223824],[0.1145363420489132],[0.1145363420489132]]],[[[0.1481077151745285],[0.1481077151745285],[0.17518279280551788],[0.17518279280551788]],[[0.1481077151745285],[0.1481077151745285],[0.17518279280551788],[0.17518279280551788]],[[0.21525655610486777],[0.21525655610486777],[0.20994288757578772],[0.20994288757578772]],[[0.21525655610486777],[0.21525655610486777],[0.20994288757578772],[0.20994288757578772]],[[0.19652893816223824],[0.19652893816223824],[0.1145363420489132],[0.1145363420489132]],[[0.19652893816223824],[0.19652893816223824],[0.1145363420489132],[0.1145363420489132]]],[[[-0.14810771517452853],[-0.14810771517452853],[-0.17518279280551785],[-0.17518279280551785]],[[-0.14810771517452853],[-0.14810771517452853],[-0.17518279280551785],[-0.17518279280551785]],[[-0.2152565561048678],[-0.2152565561048678],[-0.2099428875757878],[-0.2099428875757878]],[[-0.2152565561048678],[-0.2152565561048678],[-0.2099428875757878],[-0.2099428875757878]],[[-0.19652893816223824],[-0.19652893816223824],[-0.1145363420489132],[-0.1145363420489132]],[[-0.19652893816223824],[-0.19652893816223824],[-0.1145363420489132],[-0.1145363420489132]]],[[[-0.14810771517452853],[-0.14810771517452853],[-0.17518279280551785],[-0.17518279280551785]],[[-0.14810771517452853],[-0.14810771517452853],[-0.17518279280551785],[-0.17518279280551785]],[[-0.2152565561048678],[-0.2152565561048678],[-0.2099428875757878],[-0.2099428875757878]],[[-0.2152565561048678],[-0.2152565561048678],[-0.2099428875757878],[-0.2099428875757878]],[[-0.19652893816223824],[-0.19652893816223824],[-0.1145363420489132],[-0.1145363420489132]],[[-0.19652893816223824],[-0.19652893816223824],[-0.1145363420489132],[-0.1145363420489132]]]]]

Actual:   [[[[[0.1482], [0.1482], [0.1752], [0.1752]], [[0.1482], [0.1482], [0.1752], [0.1752]], [[0.2153], [0.2153], [0.21], [0.21]], [[0.2153], [0.2153], [0.21], [0.21]], [[0.1966], [0.1966], [0.1146], [0.1146]], [[0.1966], [0.1966], [0.1146], [0.1146]]], [[[0.1482], [0.1482], [0.1752], [0.1752]], [[0.1482], [0.1482], [0.1752], [0.1752]], [[0.2153], [0.2153], [0.21], [0.21]], [[0.2153], [0.2153], [0.21], [0.21]], [[0.1966], [0.1966], [0.1146], [0.1146]], [[0.1966], [0.1966], [0.1146], [0.1146]]], [[[-0.1481], [-0.1481], [-0.1751], [-0.1751]], [[-0.1481], [-0.1481], [-0.1751], [-0.1751]], [[-0.2152], [-0.2152], [-0.2099], [-0.2099]], [[-0.2152], [-0.2152], [-0.2099], [-0.2099]], [[-0.1965], [-0.1965], [-0.1145], [-0.1145]], [[-0.1965], [-0.1965], [-0.1145], [-0.1145]]], [[[-0.1481], [-0.1481], [-0.1751], [-0.1751]], [[-0.1481], [-0.1481], [-0.1751], [-0.1751]], [[-0.2152], [-0.2152], [-0.2099], [-0.2099]], [[-0.2152], [-0.2152], [-0.2099], [-0.2099]], [[-0.1965], [-0.1965], [-0.1145], [-0.1145]], [[-0.1965], [-0.1965], [-0.1145], [-0.1145]]]]]

Expected: [[[[[0.1482], [0.1482], [0.1752], [0.1752]], [[0.1482], [0.1482], [0.1752], [0.1752]], [[0.2153], [0.2153], [0.21], [0.21]], [[0.2153], [0.2153], [0.21], [0.21]], [[0.1966], [0.1966], [0.1146], [0.1146]], [[0.1966], [0.1966], [0.1146], [0.1146]]], [[[0.1482], [0.1482], [0.1752], [0.1752]], [[0.1482], [0.1482], [0.1752], [0.1752]], [[0.2153], [0.2153], [0.21], [0.21]], [[0.2153], [0.2153], [0.21], [0.21]], [[0.1966], [0.1966], [0.1146], [0.1146]], [[0.1966], [0.1966], [0.1146], [0.1146]]], [[[-0.1481], [-0.1481], [-0.1751], [-0.1751]], [[-0.1481], [-0.1481], [-0.1751], [-0.1751]], [[-0.2152], [-0.2152], [-0.2099], [-0.2099]], [[-0.2152], [-0.2152], [-0.2099], [-0.2099]], [[-0.1965], [-0.1965], [-0.1145], [-0.1145]], [[-0.1965], [-0.1965], [-0.1145], [-0.1145]]], [[[-0.1481], [-0.1481], [-0.1751], [-0.1751]], [[-0.1481], [-0.1481], [-0.1751], [-0.1751]], [[-0.2152], [-0.2152], [-0.2099], [-0.2099]], [[-0.2152], [-0.2152], [-0.2099], [-0.2099]], [[-0.1965], [-0.1965], [-0.1145], [-0.1145]], [[-0.1965], [-0.1965], [-0.1145], [-0.1145]]]]]