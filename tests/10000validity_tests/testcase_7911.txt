import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ReL23769 = tf.keras.layers.Input(shape=([1, 1]))
in0Zer91113 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con74270 = tf.keras.layers.Input(shape=([1]))

ReL23769 = keras.layers.ReLU(max_value=4.692725278248227, negative_slope=5.110747934605884, threshold=4.993755086163737, name = 'ReL23769', input_shape=(1, 1))(in0ReL23769)
Lay57931 = keras.layers.LayerNormalization(axis=2, epsilon=1.6109743633822882, name = 'Lay57931', )(ReL23769)
Den91477 = keras.layers.Dense(3,name = 'Den91477', )(Lay57931)
Fla57398 = keras.layers.Flatten(name = 'Fla57398', )(Den91477)
Zer91113 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer91113', )(in0Zer91113)
Res78401 = keras.layers.Reshape((3, 6), name = 'Res78401', )(Zer91113)
Sim32430 = keras.layers.SimpleRNN(2,name = 'Sim32430', )(Res78401)
Con74270 = keras.layers.Concatenate(axis=1, name = 'Con74270', )([Sim32430,in0Con74270])
Mul8789 = keras.layers.Multiply(name = 'Mul8789', )([Fla57398,Con74270])
model = tf.keras.models.Model(inputs=[in0ReL23769,in0Zer91113,in0Con74270], outputs=Mul8789)
w = model.get_layer('Den91477').get_weights() 
w[0] = np.array([[0.1835, 0.1168, 0.6334]])
w[1] = np.array([0.8619, 0.9638, 0.6151])
model.get_layer('Den91477').set_weights(w) 
w = model.get_layer('Sim32430').get_weights() 
w[0] = np.array([[6, 8], [8, 5], [5, 8], [2, 1], [1, 8], [9, 5]])
w[1] = np.array([[10, 8], [7, 2]])
w[2] = np.array([4, 2])
model.get_layer('Sim32430').set_weights(w) 
in0ReL23769 = tf.constant([[[0.6839]]])
in0Zer91113 = tf.constant([[[[1.5312, 1.8141]]]])
in0Con74270 = tf.constant([[0.3862]])
print (np.array2string(model.predict([in0ReL23769,in0Zer91113,in0Con74270],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul8789.png')

LReL23769 = relu_layer([[[0.6839]]], 4.692725278248227, 5.110747934605884, 4.993755086163737, ReL23769), 
LLay57931 = layer_normalization_layer(ReL23769, 2, 1.6109743633822882, Lay57931), 
LDen91477 = dense_layer(Lay57931, [[0.1835, 0.1168, 0.6334]],[0.8619, 0.9638, 0.6151], Den91477), 
LFla57398 = flatten_layer(Den91477, Fla57398), 
LZer91113 = zero_padding2D_layer([[[[1.5312, 1.8141]]]], 1, 1, 1, 1, Zer91113), 
LRes78401 = reshape_layer(Zer91113, [3, 6], Res78401), 
LSim32430 = simple_rnn_layer(Res78401,[[6, 8], [8, 5], [5, 8], [2, 1], [1, 8], [9, 5]],[[10, 8], [7, 2]],[4, 2], Sim32430), 
LCon74270 = concatenate_layer([Sim32430,[[0.3862]]], 1, Con74270), 
LMul8789 = multiply_layer([Fla57398,Con74270], Mul8789), 
exec_layers([LReL23769,LLay57931,LDen91477,LFla57398,LZer91113,LRes78401,LSim32430,LCon74270,LMul8789],["ReL23769","Lay57931","Den91477","Fla57398","Zer91113","Res78401","Sim32430","Con74270","Mul8789"],Mul8789,"Mul8789")

Actual (Unparsed): [[0.8619000, 0.9638000, 0.2375516]]

Expected (Unparsed): [[0.8619,0.9637999999272304,0.23755162]]

Actual:   [[0.8619, 0.9638, 0.2376]]

Expected: [[0.8619, 0.9638, 0.2376]]