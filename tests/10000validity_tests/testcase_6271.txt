import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add72364 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Add72364 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con12316 = tf.keras.layers.Input(shape=([2, 2]))
in0Con25353 = tf.keras.layers.Input(shape=([2, 1]))
in0Fla64324 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con66617 = tf.keras.layers.Input(shape=([2, 1, 3]))
in0Con7100 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con98299 = tf.keras.layers.Input(shape=([5]))

Add72364 = keras.layers.Add(name = 'Add72364', )([in0Add72364,in1Add72364])
Res40444 = keras.layers.Reshape((2, 1), name = 'Res40444', )(Add72364)
Con12316 = keras.layers.Concatenate(axis=2, name = 'Con12316', )([Res40444,in0Con12316])
Con25353 = keras.layers.Conv1D(3, (1),strides=(1), padding='valid', dilation_rate=(1), name = 'Con25353', )(in0Con25353)
Sub36390 = keras.layers.Subtract(name = 'Sub36390', )([Con12316,Con25353])
Res45632 = keras.layers.Reshape((2, 3, 1), name = 'Res45632', )(Sub36390)
Res69893 = keras.layers.Reshape((2, 3, 1, 1), name = 'Res69893', )(Res45632)
Con16609 = keras.layers.Conv3D(3, (1, 2, 1),strides=(2, 1, 1), padding='same', dilation_rate=(1, 1, 1), name = 'Con16609', )(Res69893)
Res16148 = keras.layers.Reshape((1, 3, 3), name = 'Res16148', )(Con16609)
Res63339 = keras.layers.Reshape((1, 9), name = 'Res63339', )(Res16148)
Fla47331 = keras.layers.Flatten(name = 'Fla47331', )(Res63339)
Fla64324 = keras.layers.Flatten(name = 'Fla64324', )(in0Fla64324)
Res1318 = keras.layers.Reshape((2, 1), name = 'Res1318', )(Fla64324)
Res64686 = keras.layers.Reshape((2, 1, 1), name = 'Res64686', )(Res1318)
Con66617 = keras.layers.Concatenate(axis=3, name = 'Con66617', )([Res64686,in0Con66617])
Con7100 = keras.layers.Conv2D(4, (1, 1),strides=(1, 1), padding='valid', dilation_rate=(1, 1), name = 'Con7100', )(in0Con7100)
Zer56287 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer56287', )(Con7100)
Max13150 = keras.layers.Maximum(name = 'Max13150', )([Con66617,Zer56287])
Res1841 = keras.layers.Reshape((2, 4), name = 'Res1841', )(Max13150)
Glo42377 = keras.layers.GlobalAveragePooling1D(name = 'Glo42377', )(Res1841)
Con98299 = keras.layers.Concatenate(axis=1, name = 'Con98299', )([Glo42377,in0Con98299])
Add54046 = keras.layers.Add(name = 'Add54046', )([Fla47331,Con98299])
model = tf.keras.models.Model(inputs=[in0Add72364,in1Add72364,in0Con12316,in0Con25353,in0Fla64324,in0Con66617,in0Con7100,in0Con98299], outputs=Add54046)
w = model.get_layer('Con25353').get_weights() 
w[0] = np.array([[[0.2074, 0.4999, 0.6671]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con25353').set_weights(w) 
w = model.get_layer('Con16609').get_weights() 
w[0] = np.array([[[[[0.0708, 0.3256, 0.7213]]], [[[0.981, 0.2314, 0.7431]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con16609').set_weights(w) 
w = model.get_layer('Con7100').get_weights() 
w[0] = np.array([[[[0.6458, 0.9094, 0.7152, 0.4388]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con7100').set_weights(w) 
in0Add72364 = tf.constant([[[[0.1798]], [[0.9192]]]])
in1Add72364 = tf.constant([[[[0.2164]], [[0.9079]]]])
in0Con12316 = tf.constant([[[0.3446, 0.5995], [0.3382, 0.0365]]])
in0Con25353 = tf.constant([[[0.4625], [0.8479]]])
in0Fla64324 = tf.constant([[[[1.7629], [1.1416]]]])
in0Con66617 = tf.constant([[[[0.2227, 0.3582, 0.2504]], [[0.492, 0.9811, 0.226]]]])
in0Con7100 = tf.constant([[[[0.3804]]]])
in0Con98299 = tf.constant([[0.3967, 0.6439, 0.0535, 0.0773, 0.94]])
print (np.array2string(model.predict([in0Add72364,in1Add72364,in0Con12316,in0Con25353,in0Fla64324,in0Con66617,in0Con7100,in0Con98299],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add54046.png')

LAdd72364 = add_layer([[[[[0.1798]], [[0.9192]]]], [[[[0.2164]], [[0.9079]]]]], Add72364), 
LRes40444 = reshape_layer(Add72364, [2, 1], Res40444), 
LCon12316 = concatenate_layer([Res40444,[[[0.3446, 0.5995], [0.3382, 0.0365]]]], 2, Con12316), 
LCon25353 = conv1D_layer([[[0.4625], [0.8479]]], 1,[[[0.2074, 0.4999, 0.6671]]],[0, 0, 0], 1, false, 1, Con25353), 
LSub36390 = subtract_layer(Con12316,Con25353, Sub36390), 
LRes45632 = reshape_layer(Sub36390, [2, 3, 1], Res45632), 
LRes69893 = reshape_layer(Res45632, [2, 3, 1, 1], Res69893), 
LCon16609 = conv3D_layer(Res69893, 1, 2, 1,[[[[[0.0708, 0.3256, 0.7213]]], [[[0.981, 0.2314, 0.7431]]]]],[0, 0, 0], 2, 1, 1, true, 1, 1, 1, Con16609), 
LRes16148 = reshape_layer(Con16609, [1, 3, 3], Res16148), 
LRes63339 = reshape_layer(Res16148, [1, 9], Res63339), 
LFla47331 = flatten_layer(Res63339, Fla47331), 
LFla64324 = flatten_layer([[[[1.7629], [1.1416]]]], Fla64324), 
LRes1318 = reshape_layer(Fla64324, [2, 1], Res1318), 
LRes64686 = reshape_layer(Res1318, [2, 1, 1], Res64686), 
LCon66617 = concatenate_layer([Res64686,[[[[0.2227, 0.3582, 0.2504]], [[0.492, 0.9811, 0.226]]]]], 3, Con66617), 
LCon7100 = conv2D_layer([[[[0.3804]]]], 1, 1,[[[[0.6458, 0.9094, 0.7152, 0.4388]]]],[0, 0, 0, 0], 1, 1, false, 1, 1, Con7100), 
LZer56287 = zero_padding2D_layer(Con7100, 1, 0, 0, 0, Zer56287), 
LMax13150 = maximum_layer([Con66617,Zer56287], Max13150), 
LRes1841 = reshape_layer(Max13150, [2, 4], Res1841), 
LGlo42377 = global_average_pooling1D_layer(Res1841, Glo42377), 
LCon98299 = concatenate_layer([Glo42377,[[0.3967, 0.6439, 0.0535, 0.0773, 0.94]]], 1, Con98299), 
LAdd54046 = add_layer([Fla47331,Con98299], Add54046), 
exec_layers([LAdd72364,LRes40444,LCon12316,LCon25353,LSub36390,LRes45632,LRes69893,LCon16609,LRes16148,LRes63339,LFla47331,LFla64324,LRes1318,LRes64686,LCon66617,LCon7100,LZer56287,LMax13150,LRes1841,LGlo42377,LCon98299,LAdd54046],["Add72364","Res40444","Con12316","Con25353","Sub36390","Res45632","Res69893","Con16609","Res16148","Res63339","Fla47331","Fla64324","Res1318","Res64686","Con66617","Con7100","Zer56287","Max13150","Res1841","Glo42377","Con98299","Add54046"],Add54046,"Add54046")

Actual (Unparsed): [[1.5847514, 0.4813603, 0.9705049, 0.5316663, 0.5009514, 0.9419097, 0.0741004, 0.1720386, 1.1498740]]

Expected (Unparsed): [[1.5847513682499998,0.48136024624999996,0.970504914125,0.5316663457499999,0.50095140925,0.9419097355,0.07410041049999999,0.172038611,1.149873956125]]

Actual:   [[1.5848, 0.4814, 0.9706, 0.5317, 0.501, 0.942, 0.0742, 0.1721, 1.1499]]

Expected: [[1.5848, 0.4814, 0.9706, 0.5317, 0.501, 0.942, 0.0742, 0.1721, 1.1499]]