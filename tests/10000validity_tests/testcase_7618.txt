import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul7257 = tf.keras.layers.Input(shape=([1, 1]))
in1Mul7257 = tf.keras.layers.Input(shape=([1, 1]))
in0Max29688 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in1Max29688 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0Con60664 = tf.keras.layers.Input(shape=([35]))

Mul7257 = keras.layers.Multiply(name = 'Mul7257', )([in0Mul7257,in1Mul7257])
Res9296 = keras.layers.Reshape((1, 1, 1), name = 'Res9296', )(Mul7257)
Con3043 = keras.layers.Conv2DTranspose(2, (1, 1),strides=(1, 1), padding='valid', name = 'Con3043', )(Res9296)
Res93775 = keras.layers.Reshape((1, 1, 2, 1), name = 'Res93775', )(Con3043)
Zer60912 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer60912', )(Res93775)
Res55821 = keras.layers.Reshape((3, 3, 4), name = 'Res55821', )(Zer60912)
Res13192 = keras.layers.Reshape((3, 12), name = 'Res13192', )(Res55821)
Fla35886 = keras.layers.Flatten(name = 'Fla35886', )(Res13192)
Max29688 = keras.layers.Maximum(name = 'Max29688', )([in0Max29688,in1Max29688])
Glo17436 = keras.layers.GlobalMaxPool3D(name = 'Glo17436', )(Max29688)
Con60664 = keras.layers.Concatenate(axis=1, name = 'Con60664', )([Glo17436,in0Con60664])
Add4902 = keras.layers.Add(name = 'Add4902', )([Fla35886,Con60664])
model = tf.keras.models.Model(inputs=[in0Mul7257,in1Mul7257,in0Max29688,in1Max29688,in0Con60664], outputs=Add4902)
w = model.get_layer('Con3043').get_weights() 
w[0] = np.array([[[[0.9765], [0.5711]]]])
w[1] = np.array([0, 0])
model.get_layer('Con3043').set_weights(w) 
in0Mul7257 = tf.constant([[[0.3665]]])
in1Mul7257 = tf.constant([[[0.2669]]])
in0Max29688 = tf.constant([[[[[0.1906]], [[0.9645]]]]])
in1Max29688 = tf.constant([[[[[0.806]], [[0.4639]]]]])
in0Con60664 = tf.constant([[0.1098, 0.3441, 0.5973, 0.3221, 0.9238, 0.1339, 0.9595, 0.0474, 0.8749, 0.518, 0.7759, 0.5064, 0.0352, 0.4824, 0.1081, 0.1135, 0.9144, 0.4933, 0.0412, 0.8526, 0.2457, 0.2996, 0.9859, 0.9483, 0.9335, 0.118, 0.8713, 0.3561, 0.7985, 0.1821, 0.9718, 0.4323, 0.5379, 0.2777, 0.1557]])
print (np.array2string(model.predict([in0Mul7257,in1Mul7257,in0Max29688,in1Max29688,in0Con60664],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add4902.png')

LMul7257 = multiply_layer([[[[0.3665]]], [[[0.2669]]]], Mul7257), 
LRes9296 = reshape_layer(Mul7257, [1, 1, 1], Res9296), 
LCon3043 = conv2D_transpose_layer(Res9296, 1, 1,[[[[0.9765], [0.5711]]]],[0, 0], 1, 1, false, Con3043), 
LRes93775 = reshape_layer(Con3043, [1, 1, 2, 1], Res93775), 
LZer60912 = zero_padding3D_layer(Res93775, 1, 1, 1, 1, 1, 1, Zer60912), 
LRes55821 = reshape_layer(Zer60912, [3, 3, 4], Res55821), 
LRes13192 = reshape_layer(Res55821, [3, 12], Res13192), 
LFla35886 = flatten_layer(Res13192, Fla35886), 
LMax29688 = maximum_layer([[[[[[0.1906]], [[0.9645]]]]], [[[[[0.806]], [[0.4639]]]]]], Max29688), 
LGlo17436 = global_max_pool3D_layer(Max29688, Glo17436), 
LCon60664 = concatenate_layer([Glo17436,[[0.1098, 0.3441, 0.5973, 0.3221, 0.9238, 0.1339, 0.9595, 0.0474, 0.8749, 0.518, 0.7759, 0.5064, 0.0352, 0.4824, 0.1081, 0.1135, 0.9144, 0.4933, 0.0412, 0.8526, 0.2457, 0.2996, 0.9859, 0.9483, 0.9335, 0.118, 0.8713, 0.3561, 0.7985, 0.1821, 0.9718, 0.4323, 0.5379, 0.2777, 0.1557]]], 1, Con60664), 
LAdd4902 = add_layer([Fla35886,Con60664], Add4902), 
exec_layers([LMul7257,LRes9296,LCon3043,LRes93775,LZer60912,LRes55821,LRes13192,LFla35886,LMax29688,LGlo17436,LCon60664,LAdd4902],["Mul7257","Res9296","Con3043","Res93775","Zer60912","Res55821","Res13192","Fla35886","Max29688","Glo17436","Con60664","Add4902"],Add4902,"Add4902")

Actual (Unparsed): [[0.9645000, 0.1098000, 0.3441000, 0.5973000, 0.3221000, 0.9238000, 0.1339000, 0.9595000, 0.0474000, 0.8749000, 0.5180000, 0.7759000, 0.5064000, 0.0352000, 0.4824000, 0.1081000, 0.1135000, 1.0099201, 0.5491643, 0.0412000, 0.8526000, 0.2457000, 0.2996000, 0.9859000, 0.9483000, 0.9335000, 0.1180000, 0.8713000, 0.3561000, 0.7985000, 0.1821000, 0.9718000, 0.4323000, 0.5379000, 0.2777000, 0.1557000]]

Expected (Unparsed): [[0.9645,0.1098,0.3441,0.5973,0.3221,0.9238,0.1339,0.9595,0.0474,0.8749,0.518,0.7759,0.5064,0.0352,0.4824,0.1081,0.1135,1.009920107025,0.549164345235,0.0412,0.8526,0.2457,0.2996,0.9859,0.9483,0.9335,0.118,0.8713,0.3561,0.7985,0.1821,0.9718,0.4323,0.5379,0.2777,0.1557]]

Actual:   [[0.9645, 0.1098, 0.3441, 0.5973, 0.3221, 0.9238, 0.1339, 0.9595, 0.0474, 0.8749, 0.518, 0.7759, 0.5064, 0.0352, 0.4824, 0.1081, 0.1135, 1.01, 0.5492, 0.0412, 0.8526, 0.2457, 0.2996, 0.9859, 0.9483, 0.9335, 0.118, 0.8713, 0.3561, 0.7985, 0.1821, 0.9718, 0.4323, 0.5379, 0.2777, 0.1557]]

Expected: [[0.9645, 0.1098, 0.3441, 0.5973, 0.3221, 0.9238, 0.1339, 0.9595, 0.0474, 0.8749, 0.518, 0.7759, 0.5064, 0.0352, 0.4824, 0.1081, 0.1135, 1.01, 0.5492, 0.0412, 0.8526, 0.2457, 0.2996, 0.9859, 0.9483, 0.9335, 0.118, 0.8713, 0.3561, 0.7985, 0.1821, 0.9718, 0.4323, 0.5379, 0.2777, 0.1557]]