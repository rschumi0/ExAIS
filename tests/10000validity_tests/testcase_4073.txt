import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub45582 = tf.keras.layers.Input(shape=([2, 3, 2]))
in1Sub45582 = tf.keras.layers.Input(shape=([2, 3, 2]))
in0Fla59131 = tf.keras.layers.Input(shape=([4, 4, 4]))
in0Dep16839 = tf.keras.layers.Input(shape=([1, 1, 1]))

Sub45582 = keras.layers.Subtract(name = 'Sub45582', )([in0Sub45582,in1Sub45582])
Res2463 = keras.layers.Reshape((2, 6), name = 'Res2463', )(Sub45582)
Res13175 = keras.layers.Reshape((2, 6, 1), name = 'Res13175', )(Res2463)
Ave5389 = keras.layers.AveragePooling2D(pool_size=(2, 5), name = 'Ave5389', )(Res13175)
Zer23794 = keras.layers.ZeroPadding2D(padding=((63, 0), (0, 0)), name = 'Zer23794', )(Ave5389)
Fla59131 = keras.layers.Flatten(name = 'Fla59131', )(in0Fla59131)
Res54771 = keras.layers.Reshape((64, 1), name = 'Res54771', )(Fla59131)
Res85662 = keras.layers.Reshape((64, 1, 1), name = 'Res85662', )(Res54771)
Dep16839 = keras.layers.DepthwiseConv2D((1, 1),strides=(1, 1), padding='same', name = 'Dep16839', )(in0Dep16839)
Zer52914 = keras.layers.ZeroPadding2D(padding=((63, 0), (0, 0)), name = 'Zer52914', )(Dep16839)
Mul64320 = keras.layers.Multiply(name = 'Mul64320', )([Res85662,Zer52914])
Bat74908 = keras.layers.BatchNormalization(axis=1, epsilon=0.8556919027080131,  name = 'Bat74908', )(Mul64320)
Ave6627 = keras.layers.AveragePooling2D(pool_size=(1, 1), strides=(1, 1), padding='valid', name = 'Ave6627', )(Bat74908)
Mul67800 = keras.layers.Multiply(name = 'Mul67800', )([Zer23794,Ave6627])
model = tf.keras.models.Model(inputs=[in0Sub45582,in1Sub45582,in0Fla59131,in0Dep16839], outputs=Mul67800)
w = model.get_layer('Dep16839').get_weights() 
w[0] = np.array([[[[0.3234]]]])
w[1] = np.array([0])
model.get_layer('Dep16839').set_weights(w) 
w = model.get_layer('Bat74908').get_weights() 
w[0] = np.array([0.7958, 0.901, 0.1639, 0.9966, 0.1463, 0.0442, 0.1433, 0.1265, 0.1133, 0.7779, 0.1607, 0.0197, 0.2444, 0.804, 0.5665, 0.6875, 0.2165, 0.6218, 0.5224, 0.4636, 0.2391, 0.619, 0.9547, 0.5616, 0.7722, 0.3877, 0.5969, 0.1749, 0.9857, 0.4398, 0.08, 0.1714, 0.3055, 0.6635, 0.2707, 0.0557, 0.2017, 0.192, 0.7012, 0.1533, 0.1026, 0.8322, 0.9872, 0.9011, 0.9466, 0.8425, 0.5896, 0.724, 0.4196, 0.6412, 0.1368, 0.2209, 0.3694, 0.977, 0.7978, 0.2896, 0.2356, 0.2, 0.8725, 0.3762, 0.5893, 0.5346, 0.8462, 0.255])
w[1] = np.array([0.0385, 0.6743, 0.6495, 0.6127, 0.8209, 0.5924, 0.754, 0.2404, 0.3811, 0.1973, 0.0415, 0.8244, 0.1085, 0.3447, 0.0898, 0.1614, 0.1971, 0.7664, 0.6319, 0.1278, 0.2831, 0.6731, 0.4681, 0.8806, 0.1134, 0.1466, 0.0342, 0.5798, 0.0029, 0.9496, 0.1668, 0.3876, 0.2494, 0.0479, 0.3388, 0.6209, 0.9944, 0.9691, 0.7921, 0.7134, 0.2388, 0.0986, 0.5392, 0.0759, 0.8539, 0.1553, 0.1667, 0.0376, 0.4648, 0.382, 0.7385, 0.794, 0.0244, 0.4336, 0.8656, 0.6947, 0.7451, 0.5573, 0.1851, 0.2605, 0.8114, 0.4168, 0.0781, 0.0367])
w[2] = np.array([0.956, 0.8341, 0.4403, 0.7619, 0.5501, 0.7982, 0.7187, 0.3586, 0.3334, 0.3189, 0.2276, 0.9368, 0.2869, 0.0948, 0.9647, 0.3448, 0.4394, 0.505, 0.7648, 0.794, 0.5904, 0.1377, 0.6455, 0.7428, 0.0318, 0.9233, 0.6298, 0.5305, 0.3528, 0.9519, 0.16, 0.2203, 0.3269, 0.2259, 0.4601, 0.731, 0.6965, 0.9219, 0.8464, 0.6157, 0.3909, 0.2191, 0.0383, 0.7816, 0.3493, 0.3865, 0.9824, 0.0345, 0.6509, 0.6185, 0.5622, 0.5782, 0.0999, 0.0569, 0.8398, 0.5038, 0.7618, 0.5425, 0.1529, 0.8635, 0.1989, 0.9051, 0.4697, 0.1371])
w[3] = np.array([0.3195, 0.0171, 0.8992, 0.7738, 0.8173, 0.4134, 0.1444, 0.02, 0.1556, 0.0084, 0.9911, 0.4267, 0.9265, 0.333, 0.6323, 0.2722, 0.2056, 0.7545, 0.7414, 0.6338, 0.2124, 0.3443, 0.7295, 0.9926, 0.1855, 0.4155, 0.5475, 0.0685, 0.8878, 0.2633, 0.727, 0.0456, 0.5671, 0.311, 0.0943, 0.472, 0.515, 0.6903, 0.736, 0.8951, 0.5903, 0.2648, 0.3471, 0.7292, 0.204, 0.2436, 0.0499, 0.9423, 0.2989, 0.8268, 0.1378, 0.8963, 0.7969, 0.7736, 0.9666, 0.0769, 0.8405, 0.3907, 0.3935, 0.5129, 0.9042, 0.202, 0.7485, 0.395])
model.get_layer('Bat74908').set_weights(w) 
in0Sub45582 = tf.constant([[[[0.3088, 0.5394], [0.9441, 0.4519], [0.5955, 0.1463]], [[0.2329, 0.9583], [0.3164, 0.4768], [0.7309, 0.1591]]]])
in1Sub45582 = tf.constant([[[[0.7675, 0.7826], [0.2926, 0.0694], [0.9999, 0.2959]], [[0.7555, 0.1209], [0.7645, 0.8777], [0.4297, 0.487]]]])
in0Fla59131 = tf.constant([[[[1.9739, 1.2431, 1.8937, 1.4862], [1.1502, 1.5365, 1.3024, 1.86], [1.032, 1.8638, 1.2023, 1.7647], [1.6289, 1.8914, 1.5383, 1.5168]], [[1.5355, 1.7724, 1.1386, 1.4881], [1.238, 1.4696, 1.4648, 1.0592], [1.485, 1.0128, 1.8297, 1.2097], [1.5304, 1.348, 1.6002, 1.1473]], [[1.2015, 1.2157, 1.1264, 1.3609], [1.2993, 1.9286, 1.269, 1.6197], [1.7938, 1.012, 1.4327, 1.7343], [1.6436, 1.4154, 1.955, 1.3452]], [[1.8365, 1.4071, 1.549, 1.6137], [1.4279, 1.3255, 1.2553, 1.4477], [1.9352, 1.0736, 1.015, 1.8193], [1.4345, 1.6163, 1.5483, 1.8018]]]])
in0Dep16839 = tf.constant([[[[0.1045]]]])
print (np.array2string(model.predict([in0Sub45582,in1Sub45582,in0Fla59131,in0Dep16839],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul67800.png')

LSub45582 = subtract_layer([[[[0.3088, 0.5394], [0.9441, 0.4519], [0.5955, 0.1463]], [[0.2329, 0.9583], [0.3164, 0.4768], [0.7309, 0.1591]]]], [[[[0.7675, 0.7826], [0.2926, 0.0694], [0.9999, 0.2959]], [[0.7555, 0.1209], [0.7645, 0.8777], [0.4297, 0.487]]]], Sub45582), 
LRes2463 = reshape_layer(Sub45582, [2, 6], Res2463), 
LRes13175 = reshape_layer(Res2463, [2, 6, 1], Res13175), 
LAve5389 = average_pooling2D_layer(Res13175, 2, 5, Ave5389), 
LZer23794 = zero_padding2D_layer(Ave5389, 63, 0, 0, 0, Zer23794), 
LFla59131 = flatten_layer([[[[1.9739, 1.2431, 1.8937, 1.4862], [1.1502, 1.5365, 1.3024, 1.86], [1.032, 1.8638, 1.2023, 1.7647], [1.6289, 1.8914, 1.5383, 1.5168]], [[1.5355, 1.7724, 1.1386, 1.4881], [1.238, 1.4696, 1.4648, 1.0592], [1.485, 1.0128, 1.8297, 1.2097], [1.5304, 1.348, 1.6002, 1.1473]], [[1.2015, 1.2157, 1.1264, 1.3609], [1.2993, 1.9286, 1.269, 1.6197], [1.7938, 1.012, 1.4327, 1.7343], [1.6436, 1.4154, 1.955, 1.3452]], [[1.8365, 1.4071, 1.549, 1.6137], [1.4279, 1.3255, 1.2553, 1.4477], [1.9352, 1.0736, 1.015, 1.8193], [1.4345, 1.6163, 1.5483, 1.8018]]]], Fla59131), 
LRes54771 = reshape_layer(Fla59131, [64, 1], Res54771), 
LRes85662 = reshape_layer(Res54771, [64, 1, 1], Res85662), 
LDep16839 = depthwise_conv2D_layer([[[[0.1045]]]], 1, 1,[[[[0.3234]]]],[0], 1, 1, true, Dep16839), 
LZer52914 = zero_padding2D_layer(Dep16839, 63, 0, 0, 0, Zer52914), 
LMul64320 = multiply_layer([Res85662,Zer52914], Mul64320), 
LBat74908 = batch_normalization_layer(Mul64320, 1, 0.8556919027080131, [0.7958, 0.901, 0.1639, 0.9966, 0.1463, 0.0442, 0.1433, 0.1265, 0.1133, 0.7779, 0.1607, 0.0197, 0.2444, 0.804, 0.5665, 0.6875, 0.2165, 0.6218, 0.5224, 0.4636, 0.2391, 0.619, 0.9547, 0.5616, 0.7722, 0.3877, 0.5969, 0.1749, 0.9857, 0.4398, 0.08, 0.1714, 0.3055, 0.6635, 0.2707, 0.0557, 0.2017, 0.192, 0.7012, 0.1533, 0.1026, 0.8322, 0.9872, 0.9011, 0.9466, 0.8425, 0.5896, 0.724, 0.4196, 0.6412, 0.1368, 0.2209, 0.3694, 0.977, 0.7978, 0.2896, 0.2356, 0.2, 0.8725, 0.3762, 0.5893, 0.5346, 0.8462, 0.255], [0.0385, 0.6743, 0.6495, 0.6127, 0.8209, 0.5924, 0.754, 0.2404, 0.3811, 0.1973, 0.0415, 0.8244, 0.1085, 0.3447, 0.0898, 0.1614, 0.1971, 0.7664, 0.6319, 0.1278, 0.2831, 0.6731, 0.4681, 0.8806, 0.1134, 0.1466, 0.0342, 0.5798, 0.0029, 0.9496, 0.1668, 0.3876, 0.2494, 0.0479, 0.3388, 0.6209, 0.9944, 0.9691, 0.7921, 0.7134, 0.2388, 0.0986, 0.5392, 0.0759, 0.8539, 0.1553, 0.1667, 0.0376, 0.4648, 0.382, 0.7385, 0.794, 0.0244, 0.4336, 0.8656, 0.6947, 0.7451, 0.5573, 0.1851, 0.2605, 0.8114, 0.4168, 0.0781, 0.0367], [0.956, 0.8341, 0.4403, 0.7619, 0.5501, 0.7982, 0.7187, 0.3586, 0.3334, 0.3189, 0.2276, 0.9368, 0.2869, 0.0948, 0.9647, 0.3448, 0.4394, 0.505, 0.7648, 0.794, 0.5904, 0.1377, 0.6455, 0.7428, 0.0318, 0.9233, 0.6298, 0.5305, 0.3528, 0.9519, 0.16, 0.2203, 0.3269, 0.2259, 0.4601, 0.731, 0.6965, 0.9219, 0.8464, 0.6157, 0.3909, 0.2191, 0.0383, 0.7816, 0.3493, 0.3865, 0.9824, 0.0345, 0.6509, 0.6185, 0.5622, 0.5782, 0.0999, 0.0569, 0.8398, 0.5038, 0.7618, 0.5425, 0.1529, 0.8635, 0.1989, 0.9051, 0.4697, 0.1371], [0.3195, 0.0171, 0.8992, 0.7738, 0.8173, 0.4134, 0.1444, 0.02, 0.1556, 0.0084, 0.9911, 0.4267, 0.9265, 0.333, 0.6323, 0.2722, 0.2056, 0.7545, 0.7414, 0.6338, 0.2124, 0.3443, 0.7295, 0.9926, 0.1855, 0.4155, 0.5475, 0.0685, 0.8878, 0.2633, 0.727, 0.0456, 0.5671, 0.311, 0.0943, 0.472, 0.515, 0.6903, 0.736, 0.8951, 0.5903, 0.2648, 0.3471, 0.7292, 0.204, 0.2436, 0.0499, 0.9423, 0.2989, 0.8268, 0.1378, 0.8963, 0.7969, 0.7736, 0.9666, 0.0769, 0.8405, 0.3907, 0.3935, 0.5129, 0.9042, 0.202, 0.7485, 0.395], Bat74908), 
LAve6627 = average_pooling2D_layer(Bat74908, 1, 1, 1, 1, false, Ave6627), 
LMul67800 = multiply_layer([Zer23794,Ave6627], Mul67800), 
exec_layers([LSub45582,LRes2463,LRes13175,LAve5389,LZer23794,LFla59131,LRes54771,LRes85662,LDep16839,LZer52914,LMul64320,LBat74908,LAve6627,LMul67800],["Sub45582","Res2463","Res13175","Ave5389","Zer23794","Fla59131","Res54771","Res85662","Dep16839","Zer52914","Mul64320","Bat74908","Ave6627","Mul67800"],Mul67800,"Mul67800")

Actual (Unparsed): [[[[-0.0000000]], [[-0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[-0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[-0.0000000]], [[-0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[-0.0000000]], [[0.0000000]], [[0.0000000]], [[-0.0000000]], [[0.0000000]], [[0.0000000]], [[-0.0000000]], [[-0.0000000]], [[0.0000000]], [[-0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[-0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[-0.0000000]], [[0.0000000]], [[-0.0000000]], [[0.0000000]], [[-0.0000000]], [[-0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[-0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[0.0000000]], [[-0.0000000]], [[0.0000000]], [[-0.0000000]], [[-0.0000000]], [[-0.0005899]]]]

Expected (Unparsed): [[[[-0.0]],[[-0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[-0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[-0.0]],[[-0.0]],[[0.0]],[[0.0]],[[0.0]],[[-0.0]],[[0.0]],[[0.0]],[[-0.0]],[[0.0]],[[0.0]],[[-0.0]],[[-0.0]],[[0.0]],[[-0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[-0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[-0.0]],[[0.0]],[[-0.0]],[[0.0]],[[-0.0]],[[-0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[-0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[0.0]],[[-0.0]],[[0.0]],[[-0.0]],[[-0.0]],[[-0.0005899450459514977]]]]

Actual:   [[[[-0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[-0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[0]], [[-0]], [[0]], [[0]], [[-0]], [[-0]], [[0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[-0]], [[0]], [[-0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[-0]], [[-0]], [[-0.0005]]]]

Expected: [[[[-0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[-0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[0]], [[-0]], [[0]], [[0]], [[-0]], [[-0]], [[0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[-0]], [[0]], [[-0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[0]], [[-0]], [[0]], [[-0]], [[-0]], [[-0.0005]]]]