import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Den40182 = tf.keras.layers.Input(shape=([4, 2, 4]))
in0Lay84842 = tf.keras.layers.Input(shape=([4, 2]))
in0Con28975 = tf.keras.layers.Input(shape=([30]))

Den40182 = keras.layers.Dense(4,name = 'Den40182', )(in0Den40182)
Res85423 = keras.layers.Reshape((4, 8), name = 'Res85423', )(Den40182)
Fla53338 = keras.layers.Flatten(name = 'Fla53338', )(Res85423)
Lay84842 = keras.layers.LayerNormalization(axis=1, epsilon=2.3262808369940036, name = 'Lay84842', )(in0Lay84842)
Glo88671 = keras.layers.GlobalAveragePooling1D(name = 'Glo88671', )(Lay84842)
Con28975 = keras.layers.Concatenate(axis=1, name = 'Con28975', )([Glo88671,in0Con28975])
Sub67509 = keras.layers.Subtract(name = 'Sub67509', )([Fla53338,Con28975])
model = tf.keras.models.Model(inputs=[in0Den40182,in0Lay84842,in0Con28975], outputs=Sub67509)
w = model.get_layer('Den40182').get_weights() 
w[0] = np.array([[0.702, 0.4032, 0.0202, 0.2641], [0.5842, 0.6143, 0.1494, 0.0574], [0.9024, 0.571, 0.232, 0.2148], [0.6326, 0.1678, 0.1755, 0.7171]])
w[1] = np.array([0.5756, 0.4585, 0.9911, 0.1142])
model.get_layer('Den40182').set_weights(w) 
in0Den40182 = tf.constant([[[[0.9996, 0.8336, 0.4826, 0.4675], [0.0626, 0.0666, 0.4924, 0.8341]], [[0.641, 0.4317, 0.81, 0.7665], [0.5561, 0.7753, 0.8388, 0.7073]], [[0.796, 0.1104, 0.618, 0.4195], [0.4326, 0.0831, 0.774, 0.3558]], [[0.5737, 0.7445, 0.0261, 0.0857], [0.5572, 0.0251, 0.1868, 0.3868]]]])
in0Lay84842 = tf.constant([[[1.1643, 1.3861], [1.9946, 1.6297], [1.0995, 1.3514], [1.9171, 1.774]]])
in0Con28975 = tf.constant([[0.9811, 0.8802, 0.8691, 0.391, 0.2669, 0.2961, 0.4119, 0.3731, 0.975, 0.926, 0.773, 0.5306, 0.716, 0.0911, 0.7037, 0.1273, 0.9843, 0.3162, 0.1256, 0.1142, 0.2061, 0.3311, 0.548, 0.9584, 0.4219, 0.3079, 0.7426, 0.656, 0.1469, 0.4513]])
print (np.array2string(model.predict([in0Den40182,in0Lay84842,in0Con28975],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub67509.png')

LDen40182 = dense_layer([[[[0.9996, 0.8336, 0.4826, 0.4675], [0.0626, 0.0666, 0.4924, 0.8341]], [[0.641, 0.4317, 0.81, 0.7665], [0.5561, 0.7753, 0.8388, 0.7073]], [[0.796, 0.1104, 0.618, 0.4195], [0.4326, 0.0831, 0.774, 0.3558]], [[0.5737, 0.7445, 0.0261, 0.0857], [0.5572, 0.0251, 0.1868, 0.3868]]]], [[0.702, 0.4032, 0.0202, 0.2641], [0.5842, 0.6143, 0.1494, 0.0574], [0.9024, 0.571, 0.232, 0.2148], [0.6326, 0.1678, 0.1755, 0.7171]],[0.5756, 0.4585, 0.9911, 0.1142], Den40182), 
LRes85423 = reshape_layer(Den40182, [4, 8], Res85423), 
LFla53338 = flatten_layer(Res85423, Fla53338), 
LLay84842 = layer_normalization_layer([[[1.1643, 1.3861], [1.9946, 1.6297], [1.0995, 1.3514], [1.9171, 1.774]]], 1, 2.3262808369940036, Lay84842), 
LGlo88671 = global_average_pooling1D_layer(Lay84842, Glo88671), 
LCon28975 = concatenate_layer([Glo88671,[[0.9811, 0.8802, 0.8691, 0.391, 0.2669, 0.2961, 0.4119, 0.3731, 0.975, 0.926, 0.773, 0.5306, 0.716, 0.0911, 0.7037, 0.1273, 0.9843, 0.3162, 0.1256, 0.1142, 0.2061, 0.3311, 0.548, 0.9584, 0.4219, 0.3079, 0.7426, 0.656, 0.1469, 0.4513]]], 1, Con28975), 
LSub67509 = subtract_layer(Fla53338,Con28975, Sub67509), 
exec_layers([LDen40182,LRes85423,LFla53338,LLay84842,LGlo88671,LCon28975,LSub67509],["Den40182","Res85423","Fla53338","Lay84842","Glo88671","Con28975","Sub67509"],Sub67509,"Sub67509")

Actual (Unparsed): [[2.4955471, 1.7276303, 0.3487412, -0.0152503, 0.7613464, 0.5547751, 0.9960359, 0.5423561, 2.0817130, 1.2001732, 0.4159849, 0.1059128, 1.8502836, 1.2260261, 0.7208958, 0.9018473, 1.3182465, 1.1432360, 0.2563712, 0.4481304, 1.7257689, 1.0714299, 1.0481646, 0.3235190, 0.9430408, 0.2180457, 0.7131126, 0.0676102, 0.6520758, 0.2141498, 0.9704264, 0.1289962]]

Expected (Unparsed): [[2.49554706,1.7276303,0.3487412099999999,-0.0152502699999999,0.7613463399999998,0.55477508,0.9960359100000001,0.5423561299999999,2.08171304,1.20017321,0.41598493000000014,0.10591282999999996,1.8502835599999998,1.22602605,0.7208957899999999,0.9018473,1.3182465799999998,1.1432360200000002,0.25637120999999974,0.44813041000000003,1.7257689,1.0714298899999997,1.04816456,0.32351897999999996,0.9430407599999999,0.21804574999999982,0.7131125900000002,0.06761022,0.65207582,0.21414981,0.9704263799999999,0.12899617999999996]]

Actual:   [[2.4956, 1.7277, 0.3488, -0.0152, 0.7614, 0.5548, 0.9961, 0.5424, 2.0818, 1.2002, 0.416, 0.106, 1.8503, 1.2261, 0.7209, 0.9019, 1.3183, 1.1433, 0.2564, 0.4482, 1.7258, 1.0715, 1.0482, 0.3236, 0.9431, 0.2181, 0.7132, 0.0677, 0.6521, 0.2142, 0.9705, 0.129]]

Expected: [[2.4956, 1.7277, 0.3488, -0.0152, 0.7614, 0.5548, 0.9961, 0.5424, 2.0818, 1.2002, 0.416, 0.106, 1.8503, 1.2261, 0.7209, 0.9019, 1.3183, 1.1433, 0.2564, 0.4482, 1.7258, 1.0715, 1.0482, 0.3236, 0.9431, 0.2181, 0.7132, 0.0677, 0.6521, 0.2142, 0.9705, 0.129]]