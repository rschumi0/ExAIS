import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo74493 = tf.keras.layers.Input(shape=([2, 2]))
in0Con53761 = tf.keras.layers.Input(shape=([5, 4, 1]))
in0Zer16204 = tf.keras.layers.Input(shape=([3, 2, 2]))

Glo74493 = keras.layers.GlobalAveragePooling1D(name = 'Glo74493', )(in0Glo74493)
Res15865 = keras.layers.Reshape((2, 1), name = 'Res15865', )(Glo74493)
Res30024 = keras.layers.Reshape((2, 1, 1), name = 'Res30024', )(Res15865)
Res75163 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res75163', )(Res30024)
Up_32775 = keras.layers.UpSampling3D(size=(2, 2, 1), name = 'Up_32775', )(Res75163)
Lea83080 = keras.layers.LeakyReLU(alpha=5.784635726558368, name = 'Lea83080', )(Up_32775)
Res16817 = keras.layers.Reshape((4, 2, 1), name = 'Res16817', )(Lea83080)
Zer87161 = keras.layers.ZeroPadding2D(padding=((1, 0), (2, 0)), name = 'Zer87161', )(Res16817)
Con53761 = keras.layers.Concatenate(axis=3, name = 'Con53761', )([Zer87161,in0Con53761])
Zer16204 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer16204', )(in0Zer16204)
PRe22102 = keras.layers.PReLU(name = 'PRe22102', )(Zer16204)
Add41563 = keras.layers.Add(name = 'Add41563', )([Con53761,PRe22102])
model = tf.keras.models.Model(inputs=[in0Glo74493,in0Con53761,in0Zer16204], outputs=Add41563)
w = model.get_layer('PRe22102').get_weights() 
w[0] = np.array([[[0.0502, 0.241], [0.6855, 0.1814], [0.79, 0.4429], [0.4368, 0.7903]], [[0.0343, 0.3662], [0.3691, 0.3119], [0.8505, 0.5364], [0.6204, 0.9752]], [[0.5303, 0.721], [0.1114, 0.0911], [0.8001, 0.0214], [0.3689, 0.5639]], [[0.9002, 0.8633], [0.6682, 0.876], [0.0084, 0.5828], [0.018, 0.263]], [[0.6815, 0.0076], [0.5319, 0.4503], [0.0802, 0.2892], [0.156, 0.6302]]])
model.get_layer('PRe22102').set_weights(w) 
in0Glo74493 = tf.constant([[[1.9797, 1.8594], [1.2362, 1.1965]]])
in0Con53761 = tf.constant([[[[0.6859], [0.2853], [0.8101], [0.2381]], [[0.753], [0.6262], [0.6032], [0.4754]], [[0.255], [0.6061], [0.5161], [0.6433]], [[0.5246], [0.069], [0.3111], [0.4805]], [[0.9393], [0.6839], [0.4749], [0.9236]]]])
in0Zer16204 = tf.constant([[[[1.6425, 1.9473], [1.0662, 1.9195]], [[1.3504, 1.2818], [1.614, 1.7871]], [[1.4172, 1.8744], [1.0844, 1.3244]]]])
print (np.array2string(model.predict([in0Glo74493,in0Con53761,in0Zer16204],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add41563.png')

LGlo74493 = global_average_pooling1D_layer([[[1.9797, 1.8594], [1.2362, 1.1965]]], Glo74493), 
LRes15865 = reshape_layer(Glo74493, [2, 1], Res15865), 
LRes30024 = reshape_layer(Res15865, [2, 1, 1], Res30024), 
LRes75163 = reshape_layer(Res30024, [2, 1, 1, 1], Res75163), 
LUp_32775 = up_sampling3D_layer(Res75163, 2, 2, 1, Up_32775), 
LLea83080 = leaky_relu_layer(Up_32775, 5.784635726558368, Lea83080), 
LRes16817 = reshape_layer(Lea83080, [4, 2, 1], Res16817), 
LZer87161 = zero_padding2D_layer(Res16817, 1, 0, 2, 0, Zer87161), 
LCon53761 = concatenate_layer([Zer87161,[[[[0.6859], [0.2853], [0.8101], [0.2381]], [[0.753], [0.6262], [0.6032], [0.4754]], [[0.255], [0.6061], [0.5161], [0.6433]], [[0.5246], [0.069], [0.3111], [0.4805]], [[0.9393], [0.6839], [0.4749], [0.9236]]]]], 3, Con53761), 
LZer16204 = zero_padding2D_layer([[[[1.6425, 1.9473], [1.0662, 1.9195]], [[1.3504, 1.2818], [1.614, 1.7871]], [[1.4172, 1.8744], [1.0844, 1.3244]]]], 1, 1, 1, 1, Zer16204), 
LPRe22102 = prelu_layer(Zer16204, [[[0.0502, 0.241], [0.6855, 0.1814], [0.79, 0.4429], [0.4368, 0.7903]], [[0.0343, 0.3662], [0.3691, 0.3119], [0.8505, 0.5364], [0.6204, 0.9752]], [[0.5303, 0.721], [0.1114, 0.0911], [0.8001, 0.0214], [0.3689, 0.5639]], [[0.9002, 0.8633], [0.6682, 0.876], [0.0084, 0.5828], [0.018, 0.263]], [[0.6815, 0.0076], [0.5319, 0.4503], [0.0802, 0.2892], [0.156, 0.6302]]], PRe22102), 
LAdd41563 = add_layer([Con53761,PRe22102], Add41563), 
exec_layers([LGlo74493,LRes15865,LRes30024,LRes75163,LUp_32775,LLea83080,LRes16817,LZer87161,LCon53761,LZer16204,LPRe22102,LAdd41563],["Glo74493","Res15865","Res30024","Res75163","Up_32775","Lea83080","Res16817","Zer87161","Con53761","Zer16204","PRe22102","Add41563"],Add41563,"Add41563")

Actual (Unparsed): [[[[0.0000000, 0.6859000], [0.0000000, 0.2853000], [0.0000000, 0.8101000], [0.0000000, 0.2381000]], [[0.0000000, 0.7530000], [1.6425000, 2.5735000], [2.6741500, 2.5227000], [1.6079500, 0.4754000]], [[0.0000000, 0.2550000], [1.3504000, 1.8879001], [3.2219499, 2.3031999], [1.6079500, 0.6433000]], [[0.0000000, 0.5246000], [1.4172000, 1.9434000], [2.6123500, 1.6355000], [1.5279500, 0.4805000]], [[0.0000000, 0.9393000], [0.0000000, 0.6839000], [1.5279500, 0.4749000], [1.5279500, 0.9236000]]]]

Expected (Unparsed): [[[[0,0.6859],[0,0.2853],[0,0.8101],[0,0.2381]],[[0,0.753],[1.6425,2.5735],[2.67415,2.5227],[1.60795,0.4754]],[[0,0.255],[1.3504,1.8879000000000001],[3.22195,2.3032],[1.60795,0.6433]],[[0,0.5246],[1.4172,1.9434],[2.61235,1.6355],[1.52795,0.4805]],[[0,0.9393],[0,0.6839],[1.52795,0.4749],[1.52795,0.9236]]]]

Actual:   [[[[0, 0.6859], [0, 0.2853], [0, 0.8101], [0, 0.2381]], [[0, 0.753], [1.6425, 2.5735], [2.6742, 2.5227], [1.608, 0.4754]], [[0, 0.255], [1.3504, 1.888], [3.222, 2.3032], [1.608, 0.6433]], [[0, 0.5246], [1.4172, 1.9434], [2.6124, 1.6355], [1.528, 0.4805]], [[0, 0.9393], [0, 0.6839], [1.528, 0.4749], [1.528, 0.9236]]]]

Expected: [[[[0, 0.6859], [0, 0.2853], [0, 0.8101], [0, 0.2381]], [[0, 0.753], [1.6425, 2.5735], [2.6742, 2.5227], [1.608, 0.4754]], [[0, 0.255], [1.3504, 1.888], [3.222, 2.3032], [1.608, 0.6433]], [[0, 0.5246], [1.4172, 1.9434], [2.6124, 1.6355], [1.528, 0.4805]], [[0, 0.9393], [0, 0.6839], [1.528, 0.4749], [1.528, 0.9236]]]]