import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max47765 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in1Max47765 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in0Con58829 = tf.keras.layers.Input(shape=([2, 3, 3, 3]))
in0Con2641 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in0Max96303 = tf.keras.layers.Input(shape=([1, 2, 2]))
in1Max96303 = tf.keras.layers.Input(shape=([1, 2, 2]))
in0Glo78898 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con82429 = tf.keras.layers.Input(shape=([2]))
in0Con796 = tf.keras.layers.Input(shape=([68]))
in0Sim71023 = tf.keras.layers.Input(shape=([3, 3]))
in0Con42333 = tf.keras.layers.Input(shape=([70]))

Max47765 = keras.layers.Maximum(name = 'Max47765', )([in0Max47765,in1Max47765])
Zer20180 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (1, 0)), name = 'Zer20180', )(Max47765)
Con58829 = keras.layers.Concatenate(axis=4, name = 'Con58829', )([Zer20180,in0Con58829])
Con2641 = keras.layers.Conv3D(4, (1, 1, 2),strides=(1, 1, 1), padding='valid', dilation_rate=(1, 1, 1), name = 'Con2641', )(in0Con2641)
Zer59165 = keras.layers.ZeroPadding3D(padding=((0, 0), (2, 0), (2, 0)), name = 'Zer59165', )(Con2641)
Mul25209 = keras.layers.Multiply(name = 'Mul25209', )([Con58829,Zer59165])
Res72821 = keras.layers.Reshape((2, 3, 12), name = 'Res72821', )(Mul25209)
Res62881 = keras.layers.Reshape((2, 36), name = 'Res62881', )(Res72821)
Fla72960 = keras.layers.Flatten(name = 'Fla72960', )(Res62881)
Max96303 = keras.layers.Maximum(name = 'Max96303', )([in0Max96303,in1Max96303])
Res76323 = keras.layers.Reshape((1, 4), name = 'Res76323', )(Max96303)
Fla28265 = keras.layers.Flatten(name = 'Fla28265', )(Res76323)
Glo78898 = keras.layers.GlobalAveragePooling2D(name = 'Glo78898', )(in0Glo78898)
Con82429 = keras.layers.Concatenate(axis=1, name = 'Con82429', )([Glo78898,in0Con82429])
Sub62456 = keras.layers.Subtract(name = 'Sub62456', )([Fla28265,Con82429])
Con796 = keras.layers.Concatenate(axis=1, name = 'Con796', )([Sub62456,in0Con796])
Add12549 = keras.layers.Add(name = 'Add12549', )([Fla72960,Con796])
Sim71023 = keras.layers.SimpleRNN(2,name = 'Sim71023', )(in0Sim71023)
Con42333 = keras.layers.Concatenate(axis=1, name = 'Con42333', )([Sim71023,in0Con42333])
Add62194 = keras.layers.Add(name = 'Add62194', )([Add12549,Con42333])
model = tf.keras.models.Model(inputs=[in0Max47765,in1Max47765,in0Con58829,in0Con2641,in0Max96303,in1Max96303,in0Glo78898,in0Con82429,in0Con796,in0Sim71023,in0Con42333], outputs=Add62194)
w = model.get_layer('Con2641').get_weights() 
w[0] = np.array([[[[[0.5374, 0.345, 0.8386, 0.4529], [0.7542, 0.7131, 0.4779, 0.0551]], [[0.6144, 0.5167, 0.2573, 0.933], [0.8441, 0.2364, 0.2012, 0.2255]]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con2641').set_weights(w) 
w = model.get_layer('Sim71023').get_weights() 
w[0] = np.array([[5, 1], [6, 10], [8, 10]])
w[1] = np.array([[9, 8], [1, 6]])
w[2] = np.array([4, 6])
model.get_layer('Sim71023').set_weights(w) 
in0Max47765 = tf.constant([[[[[0.2146], [0.849]], [[0.5453], [0.2477]]]]])
in1Max47765 = tf.constant([[[[[0.8287], [0.1529]], [[0.1183], [0.164]]]]])
in0Con58829 = tf.constant([[[[[0.7199, 0.4763, 0.8191], [0.1654, 0.1176, 0.9957], [0.0207, 0.0632, 0.6367]], [[0.5686, 0.417, 0.7644], [0.2998, 0.8309, 0.7536], [0.0715, 0.4271, 0.4621]], [[0.5184, 0.5211, 0.8422], [0.7878, 0.569, 0.4701], [0.9859, 0.3088, 0.4802]]], [[[0.6233, 0.4197, 0.2651], [0.2014, 0.6941, 0.5185], [0.1709, 0.7605, 0.6647]], [[0.3754, 0.2351, 0.2999], [0.5493, 0.071, 0.7202], [0.6904, 0.6526, 0.4965]], [[0.5883, 0.3319, 0.0653], [0.8612, 0.2305, 0.5209], [0.5391, 0.8655, 0.6848]]]]])
in0Con2641 = tf.constant([[[[[0.1881, 0.4561], [0.6803, 0.8969]]], [[[0.689, 0.3517], [0.1198, 0.923]]]]])
in0Max96303 = tf.constant([[[[0.2709, 0.1699], [0.9815, 0.5703]]]])
in1Max96303 = tf.constant([[[[0.1434, 0.7944], [0.0149, 0.4463]]]])
in0Glo78898 = tf.constant([[[[1.4176, 1.251]]]])
in0Con82429 = tf.constant([[0.1016, 0.8155]])
in0Con796 = tf.constant([[0.1424, 0.0601, 0.3847, 0.3094, 0.8927, 0.9672, 0.6813, 0.9108, 0.1403, 0.7852, 0.9789, 0.5602, 0.8864, 0.6078, 0.1615, 0.7605, 0.3654, 0.2684, 0.4561, 0.7034, 0.2001, 0.9278, 0.4764, 0.889, 0.3867, 0.3895, 0.5615, 0.1603, 0.3618, 0.6061, 0.6708, 0.942, 0.9654, 0.0974, 0.3643, 0.5575, 0.3272, 0.1582, 0.8106, 0.9895, 0.5772, 0.8059, 0.3437, 0.3394, 0.8097, 0.3873, 0.8205, 0.5488, 0.9135, 0.647, 0.9186, 0.6509, 0.7235, 0.8441, 0.556, 0.933, 0.444, 0.1969, 0.8185, 0.916, 0.4489, 0.5344, 0.1325, 0.9781, 0.3733, 0.5371, 0.9375, 0.7876]])
in0Sim71023 = tf.constant([[[8, 2, 2], [7, 9, 7], [9, 5, 8]]])
in0Con42333 = tf.constant([[0.572, 0.7642, 0.5677, 0.3939, 0.4286, 0.0469, 0.7363, 0.6628, 0.3159, 0.3113, 0.1553, 0.059, 0.5426, 0.502, 0.9709, 0.1725, 0.9144, 0.6943, 0.9748, 0.9206, 0.2774, 0.9156, 0.7202, 0.4891, 0.56, 0.5475, 0.3657, 0.1243, 0.0461, 0.0182, 0.1434, 0.217, 0.9826, 0.0595, 0.4255, 0.5159, 0.6535, 0.2789, 0.594, 0.1077, 0.7376, 0.1756, 0.3048, 0.0117, 0.1055, 0.0161, 0.285, 0.8494, 0.213, 0.1771, 0.4973, 0.0697, 0.896, 0.662, 0.3663, 0.6395, 0.6857, 0.5028, 0.7715, 0.9385, 0.7279, 0.6691, 0.6828, 0.8414, 0.0091, 0.9251, 0.6363, 0.61, 0.876, 0.797]])
print (np.array2string(model.predict([in0Max47765,in1Max47765,in0Con58829,in0Con2641,in0Max96303,in1Max96303,in0Glo78898,in0Con82429,in0Con796,in0Sim71023,in0Con42333],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add62194.png')

LMax47765 = maximum_layer([[[[[[0.2146], [0.849]], [[0.5453], [0.2477]]]]], [[[[[0.8287], [0.1529]], [[0.1183], [0.164]]]]]], Max47765), 
LZer20180 = zero_padding3D_layer(Max47765, 1, 0, 1, 0, 1, 0, Zer20180), 
LCon58829 = concatenate_layer([Zer20180,[[[[[0.7199, 0.4763, 0.8191], [0.1654, 0.1176, 0.9957], [0.0207, 0.0632, 0.6367]], [[0.5686, 0.417, 0.7644], [0.2998, 0.8309, 0.7536], [0.0715, 0.4271, 0.4621]], [[0.5184, 0.5211, 0.8422], [0.7878, 0.569, 0.4701], [0.9859, 0.3088, 0.4802]]], [[[0.6233, 0.4197, 0.2651], [0.2014, 0.6941, 0.5185], [0.1709, 0.7605, 0.6647]], [[0.3754, 0.2351, 0.2999], [0.5493, 0.071, 0.7202], [0.6904, 0.6526, 0.4965]], [[0.5883, 0.3319, 0.0653], [0.8612, 0.2305, 0.5209], [0.5391, 0.8655, 0.6848]]]]]], 4, Con58829), 
LCon2641 = conv3D_layer([[[[[0.1881, 0.4561], [0.6803, 0.8969]]], [[[0.689, 0.3517], [0.1198, 0.923]]]]], 1, 1, 2,[[[[[0.5374, 0.345, 0.8386, 0.4529], [0.7542, 0.7131, 0.4779, 0.0551]], [[0.6144, 0.5167, 0.2573, 0.933], [0.8441, 0.2364, 0.2012, 0.2255]]]]],[0, 0, 0, 0], 1, 1, 1, false, 1, 1, 1, Con2641), 
LZer59165 = zero_padding3D_layer(Con2641, 0, 0, 2, 0, 2, 0, Zer59165), 
LMul25209 = multiply_layer([Con58829,Zer59165], Mul25209), 
LRes72821 = reshape_layer(Mul25209, [2, 3, 12], Res72821), 
LRes62881 = reshape_layer(Res72821, [2, 36], Res62881), 
LFla72960 = flatten_layer(Res62881, Fla72960), 
LMax96303 = maximum_layer([[[[[0.2709, 0.1699], [0.9815, 0.5703]]]], [[[[0.1434, 0.7944], [0.0149, 0.4463]]]]], Max96303), 
LRes76323 = reshape_layer(Max96303, [1, 4], Res76323), 
LFla28265 = flatten_layer(Res76323, Fla28265), 
LGlo78898 = global_average_pooling2D_layer([[[[1.4176, 1.251]]]], Glo78898), 
LCon82429 = concatenate_layer([Glo78898,[[0.1016, 0.8155]]], 1, Con82429), 
LSub62456 = subtract_layer(Fla28265,Con82429, Sub62456), 
LCon796 = concatenate_layer([Sub62456,[[0.1424, 0.0601, 0.3847, 0.3094, 0.8927, 0.9672, 0.6813, 0.9108, 0.1403, 0.7852, 0.9789, 0.5602, 0.8864, 0.6078, 0.1615, 0.7605, 0.3654, 0.2684, 0.4561, 0.7034, 0.2001, 0.9278, 0.4764, 0.889, 0.3867, 0.3895, 0.5615, 0.1603, 0.3618, 0.6061, 0.6708, 0.942, 0.9654, 0.0974, 0.3643, 0.5575, 0.3272, 0.1582, 0.8106, 0.9895, 0.5772, 0.8059, 0.3437, 0.3394, 0.8097, 0.3873, 0.8205, 0.5488, 0.9135, 0.647, 0.9186, 0.6509, 0.7235, 0.8441, 0.556, 0.933, 0.444, 0.1969, 0.8185, 0.916, 0.4489, 0.5344, 0.1325, 0.9781, 0.3733, 0.5371, 0.9375, 0.7876]]], 1, Con796), 
LAdd12549 = add_layer([Fla72960,Con796], Add12549), 
LSim71023 = simple_rnn_layer([[[8, 2, 2], [7, 9, 7], [9, 5, 8]]],[[5, 1], [6, 10], [8, 10]],[[9, 8], [1, 6]],[4, 6], Sim71023), 
LCon42333 = concatenate_layer([Sim71023,[[0.572, 0.7642, 0.5677, 0.3939, 0.4286, 0.0469, 0.7363, 0.6628, 0.3159, 0.3113, 0.1553, 0.059, 0.5426, 0.502, 0.9709, 0.1725, 0.9144, 0.6943, 0.9748, 0.9206, 0.2774, 0.9156, 0.7202, 0.4891, 0.56, 0.5475, 0.3657, 0.1243, 0.0461, 0.0182, 0.1434, 0.217, 0.9826, 0.0595, 0.4255, 0.5159, 0.6535, 0.2789, 0.594, 0.1077, 0.7376, 0.1756, 0.3048, 0.0117, 0.1055, 0.0161, 0.285, 0.8494, 0.213, 0.1771, 0.4973, 0.0697, 0.896, 0.662, 0.3663, 0.6395, 0.6857, 0.5028, 0.7715, 0.9385, 0.7279, 0.6691, 0.6828, 0.8414, 0.0091, 0.9251, 0.6363, 0.61, 0.876, 0.797]]], 1, Con42333), 
LAdd62194 = add_layer([Add12549,Con42333], Add62194), 
exec_layers([LMax47765,LZer20180,LCon58829,LCon2641,LZer59165,LMul25209,LRes72821,LRes62881,LFla72960,LMax96303,LRes76323,LFla28265,LGlo78898,LCon82429,LSub62456,LCon796,LAdd12549,LSim71023,LCon42333,LAdd62194],["Max47765","Zer20180","Con58829","Con2641","Zer59165","Mul25209","Res72821","Res62881","Fla72960","Max96303","Res76323","Fla28265","Glo78898","Con82429","Sub62456","Con796","Add12549","Sim71023","Con42333","Add62194"],Add62194,"Add62194")

Actual (Unparsed): [[-0.1467000, 0.5433999, 1.4519001, 0.5189999, 0.7101000, 0.4540000, 0.8133000, 0.3563000, 1.6290000, 1.6300000, 0.9972000, 1.2221000, 0.2956000, 0.8442000, 1.5215000, 1.0622000, 1.8573000, 0.7803000, 1.0759000, 1.4548000, 1.3402000, 1.1890000, 0.7335000, 1.6190000, 0.9203000, 1.4169000, 1.0364000, 1.4365000, 0.7524000, 0.5138000, 0.6076000, 0.1785000, 0.5052000, 1.7633307, 1.8791971, 1.4563898, 1.3909000, 0.6133000, 1.0178000, 0.8364000, 0.9212000, 0.2659000, 1.5482000, 1.1651000, 0.8820000, 0.8176000, 0.4492000, 0.3555000, 1.0947000, 1.2367000, 1.0335000, 0.7259000, 1.4108000, 0.7167000, 1.8146001, 1.3129000, 1.0898000, 1.4836000, 1.2417000, 1.4358000, 1.2155000, 1.1354000, 1.5464000, 1.5851000, 1.1317000, 1.3758000, 0.1416000, 1.9032000, 1.3782346, 1.5614524, 2.6464615, 2.0306353]]

Expected (Unparsed): [[-0.14670000000000005,0.5434000000000001,1.4519,0.519,0.7101,0.45399999999999996,0.8132999999999999,0.3563,1.629,1.63,0.9972000000000001,1.2221000000000002,0.2956,0.8442000000000001,1.5215,1.0622,1.8573,0.7803,1.0759,1.4548,1.3402,1.189,0.7335,1.619,0.9202999999999999,1.4169,1.0364,1.4365,0.7524,0.5138,0.6076,0.1785,0.5052,1.7633307261220001,1.8791971292160001,1.45638983449,1.3909,0.6133000000000001,1.0178,0.8364,0.9212,0.2659,1.5482,1.1651,0.8820000000000001,0.8176,0.4492,0.3555,1.0947,1.2367,1.0335,0.7259,1.4108,0.7167,1.8146,1.3129,1.0898,1.4836,1.2417,1.4358,1.2155,1.1354,1.5464,1.5851000000000002,1.1317,1.3758,0.1416,1.9032,1.378234610632,1.561452330083,2.6464615015349997,2.030635351616]]

Actual:   [[-0.1467, 0.5434, 1.452, 0.519, 0.7101, 0.454, 0.8133, 0.3563, 1.629, 1.63, 0.9972, 1.2221, 0.2956, 0.8442, 1.5215, 1.0622, 1.8573, 0.7803, 1.0759, 1.4548, 1.3402, 1.189, 0.7335, 1.619, 0.9203, 1.4169, 1.0364, 1.4365, 0.7524, 0.5138, 0.6076, 0.1785, 0.5052, 1.7634, 1.8792, 1.4564, 1.3909, 0.6133, 1.0178, 0.8364, 0.9212, 0.2659, 1.5482, 1.1651, 0.882, 0.8176, 0.4492, 0.3555, 1.0947, 1.2367, 1.0335, 0.7259, 1.4108, 0.7167, 1.8147, 1.3129, 1.0898, 1.4836, 1.2417, 1.4358, 1.2155, 1.1354, 1.5464, 1.5851, 1.1317, 1.3758, 0.1416, 1.9032, 1.3783, 1.5615, 2.6465, 2.0307]]

Expected: [[-0.1467, 0.5435, 1.4519, 0.519, 0.7101, 0.454, 0.8133, 0.3563, 1.629, 1.63, 0.9973, 1.2222, 0.2956, 0.8443, 1.5215, 1.0622, 1.8573, 0.7803, 1.0759, 1.4548, 1.3402, 1.189, 0.7335, 1.619, 0.9203, 1.4169, 1.0364, 1.4365, 0.7524, 0.5138, 0.6076, 0.1785, 0.5052, 1.7634, 1.8792, 1.4564, 1.3909, 0.6134, 1.0178, 0.8364, 0.9212, 0.2659, 1.5482, 1.1651, 0.8821, 0.8176, 0.4492, 0.3555, 1.0947, 1.2367, 1.0335, 0.7259, 1.4108, 0.7167, 1.8146, 1.3129, 1.0898, 1.4836, 1.2417, 1.4358, 1.2155, 1.1354, 1.5464, 1.5852, 1.1317, 1.3758, 0.1416, 1.9032, 1.3783, 1.5615, 2.6465, 2.0307]]