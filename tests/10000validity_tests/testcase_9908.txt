import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul19304 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in1Mul19304 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in0Add85898 = tf.keras.layers.Input(shape=([1, 2]))
in1Add85898 = tf.keras.layers.Input(shape=([1, 2]))
in0Con47695 = tf.keras.layers.Input(shape=([2, 2]))
in0Min10229 = tf.keras.layers.Input(shape=([1, 2, 1]))
in1Min10229 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Lay5926 = tf.keras.layers.Input(shape=([2]))
in0Con65512 = tf.keras.layers.Input(shape=([22, 12]))

Mul19304 = keras.layers.Multiply(name = 'Mul19304', )([in0Mul19304,in1Mul19304])
Res13852 = keras.layers.Reshape((2, 1, 4), name = 'Res13852', )(Mul19304)
Res53384 = keras.layers.Reshape((2, 4), name = 'Res53384', )(Res13852)
Add85898 = keras.layers.Add(name = 'Add85898', )([in0Add85898,in1Add85898])
Lea34717 = keras.layers.LeakyReLU(alpha=7.008912599413901, name = 'Lea34717', )(Add85898)
Zer19499 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer19499', )(Lea34717)
Con47695 = keras.layers.Concatenate(axis=2, name = 'Con47695', )([Zer19499,in0Con47695])
Min61860 = keras.layers.Minimum(name = 'Min61860', )([Res53384,Con47695])
Res76966 = keras.layers.Reshape((2, 4, 1), name = 'Res76966', )(Min61860)
Res35467 = keras.layers.Reshape((2, 4, 1, 1), name = 'Res35467', )(Res76966)
Con74950 = keras.layers.Conv3DTranspose(2, (1, 4, 1),strides=(11, 1, 1), padding='valid', name = 'Con74950', )(Res35467)
Res80330 = keras.layers.Reshape((22, 7, 2), name = 'Res80330', )(Con74950)
Res92251 = keras.layers.Reshape((22, 14), name = 'Res92251', )(Res80330)
Min10229 = keras.layers.Minimum(name = 'Min10229', )([in0Min10229,in1Min10229])
Res48493 = keras.layers.Reshape((1, 2), name = 'Res48493', )(Min10229)
Lay5926 = keras.layers.LayerNormalization(axis=1, epsilon=1.1537893195323734, name = 'Lay5926', )(in0Lay5926)
Res46642 = keras.layers.Reshape((1, 2), name = 'Res46642', )(Lay5926)
Add14416 = keras.layers.Add(name = 'Add14416', )([Res48493,Res46642])
Zer40188 = keras.layers.ZeroPadding1D(padding=((21, 0)), name = 'Zer40188', )(Add14416)
Con65512 = keras.layers.Concatenate(axis=2, name = 'Con65512', )([Zer40188,in0Con65512])
Min59939 = keras.layers.Minimum(name = 'Min59939', )([Res92251,Con65512])
model = tf.keras.models.Model(inputs=[in0Mul19304,in1Mul19304,in0Add85898,in1Add85898,in0Con47695,in0Min10229,in1Min10229,in0Lay5926,in0Con65512], outputs=Min59939)
w = model.get_layer('Con74950').get_weights() 
w[0] = np.array([[[[[0.7417], [0.4488]]], [[[0.9751], [0.8988]]], [[[0.585], [0.6217]]], [[[0.3547], [0.0603]]]]])
w[1] = np.array([0, 0])
model.get_layer('Con74950').set_weights(w) 
in0Mul19304 = tf.constant([[[[[0.9373, 0.4584], [0.4168, 0.0022]]], [[[0.8597, 0.4895], [0.2129, 0.9485]]]]])
in1Mul19304 = tf.constant([[[[[0.549, 0.352], [0.2644, 0.4535]]], [[[0.5321, 0.1826], [0.369, 0.1925]]]]])
in0Add85898 = tf.constant([[[0.631, 0.0017]]])
in1Add85898 = tf.constant([[[0.243, 0.9772]]])
in0Con47695 = tf.constant([[[0.9102, 0.6632], [0.0804, 0.2208]]])
in0Min10229 = tf.constant([[[[0.7301], [0.9781]]]])
in1Min10229 = tf.constant([[[[0.415], [0.8897]]]])
in0Lay5926 = tf.constant([[1.6021, 1.9963]])
in0Con65512 = tf.constant([[[0.4308, 0.2435, 0.9538, 0.0886, 0.4158, 0.6267, 0.2456, 0.0579, 0.9256, 0.2544, 0.2821, 0.0564], [0.3674, 0.3741, 0.311, 0.704, 0.0561, 0.8146, 0.9097, 0.5249, 0.7402, 0.9255, 0.1152, 0.2442], [0.8841, 0.1118, 0.6217, 0.9294, 0.9335, 0.6903, 0.1133, 0.1892, 0.7961, 0.3947, 0.5701, 0.633], [0.5479, 0.4945, 0.4285, 0.3196, 0.941, 0.1525, 0.8106, 0.9801, 0.6334, 0.3469, 0.6444, 0.3848], [0.1869, 0.407, 0.3903, 0.3446, 0.7856, 0.975, 0.2601, 0.4854, 0.3187, 0.9927, 0.2718, 0.1138], [0.9377, 0.1337, 0.2162, 0.2069, 0.4504, 0.9573, 0.628, 0.8, 0.9481, 0.9403, 0.155, 0.82], [0.8727, 0.4588, 0.2934, 0.7215, 0.3277, 0.7416, 0.322, 0.1141, 0.8113, 0.789, 0.4067, 0.9431], [0.7083, 0.2645, 0.2709, 0.6808, 0.816, 0.4035, 0.5308, 0.4189, 0.8968, 0.0562, 0.7813, 0.7137], [0.755, 0.0847, 0.783, 0.528, 0.6141, 0.4659, 0.6495, 0.6403, 0.6359, 0.6193, 0.764, 0.4446], [0.2674, 0.674, 0.2628, 0.1535, 0.7272, 0.6168, 0.3173, 0.0345, 0.3508, 0.5211, 0.1166, 0.4581], [0.7015, 0.3498, 0.4075, 0.2185, 0.3249, 0.1411, 0.6862, 0.7988, 0.7747, 0.7444, 0.6492, 0.9948], [0.0708, 0.6531, 0.3111, 0.5876, 0.0626, 0.8986, 0.2752, 0.5611, 0.2674, 0.4147, 0.0039, 0.6941], [0.6278, 0.7594, 0.576, 0.2293, 0.2894, 0.5915, 0.3431, 0.7182, 0.9405, 0.8359, 0.0984, 0.0719], [0.4727, 0.047, 0.8602, 0.31, 0.724, 0.0786, 0.1359, 0.4937, 0.847, 0.8052, 0.581, 0.8524], [0.4099, 0.3026, 0.2983, 0.1689, 0.6807, 0.5923, 0.631, 0.0759, 0.6731, 0.7846, 0.1943, 0.0353], [0.4376, 0.2085, 0.0668, 0.4181, 0.7719, 0.9123, 0.5121, 0.2875, 0.9928, 0.7365, 0.3407, 0.1973], [0.6636, 0.0143, 0.0347, 0.5598, 0.2039, 0.8388, 0.0613, 0.9158, 0.1193, 0.7509, 0.3729, 0.7404], [0.1878, 0.6486, 0.9593, 0.2581, 0.311, 0.694, 0.4532, 0.1086, 0.8985, 0.0077, 0.2176, 0.6021], [0.5921, 0.9738, 0.0439, 0.7365, 0.8541, 0.056, 0.578, 0.1086, 0.4465, 0.1239, 0.8565, 0.3456], [0.1119, 0.425, 0.8832, 0.7065, 0.8255, 0.5006, 0.0059, 0.0611, 0.8376, 0.5417, 0.9637, 0.5383], [0.3485, 0.9083, 0.865, 0.7546, 0.0668, 0.7941, 0.032, 0.685, 0.0885, 0.3076, 0.5996, 0.9159], [0.5073, 0.5643, 0.992, 0.2339, 0.9143, 0.7354, 0.9182, 0.2469, 0.4785, 0.3816, 0.3245, 0.008]]])
print (np.array2string(model.predict([in0Mul19304,in1Mul19304,in0Add85898,in1Add85898,in0Con47695,in0Min10229,in1Min10229,in0Lay5926,in0Con65512],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min59939.png')

LMul19304 = multiply_layer([[[[[[0.9373, 0.4584], [0.4168, 0.0022]]], [[[0.8597, 0.4895], [0.2129, 0.9485]]]]], [[[[[0.549, 0.352], [0.2644, 0.4535]]], [[[0.5321, 0.1826], [0.369, 0.1925]]]]]], Mul19304), 
LRes13852 = reshape_layer(Mul19304, [2, 1, 4], Res13852), 
LRes53384 = reshape_layer(Res13852, [2, 4], Res53384), 
LAdd85898 = add_layer([[[[0.631, 0.0017]]], [[[0.243, 0.9772]]]], Add85898), 
LLea34717 = leaky_relu_layer(Add85898, 7.008912599413901, Lea34717), 
LZer19499 = zero_padding1D_layer(Lea34717, 1, 0, Zer19499), 
LCon47695 = concatenate_layer([Zer19499,[[[0.9102, 0.6632], [0.0804, 0.2208]]]], 2, Con47695), 
LMin61860 = minimum_layer([Res53384,Con47695], Min61860), 
LRes76966 = reshape_layer(Min61860, [2, 4, 1], Res76966), 
LRes35467 = reshape_layer(Res76966, [2, 4, 1, 1], Res35467), 
LCon74950 = conv3D_transpose_layer(Res35467, 1, 4, 1,[[[[[0.7417], [0.4488]]], [[[0.9751], [0.8988]]], [[[0.585], [0.6217]]], [[[0.3547], [0.0603]]]]],[0, 0], 11, 1, 1, false, Con74950), 
LRes80330 = reshape_layer(Con74950, [22, 7, 2], Res80330), 
LRes92251 = reshape_layer(Res80330, [22, 14], Res92251), 
LMin10229 = minimum_layer([[[[[0.7301], [0.9781]]]], [[[[0.415], [0.8897]]]]], Min10229), 
LRes48493 = reshape_layer(Min10229, [1, 2], Res48493), 
LLay5926 = layer_normalization_layer([[1.6021, 1.9963]], 1, 1.1537893195323734, Lay5926), 
LRes46642 = reshape_layer(Lay5926, [1, 2], Res46642), 
LAdd14416 = add_layer([Res48493,Res46642], Add14416), 
LZer40188 = zero_padding1D_layer(Add14416, 21, 0, Zer40188), 
LCon65512 = concatenate_layer([Zer40188,[[[0.4308, 0.2435, 0.9538, 0.0886, 0.4158, 0.6267, 0.2456, 0.0579, 0.9256, 0.2544, 0.2821, 0.0564], [0.3674, 0.3741, 0.311, 0.704, 0.0561, 0.8146, 0.9097, 0.5249, 0.7402, 0.9255, 0.1152, 0.2442], [0.8841, 0.1118, 0.6217, 0.9294, 0.9335, 0.6903, 0.1133, 0.1892, 0.7961, 0.3947, 0.5701, 0.633], [0.5479, 0.4945, 0.4285, 0.3196, 0.941, 0.1525, 0.8106, 0.9801, 0.6334, 0.3469, 0.6444, 0.3848], [0.1869, 0.407, 0.3903, 0.3446, 0.7856, 0.975, 0.2601, 0.4854, 0.3187, 0.9927, 0.2718, 0.1138], [0.9377, 0.1337, 0.2162, 0.2069, 0.4504, 0.9573, 0.628, 0.8, 0.9481, 0.9403, 0.155, 0.82], [0.8727, 0.4588, 0.2934, 0.7215, 0.3277, 0.7416, 0.322, 0.1141, 0.8113, 0.789, 0.4067, 0.9431], [0.7083, 0.2645, 0.2709, 0.6808, 0.816, 0.4035, 0.5308, 0.4189, 0.8968, 0.0562, 0.7813, 0.7137], [0.755, 0.0847, 0.783, 0.528, 0.6141, 0.4659, 0.6495, 0.6403, 0.6359, 0.6193, 0.764, 0.4446], [0.2674, 0.674, 0.2628, 0.1535, 0.7272, 0.6168, 0.3173, 0.0345, 0.3508, 0.5211, 0.1166, 0.4581], [0.7015, 0.3498, 0.4075, 0.2185, 0.3249, 0.1411, 0.6862, 0.7988, 0.7747, 0.7444, 0.6492, 0.9948], [0.0708, 0.6531, 0.3111, 0.5876, 0.0626, 0.8986, 0.2752, 0.5611, 0.2674, 0.4147, 0.0039, 0.6941], [0.6278, 0.7594, 0.576, 0.2293, 0.2894, 0.5915, 0.3431, 0.7182, 0.9405, 0.8359, 0.0984, 0.0719], [0.4727, 0.047, 0.8602, 0.31, 0.724, 0.0786, 0.1359, 0.4937, 0.847, 0.8052, 0.581, 0.8524], [0.4099, 0.3026, 0.2983, 0.1689, 0.6807, 0.5923, 0.631, 0.0759, 0.6731, 0.7846, 0.1943, 0.0353], [0.4376, 0.2085, 0.0668, 0.4181, 0.7719, 0.9123, 0.5121, 0.2875, 0.9928, 0.7365, 0.3407, 0.1973], [0.6636, 0.0143, 0.0347, 0.5598, 0.2039, 0.8388, 0.0613, 0.9158, 0.1193, 0.7509, 0.3729, 0.7404], [0.1878, 0.6486, 0.9593, 0.2581, 0.311, 0.694, 0.4532, 0.1086, 0.8985, 0.0077, 0.2176, 0.6021], [0.5921, 0.9738, 0.0439, 0.7365, 0.8541, 0.056, 0.578, 0.1086, 0.4465, 0.1239, 0.8565, 0.3456], [0.1119, 0.425, 0.8832, 0.7065, 0.8255, 0.5006, 0.0059, 0.0611, 0.8376, 0.5417, 0.9637, 0.5383], [0.3485, 0.9083, 0.865, 0.7546, 0.0668, 0.7941, 0.032, 0.685, 0.0885, 0.3076, 0.5996, 0.9159], [0.5073, 0.5643, 0.992, 0.2339, 0.9143, 0.7354, 0.9182, 0.2469, 0.4785, 0.3816, 0.3245, 0.008]]]], 2, Con65512), 
LMin59939 = minimum_layer([Res92251,Con65512], Min59939), 
exec_layers([LMul19304,LRes13852,LRes53384,LAdd85898,LLea34717,LZer19499,LCon47695,LMin61860,LRes76966,LRes35467,LCon74950,LRes80330,LRes92251,LMin10229,LRes48493,LLay5926,LRes46642,LAdd14416,LZer40188,LCon65512,LMin59939],["Mul19304","Res13852","Res53384","Add85898","Lea34717","Zer19499","Con47695","Min61860","Res76966","Res35467","Con74950","Res80330","Res92251","Min10229","Res48493","Lay5926","Res46642","Add14416","Zer40188","Con65512","Min59939"],Min59939,"Min59939")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0817368, 0.0494586, 0.1081979, 0.0994973, 0.0654410, 0.0579000, 0.0396723, 0.0072654, 0.0003539, 0.0000602], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0708000, 0.4512678, 0.3111000, 0.3999894, 0.0626000, 0.2357078, 0.2557015, 0.2183391, 0.1346782, 0.1182510, 0.0039000, 0.0110100], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000]]]

Expected (Unparsed): [[[0.0,0.0,0.0,0.0,0.081736764064,0.049458621696,0.108197886282,0.09949725345600001,0.06544098047000001,0.0579,0.03967227552400001,0.007265445866,0.00035388419,6.0161310000000004e-5],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0.0708,0.4512677531160001,0.3111,0.39998935186900003,0.0626,0.23570776758100004,0.255701554565,0.21833911248000004,0.13467822372,0.11825104565500001,0.0039,0.011009950875],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0]]]

Actual:   [[[0, 0, 0, 0, 0.0818, 0.0495, 0.1082, 0.0995, 0.0655, 0.0579, 0.0397, 0.0073, 0.0004, 0.0001], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0.0708, 0.4513, 0.3111, 0.4, 0.0626, 0.2358, 0.2558, 0.2184, 0.1347, 0.1183, 0.0039, 0.0111], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]

Expected: [[[0, 0, 0, 0, 0.0818, 0.0495, 0.1082, 0.0995, 0.0655, 0.0579, 0.0397, 0.0073, 0.0004, 0.0001], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0.0708, 0.4513, 0.3111, 0.4, 0.0626, 0.2358, 0.2558, 0.2184, 0.1347, 0.1183, 0.0039, 0.0111], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]