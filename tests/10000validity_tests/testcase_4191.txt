import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer72190 = tf.keras.layers.Input(shape=([3, 1]))
in0Min97621 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in1Min97621 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in0Con78213 = tf.keras.layers.Input(shape=([59]))

Zer72190 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer72190', )(in0Zer72190)
Res57256 = keras.layers.Reshape((5, 1, 1), name = 'Res57256', )(Zer72190)
Res34640 = keras.layers.Reshape((5, 1, 1, 1), name = 'Res34640', )(Res57256)
Zer19521 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer19521', )(Res34640)
Res17408 = keras.layers.Reshape((7, 3, 3), name = 'Res17408', )(Zer19521)
Res32197 = keras.layers.Reshape((7, 9), name = 'Res32197', )(Res17408)
Fla44727 = keras.layers.Flatten(name = 'Fla44727', )(Res32197)
Min97621 = keras.layers.Minimum(name = 'Min97621', )([in0Min97621,in1Min97621])
Res70527 = keras.layers.Reshape((2, 1, 4), name = 'Res70527', )(Min97621)
Glo76227 = keras.layers.GlobalMaxPool2D(name = 'Glo76227', )(Res70527)
Con78213 = keras.layers.Concatenate(axis=1, name = 'Con78213', )([Glo76227,in0Con78213])
Max4003 = keras.layers.Maximum(name = 'Max4003', )([Fla44727,Con78213])
model = tf.keras.models.Model(inputs=[in0Zer72190,in0Min97621,in1Min97621,in0Con78213], outputs=Max4003)
in0Zer72190 = tf.constant([[[1.4957], [1.217], [1.1973]]])
in0Min97621 = tf.constant([[[[[0.0168, 0.0853], [0.7047, 0.2441]]], [[[0.8103, 0.918], [0.4086, 0.8101]]]]])
in1Min97621 = tf.constant([[[[[0.2751, 0.8577], [0.0064, 0.3541]]], [[[0.8335, 0.8831], [0.2337, 0.8035]]]]])
in0Con78213 = tf.constant([[0.4779, 0.4161, 0.827, 0.3693, 0.8989, 0.9825, 0.0165, 0.9484, 0.0619, 0.8077, 0.0716, 0.3516, 0.4012, 0.5116, 0.553, 0.9464, 0.778, 0.1665, 0.5461, 0.9129, 0.6398, 0.3326, 0.2324, 0.1278, 0.8741, 0.5342, 0.8555, 0.5987, 0.2568, 0.5464, 0.9233, 0.9665, 0.2232, 0.4171, 0.331, 0.791, 0.7996, 0.2352, 0.7176, 0.5612, 0.9275, 0.2763, 0.7753, 0.6309, 0.0815, 0.3033, 0.4177, 0.5703, 0.0394, 0.4846, 0.6857, 0.7461, 0.8968, 0.5988, 0.0188, 0.2947, 0.9349, 0.9431, 0.0516]])
print (np.array2string(model.predict([in0Zer72190,in0Min97621,in1Min97621,in0Con78213],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max4003.png')

LZer72190 = zero_padding1D_layer([[[1.4957], [1.217], [1.1973]]], 1, 1, Zer72190), 
LRes57256 = reshape_layer(Zer72190, [5, 1, 1], Res57256), 
LRes34640 = reshape_layer(Res57256, [5, 1, 1, 1], Res34640), 
LZer19521 = zero_padding3D_layer(Res34640, 1, 1, 1, 1, 1, 1, Zer19521), 
LRes17408 = reshape_layer(Zer19521, [7, 3, 3], Res17408), 
LRes32197 = reshape_layer(Res17408, [7, 9], Res32197), 
LFla44727 = flatten_layer(Res32197, Fla44727), 
LMin97621 = minimum_layer([[[[[[0.0168, 0.0853], [0.7047, 0.2441]]], [[[0.8103, 0.918], [0.4086, 0.8101]]]]], [[[[[0.2751, 0.8577], [0.0064, 0.3541]]], [[[0.8335, 0.8831], [0.2337, 0.8035]]]]]], Min97621), 
LRes70527 = reshape_layer(Min97621, [2, 1, 4], Res70527), 
LGlo76227 = global_max_pool2D_layer(Res70527, Glo76227), 
LCon78213 = concatenate_layer([Glo76227,[[0.4779, 0.4161, 0.827, 0.3693, 0.8989, 0.9825, 0.0165, 0.9484, 0.0619, 0.8077, 0.0716, 0.3516, 0.4012, 0.5116, 0.553, 0.9464, 0.778, 0.1665, 0.5461, 0.9129, 0.6398, 0.3326, 0.2324, 0.1278, 0.8741, 0.5342, 0.8555, 0.5987, 0.2568, 0.5464, 0.9233, 0.9665, 0.2232, 0.4171, 0.331, 0.791, 0.7996, 0.2352, 0.7176, 0.5612, 0.9275, 0.2763, 0.7753, 0.6309, 0.0815, 0.3033, 0.4177, 0.5703, 0.0394, 0.4846, 0.6857, 0.7461, 0.8968, 0.5988, 0.0188, 0.2947, 0.9349, 0.9431, 0.0516]]], 1, Con78213), 
LMax4003 = maximum_layer([Fla44727,Con78213], Max4003), 
exec_layers([LZer72190,LRes57256,LRes34640,LZer19521,LRes17408,LRes32197,LFla44727,LMin97621,LRes70527,LGlo76227,LCon78213,LMax4003],["Zer72190","Res57256","Res34640","Zer19521","Res17408","Res32197","Fla44727","Min97621","Res70527","Glo76227","Con78213","Max4003"],Max4003,"Max4003")

Actual (Unparsed): [[0.8103000, 0.8831000, 0.2337000, 0.8035000, 0.4779000, 0.4161000, 0.8270000, 0.3693000, 0.8989000, 0.9825000, 0.0165000, 0.9484000, 0.0619000, 0.8077000, 0.0716000, 0.3516000, 0.4012000, 0.5116000, 0.5530000, 0.9464000, 0.7780000, 0.1665000, 1.4957000, 0.9129000, 0.6398000, 0.3326000, 0.2324000, 0.1278000, 0.8741000, 0.5342000, 0.8555000, 1.2170000, 0.2568000, 0.5464000, 0.9233000, 0.9665000, 0.2232000, 0.4171000, 0.3310000, 0.7910000, 1.1973000, 0.2352000, 0.7176000, 0.5612000, 0.9275000, 0.2763000, 0.7753000, 0.6309000, 0.0815000, 0.3033000, 0.4177000, 0.5703000, 0.0394000, 0.4846000, 0.6857000, 0.7461000, 0.8968000, 0.5988000, 0.0188000, 0.2947000, 0.9349000, 0.9431000, 0.0516000]]

Expected (Unparsed): [[0.8103,0.8831,0.2337,0.8035,0.4779,0.4161,0.827,0.3693,0.8989,0.9825,0.0165,0.9484,0.0619,0.8077,0.0716,0.3516,0.4012,0.5116,0.553,0.9464,0.778,0.1665,1.4957,0.9129,0.6398,0.3326,0.2324,0.1278,0.8741,0.5342,0.8555,1.217,0.2568,0.5464,0.9233,0.9665,0.2232,0.4171,0.331,0.791,1.1973,0.2352,0.7176,0.5612,0.9275,0.2763,0.7753,0.6309,0.0815,0.3033,0.4177,0.5703,0.0394,0.4846,0.6857,0.7461,0.8968,0.5988,0.0188,0.2947,0.9349,0.9431,0.0516]]

Actual:   [[0.8103, 0.8831, 0.2337, 0.8035, 0.4779, 0.4161, 0.827, 0.3693, 0.8989, 0.9825, 0.0165, 0.9484, 0.0619, 0.8077, 0.0716, 0.3516, 0.4012, 0.5116, 0.553, 0.9464, 0.778, 0.1665, 1.4957, 0.9129, 0.6398, 0.3326, 0.2324, 0.1278, 0.8741, 0.5342, 0.8555, 1.217, 0.2568, 0.5464, 0.9233, 0.9665, 0.2232, 0.4171, 0.331, 0.791, 1.1973, 0.2352, 0.7176, 0.5612, 0.9275, 0.2763, 0.7753, 0.6309, 0.0815, 0.3033, 0.4177, 0.5703, 0.0394, 0.4846, 0.6857, 0.7461, 0.8968, 0.5988, 0.0188, 0.2947, 0.9349, 0.9431, 0.0516]]

Expected: [[0.8103, 0.8831, 0.2337, 0.8035, 0.4779, 0.4161, 0.827, 0.3693, 0.8989, 0.9825, 0.0165, 0.9484, 0.0619, 0.8077, 0.0716, 0.3516, 0.4012, 0.5116, 0.553, 0.9464, 0.778, 0.1665, 1.4957, 0.9129, 0.6398, 0.3326, 0.2324, 0.1278, 0.8741, 0.5342, 0.8555, 1.217, 0.2568, 0.5464, 0.9233, 0.9665, 0.2232, 0.4171, 0.331, 0.791, 1.1973, 0.2352, 0.7176, 0.5612, 0.9275, 0.2763, 0.7753, 0.6309, 0.0815, 0.3033, 0.4177, 0.5703, 0.0394, 0.4846, 0.6857, 0.7461, 0.8968, 0.5988, 0.0188, 0.2947, 0.9349, 0.9431, 0.0516]]