import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot63656 = tf.keras.layers.Input(shape=([3]))
in1Dot63656 = tf.keras.layers.Input(shape=([3]))
in0Con48273 = tf.keras.layers.Input(shape=([4, 2]))
in0Bat85040 = tf.keras.layers.Input(shape=([4, 3]))
in0Dot73908 = tf.keras.layers.Input(shape=([2]))
in1Dot73908 = tf.keras.layers.Input(shape=([2]))
in0Con82529 = tf.keras.layers.Input(shape=([4, 2]))

Dot63656 = keras.layers.Dot(axes=(1, 1), name = 'Dot63656', )([in0Dot63656,in1Dot63656])
Res77191 = keras.layers.Reshape((1, 1), name = 'Res77191', )(Dot63656)
Zer52804 = keras.layers.ZeroPadding1D(padding=((3, 0)), name = 'Zer52804', )(Res77191)
Con48273 = keras.layers.Concatenate(axis=2, name = 'Con48273', )([Zer52804,in0Con48273])
Bat85040 = keras.layers.BatchNormalization(axis=1, epsilon=0.6987481501076557,  name = 'Bat85040', )(in0Bat85040)
Dot73908 = keras.layers.Dot(axes=(1, 1), name = 'Dot73908', )([in0Dot73908,in1Dot73908])
Res29536 = keras.layers.Reshape((1, 1), name = 'Res29536', )(Dot73908)
Zer67400 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer67400', )(Res29536)
Zer44816 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer44816', )(Zer67400)
Con82529 = keras.layers.Concatenate(axis=2, name = 'Con82529', )([Zer44816,in0Con82529])
Min58448 = keras.layers.Minimum(name = 'Min58448', )([Bat85040,Con82529])
Add59838 = keras.layers.Add(name = 'Add59838', )([Con48273,Min58448])
model = tf.keras.models.Model(inputs=[in0Dot63656,in1Dot63656,in0Con48273,in0Bat85040,in0Dot73908,in1Dot73908,in0Con82529], outputs=Add59838)
w = model.get_layer('Bat85040').get_weights() 
w[0] = np.array([0.3514, 0.1542, 0.3632, 0.9493])
w[1] = np.array([0.6232, 0.5562, 0.3708, 0.5119])
w[2] = np.array([0.6872, 0.0522, 0.0138, 0.0503])
w[3] = np.array([0.142, 0.6685, 0.3935, 0.7748])
model.get_layer('Bat85040').set_weights(w) 
in0Dot63656 = tf.constant([[0.1565, 0.7859, 0.9388]])
in1Dot63656 = tf.constant([[0.5744, 0.1046, 0.3947]])
in0Con48273 = tf.constant([[[0.7319, 0.4572], [0.0432, 0.0256], [0.5729, 0.7493], [0.0617, 0.4914]]])
in0Bat85040 = tf.constant([[[1.8396, 1.2799, 1.6951], [1.9703, 1.5062, 1.7611], [1.9133, 1.3854, 1.6683], [1.765, 1.4516, 1.0015]]])
in0Dot73908 = tf.constant([[0.5058, 0.5451]])
in1Dot73908 = tf.constant([[0.0751, 0.5053]])
in0Con82529 = tf.constant([[[0.2859, 0.8602], [0.0988, 0.5165], [0.1813, 0.4732], [0.494, 0.2953]]])
print (np.array2string(model.predict([in0Dot63656,in1Dot63656,in0Con48273,in0Bat85040,in0Dot73908,in1Dot73908,in0Con82529],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add59838.png')

LDot63656 = dot_layer([[0.1565, 0.7859, 0.9388]], [[0.5744, 0.1046, 0.3947]], 1, 1, Dot63656), 
LRes77191 = reshape_layer(Dot63656, [1, 1], Res77191), 
LZer52804 = zero_padding1D_layer(Res77191, 3, 0, Zer52804), 
LCon48273 = concatenate_layer([Zer52804,[[[0.7319, 0.4572], [0.0432, 0.0256], [0.5729, 0.7493], [0.0617, 0.4914]]]], 2, Con48273), 
LBat85040 = batch_normalization_layer([[[1.8396, 1.2799, 1.6951], [1.9703, 1.5062, 1.7611], [1.9133, 1.3854, 1.6683], [1.765, 1.4516, 1.0015]]], 1, 0.6987481501076557, [0.3514, 0.1542, 0.3632, 0.9493], [0.6232, 0.5562, 0.3708, 0.5119], [0.6872, 0.0522, 0.0138, 0.0503], [0.142, 0.6685, 0.3935, 0.7748], Bat85040), 
LDot73908 = dot_layer([[0.5058, 0.5451]], [[0.0751, 0.5053]], 1, 1, Dot73908), 
LRes29536 = reshape_layer(Dot73908, [1, 1], Res29536), 
LZer67400 = zero_padding1D_layer(Res29536, 1, 1, Zer67400), 
LZer44816 = zero_padding1D_layer(Zer67400, 1, 0, Zer44816), 
LCon82529 = concatenate_layer([Zer44816,[[[0.2859, 0.8602], [0.0988, 0.5165], [0.1813, 0.4732], [0.494, 0.2953]]]], 2, Con82529), 
LMin58448 = minimum_layer([Bat85040,Con82529], Min58448), 
LAdd59838 = add_layer([Con48273,Min58448], Add59838), 
exec_layers([LDot63656,LRes77191,LZer52804,LCon48273,LBat85040,LDot73908,LRes29536,LZer67400,LZer44816,LCon82529,LMin58448,LAdd59838],["Dot63656","Res77191","Zer52804","Con48273","Bat85040","Dot73908","Res29536","Zer67400","Zer44816","Con82529","Min58448","Add59838"],Add59838,"Add59838")

Actual (Unparsed): [[[0.0000000, 1.0178000, 1.3174000], [0.0000000, 0.1420000, 0.5421000], [0.3134246, 0.7542000, 1.2225000], [0.5426431, 0.5557000, 0.7867000]]]

Expected (Unparsed): [[[0,1.0178,1.3174],[0,0.14200000000000002,0.5420999999999999],[0.31342461,0.7542,1.2225],[0.5426431,0.5557,0.7867]]]

Actual:   [[[0, 1.0178, 1.3174], [0, 0.142, 0.5421], [0.3135, 0.7542, 1.2225], [0.5427, 0.5557, 0.7867]]]

Expected: [[[0, 1.0178, 1.3174], [0, 0.1421, 0.5421], [0.3135, 0.7542, 1.2225], [0.5427, 0.5557, 0.7867]]]