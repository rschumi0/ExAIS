import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub90544 = tf.keras.layers.Input(shape=([3, 3, 2]))
in1Sub90544 = tf.keras.layers.Input(shape=([3, 3, 2]))
in0Dot23498 = tf.keras.layers.Input(shape=([2, 3]))
in1Dot23498 = tf.keras.layers.Input(shape=([2, 3]))
in0Con21856 = tf.keras.layers.Input(shape=([3, 3]))
in0Bat71195 = tf.keras.layers.Input(shape=([2, 2]))
in0Dot30025 = tf.keras.layers.Input(shape=([2]))
in1Dot30025 = tf.keras.layers.Input(shape=([2]))
in0Con62892 = tf.keras.layers.Input(shape=([3]))
in0Con8418 = tf.keras.layers.Input(shape=([14]))

Sub90544 = keras.layers.Subtract(name = 'Sub90544', )([in0Sub90544,in1Sub90544])
Res55960 = keras.layers.Reshape((3, 6), name = 'Res55960', )(Sub90544)
Dot23498 = keras.layers.Dot(axes=(1, 1), name = 'Dot23498', )([in0Dot23498,in1Dot23498])
Con21856 = keras.layers.Concatenate(axis=2, name = 'Con21856', )([Dot23498,in0Con21856])
Ave43141 = keras.layers.Average(name = 'Ave43141', )([Res55960,Con21856])
Fla2313 = keras.layers.Flatten(name = 'Fla2313', )(Ave43141)
Bat71195 = keras.layers.BatchNormalization(axis=2, epsilon=0.5700673683117542,  name = 'Bat71195', )(in0Bat71195)
Per17458 = keras.layers.Permute((2,1), name = 'Per17458',)(Bat71195)
Fla28509 = keras.layers.Flatten(name = 'Fla28509', )(Per17458)
Dot30025 = keras.layers.Dot(axes=(1, 1), name = 'Dot30025', )([in0Dot30025,in1Dot30025])
Con62892 = keras.layers.Concatenate(axis=1, name = 'Con62892', )([Dot30025,in0Con62892])
Ave72174 = keras.layers.Average(name = 'Ave72174', )([Fla28509,Con62892])
Con8418 = keras.layers.Concatenate(axis=1, name = 'Con8418', )([Ave72174,in0Con8418])
Ave36698 = keras.layers.Average(name = 'Ave36698', )([Fla2313,Con8418])
model = tf.keras.models.Model(inputs=[in0Sub90544,in1Sub90544,in0Dot23498,in1Dot23498,in0Con21856,in0Bat71195,in0Dot30025,in1Dot30025,in0Con62892,in0Con8418], outputs=Ave36698)
w = model.get_layer('Bat71195').get_weights() 
w[0] = np.array([0.2445, 0.6816])
w[1] = np.array([0.8165, 0.2488])
w[2] = np.array([0.6132, 0.2462])
w[3] = np.array([0.3964, 0.6062])
model.get_layer('Bat71195').set_weights(w) 
in0Sub90544 = tf.constant([[[[0.3552, 0.1301], [0.1264, 0.0731], [0.1386, 0.3859]], [[0.4058, 0.9366], [0.1516, 0.376], [0.8345, 0.0599]], [[0.2792, 0.657], [0.3784, 0.4975], [0.383, 0.5654]]]])
in1Sub90544 = tf.constant([[[[0.7343, 0.1515], [0.9713, 0.2335], [0.6173, 0.8174]], [[0.4072, 0.7255], [0.4302, 0.6103], [0.0693, 0.5494]], [[0.2149, 0.1899], [0.4795, 0.5692], [0.7768, 0.9822]]]])
in0Dot23498 = tf.constant([[[0.0507, 0.3876, 0.3978], [0.1624, 0.7662, 0.5999]]])
in1Dot23498 = tf.constant([[[0.6103, 0.5061, 0.8043], [0.9287, 0.0907, 0.342]]])
in0Con21856 = tf.constant([[[0.8546, 0.5786, 0.9691], [0.3979, 0.2961, 0.1607], [0.6755, 0.3584, 0.2414]]])
in0Bat71195 = tf.constant([[[1.8456, 1.143], [1.8488, 1.7477]]])
in0Dot30025 = tf.constant([[0.5619, 0.8358]])
in1Dot30025 = tf.constant([[0.5397, 0.818]])
in0Con62892 = tf.constant([[0.0139, 0.4985, 0.966]])
in0Con8418 = tf.constant([[0.5435, 0.9146, 0.9988, 0.418, 0.7614, 0.5107, 0.4293, 0.4943, 0.8597, 0.4705, 0.1515, 0.3308, 0.7294, 0.6173]])
print (np.array2string(model.predict([in0Sub90544,in1Sub90544,in0Dot23498,in1Dot23498,in0Con21856,in0Bat71195,in0Dot30025,in1Dot30025,in0Con62892,in0Con8418],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave36698.png')

LSub90544 = subtract_layer([[[[0.3552, 0.1301], [0.1264, 0.0731], [0.1386, 0.3859]], [[0.4058, 0.9366], [0.1516, 0.376], [0.8345, 0.0599]], [[0.2792, 0.657], [0.3784, 0.4975], [0.383, 0.5654]]]], [[[[0.7343, 0.1515], [0.9713, 0.2335], [0.6173, 0.8174]], [[0.4072, 0.7255], [0.4302, 0.6103], [0.0693, 0.5494]], [[0.2149, 0.1899], [0.4795, 0.5692], [0.7768, 0.9822]]]], Sub90544), 
LRes55960 = reshape_layer(Sub90544, [3, 6], Res55960), 
LDot23498 = dot_layer([[[0.0507, 0.3876, 0.3978], [0.1624, 0.7662, 0.5999]]], [[[0.6103, 0.5061, 0.8043], [0.9287, 0.0907, 0.342]]], 1, 1, Dot23498), 
LCon21856 = concatenate_layer([Dot23498,[[[0.8546, 0.5786, 0.9691], [0.3979, 0.2961, 0.1607], [0.6755, 0.3584, 0.2414]]]], 2, Con21856), 
LAve43141 = average_layer([Res55960,Con21856], Ave43141), 
LFla2313 = flatten_layer(Ave43141, Fla2313), 
LBat71195 = batch_normalization_layer([[[1.8456, 1.143], [1.8488, 1.7477]]], 2, 0.5700673683117542, [0.2445, 0.6816], [0.8165, 0.2488], [0.6132, 0.2462], [0.3964, 0.6062], Bat71195), 
LPer17458 = permute_layer(Bat71195, 2,1, Per17458), 
LFla28509 = flatten_layer(Per17458, Fla28509), 
LDot30025 = dot_layer([[0.5619, 0.8358]], [[0.5397, 0.818]], 1, 1, Dot30025), 
LCon62892 = concatenate_layer([Dot30025,[[0.0139, 0.4985, 0.966]]], 1, Con62892), 
LAve72174 = average_layer([Fla28509,Con62892], Ave72174), 
LCon8418 = concatenate_layer([Ave72174,[[0.5435, 0.9146, 0.9988, 0.418, 0.7614, 0.5107, 0.4293, 0.4943, 0.8597, 0.4705, 0.1515, 0.3308, 0.7294, 0.6173]]], 1, Con8418), 
LAve36698 = average_layer([Fla2313,Con8418], Ave36698), 
exec_layers([LSub90544,LRes55960,LDot23498,LCon21856,LAve43141,LFla2313,LBat71195,LPer17458,LFla28509,LDot30025,LCon62892,LAve72174,LCon8418,LAve36698],["Sub90544","Res55960","Dot23498","Con21856","Ave43141","Fla2313","Bat71195","Per17458","Fla28509","Dot30025","Con62892","Ave72174","Con8418","Ave36698"],Ave36698,"Ave36698")

Actual (Unparsed): [[0.4781524, 0.2891723, 0.1405801, 0.7131576, 0.2967250, 0.5917000, 0.7360805, 0.3281897, 0.4544968, 0.2962500, 0.4799750, 0.1649500, 0.6459011, 0.4159594, 0.1817541, 0.3163500, 0.3558500, 0.2648000]]

Expected (Unparsed): [[0.4781523727248786,0.28917234456820834,0.14058008285236775,0.7131575837411688,0.296725,0.5917,0.736080555,0.32818967499999996,0.45449677,0.29625,0.479975,0.16495,0.6459011175,0.4159593775,0.181754085,0.31634999999999996,0.35585,0.2648]]

Actual:   [[0.4782, 0.2892, 0.1406, 0.7132, 0.2968, 0.5917, 0.7361, 0.3282, 0.4545, 0.2963, 0.48, 0.165, 0.646, 0.416, 0.1818, 0.3164, 0.3559, 0.2648]]

Expected: [[0.4782, 0.2892, 0.1406, 0.7132, 0.2968, 0.5917, 0.7361, 0.3282, 0.4545, 0.2963, 0.48, 0.165, 0.646, 0.416, 0.1818, 0.3164, 0.3559, 0.2648]]