import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub41702 = tf.keras.layers.Input(shape=([2, 3, 3, 2]))
in1Sub41702 = tf.keras.layers.Input(shape=([2, 3, 3, 2]))

Sub41702 = keras.layers.Subtract(name = 'Sub41702', )([in0Sub41702,in1Sub41702])
Res60624 = keras.layers.Reshape((2, 3, 6), name = 'Res60624', )(Sub41702)
Res66981 = keras.layers.Reshape((2, 18), name = 'Res66981', )(Res60624)
LST63635 = keras.layers.LSTM(2,recurrent_activation='sigmoid', name = 'LST63635', )(Res66981)
model = tf.keras.models.Model(inputs=[in0Sub41702,in1Sub41702], outputs=LST63635)
w = model.get_layer('LST63635').get_weights() 
w[0] = np.array([[1, 5, 4, 8, 2, 3, 1, 10], [7, 5, 4, 7, 1, 7, 4, 6], [6, 2, 1, 8, 8, 4, 9, 6], [8, 8, 9, 1, 8, 1, 10, 7], [1, 6, 7, 2, 5, 2, 10, 3], [6, 3, 1, 8, 3, 10, 9, 10], [10, 7, 7, 7, 1, 5, 3, 3], [8, 8, 3, 8, 6, 4, 6, 3], [10, 8, 9, 8, 7, 2, 8, 8], [6, 6, 10, 9, 1, 8, 7, 5], [5, 5, 3, 9, 5, 9, 5, 5], [7, 4, 3, 5, 9, 8, 5, 4], [4, 3, 2, 3, 6, 3, 4, 1], [6, 2, 1, 5, 8, 3, 6, 3], [9, 1, 1, 7, 7, 8, 4, 3], [3, 3, 3, 3, 10, 3, 4, 6], [7, 4, 2, 10, 1, 1, 9, 3], [1, 8, 1, 9, 6, 8, 3, 7]])
w[1] = np.array([[2, 1, 5, 5, 10, 10, 6, 5], [1, 3, 6, 8, 3, 10, 9, 6]])
w[2] = np.array([1, 4, 8, 4, 9, 4, 9, 10])
model.get_layer('LST63635').set_weights(w) 
in0Sub41702 = tf.constant([[[[[0.4874, 0.0581], [0.2163, 0.236], [0.9764, 0.4395]], [[0.5616, 0.4453], [0.6565, 0.6998], [0.673, 0.1376]], [[0.6339, 0.197], [0.4062, 0.5781], [0.267, 0.6149]]], [[[0.9031, 0.8712], [0.7045, 0.835], [0.6972, 0.0029]], [[0.8984, 0.5991], [0.8887, 0.0832], [0.2375, 0.127]], [[0.2362, 0.0803], [0.489, 0.0504], [0.9486, 0.5546]]]]])
in1Sub41702 = tf.constant([[[[[0.3035, 0.5168], [0.4154, 0.9058], [0.1449, 0.0777]], [[0.1147, 0.4245], [0.138, 0.0276], [0.4558, 0.0061]], [[0.9931, 0.187], [0.3736, 0.728], [0.8618, 0.7343]]], [[[0.0759, 0.6175], [0.7079, 0.5812], [0.4658, 0.8452]], [[0.533, 0.9619], [0.4066, 0.2672], [0.5899, 0.3582]], [[0.1833, 0.7085], [0.535, 0.6178], [0.2192, 0.6316]]]]])
print (np.array2string(model.predict([in0Sub41702,in1Sub41702],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='LST63635.png')

LSub41702 = subtract_layer([[[[[0.4874, 0.0581], [0.2163, 0.236], [0.9764, 0.4395]], [[0.5616, 0.4453], [0.6565, 0.6998], [0.673, 0.1376]], [[0.6339, 0.197], [0.4062, 0.5781], [0.267, 0.6149]]], [[[0.9031, 0.8712], [0.7045, 0.835], [0.6972, 0.0029]], [[0.8984, 0.5991], [0.8887, 0.0832], [0.2375, 0.127]], [[0.2362, 0.0803], [0.489, 0.0504], [0.9486, 0.5546]]]]], [[[[[0.3035, 0.5168], [0.4154, 0.9058], [0.1449, 0.0777]], [[0.1147, 0.4245], [0.138, 0.0276], [0.4558, 0.0061]], [[0.9931, 0.187], [0.3736, 0.728], [0.8618, 0.7343]]], [[[0.0759, 0.6175], [0.7079, 0.5812], [0.4658, 0.8452]], [[0.533, 0.9619], [0.4066, 0.2672], [0.5899, 0.3582]], [[0.1833, 0.7085], [0.535, 0.6178], [0.2192, 0.6316]]]]], Sub41702), 
LRes60624 = reshape_layer(Sub41702, [2, 3, 6], Res60624), 
LRes66981 = reshape_layer(Res60624, [2, 18], Res66981), 
LLST63635 = lstm_layer(Res66981,[[1, 5, 4, 8, 2, 3, 1, 10], [7, 5, 4, 7, 1, 7, 4, 6], [6, 2, 1, 8, 8, 4, 9, 6], [8, 8, 9, 1, 8, 1, 10, 7], [1, 6, 7, 2, 5, 2, 10, 3], [6, 3, 1, 8, 3, 10, 9, 10], [10, 7, 7, 7, 1, 5, 3, 3], [8, 8, 3, 8, 6, 4, 6, 3], [10, 8, 9, 8, 7, 2, 8, 8], [6, 6, 10, 9, 1, 8, 7, 5], [5, 5, 3, 9, 5, 9, 5, 5], [7, 4, 3, 5, 9, 8, 5, 4], [4, 3, 2, 3, 6, 3, 4, 1], [6, 2, 1, 5, 8, 3, 6, 3], [9, 1, 1, 7, 7, 8, 4, 3], [3, 3, 3, 3, 10, 3, 4, 6], [7, 4, 2, 10, 1, 1, 9, 3], [1, 8, 1, 9, 6, 8, 3, 7]],[[2, 1, 5, 5, 10, 10, 6, 5], [1, 3, 6, 8, 3, 10, 9, 6]],[1, 4, 8, 4, 9, 4, 9, 10], LST63635), 
exec_layers([LSub41702,LRes60624,LRes66981,LLST63635],["Sub41702","Res60624","Res66981","LST63635"],LST63635,"LST63635")

Actual (Unparsed): [[0.9610581, 0.9640262]]

Expected (Unparsed): [[0.9610581345102124,0.9640262040890102]]

Actual:   [[0.9611, 0.9641]]

Expected: [[0.9611, 0.9641]]