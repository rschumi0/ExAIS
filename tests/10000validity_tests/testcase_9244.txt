import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot71912 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot71912 = tf.keras.layers.Input(shape=([3, 3]))
in0Con38996 = tf.keras.layers.Input(shape=([3, 4, 2]))
in0Ave59150 = tf.keras.layers.Input(shape=([1, 2, 1]))
in1Ave59150 = tf.keras.layers.Input(shape=([1, 2, 1]))

Dot71912 = keras.layers.Dot(axes=(1, 2), name = 'Dot71912', )([in0Dot71912,in1Dot71912])
Res13675 = keras.layers.Reshape((3, 3, 1), name = 'Res13675', )(Dot71912)
Res39026 = keras.layers.Reshape((3, 3, 1, 1), name = 'Res39026', )(Res13675)
Glo19142 = keras.layers.GlobalMaxPool3D(name = 'Glo19142', )(Res39026)
Res16094 = keras.layers.Reshape((1, 1), name = 'Res16094', )(Glo19142)
Res35802 = keras.layers.Reshape((1, 1, 1), name = 'Res35802', )(Res16094)
Zer3369 = keras.layers.ZeroPadding2D(padding=((2, 0), (3, 0)), name = 'Zer3369', )(Res35802)
Con38996 = keras.layers.Concatenate(axis=3, name = 'Con38996', )([Zer3369,in0Con38996])
Ave59150 = keras.layers.Average(name = 'Ave59150', )([in0Ave59150,in1Ave59150])
Zer33386 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer33386', )(Ave59150)
Den56336 = keras.layers.Dense(3,name = 'Den56336', )(Zer33386)
Sub39796 = keras.layers.Subtract(name = 'Sub39796', )([Con38996,Den56336])
model = tf.keras.models.Model(inputs=[in0Dot71912,in1Dot71912,in0Con38996,in0Ave59150,in1Ave59150], outputs=Sub39796)
w = model.get_layer('Den56336').get_weights() 
w[0] = np.array([[0.0515, 0.1347, 0.6023]])
w[1] = np.array([0.4211, 0.6083, 0.9484])
model.get_layer('Den56336').set_weights(w) 
in0Dot71912 = tf.constant([[[0.3203, 0.2559, 0.7463], [0.7807, 0.0522, 0.5147], [0.1617, 0.5373, 0.4244]]])
in1Dot71912 = tf.constant([[[0.3438, 0.8813, 0.2493], [0.223, 0.1827, 0.1909], [0.298, 0.4719, 0.5877]]])
in0Con38996 = tf.constant([[[[0.3583, 0.7052], [0.2504, 0.7765], [0.4045, 0.5001], [0.4536, 0.5152]], [[0.667, 0.7412], [0.0387, 0.0613], [0.7795, 0.8533], [0.6131, 0.5184]], [[0.5428, 0.0983], [0.6085, 0.1342], [0.8603, 0.0268], [0.6875, 0.3994]]]])
in0Ave59150 = tf.constant([[[[0.508], [0.3227]]]])
in1Ave59150 = tf.constant([[[[0.9136], [0.4489]]]])
print (np.array2string(model.predict([in0Dot71912,in1Dot71912,in0Con38996,in0Ave59150,in1Ave59150],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub39796.png')

LDot71912 = dot_layer([[[0.3203, 0.2559, 0.7463], [0.7807, 0.0522, 0.5147], [0.1617, 0.5373, 0.4244]]], [[[0.3438, 0.8813, 0.2493], [0.223, 0.1827, 0.1909], [0.298, 0.4719, 0.5877]]], 1, 2, Dot71912), 
LRes13675 = reshape_layer(Dot71912, [3, 3, 1], Res13675), 
LRes39026 = reshape_layer(Res13675, [3, 3, 1, 1], Res39026), 
LGlo19142 = global_max_pool3D_layer(Res39026, Glo19142), 
LRes16094 = reshape_layer(Glo19142, [1, 1], Res16094), 
LRes35802 = reshape_layer(Res16094, [1, 1, 1], Res35802), 
LZer3369 = zero_padding2D_layer(Res35802, 2, 0, 3, 0, Zer3369), 
LCon38996 = concatenate_layer([Zer3369,[[[[0.3583, 0.7052], [0.2504, 0.7765], [0.4045, 0.5001], [0.4536, 0.5152]], [[0.667, 0.7412], [0.0387, 0.0613], [0.7795, 0.8533], [0.6131, 0.5184]], [[0.5428, 0.0983], [0.6085, 0.1342], [0.8603, 0.0268], [0.6875, 0.3994]]]]], 3, Con38996), 
LAve59150 = average_layer([[[[[0.508], [0.3227]]]], [[[[0.9136], [0.4489]]]]], Ave59150), 
LZer33386 = zero_padding2D_layer(Ave59150, 1, 1, 1, 1, Zer33386), 
LDen56336 = dense_layer(Zer33386, [[0.0515, 0.1347, 0.6023]],[0.4211, 0.6083, 0.9484], Den56336), 
LSub39796 = subtract_layer(Con38996,Den56336, Sub39796), 
exec_layers([LDot71912,LRes13675,LRes39026,LGlo19142,LRes16094,LRes35802,LZer3369,LCon38996,LAve59150,LZer33386,LDen56336,LSub39796],["Dot71912","Res13675","Res39026","Glo19142","Res16094","Res35802","Zer3369","Con38996","Ave59150","Zer33386","Den56336","Sub39796"],Sub39796,"Sub39796")

Actual (Unparsed): [[[[-0.4211000, -0.2500000, -0.2432000], [-0.4211000, -0.3579000, -0.1719000], [-0.4211000, -0.2038000, -0.4483000], [-0.4211000, -0.1547000, -0.4332000]], [[-0.4211000, 0.0587000, -0.2072000], [-0.4577062, -0.6653448, -1.3152149], [-0.4409687, 0.1192327, -0.3274674], [-0.4211000, 0.0048000, -0.4300000]], [[-0.4211000, -0.0655000, -0.8501000], [-0.4211000, 0.0002000, -0.8142000], [-0.4211000, 0.2520000, -0.9216000], [0.4173619, 0.0792000, -0.5490000]]]]

Expected (Unparsed): [[[[-0.4211,-0.24999999999999994,-0.24319999999999997],[-0.4211,-0.35789999999999994,-0.17190000000000005],[-0.4211,-0.20379999999999993,-0.44830000000000003],[-0.4211,-0.15469999999999995,-0.43320000000000003]],[[-0.4211,0.058700000000000085,-0.20720000000000005],[-0.45770619999999995,-0.66534476,-1.31521484],[-0.4409687,0.11923274000000006,-0.3274673400000001],[-0.4211,0.0048000000000000265,-0.43000000000000005]],[[-0.4211,-0.0655,-0.8501000000000001],[-0.4211,0.000200000000000089,-0.8142],[-0.4211,0.252,-0.9216],[0.41736186000000003,0.07920000000000005,-0.549]]]]

Actual:   [[[[-0.4211, -0.25, -0.2432], [-0.4211, -0.3579, -0.1719], [-0.4211, -0.2038, -0.4483], [-0.4211, -0.1547, -0.4332]], [[-0.4211, 0.0587, -0.2072], [-0.4577, -0.6653, -1.3152], [-0.4409, 0.1193, -0.3274], [-0.4211, 0.0048, -0.43]], [[-0.4211, -0.0655, -0.8501], [-0.4211, 0.0002, -0.8142], [-0.4211, 0.252, -0.9216], [0.4174, 0.0792, -0.549]]]]

Expected: [[[[-0.4211, -0.2499, -0.2431], [-0.4211, -0.3578, -0.1719], [-0.4211, -0.2037, -0.4483], [-0.4211, -0.1546, -0.4332]], [[-0.4211, 0.0588, -0.2072], [-0.4577, -0.6653, -1.3152], [-0.4409, 0.1193, -0.3274], [-0.4211, 0.0049, -0.43]], [[-0.4211, -0.0655, -0.8501], [-0.4211, 0.0003, -0.8142], [-0.4211, 0.252, -0.9216], [0.4174, 0.0793, -0.549]]]]