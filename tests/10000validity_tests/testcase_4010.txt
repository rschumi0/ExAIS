import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer48365 = tf.keras.layers.Input(shape=([1, 4, 4, 1]))
in0Sof36219 = tf.keras.layers.Input(shape=([2, 2]))
in0Con36610 = tf.keras.layers.Input(shape=([3, 34]))

Zer48365 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer48365', )(in0Zer48365)
Res53912 = keras.layers.Reshape((3, 6, 6), name = 'Res53912', )(Zer48365)
Res85286 = keras.layers.Reshape((3, 36), name = 'Res85286', )(Res53912)
Sof36219 = keras.layers.Softmax(axis=1, name = 'Sof36219', input_shape=(2, 2))(in0Sof36219)
Up_14034 = keras.layers.UpSampling1D(size=(1), name = 'Up_14034', )(Sof36219)
Zer99066 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer99066', )(Up_14034)
Con36610 = keras.layers.Concatenate(axis=2, name = 'Con36610', )([Zer99066,in0Con36610])
Max69683 = keras.layers.Maximum(name = 'Max69683', )([Res85286,Con36610])
Glo58671 = keras.layers.GlobalMaxPool1D(name = 'Glo58671', )(Max69683)
model = tf.keras.models.Model(inputs=[in0Zer48365,in0Sof36219,in0Con36610], outputs=Glo58671)
in0Zer48365 = tf.constant([[[[[1.2845], [1.4305], [1.8718], [1.1094]], [[1.2201], [1.9945], [1.819], [1.811]], [[1.0178], [1.9413], [1.2063], [1.2828]], [[1.0357], [1.8268], [1.9049], [1.7238]]]]])
in0Sof36219 = tf.constant([[[0.2028, 0.472], [0.642, 0.465]]])
in0Con36610 = tf.constant([[[0.5186, 0.4829, 0.7096, 0.2121, 0.1134, 0.644, 0.7889, 0.8784, 0.763, 0.4128, 0.091, 0.8875, 0.4984, 0.9928, 0.9215, 0.0825, 0.6368, 0.5407, 0.5755, 0.0027, 0.607, 0.4827, 0.564, 0.0491, 0.1049, 0.3136, 0.9549, 0.9151, 0.9668, 0.8152, 0.8549, 0.3788, 0.492, 0.3347], [0.6676, 0.1405, 0.0757, 0.483, 0.6542, 0.5065, 0.916, 0.3776, 0.4976, 0.3718, 0.2502, 0.3423, 0.0238, 0.1323, 0.0444, 0.7978, 0.97, 0.8712, 0.3122, 0.9284, 0.7047, 0.4057, 0.268, 0.5974, 0.1053, 0.5558, 0.3381, 0.8939, 0.3744, 0.3031, 0.6427, 0.6448, 0.4397, 0.3409], [0.9419, 0.1991, 0.7214, 0.8914, 0.1944, 0.8044, 0.4749, 0.5582, 0.8147, 0.9318, 0.6215, 0.4178, 0.4372, 0.9796, 0.964, 0.515, 0.4944, 0.8871, 0.9502, 0.4173, 0.1997, 0.3239, 0.6974, 0.5117, 0.5874, 0.2856, 0.8176, 0.2808, 0.11, 0.1229, 0.6955, 0.8822, 0.915, 0.2581]]])
print (np.array2string(model.predict([in0Zer48365,in0Sof36219,in0Con36610],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Glo58671.png')

LZer48365 = zero_padding3D_layer([[[[[1.2845], [1.4305], [1.8718], [1.1094]], [[1.2201], [1.9945], [1.819], [1.811]], [[1.0178], [1.9413], [1.2063], [1.2828]], [[1.0357], [1.8268], [1.9049], [1.7238]]]]], 1, 1, 1, 1, 1, 1, Zer48365), 
LRes53912 = reshape_layer(Zer48365, [3, 6, 6], Res53912), 
LRes85286 = reshape_layer(Res53912, [3, 36], Res85286), 
LSof36219 = softmax_layer([[[0.2028, 0.472], [0.642, 0.465]]], 1, Sof36219), 
LUp_14034 = up_sampling1D_layer(Sof36219, 1, Up_14034), 
LZer99066 = zero_padding1D_layer(Up_14034, 1, 0, Zer99066), 
LCon36610 = concatenate_layer([Zer99066,[[[0.5186, 0.4829, 0.7096, 0.2121, 0.1134, 0.644, 0.7889, 0.8784, 0.763, 0.4128, 0.091, 0.8875, 0.4984, 0.9928, 0.9215, 0.0825, 0.6368, 0.5407, 0.5755, 0.0027, 0.607, 0.4827, 0.564, 0.0491, 0.1049, 0.3136, 0.9549, 0.9151, 0.9668, 0.8152, 0.8549, 0.3788, 0.492, 0.3347], [0.6676, 0.1405, 0.0757, 0.483, 0.6542, 0.5065, 0.916, 0.3776, 0.4976, 0.3718, 0.2502, 0.3423, 0.0238, 0.1323, 0.0444, 0.7978, 0.97, 0.8712, 0.3122, 0.9284, 0.7047, 0.4057, 0.268, 0.5974, 0.1053, 0.5558, 0.3381, 0.8939, 0.3744, 0.3031, 0.6427, 0.6448, 0.4397, 0.3409], [0.9419, 0.1991, 0.7214, 0.8914, 0.1944, 0.8044, 0.4749, 0.5582, 0.8147, 0.9318, 0.6215, 0.4178, 0.4372, 0.9796, 0.964, 0.515, 0.4944, 0.8871, 0.9502, 0.4173, 0.1997, 0.3239, 0.6974, 0.5117, 0.5874, 0.2856, 0.8176, 0.2808, 0.11, 0.1229, 0.6955, 0.8822, 0.915, 0.2581]]]], 2, Con36610), 
LMax69683 = maximum_layer([Res85286,Con36610], Max69683), 
LGlo58671 = global_max_pool1D_layer(Max69683, Glo58671), 
exec_layers([LZer48365,LRes53912,LRes85286,LSof36219,LUp_14034,LZer99066,LCon36610,LMax69683,LGlo58671],["Zer48365","Res53912","Res85286","Sof36219","Up_14034","Zer99066","Con36610","Max69683","Glo58671"],Glo58671,"Glo58671")

Actual (Unparsed): [[0.6080684, 0.5017500, 0.9419000, 0.4829000, 0.7214000, 0.8914000, 0.6542000, 1.2845000, 1.4305000, 1.8717999, 1.1094000, 0.9318000, 0.6215000, 1.2201000, 1.9945000, 1.8190000, 1.8110000, 0.7978000, 0.9700000, 1.0178000, 1.9413000, 1.2063000, 1.2828000, 0.4827000, 0.6974000, 1.0357000, 1.8268000, 1.9049000, 1.7237999, 0.9151000, 0.9668000, 0.8152000, 0.8549000, 0.8822000, 0.9150000, 0.3409000]]

Expected (Unparsed): [[0.608068390260029,0.5017499928542017,0.9419,0.4829,0.7214,0.8914,0.6542,1.2845,1.4305,1.8718,1.1094,0.9318,0.6215,1.2201,1.9945,1.819,1.811,0.7978,0.97,1.0178,1.9413,1.2063,1.2828,0.4827,0.6974,1.0357,1.8268,1.9049,1.7238,0.9151,0.9668,0.8152,0.8549,0.8822,0.915,0.3409]]

Actual:   [[0.6081, 0.5018, 0.9419, 0.4829, 0.7214, 0.8914, 0.6542, 1.2845, 1.4305, 1.8718, 1.1094, 0.9318, 0.6215, 1.2201, 1.9945, 1.819, 1.811, 0.7978, 0.97, 1.0178, 1.9413, 1.2063, 1.2828, 0.4827, 0.6974, 1.0357, 1.8268, 1.9049, 1.7238, 0.9151, 0.9668, 0.8152, 0.8549, 0.8822, 0.915, 0.3409]]

Expected: [[0.6081, 0.5018, 0.9419, 0.4829, 0.7214, 0.8914, 0.6542, 1.2845, 1.4305, 1.8718, 1.1094, 0.9318, 0.6215, 1.2201, 1.9945, 1.819, 1.811, 0.7978, 0.97, 1.0178, 1.9413, 1.2063, 1.2828, 0.4827, 0.6974, 1.0357, 1.8268, 1.9049, 1.7238, 0.9151, 0.9668, 0.8152, 0.8549, 0.8822, 0.915, 0.3409]]