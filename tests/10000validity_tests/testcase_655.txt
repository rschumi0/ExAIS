import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo12481 = tf.keras.layers.Input(shape=([1, 1]))
in0ELU84785 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con29875 = tf.keras.layers.Input(shape=([3, 3, 13, 1]))
in0Max76823 = tf.keras.layers.Input(shape=([1, 1]))
in1Max76823 = tf.keras.layers.Input(shape=([1, 1]))

Glo12481 = keras.layers.GlobalAveragePooling1D(name = 'Glo12481', )(in0Glo12481)
Res99030 = keras.layers.Reshape((1, 1), name = 'Res99030', )(Glo12481)
Res44477 = keras.layers.Reshape((1, 1, 1), name = 'Res44477', )(Res99030)
Res90160 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res90160', )(Res44477)
Zer76242 = keras.layers.ZeroPadding3D(padding=((2, 0), (2, 0), (2, 0)), name = 'Zer76242', )(Res90160)
ELU84785 = keras.layers.ELU(alpha=-3.7517758415887776, name = 'ELU84785', input_shape=(1, 1, 1))(in0ELU84785)
Res16349 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res16349', )(ELU84785)
Zer8088 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer8088', )(Res16349)
Ave5829 = keras.layers.Average(name = 'Ave5829', )([Zer76242,Zer8088])
Res33874 = keras.layers.Reshape((3, 3, 3), name = 'Res33874', )(Ave5829)
PRe27733 = keras.layers.PReLU(name = 'PRe27733', )(Res33874)
Res33323 = keras.layers.Reshape((3, 3, 3, 1), name = 'Res33323', )(PRe27733)
Zer46325 = keras.layers.ZeroPadding3D(padding=((0, 0), (0, 0), (10, 0)), name = 'Zer46325', )(Res33323)
Con29875 = keras.layers.Concatenate(axis=4, name = 'Con29875', )([Zer46325,in0Con29875])
Max76823 = keras.layers.Maximum(name = 'Max76823', )([in0Max76823,in1Max76823])
Res95139 = keras.layers.Reshape((1, 1, 1), name = 'Res95139', )(Max76823)
Res80253 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res80253', )(Res95139)
Con53168 = keras.layers.Conv3DTranspose(2, (1, 1, 1),strides=(1, 1, 8), padding='valid', name = 'Con53168', )(Res80253)
Zer77387 = keras.layers.ZeroPadding3D(padding=((2, 0), (2, 0), (5, 0)), name = 'Zer77387', )(Con53168)
Max89562 = keras.layers.Maximum(name = 'Max89562', )([Con29875,Zer77387])
model = tf.keras.models.Model(inputs=[in0Glo12481,in0ELU84785,in0Con29875,in0Max76823,in1Max76823], outputs=Max89562)
w = model.get_layer('PRe27733').get_weights() 
w[0] = np.array([[[0.4747, 0.597, 0.9244], [0.2857, 0.3036, 0.3181], [0.1833, 0.8333, 0.5085]], [[0.7957, 0.4087, 0.6995], [0.6, 0.8642, 0.7844], [0.305, 0.4227, 0.6617]], [[0.5526, 0.4804, 0.9622], [0.3067, 0.1842, 0.4182], [0.9963, 0.4265, 0.5996]]])
model.get_layer('PRe27733').set_weights(w) 
w = model.get_layer('Con53168').get_weights() 
w[0] = np.array([[[[[0.5141], [0.6254]]]]])
w[1] = np.array([0, 0])
model.get_layer('Con53168').set_weights(w) 
in0Glo12481 = tf.constant([[[1.8578]]])
in0ELU84785 = tf.constant([[[[0.767]]]])
in0Con29875 = tf.constant([[[[[0.8893], [0.4389], [0.2586], [0.26], [0.994], [0.514], [0.0811], [0.6627], [0.3394], [0.9637], [0.6704], [0.0388], [0.5898]], [[0.2755], [0.5404], [0.3836], [0.2791], [0.6355], [0.975], [0.5381], [0.3509], [0.2515], [0.9026], [0.2565], [0.6582], [0.0571]], [[0.1454], [0.0342], [0.8511], [0.5636], [0.9371], [0.7762], [0.8631], [0.6667], [0.715], [0.8824], [0.9014], [0.417], [0.7169]]], [[[0.479], [0.4444], [0.1181], [0.8364], [0.3358], [0.2553], [0.6316], [0.5249], [0.4737], [0.8292], [0.4345], [0.2679], [0.5903]], [[0.0133], [0.8003], [0.3078], [0.2082], [0.7576], [0.4583], [0.8384], [0.887], [0.0886], [0.2211], [0.8531], [0.9283], [0.4314]], [[0.3647], [0.1932], [0.7537], [0.3485], [0.9976], [0.115], [0.535], [0.6138], [0.2589], [0.8684], [0.7183], [0.2936], [0.9506]]], [[[0.3643], [0.7989], [0.1671], [0.1267], [0.9979], [0.0751], [0.3893], [0.2376], [0.0887], [0.1377], [0.7681], [0.6588], [0.2017]], [[0.5376], [0.4119], [0.8231], [0.82], [0.4135], [0.788], [0.7157], [0.457], [0.8582], [0.4228], [0.1951], [0.3119], [0.4583]], [[0.5775], [0.4569], [0.0031], [0.7476], [0.2345], [0.972], [0.7462], [0.2833], [0.6418], [0.3989], [0.5799], [0.6758], [0.4812]]]]])
in0Max76823 = tf.constant([[[0.0553]]])
in1Max76823 = tf.constant([[[0.2739]]])
print (np.array2string(model.predict([in0Glo12481,in0ELU84785,in0Con29875,in0Max76823,in1Max76823],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max89562.png')

LGlo12481 = global_average_pooling1D_layer([[[1.8578]]], Glo12481), 
LRes99030 = reshape_layer(Glo12481, [1, 1], Res99030), 
LRes44477 = reshape_layer(Res99030, [1, 1, 1], Res44477), 
LRes90160 = reshape_layer(Res44477, [1, 1, 1, 1], Res90160), 
LZer76242 = zero_padding3D_layer(Res90160, 2, 0, 2, 0, 2, 0, Zer76242), 
LELU84785 = elu_layer([[[[0.767]]]], -3.7517758415887776, ELU84785), 
LRes16349 = reshape_layer(ELU84785, [1, 1, 1, 1], Res16349), 
LZer8088 = zero_padding3D_layer(Res16349, 1, 1, 1, 1, 1, 1, Zer8088), 
LAve5829 = average_layer([Zer76242,Zer8088], Ave5829), 
LRes33874 = reshape_layer(Ave5829, [3, 3, 3], Res33874), 
LPRe27733 = prelu_layer(Res33874, [[[0.4747, 0.597, 0.9244], [0.2857, 0.3036, 0.3181], [0.1833, 0.8333, 0.5085]], [[0.7957, 0.4087, 0.6995], [0.6, 0.8642, 0.7844], [0.305, 0.4227, 0.6617]], [[0.5526, 0.4804, 0.9622], [0.3067, 0.1842, 0.4182], [0.9963, 0.4265, 0.5996]]], PRe27733), 
LRes33323 = reshape_layer(PRe27733, [3, 3, 3, 1], Res33323), 
LZer46325 = zero_padding3D_layer(Res33323, 0, 0, 0, 0, 10, 0, Zer46325), 
LCon29875 = concatenate_layer([Zer46325,[[[[[0.8893], [0.4389], [0.2586], [0.26], [0.994], [0.514], [0.0811], [0.6627], [0.3394], [0.9637], [0.6704], [0.0388], [0.5898]], [[0.2755], [0.5404], [0.3836], [0.2791], [0.6355], [0.975], [0.5381], [0.3509], [0.2515], [0.9026], [0.2565], [0.6582], [0.0571]], [[0.1454], [0.0342], [0.8511], [0.5636], [0.9371], [0.7762], [0.8631], [0.6667], [0.715], [0.8824], [0.9014], [0.417], [0.7169]]], [[[0.479], [0.4444], [0.1181], [0.8364], [0.3358], [0.2553], [0.6316], [0.5249], [0.4737], [0.8292], [0.4345], [0.2679], [0.5903]], [[0.0133], [0.8003], [0.3078], [0.2082], [0.7576], [0.4583], [0.8384], [0.887], [0.0886], [0.2211], [0.8531], [0.9283], [0.4314]], [[0.3647], [0.1932], [0.7537], [0.3485], [0.9976], [0.115], [0.535], [0.6138], [0.2589], [0.8684], [0.7183], [0.2936], [0.9506]]], [[[0.3643], [0.7989], [0.1671], [0.1267], [0.9979], [0.0751], [0.3893], [0.2376], [0.0887], [0.1377], [0.7681], [0.6588], [0.2017]], [[0.5376], [0.4119], [0.8231], [0.82], [0.4135], [0.788], [0.7157], [0.457], [0.8582], [0.4228], [0.1951], [0.3119], [0.4583]], [[0.5775], [0.4569], [0.0031], [0.7476], [0.2345], [0.972], [0.7462], [0.2833], [0.6418], [0.3989], [0.5799], [0.6758], [0.4812]]]]]], 4, Con29875), 
LMax76823 = maximum_layer([[[[0.0553]]], [[[0.2739]]]], Max76823), 
LRes95139 = reshape_layer(Max76823, [1, 1, 1], Res95139), 
LRes80253 = reshape_layer(Res95139, [1, 1, 1, 1], Res80253), 
LCon53168 = conv3D_transpose_layer(Res80253, 1, 1, 1,[[[[[0.5141], [0.6254]]]]],[0, 0], 1, 1, 8, false, Con53168), 
LZer77387 = zero_padding3D_layer(Con53168, 2, 0, 2, 0, 5, 0, Zer77387), 
LMax89562 = maximum_layer([Con29875,Zer77387], Max89562), 
exec_layers([LGlo12481,LRes99030,LRes44477,LRes90160,LZer76242,LELU84785,LRes16349,LZer8088,LAve5829,LRes33874,LPRe27733,LRes33323,LZer46325,LCon29875,LMax76823,LRes95139,LRes80253,LCon53168,LZer77387,LMax89562],["Glo12481","Res99030","Res44477","Res90160","Zer76242","ELU84785","Res16349","Zer8088","Ave5829","Res33874","PRe27733","Res33323","Zer46325","Con29875","Max76823","Res95139","Res80253","Con53168","Zer77387","Max89562"],Max89562,"Max89562")

Actual (Unparsed): [[[[[0.0000000, 0.8893000], [0.0000000, 0.4389000], [0.0000000, 0.2586000], [0.0000000, 0.2600000], [0.0000000, 0.9940000], [0.0000000, 0.5140000], [0.0000000, 0.0811000], [0.0000000, 0.6627000], [0.0000000, 0.3394000], [0.0000000, 0.9637000], [0.0000000, 0.6704000], [0.0000000, 0.0388000], [0.0000000, 0.5898000]], [[0.0000000, 0.2755000], [0.0000000, 0.5404000], [0.0000000, 0.3836000], [0.0000000, 0.2791000], [0.0000000, 0.6355000], [0.0000000, 0.9750000], [0.0000000, 0.5381000], [0.0000000, 0.3509000], [0.0000000, 0.2515000], [0.0000000, 0.9026000], [0.0000000, 0.2565000], [0.0000000, 0.6582000], [0.0000000, 0.0571000]], [[0.0000000, 0.1454000], [0.0000000, 0.0342000], [0.0000000, 0.8511000], [0.0000000, 0.5636000], [0.0000000, 0.9371000], [0.0000000, 0.7762000], [0.0000000, 0.8631000], [0.0000000, 0.6667000], [0.0000000, 0.7150000], [0.0000000, 0.8824000], [0.0000000, 0.9014000], [0.0000000, 0.4170000], [0.0000000, 0.7169000]]], [[[0.0000000, 0.4790000], [0.0000000, 0.4444000], [0.0000000, 0.1181000], [0.0000000, 0.8364000], [0.0000000, 0.3358000], [0.0000000, 0.2553000], [0.0000000, 0.6316000], [0.0000000, 0.5249000], [0.0000000, 0.4737000], [0.0000000, 0.8292000], [0.0000000, 0.4345000], [0.0000000, 0.2679000], [0.0000000, 0.5903000]], [[0.0000000, 0.0133000], [0.0000000, 0.8003000], [0.0000000, 0.3078000], [0.0000000, 0.2082000], [0.0000000, 0.7576000], [0.0000000, 0.4583000], [0.0000000, 0.8384000], [0.0000000, 0.8870000], [0.0000000, 0.0886000], [0.0000000, 0.2211000], [0.0000000, 0.8531000], [0.3835000, 0.9283000], [0.0000000, 0.4314000]], [[0.0000000, 0.3647000], [0.0000000, 0.1932000], [0.0000000, 0.7537000], [0.0000000, 0.3485000], [0.0000000, 0.9976000], [0.0000000, 0.1150000], [0.0000000, 0.5350000], [0.0000000, 0.6138000], [0.0000000, 0.2589000], [0.0000000, 0.8684000], [0.0000000, 0.7183000], [0.0000000, 0.2936000], [0.0000000, 0.9506000]]], [[[0.0000000, 0.3643000], [0.0000000, 0.7989000], [0.0000000, 0.1671000], [0.0000000, 0.1267000], [0.0000000, 0.9979000], [0.0000000, 0.0751000], [0.0000000, 0.3893000], [0.0000000, 0.2376000], [0.0000000, 0.0887000], [0.0000000, 0.1377000], [0.0000000, 0.7681000], [0.0000000, 0.6588000], [0.0000000, 0.2017000]], [[0.0000000, 0.5376000], [0.0000000, 0.4119000], [0.0000000, 0.8231000], [0.0000000, 0.8200000], [0.0000000, 0.4135000], [0.0000000, 0.7880000], [0.0000000, 0.7157000], [0.0000000, 0.4570000], [0.0000000, 0.8582000], [0.0000000, 0.4228000], [0.0000000, 0.1951000], [0.0000000, 0.3119000], [0.0000000, 0.4583000]], [[0.0000000, 0.5775000], [0.0000000, 0.4569000], [0.0000000, 0.0031000], [0.0000000, 0.7476000], [0.0000000, 0.2345000], [0.1408120, 0.9720000], [0.0000000, 0.7462000], [0.0000000, 0.2833000], [0.0000000, 0.6418000], [0.0000000, 0.3989000], [0.0000000, 0.5799000], [0.0000000, 0.6758000], [0.9289000, 0.4812000]]]]]

Expected (Unparsed): [[[[[0,0.8893],[0,0.4389],[0,0.2586],[0,0.26],[0,0.994],[0,0.514],[0,0.0811],[0,0.6627],[0,0.3394],[0,0.9637],[0,0.6704],[0,0.0388],[0,0.5898]],[[0,0.2755],[0,0.5404],[0,0.3836],[0,0.2791],[0,0.6355],[0,0.975],[0,0.5381],[0,0.3509],[0,0.2515],[0,0.9026],[0,0.2565],[0,0.6582],[0,0.0571]],[[0,0.1454],[0,0.0342],[0,0.8511],[0,0.5636],[0,0.9371],[0,0.7762],[0,0.8631],[0,0.6667],[0,0.715],[0,0.8824],[0,0.9014],[0,0.417],[0,0.7169]]],[[[0,0.479],[0,0.4444],[0,0.1181],[0,0.8364],[0,0.3358],[0,0.2553],[0,0.6316],[0,0.5249],[0,0.4737],[0,0.8292],[0,0.4345],[0,0.2679],[0,0.5903]],[[0,0.0133],[0,0.8003],[0,0.3078],[0,0.2082],[0,0.7576],[0,0.4583],[0,0.8384],[0,0.887],[0,0.0886],[0,0.2211],[0,0.8531],[0.3835,0.9283],[0,0.4314]],[[0,0.3647],[0,0.1932],[0,0.7537],[0,0.3485],[0,0.9976],[0,0.115],[0,0.535],[0,0.6138],[0,0.2589],[0,0.8684],[0,0.7183],[0,0.2936],[0,0.9506]]],[[[0,0.3643],[0,0.7989],[0,0.1671],[0,0.1267],[0,0.9979],[0,0.0751],[0,0.3893],[0,0.2376],[0,0.0887],[0,0.1377],[0,0.7681],[0,0.6588],[0,0.2017]],[[0,0.5376],[0,0.4119],[0,0.8231],[0,0.82],[0,0.4135],[0,0.788],[0,0.7157],[0,0.457],[0,0.8582],[0,0.4228],[0,0.1951],[0,0.3119],[0,0.4583]],[[0,0.5775],[0,0.4569],[0,0.0031],[0,0.7476],[0,0.2345],[0.14081199,0.972],[0,0.7462],[0,0.2833],[0,0.6418],[0,0.3989],[0,0.5799],[0,0.6758],[0.9289,0.4812]]]]]

Actual:   [[[[[0, 0.8893], [0, 0.4389], [0, 0.2586], [0, 0.26], [0, 0.994], [0, 0.514], [0, 0.0811], [0, 0.6627], [0, 0.3394], [0, 0.9637], [0, 0.6704], [0, 0.0388], [0, 0.5898]], [[0, 0.2755], [0, 0.5404], [0, 0.3836], [0, 0.2791], [0, 0.6355], [0, 0.975], [0, 0.5381], [0, 0.3509], [0, 0.2515], [0, 0.9026], [0, 0.2565], [0, 0.6582], [0, 0.0571]], [[0, 0.1454], [0, 0.0342], [0, 0.8511], [0, 0.5636], [0, 0.9371], [0, 0.7762], [0, 0.8631], [0, 0.6667], [0, 0.715], [0, 0.8824], [0, 0.9014], [0, 0.417], [0, 0.7169]]], [[[0, 0.479], [0, 0.4444], [0, 0.1181], [0, 0.8364], [0, 0.3358], [0, 0.2553], [0, 0.6316], [0, 0.5249], [0, 0.4737], [0, 0.8292], [0, 0.4345], [0, 0.2679], [0, 0.5903]], [[0, 0.0133], [0, 0.8003], [0, 0.3078], [0, 0.2082], [0, 0.7576], [0, 0.4583], [0, 0.8384], [0, 0.887], [0, 0.0886], [0, 0.2211], [0, 0.8531], [0.3835, 0.9283], [0, 0.4314]], [[0, 0.3647], [0, 0.1932], [0, 0.7537], [0, 0.3485], [0, 0.9976], [0, 0.115], [0, 0.535], [0, 0.6138], [0, 0.2589], [0, 0.8684], [0, 0.7183], [0, 0.2936], [0, 0.9506]]], [[[0, 0.3643], [0, 0.7989], [0, 0.1671], [0, 0.1267], [0, 0.9979], [0, 0.0751], [0, 0.3893], [0, 0.2376], [0, 0.0887], [0, 0.1377], [0, 0.7681], [0, 0.6588], [0, 0.2017]], [[0, 0.5376], [0, 0.4119], [0, 0.8231], [0, 0.82], [0, 0.4135], [0, 0.788], [0, 0.7157], [0, 0.457], [0, 0.8582], [0, 0.4228], [0, 0.1951], [0, 0.3119], [0, 0.4583]], [[0, 0.5775], [0, 0.4569], [0, 0.0031], [0, 0.7476], [0, 0.2345], [0.1409, 0.972], [0, 0.7462], [0, 0.2833], [0, 0.6418], [0, 0.3989], [0, 0.5799], [0, 0.6758], [0.9289, 0.4812]]]]]

Expected: [[[[[0, 0.8893], [0, 0.4389], [0, 0.2586], [0, 0.26], [0, 0.994], [0, 0.514], [0, 0.0811], [0, 0.6627], [0, 0.3394], [0, 0.9637], [0, 0.6704], [0, 0.0388], [0, 0.5898]], [[0, 0.2755], [0, 0.5404], [0, 0.3836], [0, 0.2791], [0, 0.6355], [0, 0.975], [0, 0.5381], [0, 0.3509], [0, 0.2515], [0, 0.9026], [0, 0.2565], [0, 0.6582], [0, 0.0571]], [[0, 0.1454], [0, 0.0342], [0, 0.8511], [0, 0.5636], [0, 0.9371], [0, 0.7762], [0, 0.8631], [0, 0.6667], [0, 0.715], [0, 0.8824], [0, 0.9014], [0, 0.417], [0, 0.7169]]], [[[0, 0.479], [0, 0.4444], [0, 0.1181], [0, 0.8364], [0, 0.3358], [0, 0.2553], [0, 0.6316], [0, 0.5249], [0, 0.4737], [0, 0.8292], [0, 0.4345], [0, 0.2679], [0, 0.5903]], [[0, 0.0133], [0, 0.8003], [0, 0.3078], [0, 0.2082], [0, 0.7576], [0, 0.4583], [0, 0.8384], [0, 0.887], [0, 0.0886], [0, 0.2211], [0, 0.8531], [0.3835, 0.9283], [0, 0.4314]], [[0, 0.3647], [0, 0.1932], [0, 0.7537], [0, 0.3485], [0, 0.9976], [0, 0.115], [0, 0.535], [0, 0.6138], [0, 0.2589], [0, 0.8684], [0, 0.7183], [0, 0.2936], [0, 0.9506]]], [[[0, 0.3643], [0, 0.7989], [0, 0.1671], [0, 0.1267], [0, 0.9979], [0, 0.0751], [0, 0.3893], [0, 0.2376], [0, 0.0887], [0, 0.1377], [0, 0.7681], [0, 0.6588], [0, 0.2017]], [[0, 0.5376], [0, 0.4119], [0, 0.8231], [0, 0.82], [0, 0.4135], [0, 0.788], [0, 0.7157], [0, 0.457], [0, 0.8582], [0, 0.4228], [0, 0.1951], [0, 0.3119], [0, 0.4583]], [[0, 0.5775], [0, 0.4569], [0, 0.0031], [0, 0.7476], [0, 0.2345], [0.1409, 0.972], [0, 0.7462], [0, 0.2833], [0, 0.6418], [0, 0.3989], [0, 0.5799], [0, 0.6758], [0.9289, 0.4812]]]]]