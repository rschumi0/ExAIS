import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Up_16462 = tf.keras.layers.Input(shape=([3, 3, 1]))
in0Glo87086 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con41425 = tf.keras.layers.Input(shape=([16]))
in0Max8622 = tf.keras.layers.Input(shape=([2, 1]))
in1Max8622 = tf.keras.layers.Input(shape=([2, 1]))
in0Max47115 = tf.keras.layers.Input(shape=([1, 2, 1]))
in1Max47115 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0GRU11013 = tf.keras.layers.Input(shape=([3, 1]))
in0Con77215 = tf.keras.layers.Input(shape=([1]))
in0Con95599 = tf.keras.layers.Input(shape=([66]))

Up_16462 = keras.layers.UpSampling2D(size=(1, 2), name = 'Up_16462', )(in0Up_16462)
Res59569 = keras.layers.Reshape((3, 6), name = 'Res59569', )(Up_16462)
Fla64732 = keras.layers.Flatten(name = 'Fla64732', )(Res59569)
Glo87086 = keras.layers.GlobalAveragePooling2D(name = 'Glo87086', )(in0Glo87086)
Con41425 = keras.layers.Concatenate(axis=1, name = 'Con41425', )([Glo87086,in0Con41425])
Max9271 = keras.layers.Maximum(name = 'Max9271', )([Fla64732,Con41425])
Res45398 = keras.layers.Reshape((18, 1), name = 'Res45398', )(Max9271)
Zer24534 = keras.layers.ZeroPadding1D(padding=((16, 0)), name = 'Zer24534', )(Res45398)
Max8622 = keras.layers.Maximum(name = 'Max8622', )([in0Max8622,in1Max8622])
Dot55953 = keras.layers.Dot(axes=(2, 2), name = 'Dot55953', )([Zer24534,Max8622])
Fla90714 = keras.layers.Flatten(name = 'Fla90714', )(Dot55953)
Max47115 = keras.layers.Maximum(name = 'Max47115', )([in0Max47115,in1Max47115])
Bat90063 = keras.layers.BatchNormalization(axis=2, epsilon=0.7740950675103847,  name = 'Bat90063', )(Max47115)
Res54411 = keras.layers.Reshape((1, 2), name = 'Res54411', )(Bat90063)
Fla41924 = keras.layers.Flatten(name = 'Fla41924', )(Res54411)
GRU11013 = keras.layers.GRU(3,reset_after=True, recurrent_activation='sigmoid', name = 'GRU11013', )(in0GRU11013)
Res5526 = keras.layers.Reshape((3, 1), name = 'Res5526', )(GRU11013)
Res56148 = keras.layers.Reshape((3, 1, 1), name = 'Res56148', )(Res5526)
Sep77982 = keras.layers.SeparableConv2D(3, (1, 1),strides=(1, 1), padding='valid', name = 'Sep77982', )(Res56148)
Res12749 = keras.layers.Reshape((3, 3), name = 'Res12749', )(Sep77982)
LST66498 = keras.layers.LSTM(1,recurrent_activation='sigmoid', name = 'LST66498', )(Res12749)
Con77215 = keras.layers.Concatenate(axis=1, name = 'Con77215', )([LST66498,in0Con77215])
Ave53228 = keras.layers.Average(name = 'Ave53228', )([Fla41924,Con77215])
Con95599 = keras.layers.Concatenate(axis=1, name = 'Con95599', )([Ave53228,in0Con95599])
Sub58670 = keras.layers.Subtract(name = 'Sub58670', )([Fla90714,Con95599])
model = tf.keras.models.Model(inputs=[in0Up_16462,in0Glo87086,in0Con41425,in0Max8622,in1Max8622,in0Max47115,in1Max47115,in0GRU11013,in0Con77215,in0Con95599], outputs=Sub58670)
w = model.get_layer('Bat90063').get_weights() 
w[0] = np.array([0.0805, 0.2996])
w[1] = np.array([0.628, 0.8247])
w[2] = np.array([0.1989, 0.7351])
w[3] = np.array([0.5265, 0.6871])
model.get_layer('Bat90063').set_weights(w) 
w = model.get_layer('GRU11013').get_weights() 
w[0] = np.array([[4, 10, 6, 2, 2, 8, 8, 1, 6]])
w[1] = np.array([[8, 7, 5, 7, 7, 2, 1, 7, 7], [1, 10, 9, 1, 9, 9, 9, 7, 4], [9, 1, 8, 10, 10, 6, 10, 4, 1]])
w[2] = np.array([[1, 8, 2, 2, 9, 9, 2, 2, 5], [2, 2, 2, 6, 6, 1, 10, 2, 4]])
model.get_layer('GRU11013').set_weights(w) 
w = model.get_layer('Sep77982').get_weights() 
w[0] = np.array([[[[0.881]]]])
w[1] = np.array([[[[0.2591, 0.2089, 0.0255]]]])
w[2] = np.array([0, 0, 0])
model.get_layer('Sep77982').set_weights(w) 
w = model.get_layer('LST66498').get_weights() 
w[0] = np.array([[2, 9, 7, 1], [4, 4, 1, 6], [7, 7, 10, 6]])
w[1] = np.array([[7, 6, 8, 8]])
w[2] = np.array([5, 8, 10, 5])
model.get_layer('LST66498').set_weights(w) 
in0Up_16462 = tf.constant([[[[1.8424], [1.3435], [1.8788]], [[1.5862], [1.4918], [1.8074]], [[1.4474], [1.5137], [1.9689]]]])
in0Glo87086 = tf.constant([[[[1.3847, 1.7763]]]])
in0Con41425 = tf.constant([[0.9263, 0.3238, 0.7646, 0.1574, 0.5546, 0.4378, 0.3546, 0.1333, 0.9831, 0.3937, 0.4738, 0.6356, 0.2348, 0.4161, 0.3446, 0.4797]])
in0Max8622 = tf.constant([[[0.1115], [0.2169]]])
in1Max8622 = tf.constant([[[0.4095], [0.9934]]])
in0Max47115 = tf.constant([[[[0.3468], [0.7568]]]])
in1Max47115 = tf.constant([[[[0.5889], [0.693]]]])
in0GRU11013 = tf.constant([[[1], [2], [6]]])
in0Con77215 = tf.constant([[0.6531]])
in0Con95599 = tf.constant([[0.067, 0.9597, 0.6552, 0.5256, 0.6758, 0.7207, 0.2021, 0.4247, 0.2876, 0.9711, 0.3384, 0.6408, 0.2164, 0.2841, 0.7345, 0.4825, 0.5523, 0.7454, 0.0041, 0.6982, 0.5179, 0.547, 0.8743, 0.3684, 0.1991, 0.8738, 0.7952, 0.1942, 0.4373, 0.2431, 0.7678, 0.2089, 0.8138, 0.4177, 0.2565, 0.977, 0.948, 0.3783, 0.8035, 0.2864, 0.781, 0.607, 0.3628, 0.1885, 0.1256, 0.1166, 0.4322, 0.9978, 0.5224, 0.2384, 0.7778, 0.5185, 0.3629, 0.1721, 0.9164, 0.3402, 0.3174, 0.6991, 0.5513, 0.5119, 0.3316, 0.2577, 0.8397, 0.2866, 0.8497, 0.7914]])
print (np.array2string(model.predict([in0Up_16462,in0Glo87086,in0Con41425,in0Max8622,in1Max8622,in0Max47115,in1Max47115,in0GRU11013,in0Con77215,in0Con95599],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub58670.png')

LUp_16462 = up_sampling2D_layer([[[[1.8424], [1.3435], [1.8788]], [[1.5862], [1.4918], [1.8074]], [[1.4474], [1.5137], [1.9689]]]], 1, 2, Up_16462), 
LRes59569 = reshape_layer(Up_16462, [3, 6], Res59569), 
LFla64732 = flatten_layer(Res59569, Fla64732), 
LGlo87086 = global_average_pooling2D_layer([[[[1.3847, 1.7763]]]], Glo87086), 
LCon41425 = concatenate_layer([Glo87086,[[0.9263, 0.3238, 0.7646, 0.1574, 0.5546, 0.4378, 0.3546, 0.1333, 0.9831, 0.3937, 0.4738, 0.6356, 0.2348, 0.4161, 0.3446, 0.4797]]], 1, Con41425), 
LMax9271 = maximum_layer([Fla64732,Con41425], Max9271), 
LRes45398 = reshape_layer(Max9271, [18, 1], Res45398), 
LZer24534 = zero_padding1D_layer(Res45398, 16, 0, Zer24534), 
LMax8622 = maximum_layer([[[[0.1115], [0.2169]]], [[[0.4095], [0.9934]]]], Max8622), 
LDot55953 = dot_layer(Zer24534,Max8622, 2, 2, Dot55953), 
LFla90714 = flatten_layer(Dot55953, Fla90714), 
LMax47115 = maximum_layer([[[[[0.3468], [0.7568]]]], [[[[0.5889], [0.693]]]]], Max47115), 
LBat90063 = batch_normalization_layer(Max47115, 2, 0.7740950675103847, [0.0805, 0.2996], [0.628, 0.8247], [0.1989, 0.7351], [0.5265, 0.6871], Bat90063), 
LRes54411 = reshape_layer(Bat90063, [1, 2], Res54411), 
LFla41924 = flatten_layer(Res54411, Fla41924), 
LGRU11013 = gru_layer([[[1], [2], [6]]],[[4, 10, 6, 2, 2, 8, 8, 1, 6]],[[8, 7, 5, 7, 7, 2, 1, 7, 7], [1, 10, 9, 1, 9, 9, 9, 7, 4], [9, 1, 8, 10, 10, 6, 10, 4, 1]],[[1, 8, 2, 2, 9, 9, 2, 2, 5], [2, 2, 2, 6, 6, 1, 10, 2, 4]], true, GRU11013), 
LRes5526 = reshape_layer(GRU11013, [3, 1], Res5526), 
LRes56148 = reshape_layer(Res5526, [3, 1, 1], Res56148), 
LSep77982 = separable_conv2D_layer(Res56148, 1, 1,[[[[[0.881]]]],[[[[0.2591, 0.2089, 0.0255]]]]],[0, 0, 0], 1, 1, false, Sep77982), 
LRes12749 = reshape_layer(Sep77982, [3, 3], Res12749), 
LLST66498 = lstm_layer(Res12749,[[2, 9, 7, 1], [4, 4, 1, 6], [7, 7, 10, 6]],[[7, 6, 8, 8]],[5, 8, 10, 5], LST66498), 
LCon77215 = concatenate_layer([LST66498,[[0.6531]]], 1, Con77215), 
LAve53228 = average_layer([Fla41924,Con77215], Ave53228), 
LCon95599 = concatenate_layer([Ave53228,[[0.067, 0.9597, 0.6552, 0.5256, 0.6758, 0.7207, 0.2021, 0.4247, 0.2876, 0.9711, 0.3384, 0.6408, 0.2164, 0.2841, 0.7345, 0.4825, 0.5523, 0.7454, 0.0041, 0.6982, 0.5179, 0.547, 0.8743, 0.3684, 0.1991, 0.8738, 0.7952, 0.1942, 0.4373, 0.2431, 0.7678, 0.2089, 0.8138, 0.4177, 0.2565, 0.977, 0.948, 0.3783, 0.8035, 0.2864, 0.781, 0.607, 0.3628, 0.1885, 0.1256, 0.1166, 0.4322, 0.9978, 0.5224, 0.2384, 0.7778, 0.5185, 0.3629, 0.1721, 0.9164, 0.3402, 0.3174, 0.6991, 0.5513, 0.5119, 0.3316, 0.2577, 0.8397, 0.2866, 0.8497, 0.7914]]], 1, Con95599), 
LSub58670 = subtract_layer(Fla90714,Con95599, Sub58670), 
exec_layers([LUp_16462,LRes59569,LFla64732,LGlo87086,LCon41425,LMax9271,LRes45398,LZer24534,LMax8622,LDot55953,LFla90714,LMax47115,LBat90063,LRes54411,LFla41924,LGRU11013,LRes5526,LRes56148,LSep77982,LRes12749,LLST66498,LCon77215,LAve53228,LCon95599,LSub58670],["Up_16462","Res59569","Fla64732","Glo87086","Con41425","Max9271","Res45398","Zer24534","Max8622","Dot55953","Fla90714","Max47115","Bat90063","Res54411","Fla41924","GRU11013","Res5526","Res56148","Sep77982","Res12749","LST66498","Con77215","Ave53228","Con95599","Sub58670"],Sub58670,"Sub58670")

Actual (Unparsed): [[-0.8252569, -0.7415892, -0.0670000, -0.9597000, -0.6552000, -0.5256000, -0.6758000, -0.7207000, -0.2021000, -0.4247000, -0.2876000, -0.9711000, -0.3384000, -0.6408000, -0.2164000, -0.2841000, -0.7345000, -0.4825000, -0.5523000, -0.7454000, -0.0041000, -0.6982000, -0.5179000, -0.5470000, -0.8743000, -0.3684000, -0.1991000, -0.8738000, -0.7952000, -0.1942000, -0.4373000, -0.2431000, -0.0133372, 1.6213401, -0.0593372, 1.4125401, 0.2936633, 0.3576329, -0.3978368, 0.9563329, -0.0341314, 1.5799999, -0.0116314, 1.2593999, 0.2867489, 1.3872310, 0.5239489, 1.4591310, 0.1786921, 0.4841540, 0.0884921, 1.2435540, -0.0376697, 1.2769711, 0.3772303, 1.6233711, -0.3236897, 1.0976471, 0.2753103, 0.7387471, 0.0685602, 0.9918095, 0.2882601, 1.2460096, -0.0334354, 1.6693052, -0.0434354, 1.1645052]]

Expected (Unparsed): [[-0.8252569043166387,-0.7415891649892361,-0.067,-0.9597,-0.6552,-0.5256,-0.6758,-0.7207,-0.2021,-0.4247,-0.2876,-0.9711,-0.3384,-0.6408,-0.2164,-0.2841,-0.7345,-0.4825,-0.5523,-0.7454,-0.0041,-0.6982,-0.5179,-0.547,-0.8743,-0.3684,-0.1991,-0.8738,-0.7952,-0.1942,-0.4373,-0.2431,-0.013337200000000049,1.62134016,-0.05933719999999998,1.41254016,0.2936632499999999,0.3576328999999999,-0.3978367500000001,0.9563328999999998,-0.034131400000000034,1.57999992,-0.01163140000000007,1.25939992,0.2867489,1.3872310799999998,0.5239488999999999,1.45913108,0.17869209999999996,0.4841541199999999,0.08849209999999996,1.24355412,-0.03766970000000014,1.2769711599999998,0.3772302999999999,1.6233711599999998,-0.32368969999999997,1.09764716,0.2753103,0.73874716,0.06856014999999993,0.99180958,0.28826014999999994,1.24600958,-0.03343545000000003,1.66930526,-0.04343545000000004,1.1645052599999999]]

Actual:   [[-0.8252, -0.7415, -0.067, -0.9597, -0.6552, -0.5256, -0.6758, -0.7207, -0.2021, -0.4247, -0.2876, -0.9711, -0.3384, -0.6408, -0.2164, -0.2841, -0.7345, -0.4825, -0.5523, -0.7454, -0.0041, -0.6982, -0.5179, -0.547, -0.8743, -0.3684, -0.1991, -0.8738, -0.7952, -0.1942, -0.4373, -0.2431, -0.0133, 1.6214, -0.0593, 1.4126, 0.2937, 0.3577, -0.3978, 0.9564, -0.0341, 1.58, -0.0116, 1.2594, 0.2868, 1.3873, 0.524, 1.4592, 0.1787, 0.4842, 0.0885, 1.2436, -0.0376, 1.277, 0.3773, 1.6234, -0.3236, 1.0977, 0.2754, 0.7388, 0.0686, 0.9919, 0.2883, 1.2461, -0.0334, 1.6694, -0.0434, 1.1646]]

Expected: [[-0.8252, -0.7415, -0.067, -0.9597, -0.6552, -0.5256, -0.6758, -0.7207, -0.2021, -0.4247, -0.2876, -0.9711, -0.3384, -0.6408, -0.2164, -0.2841, -0.7345, -0.4825, -0.5523, -0.7454, -0.0041, -0.6982, -0.5179, -0.547, -0.8743, -0.3684, -0.1991, -0.8738, -0.7952, -0.1942, -0.4373, -0.2431, -0.0133, 1.6214, -0.0593, 1.4126, 0.2937, 0.3577, -0.3978, 0.9564, -0.0341, 1.58, -0.0116, 1.2594, 0.2868, 1.3873, 0.524, 1.4592, 0.1787, 0.4842, 0.0885, 1.2436, -0.0376, 1.277, 0.3773, 1.6234, -0.3236, 1.0977, 0.2754, 0.7388, 0.0686, 0.9919, 0.2883, 1.2461, -0.0334, 1.6694, -0.0434, 1.1646]]