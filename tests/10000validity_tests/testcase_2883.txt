import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0LST41223 = tf.keras.layers.Input(shape=([3, 1]))
in0Con50181 = tf.keras.layers.Input(shape=([1, 2, 2]))
in0Con95334 = tf.keras.layers.Input(shape=([1, 3]))
in0Con98856 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con47510 = tf.keras.layers.Input(shape=([12, 6, 1, 1]))

LST41223 = keras.layers.LSTM(2,recurrent_activation='sigmoid', name = 'LST41223', )(in0LST41223)
Res87261 = keras.layers.Reshape((2, 1), name = 'Res87261', )(LST41223)
Res11700 = keras.layers.Reshape((2, 1, 1), name = 'Res11700', )(Res87261)
Res75829 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res75829', )(Res11700)
Con963 = keras.layers.Conv3DTranspose(3, (1, 1, 1),strides=(6, 6, 1), padding='same', name = 'Con963', )(Res75829)
Con50181 = keras.layers.Conv2D(3, (1, 1),strides=(1, 3), padding='same', dilation_rate=(1, 1), name = 'Con50181', )(in0Con50181)
Thr77486 = keras.layers.ThresholdedReLU(theta=0.9984277313755082, name = 'Thr77486', )(Con50181)
Bat19477 = keras.layers.BatchNormalization(axis=3, epsilon=0.5249566619150896,  name = 'Bat19477', )(Thr77486)
Res46806 = keras.layers.Reshape((1, 3), name = 'Res46806', )(Bat19477)
Con95334 = keras.layers.Concatenate(axis=2, name = 'Con95334', )([Res46806,in0Con95334])
Con98856 = keras.layers.Conv2D(3, (1, 1),strides=(1, 1), padding='valid', dilation_rate=(1, 1), name = 'Con98856', )(in0Con98856)
Res90093 = keras.layers.Reshape((1, 6), name = 'Res90093', )(Con98856)
Dot97643 = keras.layers.Dot(axes=(2, 2), name = 'Dot97643', )([Con95334,Res90093])
Res8094 = keras.layers.Reshape((1, 1, 1), name = 'Res8094', )(Dot97643)
Res53436 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res53436', )(Res8094)
Con15399 = keras.layers.Conv3DTranspose(2, (1, 1, 1),strides=(1, 1, 1), padding='valid', name = 'Con15399', )(Res53436)
Zer30016 = keras.layers.ZeroPadding3D(padding=((11, 0), (5, 0), (0, 0)), name = 'Zer30016', )(Con15399)
Con47510 = keras.layers.Concatenate(axis=4, name = 'Con47510', )([Zer30016,in0Con47510])
Max85351 = keras.layers.Maximum(name = 'Max85351', )([Con963,Con47510])
model = tf.keras.models.Model(inputs=[in0LST41223,in0Con50181,in0Con95334,in0Con98856,in0Con47510], outputs=Max85351)
w = model.get_layer('LST41223').get_weights() 
w[0] = np.array([[6, 2, 9, 7, 3, 3, 2, 2]])
w[1] = np.array([[8, 3, 1, 8, 6, 2, 10, 5], [2, 10, 4, 5, 6, 4, 2, 7]])
w[2] = np.array([9, 4, 9, 7, 3, 3, 9, 8])
model.get_layer('LST41223').set_weights(w) 
w = model.get_layer('Con963').get_weights() 
w[0] = np.array([[[[[0.7324], [0.8973], [0.2013]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con963').set_weights(w) 
w = model.get_layer('Con50181').get_weights() 
w[0] = np.array([[[[0.7861, 0.6097, 0.1608], [0.9468, 0.9908, 0.2806]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con50181').set_weights(w) 
w = model.get_layer('Bat19477').get_weights() 
w[0] = np.array([0.6526, 0.546, 0.4425])
w[1] = np.array([0.7593, 0.8726, 0.3039])
w[2] = np.array([0.8388, 0.7542, 0.3377])
w[3] = np.array([0.8079, 0.1157, 0.4379])
model.get_layer('Bat19477').set_weights(w) 
w = model.get_layer('Con98856').get_weights() 
w[0] = np.array([[[[0.322, 0.8578, 0.6477]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con98856').set_weights(w) 
w = model.get_layer('Con15399').get_weights() 
w[0] = np.array([[[[[0.7288], [0.7606]]]]])
w[1] = np.array([0, 0])
model.get_layer('Con15399').set_weights(w) 
in0LST41223 = tf.constant([[[5], [5], [10]]])
in0Con50181 = tf.constant([[[[0.9465, 0.9222], [0.539, 0.7614]]]])
in0Con95334 = tf.constant([[[0.6442, 0.5193, 0.7128]]])
in0Con98856 = tf.constant([[[[0.8221], [0.4696]]]])
in0Con47510 = tf.constant([[[[[0.2399]], [[0.966]], [[0.7579]], [[0.9489]], [[0.4764]], [[0.6275]]], [[[0.9211]], [[0.0615]], [[0.6132]], [[0.6853]], [[0.8263]], [[0.1121]]], [[[0.9958]], [[0.7404]], [[0.9577]], [[0.7601]], [[0.4179]], [[0.7417]]], [[[0.6621]], [[0.9849]], [[0.2898]], [[0.2467]], [[0.8176]], [[0.8563]]], [[[0.0279]], [[0.7655]], [[0.466]], [[0.917]], [[0.1178]], [[0.8097]]], [[[0.9348]], [[0.1017]], [[0.051]], [[0.0324]], [[0.5574]], [[0.8288]]], [[[0.0021]], [[0.7647]], [[0.0883]], [[0.275]], [[0.6773]], [[0.3251]]], [[[0.3071]], [[0.8725]], [[0.2409]], [[0.7172]], [[0.1051]], [[0.7491]]], [[[0.6041]], [[0.7098]], [[0.5589]], [[0.1766]], [[0.6492]], [[0.8458]]], [[[0.1066]], [[0.0885]], [[0.1519]], [[0.6205]], [[0.9649]], [[0.379]]], [[[0.2656]], [[0.9294]], [[0.352]], [[0.0091]], [[0.4344]], [[0.8969]]], [[[0.9116]], [[0.9081]], [[0.5138]], [[0.3683]], [[0.9782]], [[0.2818]]]]])
print (np.array2string(model.predict([in0LST41223,in0Con50181,in0Con95334,in0Con98856,in0Con47510],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max85351.png')

LLST41223 = lstm_layer([[[5], [5], [10]]],[[6, 2, 9, 7, 3, 3, 2, 2]],[[8, 3, 1, 8, 6, 2, 10, 5], [2, 10, 4, 5, 6, 4, 2, 7]],[9, 4, 9, 7, 3, 3, 9, 8], LST41223), 
LRes87261 = reshape_layer(LST41223, [2, 1], Res87261), 
LRes11700 = reshape_layer(Res87261, [2, 1, 1], Res11700), 
LRes75829 = reshape_layer(Res11700, [2, 1, 1, 1], Res75829), 
LCon963 = conv3D_transpose_layer(Res75829, 1, 1, 1,[[[[[0.7324], [0.8973], [0.2013]]]]],[0, 0, 0], 6, 6, 1, true, Con963), 
LCon50181 = conv2D_layer([[[[0.9465, 0.9222], [0.539, 0.7614]]]], 1, 1,[[[[0.7861, 0.6097, 0.1608], [0.9468, 0.9908, 0.2806]]]],[0, 0, 0], 1, 3, true, 1, 1, Con50181), 
LThr77486 = thresholded_relu_layer(Con50181, 0.9984277313755082, Thr77486), 
LBat19477 = batch_normalization_layer(Thr77486, 3, 0.5249566619150896, [0.6526, 0.546, 0.4425], [0.7593, 0.8726, 0.3039], [0.8388, 0.7542, 0.3377], [0.8079, 0.1157, 0.4379], Bat19477), 
LRes46806 = reshape_layer(Bat19477, [1, 3], Res46806), 
LCon95334 = concatenate_layer([Res46806,[[[0.6442, 0.5193, 0.7128]]]], 2, Con95334), 
LCon98856 = conv2D_layer([[[[0.8221], [0.4696]]]], 1, 1,[[[[0.322, 0.8578, 0.6477]]]],[0, 0, 0], 1, 1, false, 1, 1, Con98856), 
LRes90093 = reshape_layer(Con98856, [1, 6], Res90093), 
LDot97643 = dot_layer(Con95334,Res90093, 2, 2, Dot97643), 
LRes8094 = reshape_layer(Dot97643, [1, 1, 1], Res8094), 
LRes53436 = reshape_layer(Res8094, [1, 1, 1, 1], Res53436), 
LCon15399 = conv3D_transpose_layer(Res53436, 1, 1, 1,[[[[[0.7288], [0.7606]]]]],[0, 0], 1, 1, 1, false, Con15399), 
LZer30016 = zero_padding3D_layer(Con15399, 11, 0, 5, 0, 0, 0, Zer30016), 
LCon47510 = concatenate_layer([Zer30016,[[[[[0.2399]], [[0.966]], [[0.7579]], [[0.9489]], [[0.4764]], [[0.6275]]], [[[0.9211]], [[0.0615]], [[0.6132]], [[0.6853]], [[0.8263]], [[0.1121]]], [[[0.9958]], [[0.7404]], [[0.9577]], [[0.7601]], [[0.4179]], [[0.7417]]], [[[0.6621]], [[0.9849]], [[0.2898]], [[0.2467]], [[0.8176]], [[0.8563]]], [[[0.0279]], [[0.7655]], [[0.466]], [[0.917]], [[0.1178]], [[0.8097]]], [[[0.9348]], [[0.1017]], [[0.051]], [[0.0324]], [[0.5574]], [[0.8288]]], [[[0.0021]], [[0.7647]], [[0.0883]], [[0.275]], [[0.6773]], [[0.3251]]], [[[0.3071]], [[0.8725]], [[0.2409]], [[0.7172]], [[0.1051]], [[0.7491]]], [[[0.6041]], [[0.7098]], [[0.5589]], [[0.1766]], [[0.6492]], [[0.8458]]], [[[0.1066]], [[0.0885]], [[0.1519]], [[0.6205]], [[0.9649]], [[0.379]]], [[[0.2656]], [[0.9294]], [[0.352]], [[0.0091]], [[0.4344]], [[0.8969]]], [[[0.9116]], [[0.9081]], [[0.5138]], [[0.3683]], [[0.9782]], [[0.2818]]]]]], 4, Con47510), 
LMax85351 = maximum_layer([Con963,Con47510], Max85351), 
exec_layers([LLST41223,LRes87261,LRes11700,LRes75829,LCon963,LCon50181,LThr77486,LBat19477,LRes46806,LCon95334,LCon98856,LRes90093,LDot97643,LRes8094,LRes53436,LCon15399,LZer30016,LCon47510,LMax85351],["LST41223","Res87261","Res11700","Res75829","Con963","Con50181","Thr77486","Bat19477","Res46806","Con95334","Con98856","Res90093","Dot97643","Res8094","Res53436","Con15399","Zer30016","Con47510","Max85351"],Max85351,"Max85351")

Actual (Unparsed): [[[[[0.7287781, 0.8928626, 0.2399000]], [[0.0000000, 0.0000000, 0.9660000]], [[0.0000000, 0.0000000, 0.7579000]], [[0.0000000, 0.0000000, 0.9489000]], [[0.0000000, 0.0000000, 0.4764000]], [[0.0000000, 0.0000000, 0.6275000]]], [[[0.0000000, 0.0000000, 0.9211000]], [[0.0000000, 0.0000000, 0.0615000]], [[0.0000000, 0.0000000, 0.6132000]], [[0.0000000, 0.0000000, 0.6853000]], [[0.0000000, 0.0000000, 0.8263000]], [[0.0000000, 0.0000000, 0.1121000]]], [[[0.0000000, 0.0000000, 0.9958000]], [[0.0000000, 0.0000000, 0.7404000]], [[0.0000000, 0.0000000, 0.9577000]], [[0.0000000, 0.0000000, 0.7601000]], [[0.0000000, 0.0000000, 0.4179000]], [[0.0000000, 0.0000000, 0.7417000]]], [[[0.0000000, 0.0000000, 0.6621000]], [[0.0000000, 0.0000000, 0.9849000]], [[0.0000000, 0.0000000, 0.2898000]], [[0.0000000, 0.0000000, 0.2467000]], [[0.0000000, 0.0000000, 0.8176000]], [[0.0000000, 0.0000000, 0.8563000]]], [[[0.0000000, 0.0000000, 0.0279000]], [[0.0000000, 0.0000000, 0.7655000]], [[0.0000000, 0.0000000, 0.4660000]], [[0.0000000, 0.0000000, 0.9170000]], [[0.0000000, 0.0000000, 0.1178000]], [[0.0000000, 0.0000000, 0.8097000]]], [[[0.0000000, 0.0000000, 0.9348000]], [[0.0000000, 0.0000000, 0.1017000]], [[0.0000000, 0.0000000, 0.0510000]], [[0.0000000, 0.0000000, 0.0324000]], [[0.0000000, 0.0000000, 0.5574000]], [[0.0000000, 0.0000000, 0.8288000]]], [[[0.7287781, 0.8928626, 0.2003045]], [[0.0000000, 0.0000000, 0.7647000]], [[0.0000000, 0.0000000, 0.0883000]], [[0.0000000, 0.0000000, 0.2750000]], [[0.0000000, 0.0000000, 0.6773000]], [[0.0000000, 0.0000000, 0.3251000]]], [[[0.0000000, 0.0000000, 0.3071000]], [[0.0000000, 0.0000000, 0.8725000]], [[0.0000000, 0.0000000, 0.2409000]], [[0.0000000, 0.0000000, 0.7172000]], [[0.0000000, 0.0000000, 0.1051000]], [[0.0000000, 0.0000000, 0.7491000]]], [[[0.0000000, 0.0000000, 0.6041000]], [[0.0000000, 0.0000000, 0.7098000]], [[0.0000000, 0.0000000, 0.5589000]], [[0.0000000, 0.0000000, 0.1766000]], [[0.0000000, 0.0000000, 0.6492000]], [[0.0000000, 0.0000000, 0.8458000]]], [[[0.0000000, 0.0000000, 0.1066000]], [[0.0000000, 0.0000000, 0.0885000]], [[0.0000000, 0.0000000, 0.1519000]], [[0.0000000, 0.0000000, 0.6205000]], [[0.0000000, 0.0000000, 0.9649000]], [[0.0000000, 0.0000000, 0.3790000]]], [[[0.0000000, 0.0000000, 0.2656000]], [[0.0000000, 0.0000000, 0.9294000]], [[0.0000000, 0.0000000, 0.3520000]], [[0.0000000, 0.0000000, 0.0091000]], [[0.0000000, 0.0000000, 0.4344000]], [[0.0000000, 0.0000000, 0.8969000]]], [[[0.0000000, 0.0000000, 0.9116000]], [[0.0000000, 0.0000000, 0.9081000]], [[0.0000000, 0.0000000, 0.5138000]], [[0.0000000, 0.0000000, 0.3683000]], [[0.0000000, 0.0000000, 0.9782000]], [[1.3783792, 1.4385226, 0.2818000]]]]]

Expected (Unparsed): [[[[[0.7287781016001614,0.8928626304831032,0.2399]],[[0,0,0.966]],[[0,0,0.7579]],[[0,0,0.9489]],[[0,0,0.4764]],[[0,0,0.6275]]],[[[0,0,0.9211]],[[0,0,0.0615]],[[0,0,0.6132]],[[0,0,0.6853]],[[0,0,0.8263]],[[0,0,0.1121]]],[[[0,0,0.9958]],[[0,0,0.7404]],[[0,0,0.9577]],[[0,0,0.7601]],[[0,0,0.4179]],[[0,0,0.7417]]],[[[0,0,0.6621]],[[0,0,0.9849]],[[0,0,0.2898]],[[0,0,0.2467]],[[0,0,0.8176]],[[0,0,0.8563]]],[[[0,0,0.0279]],[[0,0,0.7655]],[[0,0,0.466]],[[0,0,0.917]],[[0,0,0.1178]],[[0,0,0.8097]]],[[[0,0,0.9348]],[[0,0,0.1017]],[[0,0,0.051]],[[0,0,0.0324]],[[0,0,0.5574]],[[0,0,0.8288]]],[[[0.7287780955913288,0.8928626231213808,0.20030452026561235]],[[0,0,0.7647]],[[0,0,0.0883]],[[0,0,0.275]],[[0,0,0.6773]],[[0,0,0.3251]]],[[[0,0,0.3071]],[[0,0,0.8725]],[[0,0,0.2409]],[[0,0,0.7172]],[[0,0,0.1051]],[[0,0,0.7491]]],[[[0,0,0.6041]],[[0,0,0.7098]],[[0,0,0.5589]],[[0,0,0.1766]],[[0,0,0.6492]],[[0,0,0.8458]]],[[[0,0,0.1066]],[[0,0,0.0885]],[[0,0,0.1519]],[[0,0,0.6205]],[[0,0,0.9649]],[[0,0,0.379]]],[[[0,0,0.2656]],[[0,0,0.9294]],[[0,0,0.352]],[[0,0,0.0091]],[[0,0,0.4344]],[[0,0,0.8969]]],[[[0,0,0.9116]],[[0,0,0.9081]],[[0,0,0.5138]],[[0,0,0.3683]],[[0,0,0.9782]],[[1.3783792545137536,1.4385225864203637,0.2818]]]]]

Actual:   [[[[[0.7288, 0.8929, 0.2399]], [[0, 0, 0.966]], [[0, 0, 0.7579]], [[0, 0, 0.9489]], [[0, 0, 0.4764]], [[0, 0, 0.6275]]], [[[0, 0, 0.9211]], [[0, 0, 0.0615]], [[0, 0, 0.6132]], [[0, 0, 0.6853]], [[0, 0, 0.8263]], [[0, 0, 0.1121]]], [[[0, 0, 0.9958]], [[0, 0, 0.7404]], [[0, 0, 0.9577]], [[0, 0, 0.7601]], [[0, 0, 0.4179]], [[0, 0, 0.7417]]], [[[0, 0, 0.6621]], [[0, 0, 0.9849]], [[0, 0, 0.2898]], [[0, 0, 0.2467]], [[0, 0, 0.8176]], [[0, 0, 0.8563]]], [[[0, 0, 0.0279]], [[0, 0, 0.7655]], [[0, 0, 0.466]], [[0, 0, 0.917]], [[0, 0, 0.1178]], [[0, 0, 0.8097]]], [[[0, 0, 0.9348]], [[0, 0, 0.1017]], [[0, 0, 0.051]], [[0, 0, 0.0324]], [[0, 0, 0.5574]], [[0, 0, 0.8288]]], [[[0.7288, 0.8929, 0.2004]], [[0, 0, 0.7647]], [[0, 0, 0.0883]], [[0, 0, 0.275]], [[0, 0, 0.6773]], [[0, 0, 0.3251]]], [[[0, 0, 0.3071]], [[0, 0, 0.8725]], [[0, 0, 0.2409]], [[0, 0, 0.7172]], [[0, 0, 0.1051]], [[0, 0, 0.7491]]], [[[0, 0, 0.6041]], [[0, 0, 0.7098]], [[0, 0, 0.5589]], [[0, 0, 0.1766]], [[0, 0, 0.6492]], [[0, 0, 0.8458]]], [[[0, 0, 0.1066]], [[0, 0, 0.0885]], [[0, 0, 0.1519]], [[0, 0, 0.6205]], [[0, 0, 0.9649]], [[0, 0, 0.379]]], [[[0, 0, 0.2656]], [[0, 0, 0.9294]], [[0, 0, 0.352]], [[0, 0, 0.0091]], [[0, 0, 0.4344]], [[0, 0, 0.8969]]], [[[0, 0, 0.9116]], [[0, 0, 0.9081]], [[0, 0, 0.5138]], [[0, 0, 0.3683]], [[0, 0, 0.9782]], [[1.3784, 1.4386, 0.2818]]]]]

Expected: [[[[[0.7288, 0.8929, 0.2399]], [[0, 0, 0.966]], [[0, 0, 0.7579]], [[0, 0, 0.9489]], [[0, 0, 0.4764]], [[0, 0, 0.6275]]], [[[0, 0, 0.9211]], [[0, 0, 0.0615]], [[0, 0, 0.6132]], [[0, 0, 0.6853]], [[0, 0, 0.8263]], [[0, 0, 0.1121]]], [[[0, 0, 0.9958]], [[0, 0, 0.7404]], [[0, 0, 0.9577]], [[0, 0, 0.7601]], [[0, 0, 0.4179]], [[0, 0, 0.7417]]], [[[0, 0, 0.6621]], [[0, 0, 0.9849]], [[0, 0, 0.2898]], [[0, 0, 0.2467]], [[0, 0, 0.8176]], [[0, 0, 0.8563]]], [[[0, 0, 0.0279]], [[0, 0, 0.7655]], [[0, 0, 0.466]], [[0, 0, 0.917]], [[0, 0, 0.1178]], [[0, 0, 0.8097]]], [[[0, 0, 0.9348]], [[0, 0, 0.1017]], [[0, 0, 0.051]], [[0, 0, 0.0324]], [[0, 0, 0.5574]], [[0, 0, 0.8288]]], [[[0.7288, 0.8929, 0.2004]], [[0, 0, 0.7647]], [[0, 0, 0.0883]], [[0, 0, 0.275]], [[0, 0, 0.6773]], [[0, 0, 0.3251]]], [[[0, 0, 0.3071]], [[0, 0, 0.8725]], [[0, 0, 0.2409]], [[0, 0, 0.7172]], [[0, 0, 0.1051]], [[0, 0, 0.7491]]], [[[0, 0, 0.6041]], [[0, 0, 0.7098]], [[0, 0, 0.5589]], [[0, 0, 0.1766]], [[0, 0, 0.6492]], [[0, 0, 0.8458]]], [[[0, 0, 0.1066]], [[0, 0, 0.0885]], [[0, 0, 0.1519]], [[0, 0, 0.6205]], [[0, 0, 0.9649]], [[0, 0, 0.379]]], [[[0, 0, 0.2656]], [[0, 0, 0.9294]], [[0, 0, 0.352]], [[0, 0, 0.0091]], [[0, 0, 0.4344]], [[0, 0, 0.8969]]], [[[0, 0, 0.9116]], [[0, 0, 0.9081]], [[0, 0, 0.5138]], [[0, 0, 0.3683]], [[0, 0, 0.9782]], [[1.3784, 1.4386, 0.2818]]]]]