import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub36076 = tf.keras.layers.Input(shape=([3]))
in1Sub36076 = tf.keras.layers.Input(shape=([3]))
in0Con40487 = tf.keras.layers.Input(shape=([3, 1]))
in0Sub84397 = tf.keras.layers.Input(shape=([3]))
in1Sub84397 = tf.keras.layers.Input(shape=([3]))
in0Con98604 = tf.keras.layers.Input(shape=([2, 1]))
in0Dot12710 = tf.keras.layers.Input(shape=([2, 3]))
in1Dot12710 = tf.keras.layers.Input(shape=([2, 3]))

Sub36076 = keras.layers.Subtract(name = 'Sub36076', )([in0Sub36076,in1Sub36076])
Res50832 = keras.layers.Reshape((3, 1), name = 'Res50832', )(Sub36076)
Con40487 = keras.layers.Concatenate(axis=2, name = 'Con40487', )([Res50832,in0Con40487])
Sub84397 = keras.layers.Subtract(name = 'Sub84397', )([in0Sub84397,in1Sub84397])
Res7893 = keras.layers.Reshape((3, 1), name = 'Res7893', )(Sub84397)
Glo99516 = keras.layers.GlobalAveragePooling1D(name = 'Glo99516', )(Res7893)
Res4701 = keras.layers.Reshape((1, 1), name = 'Res4701', )(Glo99516)
Zer53487 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer53487', )(Res4701)
Con98604 = keras.layers.Concatenate(axis=2, name = 'Con98604', )([Zer53487,in0Con98604])
Dot12710 = keras.layers.Dot(axes=(2, 2), name = 'Dot12710', )([in0Dot12710,in1Dot12710])
Lay67474 = keras.layers.LayerNormalization(axis=1, epsilon=1.4344400959299966, name = 'Lay67474', )(Dot12710)
Sub43479 = keras.layers.Subtract(name = 'Sub43479', )([Con98604,Lay67474])
Dot63191 = keras.layers.Dot(axes=(2, 2), name = 'Dot63191', )([Con40487,Sub43479])
model = tf.keras.models.Model(inputs=[in0Sub36076,in1Sub36076,in0Con40487,in0Sub84397,in1Sub84397,in0Con98604,in0Dot12710,in1Dot12710], outputs=Dot63191)
in0Sub36076 = tf.constant([[0.3939, 0.0661, 0.9799]])
in1Sub36076 = tf.constant([[0.676, 0.6032, 0.5019]])
in0Con40487 = tf.constant([[[0.8626], [0.95], [0.1525]]])
in0Sub84397 = tf.constant([[0.5782, 0.1194, 0.3436]])
in1Sub84397 = tf.constant([[0.2218, 0.8839, 0.3707]])
in0Con98604 = tf.constant([[[0.8274], [0.8683]]])
in0Dot12710 = tf.constant([[[0.2469, 0.385, 0.0278], [0.538, 0.2746, 0.7946]]])
in1Dot12710 = tf.constant([[[0.1512, 0.1637, 0.5183], [0.1382, 0.0765, 0.6417]]])
print (np.array2string(model.predict([in0Sub36076,in1Sub36076,in0Con40487,in0Sub84397,in1Sub84397,in0Con98604,in0Dot12710,in1Dot12710],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot63191.png')

LSub36076 = subtract_layer([[0.3939, 0.0661, 0.9799]], [[0.676, 0.6032, 0.5019]], Sub36076), 
LRes50832 = reshape_layer(Sub36076, [3, 1], Res50832), 
LCon40487 = concatenate_layer([Res50832,[[[0.8626], [0.95], [0.1525]]]], 2, Con40487), 
LSub84397 = subtract_layer([[0.5782, 0.1194, 0.3436]], [[0.2218, 0.8839, 0.3707]], Sub84397), 
LRes7893 = reshape_layer(Sub84397, [3, 1], Res7893), 
LGlo99516 = global_average_pooling1D_layer(Res7893, Glo99516), 
LRes4701 = reshape_layer(Glo99516, [1, 1], Res4701), 
LZer53487 = zero_padding1D_layer(Res4701, 1, 0, Zer53487), 
LCon98604 = concatenate_layer([Zer53487,[[[0.8274], [0.8683]]]], 2, Con98604), 
LDot12710 = dot_layer([[[0.2469, 0.385, 0.0278], [0.538, 0.2746, 0.7946]]], [[[0.1512, 0.1637, 0.5183], [0.1382, 0.0765, 0.6417]]], 2, 2, Dot12710), 
LLay67474 = layer_normalization_layer(Dot12710, 1, 1.4344400959299966, Lay67474), 
LSub43479 = subtract_layer(Con98604,Lay67474, Sub43479), 
LDot63191 = dot_layer(Con40487,Sub43479, 2, 2, Dot63191), 
exec_layers([LSub36076,LRes50832,LCon40487,LSub84397,LRes7893,LGlo99516,LRes4701,LZer53487,LCon98604,LDot12710,LLay67474,LSub43479,LDot63191],["Sub36076","Res50832","Con40487","Sub84397","Res7893","Glo99516","Res4701","Zer53487","Con98604","Dot12710","Lay67474","Sub43479","Dot63191"],Dot63191,"Dot63191")

Actual (Unparsed): [[[0.8489019, 0.6547323], [0.8955061, 0.7933242], [0.2419544, -0.0527020]]]

Expected (Unparsed): [[[0.8489018720954487,0.6547322545712182],[0.895506097253022,0.7933242094136446],[0.2419544282429434,-0.05270204490960999]]]

Actual:   [[[0.849, 0.6548], [0.8956, 0.7934], [0.242, -0.0527]]]

Expected: [[[0.849, 0.6548], [0.8956, 0.7934], [0.242, -0.0527]]]