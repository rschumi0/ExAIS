import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave35502 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in1Ave35502 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in0Glo42749 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))

Ave35502 = keras.layers.Average(name = 'Ave35502', )([in0Ave35502,in1Ave35502])
Res76180 = keras.layers.Reshape((2, 2, 1), name = 'Res76180', )(Ave35502)
Res82733 = keras.layers.Reshape((2, 2), name = 'Res82733', )(Res76180)
Up_14034 = keras.layers.UpSampling1D(size=(2), name = 'Up_14034', )(Res82733)
Lea26679 = keras.layers.LeakyReLU(alpha=1.1041210470023948, name = 'Lea26679', )(Up_14034)
Glo90314 = keras.layers.GlobalMaxPool1D(name = 'Glo90314', )(Lea26679)
Glo42749 = keras.layers.GlobalAveragePooling3D(name = 'Glo42749', )(in0Glo42749)
Add78912 = keras.layers.Add(name = 'Add78912', )([Glo90314,Glo42749])
Res76384 = keras.layers.Reshape((2, 1), name = 'Res76384', )(Add78912)
Sim60064 = keras.layers.SimpleRNN(3,name = 'Sim60064', )(Res76384)
model = tf.keras.models.Model(inputs=[in0Ave35502,in1Ave35502,in0Glo42749], outputs=Sim60064)
w = model.get_layer('Sim60064').get_weights() 
w[0] = np.array([[9, 5, 4]])
w[1] = np.array([[7, 8, 8], [1, 7, 2], [3, 3, 7]])
w[2] = np.array([10, 3, 8])
model.get_layer('Sim60064').set_weights(w) 
in0Ave35502 = tf.constant([[[[[0.7563]], [[0.5334]]], [[[0.3179]], [[0.5027]]]]])
in1Ave35502 = tf.constant([[[[[0.0317]], [[0.8503]]], [[[0.1374]], [[0.1247]]]]])
in0Glo42749 = tf.constant([[[[[1.8448, 1.5386], [1.2765, 1.5076]]], [[[1.3601, 1.5532], [1.393, 1.3936]]]]])
print (np.array2string(model.predict([in0Ave35502,in1Ave35502,in0Glo42749],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sim60064.png')

LAve35502 = average_layer([[[[[[0.7563]], [[0.5334]]], [[[0.3179]], [[0.5027]]]]], [[[[[0.0317]], [[0.8503]]], [[[0.1374]], [[0.1247]]]]]], Ave35502), 
LRes76180 = reshape_layer(Ave35502, [2, 2, 1], Res76180), 
LRes82733 = reshape_layer(Res76180, [2, 2], Res82733), 
LUp_14034 = up_sampling1D_layer(Res82733, 2, Up_14034), 
LLea26679 = leaky_relu_layer(Up_14034, 1.1041210470023948, Lea26679), 
LGlo90314 = global_max_pool1D_layer(Lea26679, Glo90314), 
LGlo42749 = global_average_pooling3D_layer([[[[[1.8448, 1.5386], [1.2765, 1.5076]]], [[[1.3601, 1.5532], [1.393, 1.3936]]]]], Glo42749), 
LAdd78912 = add_layer([Glo90314,Glo42749], Add78912), 
LRes76384 = reshape_layer(Add78912, [2, 1], Res76384), 
LSim60064 = simple_rnn_layer(Res76384,[[9, 5, 4]],[[7, 8, 8], [1, 7, 2], [3, 3, 7]],[10, 3, 8], Sim60064), 
exec_layers([LAve35502,LRes76180,LRes82733,LUp_14034,LLea26679,LGlo90314,LGlo42749,LAdd78912,LRes76384,LSim60064],["Ave35502","Res76180","Res82733","Up_14034","Lea26679","Glo90314","Glo42749","Add78912","Res76384","Sim60064"],Sim60064,"Sim60064")

Actual (Unparsed): [[1.0000000, 1.0000000, 1.0000000]]

Expected (Unparsed): [[1.0,1.0,1.0]]

Actual:   [[1, 1, 1]]

Expected: [[1, 1, 1]]