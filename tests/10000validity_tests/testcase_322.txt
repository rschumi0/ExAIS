import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul44055 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in1Mul44055 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in0Con70162 = tf.keras.layers.Input(shape=([4, 2]))
in0Bat34973 = tf.keras.layers.Input(shape=([4, 4, 1]))
in0Max63861 = tf.keras.layers.Input(shape=([2, 2]))
in1Max63861 = tf.keras.layers.Input(shape=([2, 2]))
in0Con75297 = tf.keras.layers.Input(shape=([4, 2]))

Mul44055 = keras.layers.Multiply(name = 'Mul44055', )([in0Mul44055,in1Mul44055])
Res84716 = keras.layers.Reshape((2, 1, 2), name = 'Res84716', )(Mul44055)
Res56897 = keras.layers.Reshape((2, 2), name = 'Res56897', )(Res84716)
Zer32485 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer32485', )(Res56897)
Con70162 = keras.layers.Concatenate(axis=2, name = 'Con70162', )([Zer32485,in0Con70162])
Bat34973 = keras.layers.BatchNormalization(axis=3, epsilon=0.906558694665865,  name = 'Bat34973', )(in0Bat34973)
Res27580 = keras.layers.Reshape((4, 4), name = 'Res27580', )(Bat34973)
Max63861 = keras.layers.Maximum(name = 'Max63861', )([in0Max63861,in1Max63861])
Zer95710 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer95710', )(Max63861)
Con75297 = keras.layers.Concatenate(axis=2, name = 'Con75297', )([Zer95710,in0Con75297])
Add61555 = keras.layers.Add(name = 'Add61555', )([Res27580,Con75297])
Max93493 = keras.layers.Maximum(name = 'Max93493', )([Con70162,Add61555])
model = tf.keras.models.Model(inputs=[in0Mul44055,in1Mul44055,in0Con70162,in0Bat34973,in0Max63861,in1Max63861,in0Con75297], outputs=Max93493)
w = model.get_layer('Bat34973').get_weights() 
w[0] = np.array([0.3608])
w[1] = np.array([0.6005])
w[2] = np.array([0.8956])
w[3] = np.array([0.735])
model.get_layer('Bat34973').set_weights(w) 
in0Mul44055 = tf.constant([[[[[0.949], [0.9658]]], [[[0.1245], [0.4178]]]]])
in1Mul44055 = tf.constant([[[[[0.8306], [0.1955]]], [[[0.7195], [0.8054]]]]])
in0Con70162 = tf.constant([[[0.5008, 0.4147], [0.2975, 0.4126], [0.8071, 0.8812], [0.6543, 0.6233]]])
in0Bat34973 = tf.constant([[[[1.0783], [1.6541], [1.1764], [1.423]], [[1.7661], [1.8755], [1.7193], [1.1533]], [[1.2838], [1.2539], [1.5957], [1.7005]], [[1.4855], [1.7275], [1.8514], [1.5496]]]])
in0Max63861 = tf.constant([[[0.8033, 0.3025], [0.7835, 0.0109]]])
in1Max63861 = tf.constant([[[0.0914, 0.8313], [0.8243, 0.8304]]])
in0Con75297 = tf.constant([[[0.7789, 0.0761], [0.3757, 0.7242], [0.5235, 0.4588], [0.4477, 0.7616]]])
print (np.array2string(model.predict([in0Mul44055,in1Mul44055,in0Con70162,in0Bat34973,in0Max63861,in1Max63861,in0Con75297],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max93493.png')

LMul44055 = multiply_layer([[[[[[0.949], [0.9658]]], [[[0.1245], [0.4178]]]]], [[[[[0.8306], [0.1955]]], [[[0.7195], [0.8054]]]]]], Mul44055), 
LRes84716 = reshape_layer(Mul44055, [2, 1, 2], Res84716), 
LRes56897 = reshape_layer(Res84716, [2, 2], Res56897), 
LZer32485 = zero_padding1D_layer(Res56897, 2, 0, Zer32485), 
LCon70162 = concatenate_layer([Zer32485,[[[0.5008, 0.4147], [0.2975, 0.4126], [0.8071, 0.8812], [0.6543, 0.6233]]]], 2, Con70162), 
LBat34973 = batch_normalization_layer([[[[1.0783], [1.6541], [1.1764], [1.423]], [[1.7661], [1.8755], [1.7193], [1.1533]], [[1.2838], [1.2539], [1.5957], [1.7005]], [[1.4855], [1.7275], [1.8514], [1.5496]]]], 3, 0.906558694665865, [0.3608], [0.6005], [0.8956], [0.735], Bat34973), 
LRes27580 = reshape_layer(Bat34973, [4, 4], Res27580), 
LMax63861 = maximum_layer([[[[0.8033, 0.3025], [0.7835, 0.0109]]], [[[0.0914, 0.8313], [0.8243, 0.8304]]]], Max63861), 
LZer95710 = zero_padding1D_layer(Max63861, 2, 0, Zer95710), 
LCon75297 = concatenate_layer([Zer95710,[[[0.7789, 0.0761], [0.3757, 0.7242], [0.5235, 0.4588], [0.4477, 0.7616]]]], 2, Con75297), 
LAdd61555 = add_layer([Res27580,Con75297], Add61555), 
LMax93493 = maximum_layer([Con70162,Add61555], Max93493), 
exec_layers([LMul44055,LRes84716,LRes56897,LZer32485,LCon70162,LBat34973,LRes27580,LMax63861,LZer95710,LCon75297,LAdd61555,LMax93493],["Mul44055","Res84716","Res56897","Zer32485","Con70162","Bat34973","Res27580","Max63861","Zer95710","Con75297","Add61555","Max93493"],Max93493,"Max93493")

Actual (Unparsed): [[[0.6519490, 0.8140964, 1.4584743, 0.8251178], [0.8456360, 0.8764434, 1.2081570, 1.3972693], [1.5131186, 1.5326986, 1.3211508, 1.2859628], [1.5909180, 1.6651661, 1.3173568, 1.5462688]]]

Expected (Unparsed): [[[0.6519489917589987,0.8140963888845127,1.4584743124571804,0.8251177791663706],[0.8456360006907956,0.8764434429372896,1.2081569486145989,1.3972692675221343],[1.5131185473499906,1.5326985974124205,1.321150734156951,1.285962799489973],[1.5909180089689836,1.6651660987647017,1.3173567943254019,1.5462688046545439]]]

Actual:   [[[0.652, 0.8141, 1.4585, 0.8252], [0.8457, 0.8765, 1.2082, 1.3973], [1.5132, 1.5327, 1.3212, 1.286], [1.591, 1.6652, 1.3174, 1.5463]]]

Expected: [[[0.652, 0.8141, 1.4585, 0.8252], [0.8457, 0.8765, 1.2082, 1.3973], [1.5132, 1.5327, 1.3212, 1.286], [1.591, 1.6652, 1.3174, 1.5463]]]