import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ReL45022 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0GRU2431 = tf.keras.layers.Input(shape=([2, 3]))
in0Con78006 = tf.keras.layers.Input(shape=([2]))

ReL45022 = keras.layers.ReLU(max_value=9.168357985370841, negative_slope=9.798034663719942, threshold=1.9488810892758945, name = 'ReL45022', input_shape=(1, 1, 2, 2))(in0ReL45022)
Res73625 = keras.layers.Reshape((1, 1, 4), name = 'Res73625', )(ReL45022)
Res209 = keras.layers.Reshape((1, 4), name = 'Res209', )(Res73625)
Fla61278 = keras.layers.Flatten(name = 'Fla61278', )(Res209)
GRU2431 = keras.layers.GRU(2,reset_after=True, recurrent_activation='sigmoid', name = 'GRU2431', )(in0GRU2431)
Con78006 = keras.layers.Concatenate(axis=1, name = 'Con78006', )([GRU2431,in0Con78006])
Sub90256 = keras.layers.Subtract(name = 'Sub90256', )([Fla61278,Con78006])
Res80514 = keras.layers.Reshape((4, 1), name = 'Res80514', )(Sub90256)
Max38451 = keras.layers.MaxPool1D(pool_size=(2), name = 'Max38451', )(Res80514)
model = tf.keras.models.Model(inputs=[in0ReL45022,in0GRU2431,in0Con78006], outputs=Max38451)
w = model.get_layer('GRU2431').get_weights() 
w[0] = np.array([[1, 6, 7, 8, 10, 1], [10, 8, 7, 1, 5, 9], [8, 5, 3, 8, 7, 1]])
w[1] = np.array([[1, 3, 10, 7, 2, 10], [8, 2, 2, 5, 2, 3]])
w[2] = np.array([[5, 3, 9, 9, 10, 6], [2, 7, 3, 4, 6, 7]])
model.get_layer('GRU2431').set_weights(w) 
in0ReL45022 = tf.constant([[[[[0.0781, 0.6488], [0.7068, 0.4766]]]]])
in0GRU2431 = tf.constant([[[3, 1, 8], [7, 2, 2]]])
in0Con78006 = tf.constant([[0.6407, 0.2081]])
print (np.array2string(model.predict([in0ReL45022,in0GRU2431,in0Con78006],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max38451.png')

LReL45022 = relu_layer([[[[[0.0781, 0.6488], [0.7068, 0.4766]]]]], 9.168357985370841, 9.798034663719942, 1.9488810892758945, ReL45022), 
LRes73625 = reshape_layer(ReL45022, [1, 1, 4], Res73625), 
LRes209 = reshape_layer(Res73625, [1, 4], Res209), 
LFla61278 = flatten_layer(Res209, Fla61278), 
LGRU2431 = gru_layer([[[3, 1, 8], [7, 2, 2]]],[[1, 6, 7, 8, 10, 1], [10, 8, 7, 1, 5, 9], [8, 5, 3, 8, 7, 1]],[[1, 3, 10, 7, 2, 10], [8, 2, 2, 5, 2, 3]],[[5, 3, 9, 9, 10, 6], [2, 7, 3, 4, 6, 7]], true, GRU2431), 
LCon78006 = concatenate_layer([GRU2431,[[0.6407, 0.2081]]], 1, Con78006), 
LSub90256 = subtract_layer(Fla61278,Con78006, Sub90256), 
LRes80514 = reshape_layer(Sub90256, [4, 1], Res80514), 
LMax38451 = max_pool1D_layer(Res80514, 2, Max38451), 
exec_layers([LReL45022,LRes73625,LRes209,LFla61278,LGRU2431,LCon78006,LSub90256,LRes80514,LMax38451],["ReL45022","Res73625","Res209","Fla61278","GRU2431","Con78006","Sub90256","Res80514","Max38451"],Max38451,"Max38451")

Actual (Unparsed): [[[-12.7382394], [-12.8106537]]]

Expected (Unparsed): [[[-12.738239578371996],[-12.810653567876239]]]

Actual:   [[[-12.7382], [-12.8106]]]

Expected: [[[-12.7382], [-12.8106]]]