import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo91366 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Fla69076 = tf.keras.layers.Input(shape=([4, 2]))
in0Con12331 = tf.keras.layers.Input(shape=([19]))

Glo91366 = keras.layers.GlobalMaxPool2D(name = 'Glo91366', )(in0Glo91366)
Res4638 = keras.layers.Reshape((1, 1), name = 'Res4638', )(Glo91366)
Res79207 = keras.layers.Reshape((1, 1, 1), name = 'Res79207', )(Res4638)
Res17334 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res17334', )(Res79207)
Zer27354 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer27354', )(Res17334)
Res86510 = keras.layers.Reshape((3, 3, 3), name = 'Res86510', )(Zer27354)
Res39576 = keras.layers.Reshape((3, 9), name = 'Res39576', )(Res86510)
Fla71508 = keras.layers.Flatten(name = 'Fla71508', )(Res39576)
Fla69076 = keras.layers.Flatten(name = 'Fla69076', )(in0Fla69076)
Con12331 = keras.layers.Concatenate(axis=1, name = 'Con12331', )([Fla69076,in0Con12331])
Ave51962 = keras.layers.Average(name = 'Ave51962', )([Fla71508,Con12331])
Res76216 = keras.layers.Reshape((27, 1), name = 'Res76216', )(Ave51962)
Up_71492 = keras.layers.UpSampling1D(size=(2), name = 'Up_71492', )(Res76216)
model = tf.keras.models.Model(inputs=[in0Glo91366,in0Fla69076,in0Con12331], outputs=Up_71492)
in0Glo91366 = tf.constant([[[[1.59]], [[1.8273]]]])
in0Fla69076 = tf.constant([[[1.4568, 1.2286], [1.9852, 1.944], [1.9754, 1.3988], [1.8345, 1.3819]]])
in0Con12331 = tf.constant([[0.3511, 0.3982, 0.179, 0.7929, 0.1053, 0.2563, 0.786, 0.448, 0.1452, 0.9137, 0.423, 0.6276, 0.7648, 0.7345, 0.789, 0.0817, 0.4007, 0.1969, 0.1175]])
print (np.array2string(model.predict([in0Glo91366,in0Fla69076,in0Con12331],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Up_71492.png')

LGlo91366 = global_max_pool2D_layer([[[[1.59]], [[1.8273]]]], Glo91366), 
LRes4638 = reshape_layer(Glo91366, [1, 1], Res4638), 
LRes79207 = reshape_layer(Res4638, [1, 1, 1], Res79207), 
LRes17334 = reshape_layer(Res79207, [1, 1, 1, 1], Res17334), 
LZer27354 = zero_padding3D_layer(Res17334, 1, 1, 1, 1, 1, 1, Zer27354), 
LRes86510 = reshape_layer(Zer27354, [3, 3, 3], Res86510), 
LRes39576 = reshape_layer(Res86510, [3, 9], Res39576), 
LFla71508 = flatten_layer(Res39576, Fla71508), 
LFla69076 = flatten_layer([[[1.4568, 1.2286], [1.9852, 1.944], [1.9754, 1.3988], [1.8345, 1.3819]]], Fla69076), 
LCon12331 = concatenate_layer([Fla69076,[[0.3511, 0.3982, 0.179, 0.7929, 0.1053, 0.2563, 0.786, 0.448, 0.1452, 0.9137, 0.423, 0.6276, 0.7648, 0.7345, 0.789, 0.0817, 0.4007, 0.1969, 0.1175]]], 1, Con12331), 
LAve51962 = average_layer([Fla71508,Con12331], Ave51962), 
LRes76216 = reshape_layer(Ave51962, [27, 1], Res76216), 
LUp_71492 = up_sampling1D_layer(Res76216, 2, Up_71492), 
exec_layers([LGlo91366,LRes4638,LRes79207,LRes17334,LZer27354,LRes86510,LRes39576,LFla71508,LFla69076,LCon12331,LAve51962,LRes76216,LUp_71492],["Glo91366","Res4638","Res79207","Res17334","Zer27354","Res86510","Res39576","Fla71508","Fla69076","Con12331","Ave51962","Res76216","Up_71492"],Up_71492,"Up_71492")

Actual (Unparsed): [[[0.7284000], [0.7284000], [0.6143000], [0.6143000], [0.9926000], [0.9926000], [0.9720000], [0.9720000], [0.9877000], [0.9877000], [0.6994000], [0.6994000], [0.9172500], [0.9172500], [0.6909500], [0.6909500], [0.1755500], [0.1755500], [0.1991000], [0.1991000], [0.0895000], [0.0895000], [0.3964500], [0.3964500], [0.0526500], [0.0526500], [1.0418000], [1.0418000], [0.3930000], [0.3930000], [0.2240000], [0.2240000], [0.0726000], [0.0726000], [0.4568500], [0.4568500], [0.2115000], [0.2115000], [0.3138000], [0.3138000], [0.3824000], [0.3824000], [0.3672500], [0.3672500], [0.3945000], [0.3945000], [0.0408500], [0.0408500], [0.2003500], [0.2003500], [0.0984500], [0.0984500], [0.0587500], [0.0587500]]]

Expected (Unparsed): [[[0.7284],[0.7284],[0.6143],[0.6143],[0.9926],[0.9926],[0.972],[0.972],[0.9877],[0.9877],[0.6994],[0.6994],[0.91725],[0.91725],[0.69095],[0.69095],[0.17555],[0.17555],[0.1991],[0.1991],[0.0895],[0.0895],[0.39645],[0.39645],[0.05265],[0.05265],[1.0417999999999998],[1.0417999999999998],[0.393],[0.393],[0.224],[0.224],[0.0726],[0.0726],[0.45685],[0.45685],[0.2115],[0.2115],[0.3138],[0.3138],[0.3824],[0.3824],[0.36725],[0.36725],[0.3945],[0.3945],[0.04085],[0.04085],[0.20035],[0.20035],[0.09845],[0.09845],[0.05875],[0.05875]]]

Actual:   [[[0.7284], [0.7284], [0.6143], [0.6143], [0.9926], [0.9926], [0.972], [0.972], [0.9877], [0.9877], [0.6994], [0.6994], [0.9173], [0.9173], [0.691], [0.691], [0.1756], [0.1756], [0.1991], [0.1991], [0.0895], [0.0895], [0.3965], [0.3965], [0.0527], [0.0527], [1.0418], [1.0418], [0.393], [0.393], [0.224], [0.224], [0.0726], [0.0726], [0.4569], [0.4569], [0.2115], [0.2115], [0.3138], [0.3138], [0.3824], [0.3824], [0.3673], [0.3673], [0.3945], [0.3945], [0.0409], [0.0409], [0.2004], [0.2004], [0.0985], [0.0985], [0.0588], [0.0588]]]

Expected: [[[0.7284], [0.7284], [0.6143], [0.6143], [0.9926], [0.9926], [0.972], [0.972], [0.9877], [0.9877], [0.6994], [0.6994], [0.9173], [0.9173], [0.691], [0.691], [0.1756], [0.1756], [0.1991], [0.1991], [0.0895], [0.0895], [0.3965], [0.3965], [0.0527], [0.0527], [1.0418], [1.0418], [0.393], [0.393], [0.224], [0.224], [0.0726], [0.0726], [0.4569], [0.4569], [0.2115], [0.2115], [0.3138], [0.3138], [0.3824], [0.3824], [0.3673], [0.3673], [0.3945], [0.3945], [0.0409], [0.0409], [0.2004], [0.2004], [0.0985], [0.0985], [0.0588], [0.0588]]]