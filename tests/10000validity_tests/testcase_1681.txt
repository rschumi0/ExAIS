import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer24791 = tf.keras.layers.Input(shape=([1, 1]))
in0Mul21130 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Mul21130 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con11650 = tf.keras.layers.Input(shape=([9, 3, 1]))

Zer24791 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer24791', )(in0Zer24791)
Res81752 = keras.layers.Reshape((3, 1, 1), name = 'Res81752', )(Zer24791)
Res85354 = keras.layers.Reshape((3, 1, 1, 1), name = 'Res85354', )(Res81752)
Con54567 = keras.layers.Conv3DTranspose(3, (2, 1, 1),strides=(3, 1, 1), padding='valid', name = 'Con54567', )(Res85354)
Res36726 = keras.layers.Reshape((9, 1, 3), name = 'Res36726', )(Con54567)
Zer12970 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer12970', )(Res36726)
Mul21130 = keras.layers.Multiply(name = 'Mul21130', )([in0Mul21130,in1Mul21130])
Zer9041 = keras.layers.ZeroPadding2D(padding=((7, 0), (1, 0)), name = 'Zer9041', )(Mul21130)
Con11650 = keras.layers.Concatenate(axis=3, name = 'Con11650', )([Zer9041,in0Con11650])
Sub69895 = keras.layers.Subtract(name = 'Sub69895', )([Zer12970,Con11650])
model = tf.keras.models.Model(inputs=[in0Zer24791,in0Mul21130,in1Mul21130,in0Con11650], outputs=Sub69895)
w = model.get_layer('Con54567').get_weights() 
w[0] = np.array([[[[[0.3976], [0.7964], [0.1083]]]], [[[[0.4131], [0.7335], [0.4609]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con54567').set_weights(w) 
in0Zer24791 = tf.constant([[[1.7227]]])
in0Mul21130 = tf.constant([[[[0.185, 0.0455], [0.2158, 0.4806]], [[0.3876, 0.5302], [0.3027, 0.6041]]]])
in1Mul21130 = tf.constant([[[[0.3565, 0.469], [0.1334, 0.9183]], [[0.2043, 0.6802], [0.2531, 0.5427]]]])
in0Con11650 = tf.constant([[[[0.1518], [0.6043], [0.8226]], [[0.8388], [0.8232], [0.0454]], [[0.6254], [0.684], [0.1537]], [[0.9483], [0.3792], [0.0151]], [[0.5122], [0.4921], [0.7098]], [[0.4745], [0.6532], [0.8645]], [[0.6038], [0.6909], [0.8285]], [[0.6286], [0.7382], [0.3405]], [[0.0712], [0.5931], [0.7814]]]])
print (np.array2string(model.predict([in0Zer24791,in0Mul21130,in1Mul21130,in0Con11650],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub69895.png')

LZer24791 = zero_padding1D_layer([[[1.7227]]], 1, 1, Zer24791), 
LRes81752 = reshape_layer(Zer24791, [3, 1, 1], Res81752), 
LRes85354 = reshape_layer(Res81752, [3, 1, 1, 1], Res85354), 
LCon54567 = conv3D_transpose_layer(Res85354, 2, 1, 1,[[[[[0.3976], [0.7964], [0.1083]]]], [[[[0.4131], [0.7335], [0.4609]]]]],[0, 0, 0], 3, 1, 1, false, Con54567), 
LRes36726 = reshape_layer(Con54567, [9, 1, 3], Res36726), 
LZer12970 = zero_padding2D_layer(Res36726, 0, 0, 2, 0, Zer12970), 
LMul21130 = multiply_layer([[[[[0.185, 0.0455], [0.2158, 0.4806]], [[0.3876, 0.5302], [0.3027, 0.6041]]]], [[[[0.3565, 0.469], [0.1334, 0.9183]], [[0.2043, 0.6802], [0.2531, 0.5427]]]]], Mul21130), 
LZer9041 = zero_padding2D_layer(Mul21130, 7, 0, 1, 0, Zer9041), 
LCon11650 = concatenate_layer([Zer9041,[[[[0.1518], [0.6043], [0.8226]], [[0.8388], [0.8232], [0.0454]], [[0.6254], [0.684], [0.1537]], [[0.9483], [0.3792], [0.0151]], [[0.5122], [0.4921], [0.7098]], [[0.4745], [0.6532], [0.8645]], [[0.6038], [0.6909], [0.8285]], [[0.6286], [0.7382], [0.3405]], [[0.0712], [0.5931], [0.7814]]]]], 3, Con11650), 
LSub69895 = subtract_layer(Zer12970,Con11650, Sub69895), 
exec_layers([LZer24791,LRes81752,LRes85354,LCon54567,LRes36726,LZer12970,LMul21130,LZer9041,LCon11650,LSub69895],["Zer24791","Res81752","Res85354","Con54567","Res36726","Zer12970","Mul21130","Zer9041","Con11650","Sub69895"],Sub69895,"Sub69895")

Actual (Unparsed): [[[[0.0000000, 0.0000000, -0.1518000], [0.0000000, 0.0000000, -0.6043000], [0.0000000, 0.0000000, -0.8226000]], [[0.0000000, 0.0000000, -0.8388000], [0.0000000, 0.0000000, -0.8232000], [0.0000000, 0.0000000, -0.0454000]], [[0.0000000, 0.0000000, -0.6254000], [0.0000000, 0.0000000, -0.6840000], [0.0000000, 0.0000000, -0.1537000]], [[0.0000000, 0.0000000, -0.9483000], [0.0000000, 0.0000000, -0.3792000], [0.6849455, 1.3719583, 0.1714684]], [[0.0000000, 0.0000000, -0.5122000], [0.0000000, 0.0000000, -0.4921000], [0.7116474, 1.2636004, 0.0841924]], [[0.0000000, 0.0000000, -0.4745000], [0.0000000, 0.0000000, -0.6532000], [0.0000000, 0.0000000, -0.8645000]], [[0.0000000, 0.0000000, -0.6038000], [0.0000000, 0.0000000, -0.6909000], [0.0000000, 0.0000000, -0.8285000]], [[0.0000000, 0.0000000, -0.6286000], [-0.0659525, -0.0213395, -0.7382000], [-0.0287877, -0.4413350, -0.3405000]], [[0.0000000, 0.0000000, -0.0712000], [-0.0791867, -0.3606420, -0.5931000], [-0.0766134, -0.3278451, -0.7814000]]]]

Expected (Unparsed): [[[[0,0,-0.1518],[0,0,-0.6043],[0.0,0.0,-0.8226]],[[0,0,-0.8388],[0,0,-0.8232],[0.0,0.0,-0.0454]],[[0,0,-0.6254],[0,0,-0.684],[0,0,-0.1537]],[[0,0,-0.9483],[0,0,-0.3792],[0.68494552,1.3719582799999999,0.17146841]],[[0,0,-0.5122],[0,0,-0.4921],[0.71164737,1.26360045,0.08419242999999987]],[[0,0,-0.4745],[0,0,-0.6532],[0,0,-0.8645]],[[0,0,-0.6038],[0,0,-0.6909],[0.0,0.0,-0.8285]],[[0,0,-0.6286],[-0.0659525,-0.021339499999999997,-0.7382],[-0.028787719999999996,-0.44133498000000004,-0.3405]],[[0,0,-0.0712],[-0.07918668000000001,-0.36064204,-0.5931],[-0.07661337,-0.32784506999999996,-0.7814]]]]

Actual:   [[[[0, 0, -0.1518], [0, 0, -0.6043], [0, 0, -0.8226]], [[0, 0, -0.8388], [0, 0, -0.8232], [0, 0, -0.0454]], [[0, 0, -0.6254], [0, 0, -0.684], [0, 0, -0.1537]], [[0, 0, -0.9483], [0, 0, -0.3792], [0.685, 1.372, 0.1715]], [[0, 0, -0.5122], [0, 0, -0.4921], [0.7117, 1.2637, 0.0842]], [[0, 0, -0.4745], [0, 0, -0.6532], [0, 0, -0.8645]], [[0, 0, -0.6038], [0, 0, -0.6909], [0, 0, -0.8285]], [[0, 0, -0.6286], [-0.0659, -0.0213, -0.7382], [-0.0287, -0.4413, -0.3405]], [[0, 0, -0.0712], [-0.0791, -0.3606, -0.5931], [-0.0766, -0.3278, -0.7814]]]]

Expected: [[[[0, 0, -0.1518], [0, 0, -0.6043], [0, 0, -0.8226]], [[0, 0, -0.8388], [0, 0, -0.8232], [0, 0, -0.0454]], [[0, 0, -0.6254], [0, 0, -0.684], [0, 0, -0.1537]], [[0, 0, -0.9483], [0, 0, -0.3792], [0.685, 1.372, 0.1715]], [[0, 0, -0.5122], [0, 0, -0.4921], [0.7117, 1.2637, 0.0842]], [[0, 0, -0.4745], [0, 0, -0.6532], [0, 0, -0.8645]], [[0, 0, -0.6038], [0, 0, -0.6909], [0, 0, -0.8285]], [[0, 0, -0.6286], [-0.0659, -0.0213, -0.7382], [-0.0287, -0.4413, -0.3405]], [[0, 0, -0.0712], [-0.0791, -0.3606, -0.5931], [-0.0766, -0.3278, -0.7814]]]]