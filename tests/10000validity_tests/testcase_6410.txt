import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub83171 = tf.keras.layers.Input(shape=([2, 2, 3, 2]))
in1Sub83171 = tf.keras.layers.Input(shape=([2, 2, 3, 2]))
in0Den59476 = tf.keras.layers.Input(shape=([5, 5]))
in0Con73473 = tf.keras.layers.Input(shape=([5, 10]))

Sub83171 = keras.layers.Subtract(name = 'Sub83171', )([in0Sub83171,in1Sub83171])
Res68794 = keras.layers.Reshape((2, 2, 6), name = 'Res68794', )(Sub83171)
Res88551 = keras.layers.Reshape((2, 12), name = 'Res88551', )(Res68794)
Zer49442 = keras.layers.ZeroPadding1D(padding=((3, 0)), name = 'Zer49442', )(Res88551)
Den59476 = keras.layers.Dense(2,name = 'Den59476', )(in0Den59476)
PRe58788 = keras.layers.PReLU(name = 'PRe58788', )(Den59476)
PRe13136 = keras.layers.PReLU(name = 'PRe13136', )(PRe58788)
Con73473 = keras.layers.Concatenate(axis=2, name = 'Con73473', )([PRe13136,in0Con73473])
Max97701 = keras.layers.Maximum(name = 'Max97701', )([Zer49442,Con73473])
model = tf.keras.models.Model(inputs=[in0Sub83171,in1Sub83171,in0Den59476,in0Con73473], outputs=Max97701)
w = model.get_layer('Den59476').get_weights() 
w[0] = np.array([[0.0748, 0.1224], [0.3966, 0.0271], [0.0735, 0.5059], [0.422, 0.2135], [0.7549, 0.1644]])
w[1] = np.array([0.5498, 0.8354])
model.get_layer('Den59476').set_weights(w) 
w = model.get_layer('PRe58788').get_weights() 
w[0] = np.array([[0.2421, 0.4701], [0.8875, 0.9605], [0.2446, 0.6708], [0.011, 0.7882], [0.4965, 0.2536]])
model.get_layer('PRe58788').set_weights(w) 
w = model.get_layer('PRe13136').get_weights() 
w[0] = np.array([[0.5476, 0.9238], [0.1764, 0.1077], [0.8581, 0.8316], [0.6387, 0.3173], [0.0533, 0.8041]])
model.get_layer('PRe13136').set_weights(w) 
in0Sub83171 = tf.constant([[[[[0.7386, 0.5907], [0.352, 0.7633], [0.5391, 0.4934]], [[0.8673, 0.3994], [0.1557, 0.2469], [0.8583, 0.393]]], [[[0.6408, 0.4003], [0.5063, 0.7908], [0.6954, 0.1925]], [[0.1473, 0.8429], [0.7161, 0.0066], [0.4249, 0.0939]]]]])
in1Sub83171 = tf.constant([[[[[0.5237, 0.3611], [0.8356, 0.0746], [0.086, 0.9359]], [[0.4872, 0.7118], [0.5731, 0.1928], [0.0576, 0.4035]]], [[[0.6403, 0.9932], [0.1365, 0.8173], [0.9157, 0.247]], [[0.362, 0.8598], [0.2954, 0.0264], [0.0198, 0.9401]]]]])
in0Den59476 = tf.constant([[[0.7903, 0.7745, 0.0663, 0.6035, 0.3568], [0.2025, 0.8549, 0.8445, 0.3488, 0.2226], [0.1994, 0.9303, 0.9779, 0.7972, 0.7926], [0.3583, 0.4375, 0.8953, 0.41, 0.6522], [0.1565, 0.8446, 0.7791, 0.0641, 0.9818]]])
in0Con73473 = tf.constant([[[0.1837, 0.2127, 0.7818, 0.184, 0.8491, 0.9695, 0.2561, 0.3538, 0.1623, 0.697], [0.3585, 0.7844, 0.0751, 0.2726, 0.7594, 0.0271, 0.672, 0.0866, 0.1239, 0.4783], [0.6349, 0.9501, 0.0223, 0.6853, 0.3462, 0.8091, 0.0376, 0.5742, 0.3784, 0.388], [0.6139, 0.6933, 0.3416, 0.2713, 0.8043, 0.9731, 0.3212, 0.6098, 0.2322, 0.6896], [0.4291, 0.5887, 0.2541, 0.2916, 0.3096, 0.0317, 0.53, 0.4998, 0.7974, 0.0311]]])
print (np.array2string(model.predict([in0Sub83171,in1Sub83171,in0Den59476,in0Con73473],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max97701.png')

LSub83171 = subtract_layer([[[[[0.7386, 0.5907], [0.352, 0.7633], [0.5391, 0.4934]], [[0.8673, 0.3994], [0.1557, 0.2469], [0.8583, 0.393]]], [[[0.6408, 0.4003], [0.5063, 0.7908], [0.6954, 0.1925]], [[0.1473, 0.8429], [0.7161, 0.0066], [0.4249, 0.0939]]]]], [[[[[0.5237, 0.3611], [0.8356, 0.0746], [0.086, 0.9359]], [[0.4872, 0.7118], [0.5731, 0.1928], [0.0576, 0.4035]]], [[[0.6403, 0.9932], [0.1365, 0.8173], [0.9157, 0.247]], [[0.362, 0.8598], [0.2954, 0.0264], [0.0198, 0.9401]]]]], Sub83171), 
LRes68794 = reshape_layer(Sub83171, [2, 2, 6], Res68794), 
LRes88551 = reshape_layer(Res68794, [2, 12], Res88551), 
LZer49442 = zero_padding1D_layer(Res88551, 3, 0, Zer49442), 
LDen59476 = dense_layer([[[0.7903, 0.7745, 0.0663, 0.6035, 0.3568], [0.2025, 0.8549, 0.8445, 0.3488, 0.2226], [0.1994, 0.9303, 0.9779, 0.7972, 0.7926], [0.3583, 0.4375, 0.8953, 0.41, 0.6522], [0.1565, 0.8446, 0.7791, 0.0641, 0.9818]]], [[0.0748, 0.1224], [0.3966, 0.0271], [0.0735, 0.5059], [0.422, 0.2135], [0.7549, 0.1644]],[0.5498, 0.8354], Den59476), 
LPRe58788 = prelu_layer(Den59476, [[0.2421, 0.4701], [0.8875, 0.9605], [0.2446, 0.6708], [0.011, 0.7882], [0.4965, 0.2536]], PRe58788), 
LPRe13136 = prelu_layer(PRe58788, [[0.5476, 0.9238], [0.1764, 0.1077], [0.8581, 0.8316], [0.6387, 0.3173], [0.0533, 0.8041]], PRe13136), 
LCon73473 = concatenate_layer([PRe13136,[[[0.1837, 0.2127, 0.7818, 0.184, 0.8491, 0.9695, 0.2561, 0.3538, 0.1623, 0.697], [0.3585, 0.7844, 0.0751, 0.2726, 0.7594, 0.0271, 0.672, 0.0866, 0.1239, 0.4783], [0.6349, 0.9501, 0.0223, 0.6853, 0.3462, 0.8091, 0.0376, 0.5742, 0.3784, 0.388], [0.6139, 0.6933, 0.3416, 0.2713, 0.8043, 0.9731, 0.3212, 0.6098, 0.2322, 0.6896], [0.4291, 0.5887, 0.2541, 0.2916, 0.3096, 0.0317, 0.53, 0.4998, 0.7974, 0.0311]]]], 2, Con73473), 
LMax97701 = maximum_layer([Zer49442,Con73473], Max97701), 
exec_layers([LSub83171,LRes68794,LRes88551,LZer49442,LDen59476,LPRe58788,LPRe13136,LCon73473,LMax97701],["Sub83171","Res68794","Res88551","Zer49442","Den59476","PRe58788","PRe13136","Con73473","Max97701"],Max97701,"Max97701")

Actual (Unparsed): [[[1.4449795, 1.1741680, 0.1837000, 0.2127000, 0.7818000, 0.1840000, 0.8491000, 0.9695000, 0.2561000, 0.3538000, 0.1623000, 0.6970000], [1.2813054, 1.4216506, 0.3585000, 0.7844000, 0.0751000, 0.2726000, 0.7594000, 0.0271000, 0.6720000, 0.0866000, 0.1239000, 0.4783000], [1.9402999, 1.6802430, 0.6349000, 0.9501000, 0.0223000, 0.6853000, 0.3462000, 0.8091000, 0.0376000, 0.5742000, 0.3784000, 0.3880000], [1.4812837, 1.5388011, 0.6139000, 0.6933000, 0.4531000, 0.2713000, 0.8043000, 0.9731000, 0.3212000, 0.6098000, 0.8007000, 0.6896000], [1.7219495, 1.4466842, 0.4291000, 0.5887000, 0.2541000, 0.2916000, 0.3096000, 0.0317000, 0.5300000, 0.4998000, 0.7974000, 0.0311000]]]

Expected (Unparsed): [[[1.44497951,1.17416801,0.1837,0.2127,0.7818,0.184,0.8491,0.9695,0.2561,0.3538,0.1623,0.697],[1.2813054299999997,1.4216505799999999,0.3585,0.7844,0.0751,0.2726,0.7594,0.0271,0.672,0.0866,0.1239,0.4783],[1.9402998899999997,1.68024294,0.6349,0.9501,0.0223,0.6853,0.3462,0.8091,0.0376,0.5742,0.3784,0.388],[1.4812836699999998,1.5388011200000002,0.6139,0.6933,0.45310000000000006,0.2713,0.8043,0.9731,0.3212,0.6098,0.8007,0.6896],[1.72194943,1.4466842200000003,0.4291,0.5887,0.2541,0.2916,0.3096,0.0317,0.53,0.4998,0.7974,0.0311]]]

Actual:   [[[1.445, 1.1742, 0.1837, 0.2127, 0.7818, 0.184, 0.8491, 0.9695, 0.2561, 0.3538, 0.1623, 0.697], [1.2814, 1.4217, 0.3585, 0.7844, 0.0751, 0.2726, 0.7594, 0.0271, 0.672, 0.0866, 0.1239, 0.4783], [1.9403, 1.6803, 0.6349, 0.9501, 0.0223, 0.6853, 0.3462, 0.8091, 0.0376, 0.5742, 0.3784, 0.388], [1.4813, 1.5389, 0.6139, 0.6933, 0.4531, 0.2713, 0.8043, 0.9731, 0.3212, 0.6098, 0.8007, 0.6896], [1.722, 1.4467, 0.4291, 0.5887, 0.2541, 0.2916, 0.3096, 0.0317, 0.53, 0.4998, 0.7974, 0.0311]]]

Expected: [[[1.445, 1.1742, 0.1837, 0.2127, 0.7818, 0.184, 0.8491, 0.9695, 0.2561, 0.3538, 0.1623, 0.697], [1.2814, 1.4217, 0.3585, 0.7844, 0.0751, 0.2726, 0.7594, 0.0271, 0.672, 0.0866, 0.1239, 0.4783], [1.9403, 1.6803, 0.6349, 0.9501, 0.0223, 0.6853, 0.3462, 0.8091, 0.0376, 0.5742, 0.3784, 0.388], [1.4813, 1.5389, 0.6139, 0.6933, 0.4532, 0.2713, 0.8043, 0.9731, 0.3212, 0.6098, 0.8007, 0.6896], [1.722, 1.4467, 0.4291, 0.5887, 0.2541, 0.2916, 0.3096, 0.0317, 0.53, 0.4998, 0.7974, 0.0311]]]