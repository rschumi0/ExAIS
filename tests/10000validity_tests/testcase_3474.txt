import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat90347 = tf.keras.layers.Input(shape=([1, 3]))
in0Add63095 = tf.keras.layers.Input(shape=([1, 2]))
in1Add63095 = tf.keras.layers.Input(shape=([1, 2]))
in0Con91499 = tf.keras.layers.Input(shape=([1, 1]))
in0GRU43002 = tf.keras.layers.Input(shape=([3, 1]))

Bat90347 = keras.layers.BatchNormalization(axis=1, epsilon=0.6751064698634263,  name = 'Bat90347', )(in0Bat90347)
Add63095 = keras.layers.Add(name = 'Add63095', )([in0Add63095,in1Add63095])
Con91499 = keras.layers.Concatenate(axis=2, name = 'Con91499', )([Add63095,in0Con91499])
Sub21370 = keras.layers.Subtract(name = 'Sub21370', )([Bat90347,Con91499])
Res95296 = keras.layers.Reshape((1, 3, 1), name = 'Res95296', )(Sub21370)
Res85655 = keras.layers.Reshape((1, 3, 1, 1), name = 'Res85655', )(Res95296)
Zer68215 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer68215', )(Res85655)
Res69995 = keras.layers.Reshape((3, 5, 3), name = 'Res69995', )(Zer68215)
Glo27110 = keras.layers.GlobalAveragePooling2D(name = 'Glo27110', )(Res69995)
Res2266 = keras.layers.Reshape((3, 1), name = 'Res2266', )(Glo27110)
Sim5936 = keras.layers.SimpleRNN(1,name = 'Sim5936', )(Res2266)
GRU43002 = keras.layers.GRU(3,reset_after=False, recurrent_activation='sigmoid', name = 'GRU43002', )(in0GRU43002)
Res18225 = keras.layers.Reshape((3, 1), name = 'Res18225', )(GRU43002)
Glo56702 = keras.layers.GlobalMaxPool1D(name = 'Glo56702', )(Res18225)
Min55810 = keras.layers.Minimum(name = 'Min55810', )([Sim5936,Glo56702])
model = tf.keras.models.Model(inputs=[in0Bat90347,in0Add63095,in1Add63095,in0Con91499,in0GRU43002], outputs=Min55810)
w = model.get_layer('Bat90347').get_weights() 
w[0] = np.array([0.3271])
w[1] = np.array([0.159])
w[2] = np.array([0.5828])
w[3] = np.array([0.0959])
model.get_layer('Bat90347').set_weights(w) 
w = model.get_layer('Sim5936').get_weights() 
w[0] = np.array([[8]])
w[1] = np.array([[3]])
w[2] = np.array([8])
model.get_layer('Sim5936').set_weights(w) 
w = model.get_layer('GRU43002').get_weights() 
w[0] = np.array([[10, 1, 3, 3, 10, 2, 3, 8, 6]])
w[1] = np.array([[4, 3, 9, 2, 3, 8, 10, 7, 4], [1, 10, 7, 7, 9, 5, 8, 7, 5], [1, 2, 9, 8, 5, 8, 8, 9, 3]])
w[2] = np.array([7, 9, 10, 9, 6, 3, 4, 6, 4])
model.get_layer('GRU43002').set_weights(w) 
in0Bat90347 = tf.constant([[[1.6371, 1.9775, 1.9643]]])
in0Add63095 = tf.constant([[[0.8075, 0.011]]])
in1Add63095 = tf.constant([[[0.3452, 0.733]]])
in0Con91499 = tf.constant([[[0.4915]]])
in0GRU43002 = tf.constant([[[7], [6], [3]]])
print (np.array2string(model.predict([in0Bat90347,in0Add63095,in1Add63095,in0Con91499,in0GRU43002],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min55810.png')

LBat90347 = batch_normalization_layer([[[1.6371, 1.9775, 1.9643]]], 1, 0.6751064698634263, [0.3271], [0.159], [0.5828], [0.0959], Bat90347), 
LAdd63095 = add_layer([[[[0.8075, 0.011]]], [[[0.3452, 0.733]]]], Add63095), 
LCon91499 = concatenate_layer([Add63095,[[[0.4915]]]], 2, Con91499), 
LSub21370 = subtract_layer(Bat90347,Con91499, Sub21370), 
LRes95296 = reshape_layer(Sub21370, [1, 3, 1], Res95296), 
LRes85655 = reshape_layer(Res95296, [1, 3, 1, 1], Res85655), 
LZer68215 = zero_padding3D_layer(Res85655, 1, 1, 1, 1, 1, 1, Zer68215), 
LRes69995 = reshape_layer(Zer68215, [3, 5, 3], Res69995), 
LGlo27110 = global_average_pooling2D_layer(Res69995, Glo27110), 
LRes2266 = reshape_layer(Glo27110, [3, 1], Res2266), 
LSim5936 = simple_rnn_layer(Res2266,[[8]],[[3]],[8], Sim5936), 
LGRU43002 = gru_layer([[[7], [6], [3]]],[[10, 1, 3, 3, 10, 2, 3, 8, 6]],[[4, 3, 9, 2, 3, 8, 10, 7, 4], [1, 10, 7, 7, 9, 5, 8, 7, 5], [1, 2, 9, 8, 5, 8, 8, 9, 3]],[7, 9, 10, 9, 6, 3, 4, 6, 4], false, GRU43002), 
LRes18225 = reshape_layer(GRU43002, [3, 1], Res18225), 
LGlo56702 = global_max_pool1D_layer(Res18225, Glo56702), 
LMin55810 = minimum_layer([Sim5936,Glo56702], Min55810), 
exec_layers([LBat90347,LAdd63095,LCon91499,LSub21370,LRes95296,LRes85655,LZer68215,LRes69995,LGlo27110,LRes2266,LSim5936,LGRU43002,LRes18225,LGlo56702,LMin55810],["Bat90347","Add63095","Con91499","Sub21370","Res95296","Res85655","Zer68215","Res69995","Glo27110","Res2266","Sim5936","GRU43002","Res18225","Glo56702","Min55810"],Min55810,"Min55810")

Actual (Unparsed): [[0.0000066]]

Expected (Unparsed): [[6.562583332199969e-6]]

Actual:   [[0]]

Expected: [[0]]