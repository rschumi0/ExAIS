import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat65866 = tf.keras.layers.Input(shape=([1, 4]))
in0Sub56529 = tf.keras.layers.Input(shape=([3, 3]))
in1Sub56529 = tf.keras.layers.Input(shape=([3, 3]))

Bat65866 = keras.layers.BatchNormalization(axis=1, epsilon=0.1531870520531781,  name = 'Bat65866', )(in0Bat65866)
Con47008 = keras.layers.Conv1D(4, (1),strides=(1), padding='valid', dilation_rate=(1), name = 'Con47008', )(Bat65866)
Res24136 = keras.layers.Reshape((1, 4, 1), name = 'Res24136', )(Con47008)
Zer17554 = keras.layers.ZeroPadding2D(padding=((5, 0), (2, 0)), name = 'Zer17554', )(Res24136)
Sub56529 = keras.layers.Subtract(name = 'Sub56529', )([in0Sub56529,in1Sub56529])
ELU5453 = keras.layers.ELU(alpha=0.6620131908503808, name = 'ELU5453', )(Sub56529)
Res44111 = keras.layers.Reshape((3, 3, 1), name = 'Res44111', )(ELU5453)
Up_75749 = keras.layers.UpSampling2D(size=(2, 2), name = 'Up_75749', )(Res44111)
Max11484 = keras.layers.Maximum(name = 'Max11484', )([Zer17554,Up_75749])
model = tf.keras.models.Model(inputs=[in0Bat65866,in0Sub56529,in1Sub56529], outputs=Max11484)
w = model.get_layer('Bat65866').get_weights() 
w[0] = np.array([0.2612])
w[1] = np.array([0.537])
w[2] = np.array([0.3658])
w[3] = np.array([0.0639])
model.get_layer('Bat65866').set_weights(w) 
w = model.get_layer('Con47008').get_weights() 
w[0] = np.array([[[0.7521, 0.1486, 0.6353, 0.3172], [0.0386, 0.5377, 0.8964, 0.1292], [0.9596, 0.835, 0.3858, 0.1081], [0.2296, 0.7561, 0.1601, 0.1378]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con47008').set_weights(w) 
in0Bat65866 = tf.constant([[[1.4916, 1.6105, 1.9543, 1.7554]]])
in0Sub56529 = tf.constant([[[0.8205, 0.0085, 0.1283], [0.2888, 0.9847, 0.0964], [0.9507, 0.6164, 0.8452]]])
in1Sub56529 = tf.constant([[[0.0182, 0.5702, 0.5818], [0.1802, 0.9617, 0.636], [0.739, 0.4198, 0.2182]]])
print (np.array2string(model.predict([in0Bat65866,in0Sub56529,in1Sub56529],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max11484.png')

LBat65866 = batch_normalization_layer([[[1.4916, 1.6105, 1.9543, 1.7554]]], 1, 0.1531870520531781, [0.2612], [0.537], [0.3658], [0.0639], Bat65866), 
LCon47008 = conv1D_layer(Bat65866, 1,[[[0.7521, 0.1486, 0.6353, 0.3172], [0.0386, 0.5377, 0.8964, 0.1292], [0.9596, 0.835, 0.3858, 0.1081], [0.2296, 0.7561, 0.1601, 0.1378]]],[0, 0, 0, 0], 1, false, 1, Con47008), 
LRes24136 = reshape_layer(Con47008, [1, 4, 1], Res24136), 
LZer17554 = zero_padding2D_layer(Res24136, 5, 0, 2, 0, Zer17554), 
LSub56529 = subtract_layer([[[0.8205, 0.0085, 0.1283], [0.2888, 0.9847, 0.0964], [0.9507, 0.6164, 0.8452]]], [[[0.0182, 0.5702, 0.5818], [0.1802, 0.9617, 0.636], [0.739, 0.4198, 0.2182]]], Sub56529), 
LELU5453 = elu_layer(Sub56529, 0.6620131908503808, ELU5453), 
LRes44111 = reshape_layer(ELU5453, [3, 3, 1], Res44111), 
LUp_75749 = up_sampling2D_layer(Res44111, 2, 2, Up_75749), 
LMax11484 = maximum_layer([Zer17554,Up_75749], Max11484), 
exec_layers([LBat65866,LCon47008,LRes24136,LZer17554,LSub56529,LELU5453,LRes44111,LUp_75749,LMax11484],["Bat65866","Con47008","Res24136","Zer17554","Sub56529","ELU5453","Res44111","Up_75749","Max11484"],Max11484,"Max11484")

Actual (Unparsed): [[[[0.8023000], [0.8023000], [0.0000000], [0.0000000], [0.0000000], [0.0000000]], [[0.8023000], [0.8023000], [0.0000000], [0.0000000], [0.0000000], [0.0000000]], [[0.1086000], [0.1086000], [0.0230000], [0.0230000], [0.0000000], [0.0000000]], [[0.1086000], [0.1086000], [0.0230000], [0.0230000], [0.0000000], [0.0000000]], [[0.2117000], [0.2117000], [0.1966000], [0.1966000], [0.6270000], [0.6270000]], [[0.2117000], [0.2117000], [2.5982166], [3.0245451], [2.6104030], [0.8657261]]]]

Expected (Unparsed): [[[[0.8023],[0.8023],[0],[0],[0],[0]],[[0.8023],[0.8023],[0],[0],[0],[0]],[[0.1086],[0.1086],[0.02300000000000002],[0.02300000000000002],[0],[0]],[[0.1086],[0.1086],[0.02300000000000002],[0.02300000000000002],[0],[0]],[[0.2117],[0.2117],[0.19659999999999994],[0.19659999999999994],[0.627],[0.627]],[[0.2117],[0.2117],[2.598216566049709],[3.0245450755103698],[2.6104030310494837],[0.8657260494830806]]]]

Actual:   [[[[0.8023], [0.8023], [0], [0], [0], [0]], [[0.8023], [0.8023], [0], [0], [0], [0]], [[0.1086], [0.1086], [0.023], [0.023], [0], [0]], [[0.1086], [0.1086], [0.023], [0.023], [0], [0]], [[0.2117], [0.2117], [0.1966], [0.1966], [0.627], [0.627]], [[0.2117], [0.2117], [2.5983], [3.0246], [2.6105], [0.8658]]]]

Expected: [[[[0.8023], [0.8023], [0], [0], [0], [0]], [[0.8023], [0.8023], [0], [0], [0], [0]], [[0.1086], [0.1086], [0.0231], [0.0231], [0], [0]], [[0.1086], [0.1086], [0.0231], [0.0231], [0], [0]], [[0.2117], [0.2117], [0.1966], [0.1966], [0.627], [0.627]], [[0.2117], [0.2117], [2.5983], [3.0246], [2.6105], [0.8658]]]]