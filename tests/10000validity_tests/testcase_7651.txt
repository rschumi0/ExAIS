import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sim55193 = tf.keras.layers.Input(shape=([1, 2]))
in0Sub5039 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Sub5039 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))

Sim55193 = keras.layers.SimpleRNN(1,name = 'Sim55193', )(in0Sim55193)
Res9078 = keras.layers.Reshape((1, 1), name = 'Res9078', )(Sim55193)
Zer92840 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer92840', )(Res9078)
Sub5039 = keras.layers.Subtract(name = 'Sub5039', )([in0Sub5039,in1Sub5039])
Res87234 = keras.layers.Reshape((2, 2, 4), name = 'Res87234', )(Sub5039)
Res41534 = keras.layers.Reshape((2, 8), name = 'Res41534', )(Res87234)
Dot95397 = keras.layers.Dot(axes=(1, 1), name = 'Dot95397', )([Zer92840,Res41534])
Ave70430 = keras.layers.AveragePooling1D(pool_size=(1), strides=(1), padding='valid', name = 'Ave70430', )(Dot95397)
model = tf.keras.models.Model(inputs=[in0Sim55193,in0Sub5039,in1Sub5039], outputs=Ave70430)
w = model.get_layer('Sim55193').get_weights() 
w[0] = np.array([[4], [8]])
w[1] = np.array([[2]])
w[2] = np.array([8])
model.get_layer('Sim55193').set_weights(w) 
in0Sim55193 = tf.constant([[[5, 1]]])
in0Sub5039 = tf.constant([[[[[0.5286, 0.908], [0.0644, 0.4958]], [[0.3028, 0.8231], [0.2452, 0.7136]]], [[[0.7829, 0.898], [0.7106, 0.1229]], [[0.1303, 0.573], [0.3984, 0.754]]]]])
in1Sub5039 = tf.constant([[[[[0.1023, 0.7359], [0.2967, 0.9257]], [[0.8205, 0.9777], [0.6625, 0.1891]]], [[[0.3924, 0.5933], [0.7501, 0.7299]], [[0.8214, 0.7182], [0.3754, 0.2302]]]]])
print (np.array2string(model.predict([in0Sim55193,in0Sub5039,in1Sub5039],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave70430.png')

LSim55193 = simple_rnn_layer([[[5, 1]]],[[4], [8]],[[2]],[8], Sim55193), 
LRes9078 = reshape_layer(Sim55193, [1, 1], Res9078), 
LZer92840 = zero_padding1D_layer(Res9078, 1, 0, Zer92840), 
LSub5039 = subtract_layer([[[[[0.5286, 0.908], [0.0644, 0.4958]], [[0.3028, 0.8231], [0.2452, 0.7136]]], [[[0.7829, 0.898], [0.7106, 0.1229]], [[0.1303, 0.573], [0.3984, 0.754]]]]], [[[[[0.1023, 0.7359], [0.2967, 0.9257]], [[0.8205, 0.9777], [0.6625, 0.1891]]], [[[0.3924, 0.5933], [0.7501, 0.7299]], [[0.8214, 0.7182], [0.3754, 0.2302]]]]], Sub5039), 
LRes87234 = reshape_layer(Sub5039, [2, 2, 4], Res87234), 
LRes41534 = reshape_layer(Res87234, [2, 8], Res41534), 
LDot95397 = dot_layer(Zer92840,Res41534, 1, 1, Dot95397), 
LAve70430 = average_pooling1D_layer(Dot95397, 1, 1, false, Ave70430), 
exec_layers([LSim55193,LRes9078,LZer92840,LSub5039,LRes87234,LRes41534,LDot95397,LAve70430],["Sim55193","Res9078","Zer92840","Sub5039","Res87234","Res41534","Dot95397","Ave70430"],Ave70430,"Ave70430")

Actual (Unparsed): [[[0.3905000, 0.3047000, -0.0395000, -0.6070000, -0.6911000, -0.1452000, 0.0230000, 0.5238000]]]

Expected (Unparsed): [[[0.3905,0.30469999999999997,-0.03949999999999998,-0.607,-0.6911,-0.1452,0.022999999999999965,0.5238]]]

Actual:   [[[0.3905, 0.3047, -0.0395, -0.607, -0.6911, -0.1452, 0.023, 0.5238]]]

Expected: [[[0.3905, 0.3047, -0.0394, -0.607, -0.6911, -0.1452, 0.023, 0.5238]]]