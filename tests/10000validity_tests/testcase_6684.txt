import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat89528 = tf.keras.layers.Input(shape=([3]))
in0Con14531 = tf.keras.layers.Input(shape=([3, 1]))
in0Dot76075 = tf.keras.layers.Input(shape=([2, 2]))
in1Dot76075 = tf.keras.layers.Input(shape=([2, 2]))

Bat89528 = keras.layers.BatchNormalization(axis=1, epsilon=0.36272624090780337,  name = 'Bat89528', )(in0Bat89528)
Res61342 = keras.layers.Reshape((3, 1), name = 'Res61342', )(Bat89528)
Con14531 = keras.layers.Concatenate(axis=2, name = 'Con14531', )([Res61342,in0Con14531])
Dot76075 = keras.layers.Dot(axes=(2, 1), name = 'Dot76075', )([in0Dot76075,in1Dot76075])
Sof88861 = keras.layers.Softmax(axis=1, name = 'Sof88861', )(Dot76075)
Zer90050 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer90050', )(Sof88861)
Add71309 = keras.layers.Add(name = 'Add71309', )([Con14531,Zer90050])
Max30658 = keras.layers.MaxPool1D(pool_size=(2), name = 'Max30658', )(Add71309)
model = tf.keras.models.Model(inputs=[in0Bat89528,in0Con14531,in0Dot76075,in1Dot76075], outputs=Max30658)
w = model.get_layer('Bat89528').get_weights() 
w[0] = np.array([0.3817, 0.7645, 0.4684])
w[1] = np.array([0.9015, 0.7469, 0.1715])
w[2] = np.array([0.1388, 0.0081, 0.201])
w[3] = np.array([0.8824, 0.2454, 0.7718])
model.get_layer('Bat89528').set_weights(w) 
in0Bat89528 = tf.constant([[1.5071, 1.0106, 1.8004]])
in0Con14531 = tf.constant([[[0.2258], [0.9402], [0.0874]]])
in0Dot76075 = tf.constant([[[0.4052, 0.709], [0.2327, 0.7995]]])
in1Dot76075 = tf.constant([[[0.2633, 0.9201], [0.9731, 0.3666]]])
print (np.array2string(model.predict([in0Bat89528,in0Con14531,in0Dot76075,in1Dot76075],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max30658.png')

LBat89528 = batch_normalization_layer([[1.5071, 1.0106, 1.8004]], 1, 0.36272624090780337, [0.3817, 0.7645, 0.4684], [0.9015, 0.7469, 0.1715], [0.1388, 0.0081, 0.201], [0.8824, 0.2454, 0.7718], Bat89528), 
LRes61342 = reshape_layer(Bat89528, [3, 1], Res61342), 
LCon14531 = concatenate_layer([Res61342,[[[0.2258], [0.9402], [0.0874]]]], 2, Con14531), 
LDot76075 = dot_layer([[[0.4052, 0.709], [0.2327, 0.7995]]], [[[0.2633, 0.9201], [0.9731, 0.3666]]], 2, 1, Dot76075), 
LSof88861 = softmax_layer(Dot76075, 1, Sof88861), 
LZer90050 = zero_padding1D_layer(Sof88861, 1, 0, Zer90050), 
LAdd71309 = add_layer([Con14531,Zer90050], Add71309), 
LMax30658 = max_pool1D_layer(Add71309, 2, Max30658), 
exec_layers([LBat89528,LRes61342,LCon14531,LDot76075,LSof88861,LZer90050,LAdd71309,LMax30658],["Bat89528","Res61342","Con14531","Dot76075","Sof88861","Zer90050","Add71309","Max30658"],Max30658,"Max30658")

Actual (Unparsed): [[[2.2190397, 1.4715438]]]

Expected (Unparsed): [[[2.2190397041200227,1.4715438326798571]]]

Actual:   [[[2.2191, 1.4716]]]

Expected: [[[2.2191, 1.4716]]]