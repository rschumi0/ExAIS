import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con12164 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in0Up_72103 = tf.keras.layers.Input(shape=([1, 2]))
in0Con29355 = tf.keras.layers.Input(shape=([2, 1]))
in0Lea51225 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in0Con33619 = tf.keras.layers.Input(shape=([4, 1]))

Con12164 = keras.layers.Conv3D(3, (2, 1, 1),strides=(1, 6, 10), padding='valid', dilation_rate=(1, 1, 1), name = 'Con12164', )(in0Con12164)
Res39711 = keras.layers.Reshape((1, 1, 3), name = 'Res39711', )(Con12164)
Res92384 = keras.layers.Reshape((1, 3), name = 'Res92384', )(Res39711)
Zer1750 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer1750', )(Res92384)
Up_72103 = keras.layers.UpSampling1D(size=(2), name = 'Up_72103', )(in0Up_72103)
Con29355 = keras.layers.Concatenate(axis=2, name = 'Con29355', )([Up_72103,in0Con29355])
Sub34593 = keras.layers.Subtract(name = 'Sub34593', )([Zer1750,Con29355])
Zer28601 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer28601', )(Sub34593)
Lea51225 = keras.layers.LeakyReLU(alpha=7.660175294198512, name = 'Lea51225', input_shape=(2, 2, 2, 1))(in0Lea51225)
Res92858 = keras.layers.Reshape((2, 2, 2), name = 'Res92858', )(Lea51225)
Res26927 = keras.layers.Reshape((2, 4), name = 'Res26927', )(Res92858)
Per20095 = keras.layers.Permute((2,1), name = 'Per20095',)(Res26927)
Con33619 = keras.layers.Concatenate(axis=2, name = 'Con33619', )([Per20095,in0Con33619])
Add45651 = keras.layers.Add(name = 'Add45651', )([Zer28601,Con33619])
Bat81276 = keras.layers.BatchNormalization(axis=2, epsilon=0.6737260680226735,  name = 'Bat81276', )(Add45651)
model = tf.keras.models.Model(inputs=[in0Con12164,in0Up_72103,in0Con29355,in0Lea51225,in0Con33619], outputs=Bat81276)
w = model.get_layer('Con12164').get_weights() 
w[0] = np.array([[[[[0.954, 0.9131, 0.7563], [0.7238, 0.5377, 0.5041]]]], [[[[0.8373, 0.0856, 0.4457], [0.0179, 0.2568, 0.4516]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con12164').set_weights(w) 
w = model.get_layer('Bat81276').get_weights() 
w[0] = np.array([0.239, 0.2742, 0.2334])
w[1] = np.array([0.0312, 0.4382, 0.7479])
w[2] = np.array([0.4253, 0.2586, 0.2946])
w[3] = np.array([0.8758, 0.6377, 0.4548])
model.get_layer('Bat81276').set_weights(w) 
in0Con12164 = tf.constant([[[[[0.4945, 0.028], [0.475, 0.5658]]], [[[0.6499, 0.9137], [0.9106, 0.3091]]]]])
in0Up_72103 = tf.constant([[[1.199, 1.1824]]])
in0Con29355 = tf.constant([[[0.7216], [0.5467]]])
in0Lea51225 = tf.constant([[[[[0.9619], [0.5037]], [[0.773], [0.5324]]], [[[0.605], [0.4314]], [[0.4484], [0.8998]]]]])
in0Con33619 = tf.constant([[[0.1139], [0.8841], [0.6245], [0.6795]]])
print (np.array2string(model.predict([in0Con12164,in0Up_72103,in0Con29355,in0Lea51225,in0Con33619],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat81276.png')

LCon12164 = conv3D_layer([[[[[0.4945, 0.028], [0.475, 0.5658]]], [[[0.6499, 0.9137], [0.9106, 0.3091]]]]], 2, 1, 1,[[[[[0.954, 0.9131, 0.7563], [0.7238, 0.5377, 0.5041]]]], [[[[0.8373, 0.0856, 0.4457], [0.0179, 0.2568, 0.4516]]]]],[0, 0, 0], 1, 6, 10, false, 1, 1, 1, Con12164), 
LRes39711 = reshape_layer(Con12164, [1, 1, 3], Res39711), 
LRes92384 = reshape_layer(Res39711, [1, 3], Res92384), 
LZer1750 = zero_padding1D_layer(Res92384, 1, 0, Zer1750), 
LUp_72103 = up_sampling1D_layer([[[1.199, 1.1824]]], 2, Up_72103), 
LCon29355 = concatenate_layer([Up_72103,[[[0.7216], [0.5467]]]], 2, Con29355), 
LSub34593 = subtract_layer(Zer1750,Con29355, Sub34593), 
LZer28601 = zero_padding1D_layer(Sub34593, 2, 0, Zer28601), 
LLea51225 = leaky_relu_layer([[[[[0.9619], [0.5037]], [[0.773], [0.5324]]], [[[0.605], [0.4314]], [[0.4484], [0.8998]]]]], 7.660175294198512, Lea51225), 
LRes92858 = reshape_layer(Lea51225, [2, 2, 2], Res92858), 
LRes26927 = reshape_layer(Res92858, [2, 4], Res26927), 
LPer20095 = permute_layer(Res26927, 2,1, Per20095), 
LCon33619 = concatenate_layer([Per20095,[[[0.1139], [0.8841], [0.6245], [0.6795]]]], 2, Con33619), 
LAdd45651 = add_layer([Zer28601,Con33619], Add45651), 
LBat81276 = batch_normalization_layer(Add45651, 2, 0.6737260680226735, [0.239, 0.2742, 0.2334], [0.0312, 0.4382, 0.7479], [0.4253, 0.2586, 0.2946], [0.8758, 0.6377, 0.4548], Bat81276), 
exec_layers([LCon12164,LRes39711,LRes92384,LZer1750,LUp_72103,LCon29355,LSub34593,LZer28601,LLea51225,LRes92858,LRes26927,LPer20095,LCon33619,LAdd45651,LBat81276],["Con12164","Res39711","Res92384","Zer1750","Up_72103","Con29355","Sub34593","Zer28601","Lea51225","Res92858","Res26927","Per20095","Con33619","Add45651","Bat81276"],Bat81276,"Bat81276")

Actual (Unparsed): [[[0.1342265, 0.5211418, 0.7081988], [0.0462527, 0.4795751, 0.8774176], [-0.1322486, 0.2005325, 0.6618405], [0.0236421, 0.4898359, 0.9519188]]]

Expected (Unparsed): [[[0.13422654259569394,0.5211417945661573,0.7081988390591084],[0.04625270394987403,0.4795751215387759,0.8774176224386033],[-0.132248557047548,0.20053249051279515,0.6618405382371486],[0.023642141026106674,0.48983585238119143,0.9519188173270886]]]

Actual:   [[[0.1343, 0.5212, 0.7082], [0.0463, 0.4796, 0.8775], [-0.1322, 0.2006, 0.6619], [0.0237, 0.4899, 0.952]]]

Expected: [[[0.1343, 0.5212, 0.7082], [0.0463, 0.4796, 0.8775], [-0.1322, 0.2006, 0.6619], [0.0237, 0.4899, 0.952]]]