import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min97259 = tf.keras.layers.Input(shape=([1, 2]))
in1Min97259 = tf.keras.layers.Input(shape=([1, 2]))
in0Glo13470 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con73531 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Min8375 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Min8375 = tf.keras.layers.Input(shape=([2, 2, 2]))

Min97259 = keras.layers.Minimum(name = 'Min97259', )([in0Min97259,in1Min97259])
Fla69974 = keras.layers.Flatten(name = 'Fla69974', )(Min97259)
Res81755 = keras.layers.Reshape((2, 1), name = 'Res81755', )(Fla69974)
Glo13470 = keras.layers.GlobalAveragePooling2D(name = 'Glo13470', )(in0Glo13470)
Res88149 = keras.layers.Reshape((1, 1), name = 'Res88149', )(Glo13470)
PRe17319 = keras.layers.PReLU(name = 'PRe17319', )(Res88149)
Zer86136 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer86136', )(PRe17319)
Add30316 = keras.layers.Add(name = 'Add30316', )([Res81755,Zer86136])
Res53306 = keras.layers.Reshape((2, 1, 1), name = 'Res53306', )(Add30316)
Zer83530 = keras.layers.ZeroPadding2D(padding=((0, 0), (1, 0)), name = 'Zer83530', )(Res53306)
Con73531 = keras.layers.Concatenate(axis=3, name = 'Con73531', )([Zer83530,in0Con73531])
Min8375 = keras.layers.Minimum(name = 'Min8375', )([in0Min8375,in1Min8375])
Mul27992 = keras.layers.Multiply(name = 'Mul27992', )([Con73531,Min8375])
Con73253 = keras.layers.Conv2DTranspose(4, (1, 2),strides=(1, 3), padding='same', name = 'Con73253', )(Mul27992)
model = tf.keras.models.Model(inputs=[in0Min97259,in1Min97259,in0Glo13470,in0Con73531,in0Min8375,in1Min8375], outputs=Con73253)
w = model.get_layer('PRe17319').get_weights() 
w[0] = np.array([[0.8358]])
model.get_layer('PRe17319').set_weights(w) 
w = model.get_layer('Con73253').get_weights() 
w[0] = np.array([[[[0.2679, 0.4464], [0.677, 0.8804], [0.3803, 0.8667], [0.7482, 0.9029]], [[0.662, 0.0095], [0.4605, 0.24], [0.4151, 0.4952], [0.0251, 0.8891]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con73253').set_weights(w) 
in0Min97259 = tf.constant([[[0.3075, 0.6561]]])
in1Min97259 = tf.constant([[[0.8126, 0.0457]]])
in0Glo13470 = tf.constant([[[[1.1538]], [[1.9349]]]])
in0Con73531 = tf.constant([[[[0.2856], [0.5712]], [[0.5307], [0.1091]]]])
in0Min8375 = tf.constant([[[[0.9313, 0.0865], [0.974, 0.6187]], [[0.6671, 0.028], [0.8679, 0.1528]]]])
in1Min8375 = tf.constant([[[[0.4336, 0.166], [0.1468, 0.6831]], [[0.9905, 0.2951], [0.3545, 0.8172]]]])
print (np.array2string(model.predict([in0Min97259,in1Min97259,in0Glo13470,in0Con73531,in0Min8375,in1Min8375],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Con73253.png')

LMin97259 = minimum_layer([[[[0.3075, 0.6561]]], [[[0.8126, 0.0457]]]], Min97259), 
LFla69974 = flatten_layer(Min97259, Fla69974), 
LRes81755 = reshape_layer(Fla69974, [2, 1], Res81755), 
LGlo13470 = global_average_pooling2D_layer([[[[1.1538]], [[1.9349]]]], Glo13470), 
LRes88149 = reshape_layer(Glo13470, [1, 1], Res88149), 
LPRe17319 = prelu_layer(Res88149, [[0.8358]], PRe17319), 
LZer86136 = zero_padding1D_layer(PRe17319, 1, 0, Zer86136), 
LAdd30316 = add_layer([Res81755,Zer86136], Add30316), 
LRes53306 = reshape_layer(Add30316, [2, 1, 1], Res53306), 
LZer83530 = zero_padding2D_layer(Res53306, 0, 0, 1, 0, Zer83530), 
LCon73531 = concatenate_layer([Zer83530,[[[[0.2856], [0.5712]], [[0.5307], [0.1091]]]]], 3, Con73531), 
LMin8375 = minimum_layer([[[[[0.9313, 0.0865], [0.974, 0.6187]], [[0.6671, 0.028], [0.8679, 0.1528]]]], [[[[0.4336, 0.166], [0.1468, 0.6831]], [[0.9905, 0.2951], [0.3545, 0.8172]]]]], Min8375), 
LMul27992 = multiply_layer([Con73531,Min8375], Mul27992), 
LCon73253 = conv2D_transpose_layer(Mul27992, 1, 2,[[[[0.2679, 0.4464], [0.677, 0.8804], [0.3803, 0.8667], [0.7482, 0.9029]], [[0.662, 0.0095], [0.4605, 0.24], [0.4151, 0.4952], [0.0251, 0.8891]]]],[0, 0, 0, 0], 1, 3, true, Con73253), 
exec_layers([LMin97259,LFla69974,LRes81755,LGlo13470,LRes88149,LPRe17319,LZer86136,LAdd30316,LRes53306,LZer83530,LCon73531,LMin8375,LMul27992,LCon73253],["Min97259","Fla69974","Res81755","Glo13470","Res88149","PRe17319","Zer86136","Add30316","Res53306","Zer83530","Con73531","Min8375","Mul27992","Con73253"],Con73253,"Con73253")

Actual (Unparsed): [[[[0.0110280, 0.0217498, 0.0214113, 0.0223056], [0.0002347, 0.0059291, 0.0122336, 0.0219647], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.1698517, 0.3416951, 0.3234602, 0.3528607], [0.0332407, 0.1056038, 0.1937424, 0.3153423], [0.0000000, 0.0000000, 0.0000000, 0.0000000]], [[0.0066333, 0.0130824, 0.0128788, 0.0134167], [0.0001412, 0.0035663, 0.0073585, 0.0132117], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.1584496, 0.3962831, 0.2288130, 0.4367917], [0.3733097, 0.2635722, 0.2422358, 0.0289699], [0.0000000, 0.0000000, 0.0000000, 0.0000000]]]]

Expected (Unparsed): [[[[0.011028044160000002,0.02174975376,0.02141130348,0.02230560276],[0.0002346918,0.005929056,0.01223361888,0.021964682040000003],[0,0,0,0],[0.16985167671600004,0.341695084776,0.3234601503480001,0.35286065637600006],[0.03324065568,0.10560377610000002,0.19374242218800003,0.31534225940400007],[0,0,0,0]],[[0.00663332544,0.013082391839999999,0.012878815319999999,0.013416732839999999],[0.00014116619999999998,0.0035663039999999997,0.007358473919999999,0.013211670359999999],[0,0,0,0],[0.15844962529950002,0.396283125417,0.2288130423335,0.436791709237],[0.37330971351,0.2635722050625,0.24223576984349998,0.028969909165499998],[0,0,0,0]]]]

Actual:   [[[[0.0111, 0.0218, 0.0215, 0.0224], [0.0003, 0.006, 0.0123, 0.022], [0, 0, 0, 0], [0.1699, 0.3417, 0.3235, 0.3529], [0.0333, 0.1057, 0.1938, 0.3154], [0, 0, 0, 0]], [[0.0067, 0.0131, 0.0129, 0.0135], [0.0002, 0.0036, 0.0074, 0.0133], [0, 0, 0, 0], [0.1585, 0.3963, 0.2289, 0.4368], [0.3734, 0.2636, 0.2423, 0.029], [0, 0, 0, 0]]]]

Expected: [[[[0.0111, 0.0218, 0.0215, 0.0224], [0.0003, 0.006, 0.0123, 0.022], [0, 0, 0, 0], [0.1699, 0.3417, 0.3235, 0.3529], [0.0333, 0.1057, 0.1938, 0.3154], [0, 0, 0, 0]], [[0.0067, 0.0131, 0.0129, 0.0135], [0.0002, 0.0036, 0.0074, 0.0133], [0, 0, 0, 0], [0.1585, 0.3963, 0.2289, 0.4368], [0.3734, 0.2636, 0.2423, 0.029], [0, 0, 0, 0]]]]