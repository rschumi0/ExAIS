import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con14007 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in0Con28980 = tf.keras.layers.Input(shape=([3, 4, 3]))
in0Max534 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Max534 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Mul16979 = tf.keras.layers.Input(shape=([1, 1, 1]))
in1Mul16979 = tf.keras.layers.Input(shape=([1, 1, 1]))

Con14007 = keras.layers.Conv3D(2, (1, 2, 1),strides=(1, 1, 1), padding='valid', dilation_rate=(1, 1, 1), name = 'Con14007', )(in0Con14007)
Res38772 = keras.layers.Reshape((2, 1, 4), name = 'Res38772', )(Con14007)
Res2530 = keras.layers.Reshape((2, 4), name = 'Res2530', )(Res38772)
LST57562 = keras.layers.LSTM(1,recurrent_activation='sigmoid', name = 'LST57562', )(Res2530)
Res44341 = keras.layers.Reshape((1, 1), name = 'Res44341', )(LST57562)
Res6468 = keras.layers.Reshape((1, 1, 1), name = 'Res6468', )(Res44341)
Zer42352 = keras.layers.ZeroPadding2D(padding=((2, 0), (3, 0)), name = 'Zer42352', )(Res6468)
Con28980 = keras.layers.Concatenate(axis=3, name = 'Con28980', )([Zer42352,in0Con28980])
Max534 = keras.layers.Maximum(name = 'Max534', )([in0Max534,in1Max534])
Res9544 = keras.layers.Reshape((2, 2, 4), name = 'Res9544', )(Max534)
Zer42426 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer42426', )(Res9544)
Cro21387 = keras.layers.Cropping2D(cropping=((0, 1), (0, 0)), name = 'Cro21387', )(Zer42426)
Ave86711 = keras.layers.Average(name = 'Ave86711', )([Con28980,Cro21387])
Res32444 = keras.layers.Reshape((3, 4, 4, 1), name = 'Res32444', )(Ave86711)
Mul16979 = keras.layers.Multiply(name = 'Mul16979', )([in0Mul16979,in1Mul16979])
Res46662 = keras.layers.Reshape((1, 1, 1, 1), name = 'Res46662', )(Mul16979)
Up_74845 = keras.layers.UpSampling3D(size=(1, 2, 2), name = 'Up_74845', )(Res46662)
Zer14721 = keras.layers.ZeroPadding3D(padding=((2, 0), (2, 0), (2, 0)), name = 'Zer14721', )(Up_74845)
Add54048 = keras.layers.Add(name = 'Add54048', )([Res32444,Zer14721])
model = tf.keras.models.Model(inputs=[in0Con14007,in0Con28980,in0Max534,in1Max534,in0Mul16979,in1Mul16979], outputs=Add54048)
w = model.get_layer('Con14007').get_weights() 
w[0] = np.array([[[[[0.3952, 0.3204]]], [[[0.526, 0.3872]]]]])
w[1] = np.array([0, 0])
model.get_layer('Con14007').set_weights(w) 
w = model.get_layer('LST57562').get_weights() 
w[0] = np.array([[8, 8, 8, 8], [4, 5, 9, 5], [4, 1, 3, 8], [2, 9, 1, 2]])
w[1] = np.array([[5, 8, 7, 9]])
w[2] = np.array([10, 2, 10, 7])
model.get_layer('LST57562').set_weights(w) 
in0Con14007 = tf.constant([[[[[0.5808], [0.2439]], [[0.894], [0.5823]]], [[[0.0572], [0.578]], [[0.0996], [0.0494]]]]])
in0Con28980 = tf.constant([[[[0.5213, 0.6832, 0.9275], [0.7224, 0.1733, 0.1261], [0.9436, 0.7117, 0.3911], [0.8732, 0.2602, 0.3803]], [[0.2765, 0.0649, 0.6092], [0.2392, 0.6745, 0.7177], [0.2054, 0.6044, 0.9091], [0.5844, 0.2284, 0.4788]], [[0.5556, 0.8557, 0.5533], [0.7189, 0.1271, 0.8173], [0.7065, 0.1539, 0.1951], [0.4435, 0.6789, 0.8338]]]])
in0Max534 = tf.constant([[[[[0.4665, 0.0469], [0.0791, 0.8472]], [[0.2348, 0.0427], [0.0678, 0.8662]]], [[[0.1582, 0.4828], [0.2171, 0.5644]], [[0.3351, 0.3721], [0.5789, 0.5743]]]]])
in1Max534 = tf.constant([[[[[0.2866, 0.4794], [0.0483, 0.5657]], [[0.3716, 0.5353], [0.5085, 0.4298]]], [[[0.9486, 0.0576], [0.0312, 0.4373]], [[0.8603, 0.6358], [0.8804, 0.141]]]]])
in0Mul16979 = tf.constant([[[[0.727]]]])
in1Mul16979 = tf.constant([[[[0.2669]]]])
print (np.array2string(model.predict([in0Con14007,in0Con28980,in0Max534,in1Max534,in0Mul16979,in1Mul16979],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add54048.png')

LCon14007 = conv3D_layer([[[[[0.5808], [0.2439]], [[0.894], [0.5823]]], [[[0.0572], [0.578]], [[0.0996], [0.0494]]]]], 1, 2, 1,[[[[[0.3952, 0.3204]]], [[[0.526, 0.3872]]]]],[0, 0], 1, 1, 1, false, 1, 1, 1, Con14007), 
LRes38772 = reshape_layer(Con14007, [2, 1, 4], Res38772), 
LRes2530 = reshape_layer(Res38772, [2, 4], Res2530), 
LLST57562 = lstm_layer(Res2530,[[8, 8, 8, 8], [4, 5, 9, 5], [4, 1, 3, 8], [2, 9, 1, 2]],[[5, 8, 7, 9]],[10, 2, 10, 7], LST57562), 
LRes44341 = reshape_layer(LST57562, [1, 1], Res44341), 
LRes6468 = reshape_layer(Res44341, [1, 1, 1], Res6468), 
LZer42352 = zero_padding2D_layer(Res6468, 2, 0, 3, 0, Zer42352), 
LCon28980 = concatenate_layer([Zer42352,[[[[0.5213, 0.6832, 0.9275], [0.7224, 0.1733, 0.1261], [0.9436, 0.7117, 0.3911], [0.8732, 0.2602, 0.3803]], [[0.2765, 0.0649, 0.6092], [0.2392, 0.6745, 0.7177], [0.2054, 0.6044, 0.9091], [0.5844, 0.2284, 0.4788]], [[0.5556, 0.8557, 0.5533], [0.7189, 0.1271, 0.8173], [0.7065, 0.1539, 0.1951], [0.4435, 0.6789, 0.8338]]]]], 3, Con28980), 
LMax534 = maximum_layer([[[[[[0.4665, 0.0469], [0.0791, 0.8472]], [[0.2348, 0.0427], [0.0678, 0.8662]]], [[[0.1582, 0.4828], [0.2171, 0.5644]], [[0.3351, 0.3721], [0.5789, 0.5743]]]]], [[[[[0.2866, 0.4794], [0.0483, 0.5657]], [[0.3716, 0.5353], [0.5085, 0.4298]]], [[[0.9486, 0.0576], [0.0312, 0.4373]], [[0.8603, 0.6358], [0.8804, 0.141]]]]]], Max534), 
LRes9544 = reshape_layer(Max534, [2, 2, 4], Res9544), 
LZer42426 = zero_padding2D_layer(Res9544, 1, 1, 1, 1, Zer42426), 
LCro21387 = cropping2D_layer(Zer42426, 0, 1, 0, 0, Cro21387), 
LAve86711 = average_layer([Con28980,Cro21387], Ave86711), 
LRes32444 = reshape_layer(Ave86711, [3, 4, 4, 1], Res32444), 
LMul16979 = multiply_layer([[[[[0.727]]]], [[[[0.2669]]]]], Mul16979), 
LRes46662 = reshape_layer(Mul16979, [1, 1, 1, 1], Res46662), 
LUp_74845 = up_sampling3D_layer(Res46662, 1, 2, 2, Up_74845), 
LZer14721 = zero_padding3D_layer(Up_74845, 2, 0, 2, 0, 2, 0, Zer14721), 
LAdd54048 = add_layer([Res32444,Zer14721], Add54048), 
exec_layers([LCon14007,LRes38772,LRes2530,LLST57562,LRes44341,LRes6468,LZer42352,LCon28980,LMax534,LRes9544,LZer42426,LCro21387,LAve86711,LRes32444,LMul16979,LRes46662,LUp_74845,LZer14721,LAdd54048],["Con14007","Res38772","Res2530","LST57562","Res44341","Res6468","Zer42352","Con28980","Max534","Res9544","Zer42426","Cro21387","Ave86711","Res32444","Mul16979","Res46662","Up_74845","Zer14721","Add54048"],Add54048,"Add54048")

Actual (Unparsed): [[[[[0.0000000], [0.2606500], [0.3416000], [0.4637500]], [[0.0000000], [0.3612000], [0.0866500], [0.0630500]], [[0.0000000], [0.4718000], [0.3558500], [0.1955500]], [[0.0000000], [0.4366000], [0.1301000], [0.1901500]]], [[[0.0000000], [0.1382500], [0.0324500], [0.3046000]], [[0.2332500], [0.3593000], [0.3768000], [0.7824500]], [[0.1858000], [0.3703500], [0.5564500], [0.8876500]], [[0.0000000], [0.2922000], [0.1142000], [0.2394000]]], [[[0.0000000], [0.2778000], [0.4278500], [0.2766500]], [[0.4743000], [0.6008500], [0.1721000], [0.6908500]], [[0.4301500], [0.6711500], [0.7111863], [0.5787363]], [[0.4820132], [0.2217500], [0.5334863], [0.6109363]]]]]

Expected (Unparsed): [[[[[0],[0.26065],[0.3416],[0.46375]],[[0],[0.3612],[0.08665],[0.06305]],[[0],[0.4718],[0.35585],[0.19555]],[[0],[0.4366],[0.1301],[0.19015]]],[[[0],[0.13825],[0.03245],[0.3046]],[[0.23325],[0.3593],[0.3768],[0.78245]],[[0.1858],[0.37035],[0.55645],[0.88765]],[[0],[0.2922],[0.1142],[0.2394]]],[[[0],[0.2778],[0.42785],[0.27665]],[[0.4743],[0.60085],[0.17209999999999998],[0.69085]],[[0.43015],[0.67115],[0.7111863],[0.5787363000000001]],[[0.48201321974302325],[0.22175],[0.5334863],[0.6109363]]]]]

Actual:   [[[[[0], [0.2607], [0.3416], [0.4638]], [[0], [0.3612], [0.0867], [0.0631]], [[0], [0.4718], [0.3559], [0.1956]], [[0], [0.4366], [0.1301], [0.1902]]], [[[0], [0.1383], [0.0325], [0.3046]], [[0.2333], [0.3593], [0.3768], [0.7825]], [[0.1858], [0.3704], [0.5565], [0.8877]], [[0], [0.2922], [0.1142], [0.2394]]], [[[0], [0.2778], [0.4279], [0.2767]], [[0.4743], [0.6009], [0.1721], [0.6909]], [[0.4302], [0.6712], [0.7112], [0.5788]], [[0.4821], [0.2218], [0.5335], [0.611]]]]]

Expected: [[[[[0], [0.2607], [0.3416], [0.4638]], [[0], [0.3612], [0.0867], [0.0631]], [[0], [0.4718], [0.3559], [0.1956]], [[0], [0.4366], [0.1301], [0.1902]]], [[[0], [0.1383], [0.0325], [0.3046]], [[0.2333], [0.3593], [0.3768], [0.7825]], [[0.1858], [0.3704], [0.5565], [0.8877]], [[0], [0.2922], [0.1142], [0.2394]]], [[[0], [0.2778], [0.4279], [0.2767]], [[0.4743], [0.6009], [0.1721], [0.6909]], [[0.4302], [0.6712], [0.7112], [0.5788]], [[0.4821], [0.2218], [0.5335], [0.611]]]]]