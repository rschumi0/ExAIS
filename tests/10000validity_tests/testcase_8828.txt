import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul77960 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in1Mul77960 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in0Dot31586 = tf.keras.layers.Input(shape=([2, 2]))
in1Dot31586 = tf.keras.layers.Input(shape=([2, 2]))
in0Con48407 = tf.keras.layers.Input(shape=([6]))

Mul77960 = keras.layers.Multiply(name = 'Mul77960', )([in0Mul77960,in1Mul77960])
Res26442 = keras.layers.Reshape((1, 2, 4), name = 'Res26442', )(Mul77960)
Res79369 = keras.layers.Reshape((1, 8), name = 'Res79369', )(Res26442)
Fla2275 = keras.layers.Flatten(name = 'Fla2275', )(Res79369)
Dot31586 = keras.layers.Dot(axes=(2, 2), name = 'Dot31586', )([in0Dot31586,in1Dot31586])
Glo71137 = keras.layers.GlobalMaxPool1D(name = 'Glo71137', )(Dot31586)
ReL69759 = keras.layers.ReLU(max_value=9.172581600262045, negative_slope=0.6026937875101549, threshold=7.046179378329382, name = 'ReL69759', )(Glo71137)
Con48407 = keras.layers.Concatenate(axis=1, name = 'Con48407', )([ReL69759,in0Con48407])
Mul28206 = keras.layers.Multiply(name = 'Mul28206', )([Fla2275,Con48407])
ReL55979 = keras.layers.ReLU(max_value=6.932900800219487, negative_slope=2.3966472617315167, threshold=0.37524903729952097, name = 'ReL55979', )(Mul28206)
model = tf.keras.models.Model(inputs=[in0Mul77960,in1Mul77960,in0Dot31586,in1Dot31586,in0Con48407], outputs=ReL55979)
in0Mul77960 = tf.constant([[[[[0.4239, 0.589], [0.4597, 0.4232]], [[0.6506, 0.5305], [0.2191, 0.8862]]]]])
in1Mul77960 = tf.constant([[[[[0.3964, 0.2796], [0.2359, 0.6739]], [[0.1929, 0.9036], [0.3002, 0.9592]]]]])
in0Dot31586 = tf.constant([[[0.6605, 0.4623], [0.4374, 0.0796]]])
in1Dot31586 = tf.constant([[[0.3015, 0.8885], [0.5421, 0.9457]]])
in0Con48407 = tf.constant([[0.3639, 0.1374, 0.7195, 0.8417, 0.1526, 0.8644]])
print (np.array2string(model.predict([in0Mul77960,in1Mul77960,in0Dot31586,in1Dot31586,in0Con48407],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='ReL55979.png')

LMul77960 = multiply_layer([[[[[[0.4239, 0.589], [0.4597, 0.4232]], [[0.6506, 0.5305], [0.2191, 0.8862]]]]], [[[[[0.3964, 0.2796], [0.2359, 0.6739]], [[0.1929, 0.9036], [0.3002, 0.9592]]]]]], Mul77960), 
LRes26442 = reshape_layer(Mul77960, [1, 2, 4], Res26442), 
LRes79369 = reshape_layer(Res26442, [1, 8], Res79369), 
LFla2275 = flatten_layer(Res79369, Fla2275), 
LDot31586 = dot_layer([[[0.6605, 0.4623], [0.4374, 0.0796]]], [[[0.3015, 0.8885], [0.5421, 0.9457]]], 2, 2, Dot31586), 
LGlo71137 = global_max_pool1D_layer(Dot31586, Glo71137), 
LReL69759 = relu_layer(Glo71137, 9.172581600262045, 0.6026937875101549, 7.046179378329382, ReL69759), 
LCon48407 = concatenate_layer([ReL69759,[[0.3639, 0.1374, 0.7195, 0.8417, 0.1526, 0.8644]]], 1, Con48407), 
LMul28206 = multiply_layer([Fla2275,Con48407], Mul28206), 
LReL55979 = relu_layer(Mul28206, 6.932900800219487, 2.3966472617315167, 0.37524903729952097, ReL55979), 
exec_layers([LMul77960,LRes26442,LRes79369,LFla2275,LDot31586,LGlo71137,LReL69759,LCon48407,LMul28206,LReL55979],["Mul77960","Res26442","Res79369","Fla2275","Dot31586","Glo71137","ReL69759","Con48407","Mul28206","ReL55979"],ReL55979,"ReL55979")

Actual (Unparsed): [[-2.4615272, -2.3862937, -0.8047619, -0.8054252, -0.6829276, 0.4034771, -0.8752842, 0.7347773]]

Expected (Unparsed): [[-2.461527113318134,-2.3862938031727565,-0.8047619057635611,-0.8054252254547102,-0.682927644709997,0.40347714366,-0.8752842255932403,0.734777203776]]

Actual:   [[-2.4615, -2.3862, -0.8047, -0.8054, -0.6829, 0.4035, -0.8752, 0.7348]]

Expected: [[-2.4615, -2.3862, -0.8047, -0.8054, -0.6829, 0.4035, -0.8752, 0.7348]]