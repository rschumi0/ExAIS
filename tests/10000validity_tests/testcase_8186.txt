import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min92136 = tf.keras.layers.Input(shape=([1, 1]))
in1Min92136 = tf.keras.layers.Input(shape=([1, 1]))

Min92136 = keras.layers.Minimum(name = 'Min92136', )([in0Min92136,in1Min92136])
Bat76203 = keras.layers.BatchNormalization(axis=2, epsilon=0.8122804095982313,  name = 'Bat76203', )(Min92136)
model = tf.keras.models.Model(inputs=[in0Min92136,in1Min92136], outputs=Bat76203)
w = model.get_layer('Bat76203').get_weights() 
w[0] = np.array([0.5155])
w[1] = np.array([0.3265])
w[2] = np.array([0.8307])
w[3] = np.array([0.8366])
model.get_layer('Bat76203').set_weights(w) 
in0Min92136 = tf.constant([[[0.4239]]])
in1Min92136 = tf.constant([[[0.5471]]])
print (np.array2string(model.predict([in0Min92136,in1Min92136],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat76203.png')

LMin92136 = minimum_layer([[[[0.4239]]], [[[0.5471]]]], Min92136), 
LBat76203 = batch_normalization_layer(Min92136, 2, 0.8122804095982313, [0.5155], [0.3265], [0.8307], [0.8366], Bat76203), 
exec_layers([LMin92136,LBat76203],["Min92136","Bat76203"],Bat76203,"Bat76203")

Actual (Unparsed): [[[0.1631892]]]

Expected (Unparsed): [[[0.16318915167106612]]]

Actual:   [[[0.1632]]]

Expected: [[[0.1632]]]