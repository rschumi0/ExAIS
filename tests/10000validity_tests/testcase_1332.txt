import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul64231 = tf.keras.layers.Input(shape=([1, 2, 1]))
in1Mul64231 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con66677 = tf.keras.layers.Input(shape=([3, 1]))
in0Glo72740 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con11324 = tf.keras.layers.Input(shape=([3, 2]))
in0Dot43582 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot43582 = tf.keras.layers.Input(shape=([3, 3]))
in0Add16904 = tf.keras.layers.Input(shape=([2, 1]))
in1Add16904 = tf.keras.layers.Input(shape=([2, 1]))
in0Con2374 = tf.keras.layers.Input(shape=([8]))

Mul64231 = keras.layers.Multiply(name = 'Mul64231', )([in0Mul64231,in1Mul64231])
Res63578 = keras.layers.Reshape((1, 2), name = 'Res63578', )(Mul64231)
Zer5762 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer5762', )(Res63578)
Con66677 = keras.layers.Concatenate(axis=2, name = 'Con66677', )([Zer5762,in0Con66677])
Glo72740 = keras.layers.GlobalAveragePooling2D(name = 'Glo72740', )(in0Glo72740)
Res9731 = keras.layers.Reshape((2, 1), name = 'Res9731', )(Glo72740)
Zer35742 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer35742', )(Res9731)
Con11324 = keras.layers.Concatenate(axis=2, name = 'Con11324', )([Zer35742,in0Con11324])
Dot43582 = keras.layers.Dot(axes=(2, 1), name = 'Dot43582', )([in0Dot43582,in1Dot43582])
Mul88286 = keras.layers.Multiply(name = 'Mul88286', )([Con11324,Dot43582])
Mul53932 = keras.layers.Multiply(name = 'Mul53932', )([Con66677,Mul88286])
Fla81169 = keras.layers.Flatten(name = 'Fla81169', )(Mul53932)
Add16904 = keras.layers.Add(name = 'Add16904', )([in0Add16904,in1Add16904])
GRU90773 = keras.layers.GRU(1,reset_after=True, recurrent_activation='sigmoid', name = 'GRU90773', )(Add16904)
Con2374 = keras.layers.Concatenate(axis=1, name = 'Con2374', )([GRU90773,in0Con2374])
Min86612 = keras.layers.Minimum(name = 'Min86612', )([Fla81169,Con2374])
Lea76751 = keras.layers.LeakyReLU(alpha=7.036644175041199, name = 'Lea76751', )(Min86612)
model = tf.keras.models.Model(inputs=[in0Mul64231,in1Mul64231,in0Con66677,in0Glo72740,in0Con11324,in0Dot43582,in1Dot43582,in0Add16904,in1Add16904,in0Con2374], outputs=Lea76751)
w = model.get_layer('GRU90773').get_weights() 
w[0] = np.array([[4, 9, 6]])
w[1] = np.array([[6, 10, 5]])
w[2] = np.array([[5, 2, 6], [5, 10, 2]])
model.get_layer('GRU90773').set_weights(w) 
in0Mul64231 = tf.constant([[[[0.3513], [0.2807]]]])
in1Mul64231 = tf.constant([[[[0.1235], [0.3411]]]])
in0Con66677 = tf.constant([[[0.9124], [0.4346], [0.3813]]])
in0Glo72740 = tf.constant([[[[1.7744, 1.136]]]])
in0Con11324 = tf.constant([[[0.3124, 0.5581], [0.2577, 0.1356], [0.1243, 0.7859]]])
in0Dot43582 = tf.constant([[[0.0573, 0.3897, 0.8777], [0.6066, 0.3907, 0.21], [0.2064, 0.8083, 0.8553]]])
in1Dot43582 = tf.constant([[[0.1407, 0.5476, 0.7464], [0.8985, 0.6541, 0.6391], [0.5048, 0.4211, 0.7881]]])
in0Add16904 = tf.constant([[[0.0349], [0.0413]]])
in1Add16904 = tf.constant([[[0.61], [0.3787]]])
in0Con2374 = tf.constant([[0.7634, 0.3598, 0.868, 0.0149, 0.4905, 0.008, 0.0463, 0.7873]])
print (np.array2string(model.predict([in0Mul64231,in1Mul64231,in0Con66677,in0Glo72740,in0Con11324,in0Dot43582,in1Dot43582,in0Add16904,in1Add16904,in0Con2374],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Lea76751.png')

LMul64231 = multiply_layer([[[[[0.3513], [0.2807]]]], [[[[0.1235], [0.3411]]]]], Mul64231), 
LRes63578 = reshape_layer(Mul64231, [1, 2], Res63578), 
LZer5762 = zero_padding1D_layer(Res63578, 2, 0, Zer5762), 
LCon66677 = concatenate_layer([Zer5762,[[[0.9124], [0.4346], [0.3813]]]], 2, Con66677), 
LGlo72740 = global_average_pooling2D_layer([[[[1.7744, 1.136]]]], Glo72740), 
LRes9731 = reshape_layer(Glo72740, [2, 1], Res9731), 
LZer35742 = zero_padding1D_layer(Res9731, 1, 0, Zer35742), 
LCon11324 = concatenate_layer([Zer35742,[[[0.3124, 0.5581], [0.2577, 0.1356], [0.1243, 0.7859]]]], 2, Con11324), 
LDot43582 = dot_layer([[[0.0573, 0.3897, 0.8777], [0.6066, 0.3907, 0.21], [0.2064, 0.8083, 0.8553]]], [[[0.1407, 0.5476, 0.7464], [0.8985, 0.6541, 0.6391], [0.5048, 0.4211, 0.7881]]], 2, 1, Dot43582), 
LMul88286 = multiply_layer([Con11324,Dot43582], Mul88286), 
LMul53932 = multiply_layer([Con66677,Mul88286], Mul53932), 
LFla81169 = flatten_layer(Mul53932, Fla81169), 
LAdd16904 = add_layer([[[[0.0349], [0.0413]]], [[[0.61], [0.3787]]]], Add16904), 
LGRU90773 = gru_layer(Add16904,[[4, 9, 6]],[[6, 10, 5]],[[5, 2, 6], [5, 10, 2]], true, GRU90773), 
LCon2374 = concatenate_layer([GRU90773,[[0.7634, 0.3598, 0.868, 0.0149, 0.4905, 0.008, 0.0463, 0.7873]]], 1, Con2374), 
LMin86612 = minimum_layer([Fla81169,Con2374], Min86612), 
LLea76751 = leaky_relu_layer(Min86612, 7.036644175041199, Lea76751), 
exec_layers([LMul64231,LRes63578,LZer5762,LCon66677,LGlo72740,LRes9731,LZer35742,LCon11324,LDot43582,LMul88286,LMul53932,LFla81169,LAdd16904,LGRU90773,LCon2374,LMin86612,LLea76751],["Mul64231","Res63578","Zer5762","Con66677","Glo72740","Res9731","Zer35742","Con11324","Dot43582","Mul88286","Mul53932","Fla81169","Add16904","GRU90773","Con2374","Min86612","Lea76751"],Lea76751,"Lea76751")

Actual (Unparsed): [[0.0000000, 0.0000000, 0.3598000, 0.0000000, 0.0000000, 0.0511506, 0.0080000, 0.0119239, 0.4029588]]

Expected (Unparsed): [[0.0,0.0,0.3598,0.0,0.0,0.0511506231532536,0.008,0.011923941976332657,0.40295876189875146]]

Actual:   [[0, 0, 0.3598, 0, 0, 0.0512, 0.008, 0.012, 0.403]]

Expected: [[0, 0, 0.3598, 0, 0, 0.0512, 0.008, 0.012, 0.403]]