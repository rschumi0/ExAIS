import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub51657 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Sub51657 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Min90104 = tf.keras.layers.Input(shape=([2, 1]))
in1Min90104 = tf.keras.layers.Input(shape=([2, 1]))
in0Con95922 = tf.keras.layers.Input(shape=([4, 31]))

Sub51657 = keras.layers.Subtract(name = 'Sub51657', )([in0Sub51657,in1Sub51657])
Zer78558 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer78558', )(Sub51657)
Res73687 = keras.layers.Reshape((4, 4, 8), name = 'Res73687', )(Zer78558)
Res49605 = keras.layers.Reshape((4, 32), name = 'Res49605', )(Res73687)
Min90104 = keras.layers.Minimum(name = 'Min90104', )([in0Min90104,in1Min90104])
Zer71187 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer71187', )(Min90104)
Con95922 = keras.layers.Concatenate(axis=2, name = 'Con95922', )([Zer71187,in0Con95922])
Ave59054 = keras.layers.Average(name = 'Ave59054', )([Res49605,Con95922])
Max49049 = keras.layers.MaxPool1D(pool_size=(1), name = 'Max49049', )(Ave59054)
model = tf.keras.models.Model(inputs=[in0Sub51657,in1Sub51657,in0Min90104,in1Min90104,in0Con95922], outputs=Max49049)
in0Sub51657 = tf.constant([[[[[0.4924, 0.1695], [0.2373, 0.9524]], [[0.3985, 0.2381], [0.9384, 0.4985]]], [[[0.9965, 0.1959], [0.6678, 0.6839]], [[0.0716, 0.1663], [0.1012, 0.4773]]]]])
in1Sub51657 = tf.constant([[[[[0.2201, 0.8886], [0.0536, 0.6032]], [[0.8358, 0.8216], [0.536, 0.6465]]], [[[0.5096, 0.8891], [0.1101, 0.4867]], [[0.9316, 0.5272], [0.3355, 0.2599]]]]])
in0Min90104 = tf.constant([[[0.9923], [0.2774]]])
in1Min90104 = tf.constant([[[0.2315], [0.7764]]])
in0Con95922 = tf.constant([[[0.1814, 0.6503, 0.2477, 0.7622, 0.8307, 0.3788, 0.4, 0.3463, 0.3549, 0.0046, 0.641, 0.3434, 0.2359, 0.7272, 0.0487, 0.2945, 0.0867, 0.6037, 0.6121, 0.2656, 0.6751, 0.2145, 0.7577, 0.211, 0.067, 0.9664, 0.1913, 0.5008, 0.6878, 0.5947, 0.6431], [0.3229, 0.1899, 0.051, 0.3339, 0.0672, 0.6295, 0.3703, 0.2375, 0.4694, 0.609, 0.3009, 0.5062, 0.2458, 0.7187, 0.4482, 0.7443, 0.188, 0.8243, 0.4362, 0.1721, 0.2006, 0.4928, 0.122, 0.1005, 0.5643, 0.1172, 0.2125, 0.5578, 0.7857, 0.1143, 0.7261], [0.351, 0.7551, 0.9002, 0.6203, 0.3249, 0.5751, 0.2185, 0.5607, 0.0899, 0.3465, 0.7982, 0.2478, 0.0296, 0.4009, 0.2438, 0.9357, 0.9704, 0.9556, 0.5264, 0.7795, 0.4979, 0.9335, 0.4366, 0.4294, 0.5393, 0.7364, 0.8822, 0.8528, 0.495, 0.0916, 0.9728], [0.7115, 0.8994, 0.701, 0.418, 0.7461, 0.3188, 0.3136, 0.8848, 0.527, 0.9527, 0.0146, 0.6095, 0.6208, 0.1945, 0.9794, 0.7388, 0.689, 0.2297, 0.6758, 0.5884, 0.2893, 0.6016, 0.5141, 0.2506, 0.1782, 0.5581, 0.242, 0.7533, 0.7325, 0.9101, 0.9621]]])
print (np.array2string(model.predict([in0Sub51657,in1Sub51657,in0Min90104,in1Min90104,in0Con95922],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max49049.png')

LSub51657 = subtract_layer([[[[[0.4924, 0.1695], [0.2373, 0.9524]], [[0.3985, 0.2381], [0.9384, 0.4985]]], [[[0.9965, 0.1959], [0.6678, 0.6839]], [[0.0716, 0.1663], [0.1012, 0.4773]]]]], [[[[[0.2201, 0.8886], [0.0536, 0.6032]], [[0.8358, 0.8216], [0.536, 0.6465]]], [[[0.5096, 0.8891], [0.1101, 0.4867]], [[0.9316, 0.5272], [0.3355, 0.2599]]]]], Sub51657), 
LZer78558 = zero_padding3D_layer(Sub51657, 1, 1, 1, 1, 1, 1, Zer78558), 
LRes73687 = reshape_layer(Zer78558, [4, 4, 8], Res73687), 
LRes49605 = reshape_layer(Res73687, [4, 32], Res49605), 
LMin90104 = minimum_layer([[[[0.9923], [0.2774]]], [[[0.2315], [0.7764]]]], Min90104), 
LZer71187 = zero_padding1D_layer(Min90104, 2, 0, Zer71187), 
LCon95922 = concatenate_layer([Zer71187,[[[0.1814, 0.6503, 0.2477, 0.7622, 0.8307, 0.3788, 0.4, 0.3463, 0.3549, 0.0046, 0.641, 0.3434, 0.2359, 0.7272, 0.0487, 0.2945, 0.0867, 0.6037, 0.6121, 0.2656, 0.6751, 0.2145, 0.7577, 0.211, 0.067, 0.9664, 0.1913, 0.5008, 0.6878, 0.5947, 0.6431], [0.3229, 0.1899, 0.051, 0.3339, 0.0672, 0.6295, 0.3703, 0.2375, 0.4694, 0.609, 0.3009, 0.5062, 0.2458, 0.7187, 0.4482, 0.7443, 0.188, 0.8243, 0.4362, 0.1721, 0.2006, 0.4928, 0.122, 0.1005, 0.5643, 0.1172, 0.2125, 0.5578, 0.7857, 0.1143, 0.7261], [0.351, 0.7551, 0.9002, 0.6203, 0.3249, 0.5751, 0.2185, 0.5607, 0.0899, 0.3465, 0.7982, 0.2478, 0.0296, 0.4009, 0.2438, 0.9357, 0.9704, 0.9556, 0.5264, 0.7795, 0.4979, 0.9335, 0.4366, 0.4294, 0.5393, 0.7364, 0.8822, 0.8528, 0.495, 0.0916, 0.9728], [0.7115, 0.8994, 0.701, 0.418, 0.7461, 0.3188, 0.3136, 0.8848, 0.527, 0.9527, 0.0146, 0.6095, 0.6208, 0.1945, 0.9794, 0.7388, 0.689, 0.2297, 0.6758, 0.5884, 0.2893, 0.6016, 0.5141, 0.2506, 0.1782, 0.5581, 0.242, 0.7533, 0.7325, 0.9101, 0.9621]]]], 2, Con95922), 
LAve59054 = average_layer([Res49605,Con95922], Ave59054), 
LMax49049 = max_pool1D_layer(Ave59054, 1, Max49049), 
exec_layers([LSub51657,LZer78558,LRes73687,LRes49605,LMin90104,LZer71187,LCon95922,LAve59054,LMax49049],["Sub51657","Zer78558","Res73687","Res49605","Min90104","Zer71187","Con95922","Ave59054","Max49049"],Max49049,"Max49049")

Actual (Unparsed): [[[0.0000000, 0.0907000, 0.3251500, 0.1238500, 0.3811000, 0.4153500, 0.1894000, 0.2000000, 0.1731500, 0.1774500, 0.0023000, 0.3205000, 0.1717000, 0.1179500, 0.3636000, 0.0243500, 0.1472500, 0.0433500, 0.3018500, 0.3060500, 0.1328000, 0.3375500, 0.1072500, 0.3788500, 0.1055000, 0.0335000, 0.4832000, 0.0956500, 0.2504000, 0.3439000, 0.2973500, 0.3215500], [0.0000000, 0.1614500, 0.0949500, 0.0255000, 0.1669500, 0.0336000, 0.3147500, 0.1851500, 0.1187500, 0.2347000, 0.4406500, -0.2091000, 0.3449500, 0.2975000, 0.3593500, 0.2241000, 0.3721500, 0.0940000, 0.1935000, -0.0736500, 0.2872500, 0.0263000, 0.2464000, 0.0610000, 0.0502500, 0.2821500, 0.0586000, 0.1062500, 0.2789000, 0.3928500, 0.0571500, 0.3630500], [0.1157500, 0.1755000, 0.3775500, 0.4501000, 0.3101500, 0.1624500, 0.2875500, 0.1092500, 0.2803500, 0.0449500, 0.4167000, 0.0525000, 0.4027500, 0.1134000, 0.2004500, 0.1219000, 0.4678500, 0.4852000, 0.0478000, 0.0827500, 0.2726000, 0.3576500, 0.4667500, 0.2183000, 0.2147000, 0.2696500, 0.3682000, 0.4411000, 0.4264000, 0.2475000, 0.0458000, 0.4864000], [0.1387000, 0.3557500, 0.4497000, 0.3505000, 0.2090000, 0.3730500, 0.1594000, 0.1568000, 0.4424000, 0.2635000, 0.4763500, 0.0073000, 0.3047500, 0.3104000, 0.0972500, 0.4897000, 0.3694000, 0.3445000, 0.1148500, 0.3379000, 0.2942000, 0.1446500, 0.3008000, 0.2570500, 0.1253000, 0.0891000, 0.2790500, 0.1210000, 0.3766500, 0.3662500, 0.4550500, 0.4810500]]]

Expected (Unparsed): [[[0,0.0907,0.32515,0.12385,0.3811,0.41535,0.1894,0.2,0.17315,0.17745,0.0023,0.3205,0.1717,0.11795,0.3636,0.02435,0.14725,0.04335,0.30185,0.30605,0.1328,0.33755,0.10725,0.37885,0.1055,0.0335,0.4832,0.09565,0.2504,0.3439,0.29735,0.32155],[0,0.16145,0.09495,0.0255,0.16695,0.0336,0.31475,0.18515,0.11875,0.2347,0.44065,-0.20909999999999998,0.34495,0.29750000000000004,0.35935,0.2241,0.37215,0.094,0.19350000000000003,-0.07365000000000002,0.28725,0.026300000000000018,0.2464,0.061,0.05025,0.28215,0.0586,0.10625,0.2789,0.39285,0.05715,0.36305],[0.11575,0.1755,0.37755,0.4501,0.31015,0.16245,0.28755,0.10925,0.28035,0.04495,0.41669999999999996,0.05249999999999999,0.40275,0.11339999999999997,0.20045,0.1219,0.46785,0.4852,0.04780000000000001,0.08274999999999999,0.27259999999999995,0.35765,0.46675,0.2183,0.2147,0.26965,0.3682,0.4411,0.4264,0.2475,0.0458,0.4864],[0.1387,0.35575,0.4497,0.3505,0.209,0.37305,0.1594,0.1568,0.4424,0.2635,0.47635,0.0073,0.30475,0.3104,0.09725,0.4897,0.3694,0.3445,0.11485,0.3379,0.2942,0.14465,0.3008,0.25705,0.1253,0.0891,0.27905,0.121,0.37665,0.36625,0.45505,0.48105]]]

Actual:   [[[0, 0.0907, 0.3252, 0.1239, 0.3811, 0.4154, 0.1894, 0.2, 0.1732, 0.1775, 0.0023, 0.3205, 0.1717, 0.118, 0.3636, 0.0244, 0.1473, 0.0434, 0.3019, 0.3061, 0.1328, 0.3376, 0.1073, 0.3789, 0.1055, 0.0335, 0.4832, 0.0957, 0.2504, 0.3439, 0.2974, 0.3216], [0, 0.1615, 0.095, 0.0255, 0.167, 0.0336, 0.3148, 0.1852, 0.1188, 0.2347, 0.4407, -0.2091, 0.345, 0.2975, 0.3594, 0.2241, 0.3722, 0.094, 0.1935, -0.0736, 0.2873, 0.0263, 0.2464, 0.061, 0.0503, 0.2822, 0.0586, 0.1063, 0.2789, 0.3929, 0.0572, 0.3631], [0.1158, 0.1755, 0.3776, 0.4501, 0.3102, 0.1625, 0.2876, 0.1093, 0.2804, 0.045, 0.4167, 0.0525, 0.4028, 0.1134, 0.2005, 0.1219, 0.4679, 0.4852, 0.0478, 0.0828, 0.2726, 0.3577, 0.4668, 0.2183, 0.2147, 0.2697, 0.3682, 0.4411, 0.4264, 0.2475, 0.0458, 0.4864], [0.1387, 0.3558, 0.4497, 0.3505, 0.209, 0.3731, 0.1594, 0.1568, 0.4424, 0.2635, 0.4764, 0.0073, 0.3048, 0.3104, 0.0973, 0.4897, 0.3694, 0.3445, 0.1149, 0.3379, 0.2942, 0.1447, 0.3008, 0.2571, 0.1253, 0.0891, 0.2791, 0.121, 0.3767, 0.3663, 0.4551, 0.4811]]]

Expected: [[[0, 0.0907, 0.3252, 0.1239, 0.3811, 0.4154, 0.1894, 0.2, 0.1732, 0.1775, 0.0023, 0.3205, 0.1717, 0.118, 0.3636, 0.0244, 0.1473, 0.0434, 0.3019, 0.3061, 0.1328, 0.3376, 0.1073, 0.3789, 0.1055, 0.0335, 0.4832, 0.0957, 0.2504, 0.3439, 0.2974, 0.3216], [0, 0.1615, 0.095, 0.0255, 0.167, 0.0336, 0.3148, 0.1852, 0.1188, 0.2347, 0.4407, -0.209, 0.345, 0.2976, 0.3594, 0.2241, 0.3722, 0.094, 0.1936, -0.0736, 0.2873, 0.0264, 0.2464, 0.061, 0.0503, 0.2822, 0.0586, 0.1063, 0.2789, 0.3929, 0.0572, 0.3631], [0.1158, 0.1755, 0.3776, 0.4501, 0.3102, 0.1625, 0.2876, 0.1093, 0.2804, 0.045, 0.4167, 0.0525, 0.4028, 0.1134, 0.2005, 0.1219, 0.4679, 0.4852, 0.0479, 0.0828, 0.2726, 0.3577, 0.4668, 0.2183, 0.2147, 0.2697, 0.3682, 0.4411, 0.4264, 0.2475, 0.0458, 0.4864], [0.1387, 0.3558, 0.4497, 0.3505, 0.209, 0.3731, 0.1594, 0.1568, 0.4424, 0.2635, 0.4764, 0.0073, 0.3048, 0.3104, 0.0973, 0.4897, 0.3694, 0.3445, 0.1149, 0.3379, 0.2942, 0.1447, 0.3008, 0.2571, 0.1253, 0.0891, 0.2791, 0.121, 0.3767, 0.3663, 0.4551, 0.4811]]]