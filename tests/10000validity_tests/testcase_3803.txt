import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0LST521 = tf.keras.layers.Input(shape=([1, 3]))

LST521 = keras.layers.LSTM(2,recurrent_activation='sigmoid', name = 'LST521', )(in0LST521)
Res60454 = keras.layers.Reshape((2, 1), name = 'Res60454', )(LST521)
Res64090 = keras.layers.Reshape((2, 1, 1), name = 'Res64090', )(Res60454)
Res78565 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res78565', )(Res64090)
Zer26612 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer26612', )(Res78565)
ReL1608 = keras.layers.ReLU(max_value=2.6573253264460788, negative_slope=7.041003150779696, threshold=0.5060390989916652, name = 'ReL1608', )(Zer26612)
model = tf.keras.models.Model(inputs=[in0LST521], outputs=ReL1608)
w = model.get_layer('LST521').get_weights() 
w[0] = np.array([[3, 10, 5, 10, 9, 5, 6, 2], [8, 9, 9, 5, 6, 5, 7, 4], [6, 10, 3, 8, 2, 10, 4, 10]])
w[1] = np.array([[3, 3, 10, 4, 2, 8, 7, 9], [9, 8, 2, 3, 4, 7, 9, 8]])
w[2] = np.array([6, 3, 1, 5, 8, 8, 4, 2])
model.get_layer('LST521').set_weights(w) 
in0LST521 = tf.constant([[[6, 10, 2]]])
print (np.array2string(model.predict([in0LST521],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='ReL1608.png')

LLST521 = lstm_layer([[[6, 10, 2]]],[[3, 10, 5, 10, 9, 5, 6, 2], [8, 9, 9, 5, 6, 5, 7, 4], [6, 10, 3, 8, 2, 10, 4, 10]],[[3, 3, 10, 4, 2, 8, 7, 9], [9, 8, 2, 3, 4, 7, 9, 8]],[6, 3, 1, 5, 8, 8, 4, 2], LST521), 
LRes60454 = reshape_layer(LST521, [2, 1], Res60454), 
LRes64090 = reshape_layer(Res60454, [2, 1, 1], Res64090), 
LRes78565 = reshape_layer(Res64090, [2, 1, 1, 1], Res78565), 
LZer26612 = zero_padding3D_layer(Res78565, 1, 1, 1, 1, 1, 1, Zer26612), 
LReL1608 = relu_layer(Zer26612, 2.6573253264460788, 7.041003150779696, 0.5060390989916652, ReL1608), 
exec_layers([LLST521,LRes60454,LRes64090,LRes78565,LZer26612,LReL1608],["LST521","Res60454","Res64090","Res78565","Zer26612","ReL1608"],ReL1608,"ReL1608")

Actual (Unparsed): [[[[[-3.5630229], [-3.5630229], [-3.5630229]], [[-3.5630229], [-3.5630229], [-3.5630229]], [[-3.5630229], [-3.5630229], [-3.5630229]]], [[[-3.5630229], [-3.5630229], [-3.5630229]], [[-3.5630229], [0.7615942], [-3.5630229]], [[-3.5630229], [-3.5630229], [-3.5630229]]], [[[-3.5630229], [-3.5630229], [-3.5630229]], [[-3.5630229], [0.7615942], [-3.5630229]], [[-3.5630229], [-3.5630229], [-3.5630229]]], [[[-3.5630229], [-3.5630229], [-3.5630229]], [[-3.5630229], [-3.5630229], [-3.5630229]], [[-3.5630229], [-3.5630229], [-3.5630229]]]]]

Expected (Unparsed): [[[[[-3.563022890418033],[-3.563022890418033],[-3.563022890418033]],[[-3.563022890418033],[-3.563022890418033],[-3.563022890418033]],[[-3.563022890418033],[-3.563022890418033],[-3.563022890418033]]],[[[-3.563022890418033],[-3.563022890418033],[-3.563022890418033]],[[-3.563022890418033],[0.7615941559557649],[-3.563022890418033]],[[-3.563022890418033],[-3.563022890418033],[-3.563022890418033]]],[[[-3.563022890418033],[-3.563022890418033],[-3.563022890418033]],[[-3.563022890418033],[0.7615941559557649],[-3.563022890418033]],[[-3.563022890418033],[-3.563022890418033],[-3.563022890418033]]],[[[-3.563022890418033],[-3.563022890418033],[-3.563022890418033]],[[-3.563022890418033],[-3.563022890418033],[-3.563022890418033]],[[-3.563022890418033],[-3.563022890418033],[-3.563022890418033]]]]]

Actual:   [[[[[-3.563], [-3.563], [-3.563]], [[-3.563], [-3.563], [-3.563]], [[-3.563], [-3.563], [-3.563]]], [[[-3.563], [-3.563], [-3.563]], [[-3.563], [0.7616], [-3.563]], [[-3.563], [-3.563], [-3.563]]], [[[-3.563], [-3.563], [-3.563]], [[-3.563], [0.7616], [-3.563]], [[-3.563], [-3.563], [-3.563]]], [[[-3.563], [-3.563], [-3.563]], [[-3.563], [-3.563], [-3.563]], [[-3.563], [-3.563], [-3.563]]]]]

Expected: [[[[[-3.563], [-3.563], [-3.563]], [[-3.563], [-3.563], [-3.563]], [[-3.563], [-3.563], [-3.563]]], [[[-3.563], [-3.563], [-3.563]], [[-3.563], [0.7616], [-3.563]], [[-3.563], [-3.563], [-3.563]]], [[[-3.563], [-3.563], [-3.563]], [[-3.563], [0.7616], [-3.563]], [[-3.563], [-3.563], [-3.563]]], [[[-3.563], [-3.563], [-3.563]], [[-3.563], [-3.563], [-3.563]], [[-3.563], [-3.563], [-3.563]]]]]