import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot75500 = tf.keras.layers.Input(shape=([2, 2]))
in1Dot75500 = tf.keras.layers.Input(shape=([2, 2]))
in0Con88717 = tf.keras.layers.Input(shape=([2, 30]))
in0Ave42009 = tf.keras.layers.Input(shape=([1, 1, 2, 1]))
in1Ave42009 = tf.keras.layers.Input(shape=([1, 1, 2, 1]))
in0Con69490 = tf.keras.layers.Input(shape=([1, 1, 16, 1]))
in0Con12960 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Dot27458 = tf.keras.layers.Input(shape=([3, 2]))
in1Dot27458 = tf.keras.layers.Input(shape=([3, 2]))
in0Con94755 = tf.keras.layers.Input(shape=([2, 30]))

Dot75500 = keras.layers.Dot(axes=(1, 2), name = 'Dot75500', )([in0Dot75500,in1Dot75500])
Den1891 = keras.layers.Dense(2,name = 'Den1891', )(Dot75500)
Con88717 = keras.layers.Concatenate(axis=2, name = 'Con88717', )([Den1891,in0Con88717])
Ave42009 = keras.layers.Average(name = 'Ave42009', )([in0Ave42009,in1Ave42009])
Zer6097 = keras.layers.ZeroPadding3D(padding=((0, 0), (0, 0), (14, 0)), name = 'Zer6097', )(Ave42009)
Con69490 = keras.layers.Concatenate(axis=4, name = 'Con69490', )([Zer6097,in0Con69490])
Con12960 = keras.layers.Conv3DTranspose(2, (1, 1, 2),strides=(1, 1, 8), padding='same', name = 'Con12960', )(in0Con12960)
Min23761 = keras.layers.Minimum(name = 'Min23761', )([Con69490,Con12960])
Res47212 = keras.layers.Reshape((1, 1, 32), name = 'Res47212', )(Min23761)
Res34910 = keras.layers.Reshape((1, 32), name = 'Res34910', )(Res47212)
Zer47586 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer47586', )(Res34910)
Dot27458 = keras.layers.Dot(axes=(1, 1), name = 'Dot27458', )([in0Dot27458,in1Dot27458])
Con94755 = keras.layers.Concatenate(axis=2, name = 'Con94755', )([Dot27458,in0Con94755])
Sub29071 = keras.layers.Subtract(name = 'Sub29071', )([Zer47586,Con94755])
Mul63377 = keras.layers.Multiply(name = 'Mul63377', )([Con88717,Sub29071])
model = tf.keras.models.Model(inputs=[in0Dot75500,in1Dot75500,in0Con88717,in0Ave42009,in1Ave42009,in0Con69490,in0Con12960,in0Dot27458,in1Dot27458,in0Con94755], outputs=Mul63377)
w = model.get_layer('Den1891').get_weights() 
w[0] = np.array([[0.9638, 0.7341], [0.5612, 0.6501]])
w[1] = np.array([0.1875, 0.541])
model.get_layer('Den1891').set_weights(w) 
w = model.get_layer('Con12960').get_weights() 
w[0] = np.array([[[[[0.5907, 0.7673], [0.8926, 0.984]], [[0.4856, 0.2787], [0.8881, 0.0836]]]]])
w[1] = np.array([0, 0])
model.get_layer('Con12960').set_weights(w) 
in0Dot75500 = tf.constant([[[0.6817, 0.7876], [0.7163, 0.3837]]])
in1Dot75500 = tf.constant([[[0.4965, 0.7619], [0.5832, 0.9097]]])
in0Con88717 = tf.constant([[[0.2127, 0.4737, 0.5475, 0.2775, 0.8902, 0.9117, 0.4236, 0.8121, 0.7639, 0.4786, 0.6256, 0.4695, 0.7108, 0.3353, 0.3232, 0.4285, 0.8595, 0.7207, 0.3448, 0.2003, 0.6832, 0.4514, 0.1044, 0.7598, 0.1923, 0.7827, 0.8555, 0.0077, 0.0754, 0.0445], [0.397, 0.1916, 0.9771, 0.7457, 0.8965, 0.5276, 0.098, 0.0377, 0.201, 0.2858, 0.9567, 0.5254, 0.8579, 0.0282, 0.4615, 0.4162, 0.084, 0.5223, 0.4061, 0.9126, 0.0876, 0.0914, 0.1277, 0.5688, 0.4762, 0.8081, 0.3391, 0.0557, 0.9608, 0.992]]])
in0Ave42009 = tf.constant([[[[[0.7134], [0.0304]]]]])
in1Ave42009 = tf.constant([[[[[0.9387], [0.531]]]]])
in0Con69490 = tf.constant([[[[[0.2068], [0.9912], [0.6729], [0.5981], [0.1797], [0.326], [0.2428], [0.8722], [0.4247], [0.0109], [0.306], [0.1568], [0.151], [0.5399], [0.8155], [0.7074]]]]])
in0Con12960 = tf.constant([[[[[0.4983, 0.2658], [0.5419, 0.9204]]]]])
in0Dot27458 = tf.constant([[[0.0021, 0.3591], [0.3969, 0.6769], [0.2913, 0.6683]]])
in1Dot27458 = tf.constant([[[0.3346, 0.1951], [0.7783, 0.2331], [0.8504, 0.1192]]])
in0Con94755 = tf.constant([[[0.3036, 0.534, 0.0664, 0.2408, 0.7908, 0.297, 0.6791, 0.713, 0.5206, 0.1437, 0.5328, 0.6659, 0.2337, 0.5952, 0.9577, 0.9939, 0.3906, 0.8291, 0.7073, 0.2235, 0.8707, 0.7202, 0.5298, 0.7436, 0.9751, 0.4536, 0.3067, 0.4003, 0.4858, 0.9281], [0.2323, 0.2399, 0.8229, 0.7103, 0.1186, 0.1781, 0.5335, 0.0017, 0.9317, 0.03, 0.4409, 0.9371, 0.0942, 0.6406, 0.7932, 0.5442, 0.9181, 0.8275, 0.6579, 0.8641, 0.7745, 0.462, 0.6264, 0.0589, 0.2515, 0.3009, 0.6184, 0.8109, 0.6014, 0.1094]]])
print (np.array2string(model.predict([in0Dot75500,in1Dot75500,in0Con88717,in0Ave42009,in1Ave42009,in0Con69490,in0Con12960,in0Dot27458,in1Dot27458,in0Con94755],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul63377.png')

LDot75500 = dot_layer([[[0.6817, 0.7876], [0.7163, 0.3837]]], [[[0.4965, 0.7619], [0.5832, 0.9097]]], 1, 2, Dot75500), 
LDen1891 = dense_layer(Dot75500, [[0.9638, 0.7341], [0.5612, 0.6501]],[0.1875, 0.541], Den1891), 
LCon88717 = concatenate_layer([Den1891,[[[0.2127, 0.4737, 0.5475, 0.2775, 0.8902, 0.9117, 0.4236, 0.8121, 0.7639, 0.4786, 0.6256, 0.4695, 0.7108, 0.3353, 0.3232, 0.4285, 0.8595, 0.7207, 0.3448, 0.2003, 0.6832, 0.4514, 0.1044, 0.7598, 0.1923, 0.7827, 0.8555, 0.0077, 0.0754, 0.0445], [0.397, 0.1916, 0.9771, 0.7457, 0.8965, 0.5276, 0.098, 0.0377, 0.201, 0.2858, 0.9567, 0.5254, 0.8579, 0.0282, 0.4615, 0.4162, 0.084, 0.5223, 0.4061, 0.9126, 0.0876, 0.0914, 0.1277, 0.5688, 0.4762, 0.8081, 0.3391, 0.0557, 0.9608, 0.992]]]], 2, Con88717), 
LAve42009 = average_layer([[[[[[0.7134], [0.0304]]]]], [[[[[0.9387], [0.531]]]]]], Ave42009), 
LZer6097 = zero_padding3D_layer(Ave42009, 0, 0, 0, 0, 14, 0, Zer6097), 
LCon69490 = concatenate_layer([Zer6097,[[[[[0.2068], [0.9912], [0.6729], [0.5981], [0.1797], [0.326], [0.2428], [0.8722], [0.4247], [0.0109], [0.306], [0.1568], [0.151], [0.5399], [0.8155], [0.7074]]]]]], 4, Con69490), 
LCon12960 = conv3D_transpose_layer([[[[[0.4983, 0.2658], [0.5419, 0.9204]]]]], 1, 1, 2,[[[[[0.5907, 0.7673], [0.8926, 0.984]], [[0.4856, 0.2787], [0.8881, 0.0836]]]]],[0, 0], 1, 1, 8, true, Con12960), 
LMin23761 = minimum_layer([Con69490,Con12960], Min23761), 
LRes47212 = reshape_layer(Min23761, [1, 1, 32], Res47212), 
LRes34910 = reshape_layer(Res47212, [1, 32], Res34910), 
LZer47586 = zero_padding1D_layer(Res34910, 1, 0, Zer47586), 
LDot27458 = dot_layer([[[0.0021, 0.3591], [0.3969, 0.6769], [0.2913, 0.6683]]], [[[0.3346, 0.1951], [0.7783, 0.2331], [0.8504, 0.1192]]], 1, 1, Dot27458), 
LCon94755 = concatenate_layer([Dot27458,[[[0.3036, 0.534, 0.0664, 0.2408, 0.7908, 0.297, 0.6791, 0.713, 0.5206, 0.1437, 0.5328, 0.6659, 0.2337, 0.5952, 0.9577, 0.9939, 0.3906, 0.8291, 0.7073, 0.2235, 0.8707, 0.7202, 0.5298, 0.7436, 0.9751, 0.4536, 0.3067, 0.4003, 0.4858, 0.9281], [0.2323, 0.2399, 0.8229, 0.7103, 0.1186, 0.1781, 0.5335, 0.0017, 0.9317, 0.03, 0.4409, 0.9371, 0.0942, 0.6406, 0.7932, 0.5442, 0.9181, 0.8275, 0.6579, 0.8641, 0.7745, 0.462, 0.6264, 0.0589, 0.2515, 0.3009, 0.6184, 0.8109, 0.6014, 0.1094]]]], 2, Con94755), 
LSub29071 = subtract_layer(Zer47586,Con94755, Sub29071), 
LMul63377 = multiply_layer([Con88717,Sub29071], Mul63377), 
exec_layers([LDot75500,LDen1891,LCon88717,LAve42009,LZer6097,LCon69490,LCon12960,LMin23761,LRes47212,LRes34910,LZer47586,LDot27458,LCon94755,LSub29071,LMul63377],["Dot75500","Den1891","Con88717","Ave42009","Zer6097","Con69490","Con12960","Min23761","Res47212","Res34910","Zer47586","Dot27458","Con94755","Sub29071","Mul63377"],Mul63377,"Mul63377")

Actual (Unparsed): [[[-0.9076184, -0.2389834, -0.0645757, -0.2529558, -0.0363540, -0.0668220, -0.7039702, -0.2707749, -0.2876667, -0.5790273, -0.3976863, -0.0687748, -0.3333197, -0.3126400, -0.1661140, -0.1995706, -0.3095286, -0.4258861, -0.3357207, -0.5975324, -0.2438770, -0.0447670, -0.5948622, -0.3250983, -0.0553111, -0.5649873, -0.1875117, -0.3550327, -0.2623818, -0.0030823, -0.0366293, -0.0413005], [-1.5796687, -0.1579290, -0.0922231, 0.0430834, -0.8040556, -0.5296707, -0.1063249, -0.0939656, -0.0522830, -0.0000641, -0.1872717, -0.0085740, -0.4218090, -0.4923523, -0.0808142, -0.0180649, -0.3660618, -0.0497359, -0.0771204, -0.4265102, -0.2671732, -0.7885776, -0.0678462, -0.0422268, -0.0799913, -0.0335023, -0.1197643, -0.2431573, -0.2096994, -0.0451671, -0.5778251, -0.1085248]]]

Expected (Unparsed): [[[-0.9076184125009198,-0.23898341754090124,-0.06457571999999999,-0.2529558,-0.036354,-0.066822,-0.7039701599999999,-0.2707749,-0.28766676,-0.5790273,-0.39768633999999997,-0.06877482,-0.33331968000000006,-0.31264005,-0.16611395999999998,-0.19957055999999998,-0.30952863999999997,-0.42588615,-0.33572070000000004,-0.5975323699999999,-0.24387704000000002,-0.04476705,-0.5948622400000001,-0.32509828,-0.055311120000000005,-0.5649872800000001,-0.18751173,-0.35503271999999997,-0.26238184999999997,-0.00308231,-0.03662932,-0.04130045],[-1.5796687243468353,-0.1579290171130784,-0.0922231,0.043083388676000006,-0.8040555899999999,-0.5296707100000001,-0.1063249,-0.09396556,-0.052282999999999996,-6.408999999999999e-5,-0.1872717,-0.008574,-0.42180903000000003,-0.49235234,-0.08081418,-0.018064919999999998,-0.36606180000000005,-0.0497359,-0.0771204,-0.42651017999999996,-0.26717319,-0.78857766,-0.0678462,-0.0422268,-0.07999128,-0.03350232,-0.1197643,-0.24315729000000003,-0.20969944,-0.04516713,-0.5778251200000001,-0.10852479999999999]]]

Actual:   [[[-0.9076, -0.2389, -0.0645, -0.2529, -0.0363, -0.0668, -0.7039, -0.2707, -0.2876, -0.579, -0.3976, -0.0687, -0.3333, -0.3126, -0.1661, -0.1995, -0.3095, -0.4258, -0.3357, -0.5975, -0.2438, -0.0447, -0.5948, -0.325, -0.0553, -0.5649, -0.1875, -0.355, -0.2623, -0.003, -0.0366, -0.0413], [-1.5796, -0.1579, -0.0922, 0.0431, -0.804, -0.5296, -0.1063, -0.0939, -0.0522, -0, -0.1872, -0.0085, -0.4218, -0.4923, -0.0808, -0.018, -0.366, -0.0497, -0.0771, -0.4265, -0.2671, -0.7885, -0.0678, -0.0422, -0.0799, -0.0335, -0.1197, -0.2431, -0.2096, -0.0451, -0.5778, -0.1085]]]

Expected: [[[-0.9076, -0.2389, -0.0645, -0.2529, -0.0363, -0.0668, -0.7039, -0.2707, -0.2876, -0.579, -0.3976, -0.0687, -0.3333, -0.3126, -0.1661, -0.1995, -0.3095, -0.4258, -0.3357, -0.5975, -0.2438, -0.0447, -0.5948, -0.325, -0.0553, -0.5649, -0.1875, -0.355, -0.2623, -0.003, -0.0366, -0.0413], [-1.5796, -0.1579, -0.0922, 0.0431, -0.804, -0.5296, -0.1063, -0.0939, -0.0522, -0, -0.1872, -0.0085, -0.4218, -0.4923, -0.0808, -0.018, -0.366, -0.0497, -0.0771, -0.4265, -0.2671, -0.7885, -0.0678, -0.0422, -0.0799, -0.0335, -0.1197, -0.2431, -0.2096, -0.0451, -0.5778, -0.1085]]]