import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max39401 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in1Max39401 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0Con68711 = tf.keras.layers.Input(shape=([3, 3, 2]))
in0Zer56571 = tf.keras.layers.Input(shape=([1, 1, 3]))

Max39401 = keras.layers.Maximum(name = 'Max39401', )([in0Max39401,in1Max39401])
Res38602 = keras.layers.Reshape((1, 2, 1), name = 'Res38602', )(Max39401)
Res23516 = keras.layers.Reshape((1, 2), name = 'Res23516', )(Res38602)
Glo57876 = keras.layers.GlobalAveragePooling1D(name = 'Glo57876', )(Res23516)
Res25634 = keras.layers.Reshape((2, 1), name = 'Res25634', )(Glo57876)
Res41956 = keras.layers.Reshape((2, 1, 1), name = 'Res41956', )(Res25634)
Zer4986 = keras.layers.ZeroPadding2D(padding=((1, 0), (2, 0)), name = 'Zer4986', )(Res41956)
Con68711 = keras.layers.Concatenate(axis=3, name = 'Con68711', )([Zer4986,in0Con68711])
Zer56571 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer56571', )(in0Zer56571)
Sof95464 = keras.layers.Softmax(axis=1, name = 'Sof95464', )(Zer56571)
Sub71630 = keras.layers.Subtract(name = 'Sub71630', )([Con68711,Sof95464])
model = tf.keras.models.Model(inputs=[in0Max39401,in1Max39401,in0Con68711,in0Zer56571], outputs=Sub71630)
in0Max39401 = tf.constant([[[[[0.1695]], [[0.1519]]]]])
in1Max39401 = tf.constant([[[[[0.5737]], [[0.2743]]]]])
in0Con68711 = tf.constant([[[[0.9192, 0.1363], [0.4578, 0.8334], [0.4372, 0.9445]], [[0.3783, 0.7465], [0.9559, 0.3634], [0.5551, 0.0835]], [[0.2997, 0.1429], [0.9148, 0.3545], [0.3981, 0.3882]]]])
in0Zer56571 = tf.constant([[[[1.3178, 1.9535, 1.5461]]]])
print (np.array2string(model.predict([in0Max39401,in1Max39401,in0Con68711,in0Zer56571],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub71630.png')

LMax39401 = maximum_layer([[[[[[0.1695]], [[0.1519]]]]], [[[[[0.5737]], [[0.2743]]]]]], Max39401), 
LRes38602 = reshape_layer(Max39401, [1, 2, 1], Res38602), 
LRes23516 = reshape_layer(Res38602, [1, 2], Res23516), 
LGlo57876 = global_average_pooling1D_layer(Res23516, Glo57876), 
LRes25634 = reshape_layer(Glo57876, [2, 1], Res25634), 
LRes41956 = reshape_layer(Res25634, [2, 1, 1], Res41956), 
LZer4986 = zero_padding2D_layer(Res41956, 1, 0, 2, 0, Zer4986), 
LCon68711 = concatenate_layer([Zer4986,[[[[0.9192, 0.1363], [0.4578, 0.8334], [0.4372, 0.9445]], [[0.3783, 0.7465], [0.9559, 0.3634], [0.5551, 0.0835]], [[0.2997, 0.1429], [0.9148, 0.3545], [0.3981, 0.3882]]]]], 3, Con68711), 
LZer56571 = zero_padding2D_layer([[[[1.3178, 1.9535, 1.5461]]]], 1, 1, 1, 1, Zer56571), 
LSof95464 = softmax_layer(Zer56571, 1, Sof95464), 
LSub71630 = subtract_layer(Con68711,Sof95464, Sub71630), 
exec_layers([LMax39401,LRes38602,LRes23516,LGlo57876,LRes25634,LRes41956,LZer4986,LCon68711,LZer56571,LSof95464,LSub71630],["Max39401","Res38602","Res23516","Glo57876","Res25634","Res41956","Zer4986","Con68711","Zer56571","Sof95464","Sub71630"],Sub71630,"Sub71630")

Actual (Unparsed): [[[[-0.3333333, 0.5858667, -0.1970333], [-0.1743620, 0.3473434, 0.6839931], [-0.3333333, 0.1038667, 0.6111667]], [[-0.3333333, 0.0449667, 0.4131667], [-0.6512760, 0.1768132, -0.3377862], [0.2403667, 0.2217667, -0.2498333]], [[-0.3333333, -0.0336333, -0.1904333], [-0.1743620, 0.8043434, 0.2050931], [-0.0590333, 0.0647667, 0.0548667]]]]

Expected (Unparsed): [[[[-0.3333333333333333,0.5858666666666668,-0.1970333333333333],[-0.17436199065079513,0.34734341885119535,0.6839930983306595],[-0.3333333333333333,0.10386666666666666,0.6111666666666666]],[[-0.3333333333333333,0.04496666666666671,0.41316666666666674],[-0.6512760186984097,0.17681316229760924,-0.33778619666131876],[0.24036666666666667,0.22176666666666672,-0.2498333333333333]],[[-0.3333333333333333,-0.03363333333333329,-0.19043333333333332],[-0.17436199065079513,0.8043434188511953,0.20509309833065936],[-0.05903333333333333,0.0647666666666667,0.054866666666666675]]]]

Actual:   [[[[-0.3333, 0.5859, -0.197], [-0.1743, 0.3474, 0.684], [-0.3333, 0.1039, 0.6112]], [[-0.3333, 0.045, 0.4132], [-0.6512, 0.1769, -0.3377], [0.2404, 0.2218, -0.2498]], [[-0.3333, -0.0336, -0.1904], [-0.1743, 0.8044, 0.2051], [-0.059, 0.0648, 0.0549]]]]

Expected: [[[[-0.3333, 0.5859, -0.197], [-0.1743, 0.3474, 0.684], [-0.3333, 0.1039, 0.6112]], [[-0.3333, 0.045, 0.4132], [-0.6512, 0.1769, -0.3377], [0.2404, 0.2218, -0.2498]], [[-0.3333, -0.0336, -0.1904], [-0.1743, 0.8044, 0.2051], [-0.059, 0.0648, 0.0549]]]]