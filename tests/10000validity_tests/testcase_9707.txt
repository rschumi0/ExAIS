import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min20714 = tf.keras.layers.Input(shape=([2, 2]))
in1Min20714 = tf.keras.layers.Input(shape=([2, 2]))
in0LST17065 = tf.keras.layers.Input(shape=([3, 1]))
in0Con16580 = tf.keras.layers.Input(shape=([1]))
in0Con60963 = tf.keras.layers.Input(shape=([4, 1]))
in0Add30836 = tf.keras.layers.Input(shape=([1, 2]))
in1Add30836 = tf.keras.layers.Input(shape=([1, 2]))

Min20714 = keras.layers.Minimum(name = 'Min20714', )([in0Min20714,in1Min20714])
Fla16689 = keras.layers.Flatten(name = 'Fla16689', )(Min20714)
LST17065 = keras.layers.LSTM(3,recurrent_activation='sigmoid', name = 'LST17065', )(in0LST17065)
Con16580 = keras.layers.Concatenate(axis=1, name = 'Con16580', )([LST17065,in0Con16580])
Add60318 = keras.layers.Add(name = 'Add60318', )([Fla16689,Con16580])
Res788 = keras.layers.Reshape((4, 1), name = 'Res788', )(Add60318)
Con60963 = keras.layers.Concatenate(axis=2, name = 'Con60963', )([Res788,in0Con60963])
Add30836 = keras.layers.Add(name = 'Add30836', )([in0Add30836,in1Add30836])
Zer31434 = keras.layers.ZeroPadding1D(padding=((3, 0)), name = 'Zer31434', )(Add30836)
Mul80135 = keras.layers.Multiply(name = 'Mul80135', )([Con60963,Zer31434])
Res97182 = keras.layers.Reshape((4, 2, 1), name = 'Res97182', )(Mul80135)
Res92014 = keras.layers.Reshape((4, 2, 1, 1), name = 'Res92014', )(Res97182)
Glo50958 = keras.layers.GlobalAveragePooling3D(name = 'Glo50958', )(Res92014)
model = tf.keras.models.Model(inputs=[in0Min20714,in1Min20714,in0LST17065,in0Con16580,in0Con60963,in0Add30836,in1Add30836], outputs=Glo50958)
w = model.get_layer('LST17065').get_weights() 
w[0] = np.array([[8, 4, 2, 1, 2, 9, 8, 4, 2, 6, 4, 9]])
w[1] = np.array([[3, 4, 2, 5, 3, 10, 6, 8, 3, 8, 1, 1], [5, 5, 4, 7, 3, 8, 6, 9, 9, 8, 1, 6], [7, 1, 6, 8, 10, 10, 7, 8, 6, 6, 10, 6]])
w[2] = np.array([6, 1, 10, 10, 3, 3, 9, 6, 2, 3, 4, 5])
model.get_layer('LST17065').set_weights(w) 
in0Min20714 = tf.constant([[[0.9559, 0.0582], [0.3529, 0.2168]]])
in1Min20714 = tf.constant([[[0.8312, 0.9511], [0.6207, 0.2398]]])
in0LST17065 = tf.constant([[[1], [5], [4]]])
in0Con16580 = tf.constant([[0.8464]])
in0Con60963 = tf.constant([[[0.4741], [0.4711], [0.7011], [0.0269]]])
in0Add30836 = tf.constant([[[0.3629, 0.798]]])
in1Add30836 = tf.constant([[[0.6437, 0.0629]]])
print (np.array2string(model.predict([in0Min20714,in1Min20714,in0LST17065,in0Con16580,in0Con60963,in0Add30836,in1Add30836],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Glo50958.png')

LMin20714 = minimum_layer([[[[0.9559, 0.0582], [0.3529, 0.2168]]], [[[0.8312, 0.9511], [0.6207, 0.2398]]]], Min20714), 
LFla16689 = flatten_layer(Min20714, Fla16689), 
LLST17065 = lstm_layer([[[1], [5], [4]]],[[8, 4, 2, 1, 2, 9, 8, 4, 2, 6, 4, 9]],[[3, 4, 2, 5, 3, 10, 6, 8, 3, 8, 1, 1], [5, 5, 4, 7, 3, 8, 6, 9, 9, 8, 1, 6], [7, 1, 6, 8, 10, 10, 7, 8, 6, 6, 10, 6]],[6, 1, 10, 10, 3, 3, 9, 6, 2, 3, 4, 5], LST17065), 
LCon16580 = concatenate_layer([LST17065,[[0.8464]]], 1, Con16580), 
LAdd60318 = add_layer([Fla16689,Con16580], Add60318), 
LRes788 = reshape_layer(Add60318, [4, 1], Res788), 
LCon60963 = concatenate_layer([Res788,[[[0.4741], [0.4711], [0.7011], [0.0269]]]], 2, Con60963), 
LAdd30836 = add_layer([[[[0.3629, 0.798]]], [[[0.6437, 0.0629]]]], Add30836), 
LZer31434 = zero_padding1D_layer(Add30836, 3, 0, Zer31434), 
LMul80135 = multiply_layer([Con60963,Zer31434], Mul80135), 
LRes97182 = reshape_layer(Mul80135, [4, 2, 1], Res97182), 
LRes92014 = reshape_layer(Res97182, [4, 2, 1, 1], Res92014), 
LGlo50958 = global_average_pooling3D_layer(Res92014, Glo50958), 
exec_layers([LMin20714,LFla16689,LLST17065,LCon16580,LAdd60318,LRes788,LCon60963,LAdd30836,LZer31434,LMul80135,LRes97182,LRes92014,LGlo50958],["Min20714","Fla16689","LST17065","Con16580","Add60318","Res788","Con60963","Add30836","Zer31434","Mul80135","Res97182","Res92014","Glo50958"],Glo50958,"Glo50958")

Actual (Unparsed): [[0.1366719]]

Expected (Unparsed): [[0.13667191625000005]]

Actual:   [[0.1367]]

Expected: [[0.1367]]