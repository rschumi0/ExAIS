import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add45958 = tf.keras.layers.Input(shape=([1, 2, 1]))
in1Add45958 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con14 = tf.keras.layers.Input(shape=([16]))
in0Sub8916 = tf.keras.layers.Input(shape=([3, 3, 2]))
in1Sub8916 = tf.keras.layers.Input(shape=([3, 3, 2]))
in0GRU51390 = tf.keras.layers.Input(shape=([3, 3]))
in0Con86497 = tf.keras.layers.Input(shape=([15]))

Add45958 = keras.layers.Add(name = 'Add45958', )([in0Add45958,in1Add45958])
Dep96827 = keras.layers.DepthwiseConv2D((2, 2),strides=(1, 1), padding='same', name = 'Dep96827', )(Add45958)
Res52750 = keras.layers.Reshape((1, 2), name = 'Res52750', )(Dep96827)
Ave10005 = keras.layers.AveragePooling1D(pool_size=(1), strides=(4), padding='same', name = 'Ave10005', )(Res52750)
Fla72919 = keras.layers.Flatten(name = 'Fla72919', )(Ave10005)
Con14 = keras.layers.Concatenate(axis=1, name = 'Con14', )([Fla72919,in0Con14])
Sub8916 = keras.layers.Subtract(name = 'Sub8916', )([in0Sub8916,in1Sub8916])
Res10771 = keras.layers.Reshape((3, 6), name = 'Res10771', )(Sub8916)
Fla77968 = keras.layers.Flatten(name = 'Fla77968', )(Res10771)
GRU51390 = keras.layers.GRU(3,reset_after=False, recurrent_activation='sigmoid', name = 'GRU51390', )(in0GRU51390)
Con86497 = keras.layers.Concatenate(axis=1, name = 'Con86497', )([GRU51390,in0Con86497])
Add13518 = keras.layers.Add(name = 'Add13518', )([Fla77968,Con86497])
Max86856 = keras.layers.Maximum(name = 'Max86856', )([Con14,Add13518])
model = tf.keras.models.Model(inputs=[in0Add45958,in1Add45958,in0Con14,in0Sub8916,in1Sub8916,in0GRU51390,in0Con86497], outputs=Max86856)
w = model.get_layer('Dep96827').get_weights() 
w[0] = np.array([[[[0.6017]], [[0.8657]]], [[[0.7122]], [[0.6744]]]])
w[1] = np.array([0])
model.get_layer('Dep96827').set_weights(w) 
w = model.get_layer('GRU51390').get_weights() 
w[0] = np.array([[9, 6, 8, 5, 10, 7, 5, 6, 8], [1, 9, 10, 6, 6, 4, 5, 6, 5], [10, 1, 7, 9, 1, 4, 2, 4, 8]])
w[1] = np.array([[2, 3, 1, 4, 5, 2, 3, 4, 3], [8, 6, 6, 4, 1, 5, 4, 7, 1], [1, 4, 7, 1, 6, 4, 6, 10, 8]])
w[2] = np.array([7, 3, 6, 9, 9, 10, 3, 5, 10])
model.get_layer('GRU51390').set_weights(w) 
in0Add45958 = tf.constant([[[[0.7258], [0.7169]]]])
in1Add45958 = tf.constant([[[[0.2983], [0.4418]]]])
in0Con14 = tf.constant([[0.626, 0.287, 0.6356, 0.7016, 0.1449, 0.71, 0.8329, 0.9586, 0.6596, 0.9236, 0.252, 0.1325, 0.9489, 0.0405, 0.6958, 0.8004]])
in0Sub8916 = tf.constant([[[[0.9876, 0.7403], [0.3822, 0.2607], [0.9994, 0.7932]], [[0.0929, 0.2695], [0.5002, 0.0023], [0.7613, 0.499]], [[0.1311, 0.6975], [0.6544, 0.4403], [0.1375, 0.5534]]]])
in1Sub8916 = tf.constant([[[[0.0146, 0.1981], [0.769, 0.6331], [0.6381, 0.0965]], [[0.837, 0.9118], [0.9185, 0.8336], [0.2098, 0.0903]], [[0.4988, 0.0315], [0.3801, 0.0262], [0.4136, 0.5614]]]])
in0GRU51390 = tf.constant([[[6, 5, 8], [2, 7, 5], [7, 6, 4]]])
in0Con86497 = tf.constant([[0.4787, 0.9698, 0.2969, 0.8096, 0.0613, 0.1755, 0.8671, 0.65, 0.6506, 0.2994, 0.1478, 0.6237, 0.6611, 0.5158, 0.9771]])
print (np.array2string(model.predict([in0Add45958,in1Add45958,in0Con14,in0Sub8916,in1Sub8916,in0GRU51390,in0Con86497],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max86856.png')

LAdd45958 = add_layer([[[[[0.7258], [0.7169]]]], [[[[0.2983], [0.4418]]]]], Add45958), 
LDep96827 = depthwise_conv2D_layer(Add45958, 2, 2,[[[[0.6017]], [[0.8657]]], [[[0.7122]], [[0.6744]]]],[0], 1, 1, true, Dep96827), 
LRes52750 = reshape_layer(Dep96827, [1, 2], Res52750), 
LAve10005 = average_pooling1D_layer(Res52750, 1, 4, true, Ave10005), 
LFla72919 = flatten_layer(Ave10005, Fla72919), 
LCon14 = concatenate_layer([Fla72919,[[0.626, 0.287, 0.6356, 0.7016, 0.1449, 0.71, 0.8329, 0.9586, 0.6596, 0.9236, 0.252, 0.1325, 0.9489, 0.0405, 0.6958, 0.8004]]], 1, Con14), 
LSub8916 = subtract_layer([[[[0.9876, 0.7403], [0.3822, 0.2607], [0.9994, 0.7932]], [[0.0929, 0.2695], [0.5002, 0.0023], [0.7613, 0.499]], [[0.1311, 0.6975], [0.6544, 0.4403], [0.1375, 0.5534]]]], [[[[0.0146, 0.1981], [0.769, 0.6331], [0.6381, 0.0965]], [[0.837, 0.9118], [0.9185, 0.8336], [0.2098, 0.0903]], [[0.4988, 0.0315], [0.3801, 0.0262], [0.4136, 0.5614]]]], Sub8916), 
LRes10771 = reshape_layer(Sub8916, [3, 6], Res10771), 
LFla77968 = flatten_layer(Res10771, Fla77968), 
LGRU51390 = gru_layer([[[6, 5, 8], [2, 7, 5], [7, 6, 4]]],[[9, 6, 8, 5, 10, 7, 5, 6, 8], [1, 9, 10, 6, 6, 4, 5, 6, 5], [10, 1, 7, 9, 1, 4, 2, 4, 8]],[[2, 3, 1, 4, 5, 2, 3, 4, 3], [8, 6, 6, 4, 1, 5, 4, 7, 1], [1, 4, 7, 1, 6, 4, 6, 10, 8]],[7, 3, 6, 9, 9, 10, 3, 5, 10], false, GRU51390), 
LCon86497 = concatenate_layer([GRU51390,[[0.4787, 0.9698, 0.2969, 0.8096, 0.0613, 0.1755, 0.8671, 0.65, 0.6506, 0.2994, 0.1478, 0.6237, 0.6611, 0.5158, 0.9771]]], 1, Con86497), 
LAdd13518 = add_layer([Fla77968,Con86497], Add13518), 
LMax86856 = maximum_layer([Con14,Add13518], Max86856), 
exec_layers([LAdd45958,LDep96827,LRes52750,LAve10005,LFla72919,LCon14,LSub8916,LRes10771,LFla77968,LGRU51390,LCon86497,LAdd13518,LMax86856],["Add45958","Dep96827","Res52750","Ave10005","Fla72919","Con14","Sub8916","Res10771","Fla77968","GRU51390","Con86497","Add13518","Max86856"],Max86856,"Max86856")

Actual (Unparsed): [[1.6192875, 0.6971898, 0.6260000, 0.2870000, 1.3311000, 0.9936000, 0.1449000, 0.7100000, 0.8329000, 0.9586000, 1.2015000, 1.0593000, 0.2520000, 0.8138000, 0.9489000, 1.0752000, 0.6958000, 0.9691000]]

Expected (Unparsed): [[1.61928756,0.69718979,0.626,0.287,1.3311,0.9936,0.1449,0.71,0.8329,0.9586,1.2015,1.0593,0.252,0.8138000000000001,0.9489,1.0752000000000002,0.6958,0.9691]]

Actual:   [[1.6193, 0.6972, 0.626, 0.287, 1.3311, 0.9936, 0.1449, 0.71, 0.8329, 0.9586, 1.2015, 1.0593, 0.252, 0.8138, 0.9489, 1.0752, 0.6958, 0.9691]]

Expected: [[1.6193, 0.6972, 0.626, 0.287, 1.3311, 0.9936, 0.1449, 0.71, 0.8329, 0.9586, 1.2015, 1.0593, 0.252, 0.8139, 0.9489, 1.0753, 0.6958, 0.9691]]