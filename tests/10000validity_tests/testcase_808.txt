import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo35776 = tf.keras.layers.Input(shape=([2, 1]))
in0Con38887 = tf.keras.layers.Input(shape=([1, 3]))
in0Min82986 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in1Min82986 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))

Glo35776 = keras.layers.GlobalMaxPool1D(name = 'Glo35776', )(in0Glo35776)
Res69462 = keras.layers.Reshape((1, 1), name = 'Res69462', )(Glo35776)
PRe46340 = keras.layers.PReLU(name = 'PRe46340', )(Res69462)
ReL21307 = keras.layers.ReLU(max_value=9.044701768100904, negative_slope=9.681228319275224, threshold=8.90970338066873, name = 'ReL21307', )(PRe46340)
Con38887 = keras.layers.Concatenate(axis=2, name = 'Con38887', )([ReL21307,in0Con38887])
Min82986 = keras.layers.Minimum(name = 'Min82986', )([in0Min82986,in1Min82986])
Res80704 = keras.layers.Reshape((2, 2, 2), name = 'Res80704', )(Min82986)
Res86218 = keras.layers.Reshape((2, 4), name = 'Res86218', )(Res80704)
Dot24035 = keras.layers.Dot(axes=(2, 2), name = 'Dot24035', )([Con38887,Res86218])
model = tf.keras.models.Model(inputs=[in0Glo35776,in0Con38887,in0Min82986,in1Min82986], outputs=Dot24035)
w = model.get_layer('PRe46340').get_weights() 
w[0] = np.array([[0.58]])
model.get_layer('PRe46340').set_weights(w) 
in0Glo35776 = tf.constant([[[1.0615], [1.6376]]])
in0Con38887 = tf.constant([[[0.4669, 0.6198, 0.8668]]])
in0Min82986 = tf.constant([[[[[0.0751, 0.105]], [[0.4518, 0.908]]], [[[0.2865, 0.8519]], [[0.9161, 0.0021]]]]])
in1Min82986 = tf.constant([[[[[0.9654, 0.4366]], [[0.1575, 0.5788]]], [[[0.8002, 0.9648]], [[0.1626, 0.5299]]]]])
print (np.array2string(model.predict([in0Glo35776,in0Con38887,in0Min82986,in1Min82986],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot24035.png')

LGlo35776 = global_max_pool1D_layer([[[1.0615], [1.6376]]], Glo35776), 
LRes69462 = reshape_layer(Glo35776, [1, 1], Res69462), 
LPRe46340 = prelu_layer(Res69462, [[0.58]], PRe46340), 
LReL21307 = relu_layer(PRe46340, 9.044701768100904, 9.681228319275224, 8.90970338066873, ReL21307), 
LCon38887 = concatenate_layer([ReL21307,[[[0.4669, 0.6198, 0.8668]]]], 2, Con38887), 
LMin82986 = minimum_layer([[[[[[0.0751, 0.105]], [[0.4518, 0.908]]], [[[0.2865, 0.8519]], [[0.9161, 0.0021]]]]], [[[[[0.9654, 0.4366]], [[0.1575, 0.5788]]], [[[0.8002, 0.9648]], [[0.1626, 0.5299]]]]]], Min82986), 
LRes80704 = reshape_layer(Min82986, [2, 2, 2], Res80704), 
LRes86218 = reshape_layer(Res80704, [2, 4], Res86218), 
LDot24035 = dot_layer(Con38887,Res86218, 2, 2, Dot24035), 
exec_layers([LGlo35776,LRes69462,LPRe46340,LReL21307,LCon38887,LMin82986,LRes80704,LRes86218,LDot24035],["Glo35776","Res69462","PRe46340","ReL21307","Con38887","Min82986","Res80704","Res86218","Dot24035"],Dot24035,"Dot24035")

Actual (Unparsed): [[[-4.6389103, -19.6700777]]]

Expected (Unparsed): [[[-4.638910438541003,-19.670077028828192]]]

Actual:   [[[-4.6389, -19.67]]]

Expected: [[[-4.6389, -19.67]]]