import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo82615 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in0Con94230 = tf.keras.layers.Input(shape=([3, 1]))
in0ReL83530 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Add82729 = tf.keras.layers.Input(shape=([2, 2, 1]))
in1Add82729 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Ave24271 = tf.keras.layers.Input(shape=([1, 1]))
in0Con85449 = tf.keras.layers.Input(shape=([3, 1]))

Glo82615 = keras.layers.GlobalAveragePooling3D(name = 'Glo82615', )(in0Glo82615)
Bat2111 = keras.layers.BatchNormalization(axis=1, epsilon=0.24407853103496865,  name = 'Bat2111', )(Glo82615)
Bat61068 = keras.layers.BatchNormalization(axis=1, epsilon=0.46330165037214466,  name = 'Bat61068', )(Bat2111)
Res35245 = keras.layers.Reshape((1, 1), name = 'Res35245', )(Bat61068)
Zer94082 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer94082', )(Res35245)
Con94230 = keras.layers.Concatenate(axis=2, name = 'Con94230', )([Zer94082,in0Con94230])
ReL83530 = keras.layers.ReLU(max_value=6.68724331394135, negative_slope=3.1814285199618175, threshold=0.3345664374079449, name = 'ReL83530', input_shape=(1, 2, 1))(in0ReL83530)
Res46913 = keras.layers.Reshape((1, 2), name = 'Res46913', )(ReL83530)
Zer58583 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer58583', )(Res46913)
Res71068 = keras.layers.Reshape((3, 2, 1), name = 'Res71068', )(Zer58583)
Add82729 = keras.layers.Add(name = 'Add82729', )([in0Add82729,in1Add82729])
Zer78837 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer78837', )(Add82729)
Sub17588 = keras.layers.Subtract(name = 'Sub17588', )([Res71068,Zer78837])
Res81718 = keras.layers.Reshape((3, 2), name = 'Res81718', )(Sub17588)
Ave24271 = keras.layers.AveragePooling1D(pool_size=(1), name = 'Ave24271', )(in0Ave24271)
Lea28857 = keras.layers.LeakyReLU(alpha=2.22879904540994, name = 'Lea28857', )(Ave24271)
Zer42884 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer42884', )(Lea28857)
Con85449 = keras.layers.Concatenate(axis=2, name = 'Con85449', )([Zer42884,in0Con85449])
Mul71796 = keras.layers.Multiply(name = 'Mul71796', )([Res81718,Con85449])
Mul61634 = keras.layers.Multiply(name = 'Mul61634', )([Con94230,Mul71796])
model = tf.keras.models.Model(inputs=[in0Glo82615,in0Con94230,in0ReL83530,in0Add82729,in1Add82729,in0Ave24271,in0Con85449], outputs=Mul61634)
w = model.get_layer('Bat2111').get_weights() 
w[0] = np.array([0.0179])
w[1] = np.array([0.2977])
w[2] = np.array([0.3774])
w[3] = np.array([0.05])
model.get_layer('Bat2111').set_weights(w) 
w = model.get_layer('Bat61068').get_weights() 
w[0] = np.array([0.3538])
w[1] = np.array([0.5375])
w[2] = np.array([0.5642])
w[3] = np.array([0.0768])
model.get_layer('Bat61068').set_weights(w) 
in0Glo82615 = tf.constant([[[[[1.9792]], [[1.6676]]], [[[1.4082]], [[1.4994]]]]])
in0Con94230 = tf.constant([[[0.1129], [0.2432], [0.2451]]])
in0ReL83530 = tf.constant([[[[0.1449], [0.6059]]]])
in0Add82729 = tf.constant([[[[0.2932], [0.6542]], [[0.3623], [0.865]]]])
in1Add82729 = tf.constant([[[[0.2324], [0.4985]], [[0.7646], [0.9283]]]])
in0Ave24271 = tf.constant([[[1.735]]])
in0Con85449 = tf.constant([[[0.2026], [0.5763], [0.3641]]])
print (np.array2string(model.predict([in0Glo82615,in0Con94230,in0ReL83530,in0Add82729,in1Add82729,in0Ave24271,in0Con85449],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul61634.png')

LGlo82615 = global_average_pooling3D_layer([[[[[1.9792]], [[1.6676]]], [[[1.4082]], [[1.4994]]]]], Glo82615), 
LBat2111 = batch_normalization_layer(Glo82615, 1, 0.24407853103496865, [0.0179], [0.2977], [0.3774], [0.05], Bat2111), 
LBat61068 = batch_normalization_layer(Bat2111, 1, 0.46330165037214466, [0.3538], [0.5375], [0.5642], [0.0768], Bat61068), 
LRes35245 = reshape_layer(Bat61068, [1, 1], Res35245), 
LZer94082 = zero_padding1D_layer(Res35245, 2, 0, Zer94082), 
LCon94230 = concatenate_layer([Zer94082,[[[0.1129], [0.2432], [0.2451]]]], 2, Con94230), 
LReL83530 = relu_layer([[[[0.1449], [0.6059]]]], 6.68724331394135, 3.1814285199618175, 0.3345664374079449, ReL83530), 
LRes46913 = reshape_layer(ReL83530, [1, 2], Res46913), 
LZer58583 = zero_padding1D_layer(Res46913, 1, 1, Zer58583), 
LRes71068 = reshape_layer(Zer58583, [3, 2, 1], Res71068), 
LAdd82729 = add_layer([[[[[0.2932], [0.6542]], [[0.3623], [0.865]]]], [[[[0.2324], [0.4985]], [[0.7646], [0.9283]]]]], Add82729), 
LZer78837 = zero_padding2D_layer(Add82729, 1, 0, 0, 0, Zer78837), 
LSub17588 = subtract_layer(Res71068,Zer78837, Sub17588), 
LRes81718 = reshape_layer(Sub17588, [3, 2], Res81718), 
LAve24271 = average_pooling1D_layer([[[1.735]]], 1, Ave24271), 
LLea28857 = leaky_relu_layer(Ave24271, 2.22879904540994, Lea28857), 
LZer42884 = zero_padding1D_layer(Lea28857, 2, 0, Zer42884), 
LCon85449 = concatenate_layer([Zer42884,[[[0.2026], [0.5763], [0.3641]]]], 2, Con85449), 
LMul71796 = multiply_layer([Res81718,Con85449], Mul71796), 
LMul61634 = multiply_layer([Con94230,Mul71796], Mul61634), 
exec_layers([LGlo82615,LBat2111,LBat61068,LRes35245,LZer94082,LCon94230,LReL83530,LRes46913,LZer58583,LRes71068,LAdd82729,LZer78837,LSub17588,LRes81718,LAve24271,LLea28857,LZer42884,LCon85449,LMul71796,LMul61634],["Glo82615","Bat2111","Bat61068","Res35245","Zer94082","Con94230","ReL83530","Res46913","Zer58583","Res71068","Add82729","Zer78837","Sub17588","Res81718","Ave24271","Lea28857","Zer42884","Con85449","Mul71796","Mul61634"],Mul61634,"Mul61634")

Actual (Unparsed): [[[0.0000000, 0.0000000], [-0.0000000, -0.0766374], [-0.8392457, -0.1600357]]]

Expected (Unparsed): [[[0,0.0],[-0.0,-0.07663738828800001],[-0.8392457231897607,-0.160035723903]]]

Actual:   [[[0, 0], [-0, -0.0766], [-0.8392, -0.16]]]

Expected: [[[0, 0], [-0, -0.0766], [-0.8392, -0.16]]]