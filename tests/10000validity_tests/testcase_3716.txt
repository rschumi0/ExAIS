import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer78806 = tf.keras.layers.Input(shape=([4, 4]))
in0PRe47822 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con51148 = tf.keras.layers.Input(shape=([23]))

Zer78806 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer78806', )(in0Zer78806)
Fla73642 = keras.layers.Flatten(name = 'Fla73642', )(Zer78806)
PRe47822 = keras.layers.PReLU(name = 'PRe47822', input_shape=(1, 1, 2))(in0PRe47822)
Res22206 = keras.layers.Reshape((1, 1, 2, 1), name = 'Res22206', )(PRe47822)
Glo76103 = keras.layers.GlobalAveragePooling3D(name = 'Glo76103', )(Res22206)
Con51148 = keras.layers.Concatenate(axis=1, name = 'Con51148', )([Glo76103,in0Con51148])
Add76752 = keras.layers.Add(name = 'Add76752', )([Fla73642,Con51148])
model = tf.keras.models.Model(inputs=[in0Zer78806,in0PRe47822,in0Con51148], outputs=Add76752)
w = model.get_layer('PRe47822').get_weights() 
w[0] = np.array([[[0.5979, 0.3604]]])
model.get_layer('PRe47822').set_weights(w) 
in0Zer78806 = tf.constant([[[1.5252, 1.5468, 1.1423, 1.8628], [1.3568, 1.342, 1.547, 1.4084], [1.2998, 1.8907, 1.7615, 1.7722], [1.3816, 1.7967, 1.5585, 1.2966]]])
in0PRe47822 = tf.constant([[[[0.3997, 0.0519]]]])
in0Con51148 = tf.constant([[0.6571, 0.4092, 0.4332, 0.7439, 0.4551, 0.2241, 0.5313, 0.8774, 0.5004, 0.0937, 0.6719, 0.6984, 0.5368, 0.6657, 0.5627, 0.9043, 0.4723, 0.1012, 0.9596, 0.4992, 0.8851, 0.0787, 0.3885]])
print (np.array2string(model.predict([in0Zer78806,in0PRe47822,in0Con51148],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add76752.png')

LZer78806 = zero_padding1D_layer([[[1.5252, 1.5468, 1.1423, 1.8628], [1.3568, 1.342, 1.547, 1.4084], [1.2998, 1.8907, 1.7615, 1.7722], [1.3816, 1.7967, 1.5585, 1.2966]]], 1, 1, Zer78806), 
LFla73642 = flatten_layer(Zer78806, Fla73642), 
LPRe47822 = prelu_layer([[[[0.3997, 0.0519]]]], [[[0.5979, 0.3604]]], PRe47822), 
LRes22206 = reshape_layer(PRe47822, [1, 1, 2, 1], Res22206), 
LGlo76103 = global_average_pooling3D_layer(Res22206, Glo76103), 
LCon51148 = concatenate_layer([Glo76103,[[0.6571, 0.4092, 0.4332, 0.7439, 0.4551, 0.2241, 0.5313, 0.8774, 0.5004, 0.0937, 0.6719, 0.6984, 0.5368, 0.6657, 0.5627, 0.9043, 0.4723, 0.1012, 0.9596, 0.4992, 0.8851, 0.0787, 0.3885]]], 1, Con51148), 
LAdd76752 = add_layer([Fla73642,Con51148], Add76752), 
exec_layers([LZer78806,LFla73642,LPRe47822,LRes22206,LGlo76103,LCon51148,LAdd76752],["Zer78806","Fla73642","PRe47822","Res22206","Glo76103","Con51148","Add76752"],Add76752,"Add76752")

Actual (Unparsed): [[0.2258000, 0.6571000, 0.4092000, 0.4332000, 2.2691000, 2.0019000, 1.3664000, 2.3941000, 2.2341999, 1.8424000, 1.6407000, 2.0803000, 1.9982001, 2.4275000, 2.4272000, 2.3349000, 2.2859000, 2.2690000, 1.6597001, 2.2562000, 0.4992000, 0.8851000, 0.0787000, 0.3885000]]

Expected (Unparsed): [[0.2258,0.6571,0.4092,0.4332,2.2691,2.0019,1.3664,2.3941,2.2342,1.8424,1.6406999999999998,2.0803000000000003,1.9982000000000002,2.4275,2.4272,2.3349,2.2859,2.269,1.6597,2.2561999999999998,0.4992,0.8851,0.0787,0.3885]]

Actual:   [[0.2258, 0.6571, 0.4092, 0.4332, 2.2691, 2.0019, 1.3664, 2.3941, 2.2342, 1.8424, 1.6407, 2.0803, 1.9983, 2.4275, 2.4272, 2.3349, 2.2859, 2.269, 1.6598, 2.2562, 0.4992, 0.8851, 0.0787, 0.3885]]

Expected: [[0.2258, 0.6571, 0.4092, 0.4332, 2.2691, 2.0019, 1.3664, 2.3941, 2.2342, 1.8424, 1.6407, 2.0804, 1.9983, 2.4275, 2.4272, 2.3349, 2.2859, 2.269, 1.6597, 2.2562, 0.4992, 0.8851, 0.0787, 0.3885]]