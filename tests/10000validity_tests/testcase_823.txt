import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dep13912 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con39645 = tf.keras.layers.Input(shape=([3, 5, 2]))
in0Dot89053 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot89053 = tf.keras.layers.Input(shape=([3, 3]))
in0Con14384 = tf.keras.layers.Input(shape=([3, 5, 2]))
in0Up_78243 = tf.keras.layers.Input(shape=([2, 4, 3]))

Dep13912 = keras.layers.DepthwiseConv2D((1, 1),strides=(1, 1), padding='same', name = 'Dep13912', )(in0Dep13912)
Lea3815 = keras.layers.LeakyReLU(alpha=9.27277606508173, name = 'Lea3815', )(Dep13912)
ReL82913 = keras.layers.ReLU(max_value=4.198368506643421, negative_slope=6.308007988592667, threshold=0.41002257355255756, name = 'ReL82913', )(Lea3815)
Zer29021 = keras.layers.ZeroPadding2D(padding=((2, 0), (3, 0)), name = 'Zer29021', )(ReL82913)
Con39645 = keras.layers.Concatenate(axis=3, name = 'Con39645', )([Zer29021,in0Con39645])
Dot89053 = keras.layers.Dot(axes=(2, 2), name = 'Dot89053', )([in0Dot89053,in1Dot89053])
Res25947 = keras.layers.Reshape((3, 3, 1), name = 'Res25947', )(Dot89053)
Zer43610 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer43610', )(Res25947)
Con14384 = keras.layers.Concatenate(axis=3, name = 'Con14384', )([Zer43610,in0Con14384])
Up_78243 = keras.layers.UpSampling2D(size=(1, 1), name = 'Up_78243', )(in0Up_78243)
Zer54496 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer54496', )(Up_78243)
Max57806 = keras.layers.Maximum(name = 'Max57806', )([Con14384,Zer54496])
Sub73792 = keras.layers.Subtract(name = 'Sub73792', )([Con39645,Max57806])
model = tf.keras.models.Model(inputs=[in0Dep13912,in0Con39645,in0Dot89053,in1Dot89053,in0Con14384,in0Up_78243], outputs=Sub73792)
w = model.get_layer('Dep13912').get_weights() 
w[0] = np.array([[[[0.7721]]]])
w[1] = np.array([0])
model.get_layer('Dep13912').set_weights(w) 
in0Dep13912 = tf.constant([[[[0.5976], [0.7329]]]])
in0Con39645 = tf.constant([[[[0.5915, 0.0841], [0.4535, 0.3448], [0.9268, 0.7967], [0.3075, 0.8992], [0.1219, 0.3653]], [[0.7769, 0.0834], [0.3959, 0.676], [0.2433, 0.3915], [0.3882, 0.4011], [0.0061, 0.3833]], [[0.4137, 0.6525], [0.7042, 0.986], [0.8013, 0.7603], [0.1597, 0.3869], [0.9657, 0.2837]]]])
in0Dot89053 = tf.constant([[[0.3626, 0.5421, 0.4555], [0.4678, 0.9942, 0.0545], [0.7843, 0.9091, 0.7483]]])
in1Dot89053 = tf.constant([[[0.6632, 0.5036, 0.3874], [0.5593, 0.2455, 0.057], [0.6915, 0.193, 0.7066]]])
in0Con14384 = tf.constant([[[[0.8292, 0.5193], [0.399, 0.7414], [0.0056, 0.8361], [0.3285, 0.579], [0.259, 0.376]], [[0.3177, 0.5402], [0.9164, 0.2734], [0.0075, 0.0434], [0.8805, 0.5816], [0.6844, 0.4183]], [[0.7626, 0.8861], [0.8906, 0.4237], [0.8728, 0.9812], [0.7747, 0.4684], [0.9783, 0.7157]]]])
in0Up_78243 = tf.constant([[[[1.0253, 1.6085, 1.3643], [1.611, 1.6109, 1.1401], [1.4844, 1.5902, 1.4622], [1.7207, 1.8368, 1.81]], [[1.632, 1.4062, 1.2586], [1.5048, 1.9438, 1.0549], [1.3403, 1.2161, 1.6803], [1.9808, 1.7451, 1.9081]]]])
print (np.array2string(model.predict([in0Dep13912,in0Con39645,in0Dot89053,in1Dot89053,in0Con14384,in0Up_78243],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub73792.png')

LDep13912 = depthwise_conv2D_layer([[[[0.5976], [0.7329]]]], 1, 1,[[[[0.7721]]]],[0], 1, 1, true, Dep13912), 
LLea3815 = leaky_relu_layer(Dep13912, 9.27277606508173, Lea3815), 
LReL82913 = relu_layer(Lea3815, 4.198368506643421, 6.308007988592667, 0.41002257355255756, ReL82913), 
LZer29021 = zero_padding2D_layer(ReL82913, 2, 0, 3, 0, Zer29021), 
LCon39645 = concatenate_layer([Zer29021,[[[[0.5915, 0.0841], [0.4535, 0.3448], [0.9268, 0.7967], [0.3075, 0.8992], [0.1219, 0.3653]], [[0.7769, 0.0834], [0.3959, 0.676], [0.2433, 0.3915], [0.3882, 0.4011], [0.0061, 0.3833]], [[0.4137, 0.6525], [0.7042, 0.986], [0.8013, 0.7603], [0.1597, 0.3869], [0.9657, 0.2837]]]]], 3, Con39645), 
LDot89053 = dot_layer([[[0.3626, 0.5421, 0.4555], [0.4678, 0.9942, 0.0545], [0.7843, 0.9091, 0.7483]]], [[[0.6632, 0.5036, 0.3874], [0.5593, 0.2455, 0.057], [0.6915, 0.193, 0.7066]]], 2, 2, Dot89053), 
LRes25947 = reshape_layer(Dot89053, [3, 3, 1], Res25947), 
LZer43610 = zero_padding2D_layer(Res25947, 0, 0, 2, 0, Zer43610), 
LCon14384 = concatenate_layer([Zer43610,[[[[0.8292, 0.5193], [0.399, 0.7414], [0.0056, 0.8361], [0.3285, 0.579], [0.259, 0.376]], [[0.3177, 0.5402], [0.9164, 0.2734], [0.0075, 0.0434], [0.8805, 0.5816], [0.6844, 0.4183]], [[0.7626, 0.8861], [0.8906, 0.4237], [0.8728, 0.9812], [0.7747, 0.4684], [0.9783, 0.7157]]]]], 3, Con14384), 
LUp_78243 = up_sampling2D_layer([[[[1.0253, 1.6085, 1.3643], [1.611, 1.6109, 1.1401], [1.4844, 1.5902, 1.4622], [1.7207, 1.8368, 1.81]], [[1.632, 1.4062, 1.2586], [1.5048, 1.9438, 1.0549], [1.3403, 1.2161, 1.6803], [1.9808, 1.7451, 1.9081]]]], 1, 1, Up_78243), 
LZer54496 = zero_padding2D_layer(Up_78243, 1, 0, 1, 0, Zer54496), 
LMax57806 = maximum_layer([Con14384,Zer54496], Max57806), 
LSub73792 = subtract_layer(Con39645,Max57806, Sub73792), 
exec_layers([LDep13912,LLea3815,LReL82913,LZer29021,LCon39645,LDot89053,LRes25947,LZer43610,LCon14384,LUp_78243,LZer54496,LMax57806,LSub73792],["Dep13912","Lea3815","ReL82913","Zer29021","Con39645","Dot89053","Res25947","Zer43610","Con14384","Up_78243","Zer54496","Max57806","Sub73792"],Sub73792,"Sub73792")

Actual (Unparsed): [[[[0.0000000, -0.2377000, -0.4352000], [0.0000000, 0.0545000, -0.3966000], [-0.6899386, 0.9212000, -0.0394000], [-0.3618512, -0.0210000, 0.3202000], [-0.6772195, -0.1371000, -0.0107000]], [[0.0000000, 0.4592000, -0.4568000], [-1.0253000, -1.2126000, -0.6883000], [-1.6109999, -1.3676000, -0.7486000], [-1.4844000, -1.2019999, -1.0611000], [-1.7207000, -1.8307000, -1.4266999]], [[0.0000000, -0.3489000, -0.2336000], [-1.6320000, -0.7020000, -0.2726000], [-1.5048000, -1.1425000, -0.2946001], [-0.8788930, -1.0564000, -1.2934000], [-1.4149279, -0.7794001, -1.6244000]]]]

Expected (Unparsed): [[[[0,-0.23770000000000002,-0.4352],[0,0.05449999999999999,-0.39659999999999995],[-0.6899385800000001,0.9211999999999999,-0.03939999999999999],[-0.36185122999999997,-0.02100000000000002,0.32020000000000004],[-0.6772195000000001,-0.1371,-0.010699999999999987]],[[0,0.45920000000000005,-0.4568],[-1.0253,-1.2126000000000001,-0.6883],[-1.611,-1.3676,-0.7485999999999999],[-1.4844,-1.202,-1.0611],[-1.7207,-1.8307,-1.4267]],[[0,-0.34889999999999993,-0.23360000000000003],[-1.632,-0.7019999999999998,-0.27259999999999995],[-1.5048,-1.1425,-0.2946],[-0.87889304,-1.0564,-1.2933999999999999],[-1.4149279099999998,-0.7794000000000001,-1.6243999999999998]]]]

Actual:   [[[[0, -0.2377, -0.4352], [0, 0.0545, -0.3966], [-0.6899, 0.9212, -0.0394], [-0.3618, -0.021, 0.3202], [-0.6772, -0.1371, -0.0107]], [[0, 0.4592, -0.4568], [-1.0253, -1.2126, -0.6883], [-1.6109, -1.3676, -0.7486], [-1.4844, -1.2019, -1.0611], [-1.7207, -1.8307, -1.4266]], [[0, -0.3489, -0.2336], [-1.632, -0.702, -0.2726], [-1.5048, -1.1425, -0.2946], [-0.8788, -1.0564, -1.2934], [-1.4149, -0.7794, -1.6244]]]]

Expected: [[[[0, -0.2377, -0.4352], [0, 0.0545, -0.3965], [-0.6899, 0.9212, -0.0393], [-0.3618, -0.021, 0.3203], [-0.6772, -0.1371, -0.0106]], [[0, 0.4593, -0.4568], [-1.0253, -1.2126, -0.6883], [-1.611, -1.3676, -0.7485], [-1.4844, -1.202, -1.0611], [-1.7207, -1.8307, -1.4267]], [[0, -0.3488, -0.2336], [-1.632, -0.7019, -0.2725], [-1.5048, -1.1425, -0.2946], [-0.8788, -1.0564, -1.2933], [-1.4149, -0.7794, -1.6243]]]]