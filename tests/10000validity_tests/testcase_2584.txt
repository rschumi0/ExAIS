import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot88617 = tf.keras.layers.Input(shape=([3, 2]))
in1Dot88617 = tf.keras.layers.Input(shape=([3, 2]))
in0Dot14787 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot14787 = tf.keras.layers.Input(shape=([3, 3]))
in0Con9416 = tf.keras.layers.Input(shape=([99]))
in0Dot82290 = tf.keras.layers.Input(shape=([3]))
in1Dot82290 = tf.keras.layers.Input(shape=([3]))
in0Con72414 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con80513 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in0Glo96894 = tf.keras.layers.Input(shape=([2, 1]))
in0Con29211 = tf.keras.layers.Input(shape=([1]))
in0Con95862 = tf.keras.layers.Input(shape=([106]))

Dot88617 = keras.layers.Dot(axes=(2, 2), name = 'Dot88617', )([in0Dot88617,in1Dot88617])
Res86131 = keras.layers.Reshape((3, 3, 1), name = 'Res86131', )(Dot88617)
Con29365 = keras.layers.Conv2DTranspose(4, (1, 2),strides=(1, 3), padding='valid', name = 'Con29365', )(Res86131)
Res31571 = keras.layers.Reshape((3, 36), name = 'Res31571', )(Con29365)
Fla64969 = keras.layers.Flatten(name = 'Fla64969', )(Res31571)
Dot14787 = keras.layers.Dot(axes=(1, 2), name = 'Dot14787', )([in0Dot14787,in1Dot14787])
Fla87281 = keras.layers.Flatten(name = 'Fla87281', )(Dot14787)
Con9416 = keras.layers.Concatenate(axis=1, name = 'Con9416', )([Fla87281,in0Con9416])
Add84342 = keras.layers.Add(name = 'Add84342', )([Fla64969,Con9416])
Dot82290 = keras.layers.Dot(axes=(1, 1), name = 'Dot82290', )([in0Dot82290,in1Dot82290])
Res40777 = keras.layers.Reshape((1, 1), name = 'Res40777', )(Dot82290)
PRe33645 = keras.layers.PReLU(name = 'PRe33645', )(Res40777)
Res65623 = keras.layers.Reshape((1, 1, 1), name = 'Res65623', )(PRe33645)
Con72414 = keras.layers.Concatenate(axis=3, name = 'Con72414', )([Res65623,in0Con72414])
Con80513 = keras.layers.Conv3D(2, (2, 1, 1),strides=(2, 1, 11), padding='valid', dilation_rate=(1, 1, 1), name = 'Con80513', )(in0Con80513)
Res99892 = keras.layers.Reshape((1, 1, 2), name = 'Res99892', )(Con80513)
Dep9373 = keras.layers.DepthwiseConv2D((1, 1),strides=(1, 1), padding='valid', name = 'Dep9373', )(Res99892)
Add69280 = keras.layers.Add(name = 'Add69280', )([Con72414,Dep9373])
Res42361 = keras.layers.Reshape((1, 2), name = 'Res42361', )(Add69280)
Fla95897 = keras.layers.Flatten(name = 'Fla95897', )(Res42361)
Glo96894 = keras.layers.GlobalAveragePooling1D(name = 'Glo96894', )(in0Glo96894)
Con29211 = keras.layers.Concatenate(axis=1, name = 'Con29211', )([Glo96894,in0Con29211])
Mul36968 = keras.layers.Multiply(name = 'Mul36968', )([Fla95897,Con29211])
Con95862 = keras.layers.Concatenate(axis=1, name = 'Con95862', )([Mul36968,in0Con95862])
Ave11479 = keras.layers.Average(name = 'Ave11479', )([Add84342,Con95862])
model = tf.keras.models.Model(inputs=[in0Dot88617,in1Dot88617,in0Dot14787,in1Dot14787,in0Con9416,in0Dot82290,in1Dot82290,in0Con72414,in0Con80513,in0Glo96894,in0Con29211,in0Con95862], outputs=Ave11479)
w = model.get_layer('Con29365').get_weights() 
w[0] = np.array([[[[0.4714], [0.0854], [0.5685], [0.6036]], [[0.3925], [0.521], [0.4345], [0.3769]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con29365').set_weights(w) 
w = model.get_layer('PRe33645').get_weights() 
w[0] = np.array([[0.2837]])
model.get_layer('PRe33645').set_weights(w) 
w = model.get_layer('Con80513').get_weights() 
w[0] = np.array([[[[[0.5097, 0.9263], [0.5105, 0.6035]]]], [[[[0.658, 0.42], [0.412, 0.3872]]]]])
w[1] = np.array([0, 0])
model.get_layer('Con80513').set_weights(w) 
w = model.get_layer('Dep9373').get_weights() 
w[0] = np.array([[[[0.0301], [0.0988]]]])
w[1] = np.array([0, 0])
model.get_layer('Dep9373').set_weights(w) 
in0Dot88617 = tf.constant([[[0.5744, 0.901], [0.9794, 0.3687], [0.4733, 0.6635]]])
in1Dot88617 = tf.constant([[[0.152, 0.2939], [0.1897, 0.4453], [0.7128, 0.3926]]])
in0Dot14787 = tf.constant([[[0.5303, 0.308, 0.3057], [0.8817, 0.5429, 0.5276], [0.8515, 0.8532, 0.9423]]])
in1Dot14787 = tf.constant([[[0.4806, 0.5533, 0.0468], [0.3899, 0.2644, 0.3192], [0.6648, 0.6556, 0.065]]])
in0Con9416 = tf.constant([[0.7729, 0.6768, 0.6264, 0.2961, 0.362, 0.2361, 0.2003, 0.2464, 0.7155, 0.8707, 0.8154, 0.3351, 0.8892, 0.8696, 0.5345, 0.3086, 0.291, 0.0683, 0.2911, 0.3143, 0.3488, 0.2565, 0.0895, 0.3034, 0.465, 0.9995, 0.7731, 0.7931, 0.838, 0.2604, 0.6969, 0.245, 0.253, 0.7722, 0.3095, 0.6498, 0.0023, 0.4564, 0.3396, 0.5135, 0.6808, 0.3092, 0.0173, 0.3374, 0.7205, 0.0822, 0.5117, 0.8524, 0.1791, 0.7767, 0.5627, 0.7254, 0.4753, 0.4364, 0.1016, 0.1888, 0.4785, 0.9766, 0.5101, 0.0628, 0.6018, 0.8206, 0.0514, 0.9355, 0.3217, 0.925, 0.9186, 0.8474, 0.8549, 0.3732, 0.2979, 0.6858, 0.5584, 0.0906, 0.815, 0.6362, 0.9867, 0.3923, 0.7475, 0.4615, 0.4412, 0.0144, 0.4224, 0.0831, 0.276, 0.996, 0.2907, 0.9237, 0.1864, 0.2847, 0.2734, 0.7381, 0.2006, 0.2167, 0.1079, 0.2064, 0.118, 0.0882, 0.5857]])
in0Dot82290 = tf.constant([[0.8172, 0.8217, 0.8851]])
in1Dot82290 = tf.constant([[0.5763, 0.3326, 0.9009]])
in0Con72414 = tf.constant([[[[0.0009]]]])
in0Con80513 = tf.constant([[[[[0.1599, 0.0945], [0.8324, 0.3026]]], [[[0.2924, 0.2655], [0.1593, 0.8108]]]]])
in0Glo96894 = tf.constant([[[1.3276], [1.8448]]])
in0Con29211 = tf.constant([[0.2992]])
in0Con95862 = tf.constant([[0.345, 0.9129, 0.6296, 0.6224, 0.292, 0.7024, 0.4229, 0.0571, 0.661, 0.159, 0.1226, 0.3949, 0.3817, 0.6082, 0.7731, 0.7214, 0.1949, 0.7602, 0.0821, 0.5643, 0.7992, 0.4777, 0.7018, 0.8277, 0.9501, 0.6894, 0.5598, 0.4266, 0.4739, 0.6111, 0.7604, 0.9397, 0.6332, 0.6663, 0.3854, 0.2869, 0.6613, 0.8856, 0.7272, 0.7736, 0.568, 0.1099, 0.1019, 0.8464, 0.5125, 0.0207, 0.4131, 0.5534, 0.1373, 0.8778, 0.06, 0.015, 0.2612, 0.8589, 0.6197, 0.1756, 0.2426, 0.0616, 0.9714, 0.7294, 0.1397, 0.5564, 0.1753, 0.3899, 0.5183, 0.359, 0.4722, 0.611, 0.3889, 0.8282, 0.226, 0.4537, 0.2894, 0.7906, 0.4973, 0.5438, 0.9734, 0.642, 0.2061, 0.9668, 0.5113, 0.7825, 0.5165, 0.5055, 0.8677, 0.0063, 0.1647, 0.8443, 0.1794, 0.883, 0.9326, 0.2328, 0.0243, 0.7463, 0.3738, 0.6328, 0.9473, 0.6337, 0.1931, 0.5542, 0.3881, 0.4119, 0.3933, 0.6295, 0.9409, 0.3637]])
print (np.array2string(model.predict([in0Dot88617,in1Dot88617,in0Dot14787,in1Dot14787,in0Con9416,in0Dot82290,in1Dot82290,in0Con72414,in0Con80513,in0Glo96894,in0Con29211,in0Con95862],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave11479.png')

LDot88617 = dot_layer([[[0.5744, 0.901], [0.9794, 0.3687], [0.4733, 0.6635]]], [[[0.152, 0.2939], [0.1897, 0.4453], [0.7128, 0.3926]]], 2, 2, Dot88617), 
LRes86131 = reshape_layer(Dot88617, [3, 3, 1], Res86131), 
LCon29365 = conv2D_transpose_layer(Res86131, 1, 2,[[[[0.4714], [0.0854], [0.5685], [0.6036]], [[0.3925], [0.521], [0.4345], [0.3769]]]],[0, 0, 0, 0], 1, 3, false, Con29365), 
LRes31571 = reshape_layer(Con29365, [3, 36], Res31571), 
LFla64969 = flatten_layer(Res31571, Fla64969), 
LDot14787 = dot_layer([[[0.5303, 0.308, 0.3057], [0.8817, 0.5429, 0.5276], [0.8515, 0.8532, 0.9423]]], [[[0.4806, 0.5533, 0.0468], [0.3899, 0.2644, 0.3192], [0.6648, 0.6556, 0.065]]], 1, 2, Dot14787), 
LFla87281 = flatten_layer(Dot14787, Fla87281), 
LCon9416 = concatenate_layer([Fla87281,[[0.7729, 0.6768, 0.6264, 0.2961, 0.362, 0.2361, 0.2003, 0.2464, 0.7155, 0.8707, 0.8154, 0.3351, 0.8892, 0.8696, 0.5345, 0.3086, 0.291, 0.0683, 0.2911, 0.3143, 0.3488, 0.2565, 0.0895, 0.3034, 0.465, 0.9995, 0.7731, 0.7931, 0.838, 0.2604, 0.6969, 0.245, 0.253, 0.7722, 0.3095, 0.6498, 0.0023, 0.4564, 0.3396, 0.5135, 0.6808, 0.3092, 0.0173, 0.3374, 0.7205, 0.0822, 0.5117, 0.8524, 0.1791, 0.7767, 0.5627, 0.7254, 0.4753, 0.4364, 0.1016, 0.1888, 0.4785, 0.9766, 0.5101, 0.0628, 0.6018, 0.8206, 0.0514, 0.9355, 0.3217, 0.925, 0.9186, 0.8474, 0.8549, 0.3732, 0.2979, 0.6858, 0.5584, 0.0906, 0.815, 0.6362, 0.9867, 0.3923, 0.7475, 0.4615, 0.4412, 0.0144, 0.4224, 0.0831, 0.276, 0.996, 0.2907, 0.9237, 0.1864, 0.2847, 0.2734, 0.7381, 0.2006, 0.2167, 0.1079, 0.2064, 0.118, 0.0882, 0.5857]]], 1, Con9416), 
LAdd84342 = add_layer([Fla64969,Con9416], Add84342), 
LDot82290 = dot_layer([[0.8172, 0.8217, 0.8851]], [[0.5763, 0.3326, 0.9009]], 1, 1, Dot82290), 
LRes40777 = reshape_layer(Dot82290, [1, 1], Res40777), 
LPRe33645 = prelu_layer(Res40777, [[0.2837]], PRe33645), 
LRes65623 = reshape_layer(PRe33645, [1, 1, 1], Res65623), 
LCon72414 = concatenate_layer([Res65623,[[[[0.0009]]]]], 3, Con72414), 
LCon80513 = conv3D_layer([[[[[0.1599, 0.0945], [0.8324, 0.3026]]], [[[0.2924, 0.2655], [0.1593, 0.8108]]]]], 2, 1, 1,[[[[[0.5097, 0.9263], [0.5105, 0.6035]]]], [[[[0.658, 0.42], [0.412, 0.3872]]]]],[0, 0], 2, 1, 11, false, 1, 1, 1, Con80513), 
LRes99892 = reshape_layer(Con80513, [1, 1, 2], Res99892), 
LDep9373 = depthwise_conv2D_layer(Res99892, 1, 1,[[[[0.0301], [0.0988]]]],[0, 0], 1, 1, false, Dep9373), 
LAdd69280 = add_layer([Con72414,Dep9373], Add69280), 
LRes42361 = reshape_layer(Add69280, [1, 2], Res42361), 
LFla95897 = flatten_layer(Res42361, Fla95897), 
LGlo96894 = global_average_pooling1D_layer([[[1.3276], [1.8448]]], Glo96894), 
LCon29211 = concatenate_layer([Glo96894,[[0.2992]]], 1, Con29211), 
LMul36968 = multiply_layer([Fla95897,Con29211], Mul36968), 
LCon95862 = concatenate_layer([Mul36968,[[0.345, 0.9129, 0.6296, 0.6224, 0.292, 0.7024, 0.4229, 0.0571, 0.661, 0.159, 0.1226, 0.3949, 0.3817, 0.6082, 0.7731, 0.7214, 0.1949, 0.7602, 0.0821, 0.5643, 0.7992, 0.4777, 0.7018, 0.8277, 0.9501, 0.6894, 0.5598, 0.4266, 0.4739, 0.6111, 0.7604, 0.9397, 0.6332, 0.6663, 0.3854, 0.2869, 0.6613, 0.8856, 0.7272, 0.7736, 0.568, 0.1099, 0.1019, 0.8464, 0.5125, 0.0207, 0.4131, 0.5534, 0.1373, 0.8778, 0.06, 0.015, 0.2612, 0.8589, 0.6197, 0.1756, 0.2426, 0.0616, 0.9714, 0.7294, 0.1397, 0.5564, 0.1753, 0.3899, 0.5183, 0.359, 0.4722, 0.611, 0.3889, 0.8282, 0.226, 0.4537, 0.2894, 0.7906, 0.4973, 0.5438, 0.9734, 0.642, 0.2061, 0.9668, 0.5113, 0.7825, 0.5165, 0.5055, 0.8677, 0.0063, 0.1647, 0.8443, 0.1794, 0.883, 0.9326, 0.2328, 0.0243, 0.7463, 0.3738, 0.6328, 0.9473, 0.6337, 0.1931, 0.5542, 0.3881, 0.4119, 0.3933, 0.6295, 0.9409, 0.3637]]], 1, Con95862), 
LAve11479 = average_layer([Add84342,Con95862], Ave11479), 
exec_layers([LDot88617,LRes86131,LCon29365,LRes31571,LFla64969,LDot14787,LFla87281,LCon9416,LAdd84342,LDot82290,LRes40777,LPRe33645,LRes65623,LCon72414,LCon80513,LRes99892,LDep9373,LAdd69280,LRes42361,LFla95897,LGlo96894,LCon29211,LMul36968,LCon95862,LAve11479],["Dot88617","Res86131","Con29365","Res31571","Fla64969","Dot14787","Fla87281","Con9416","Add84342","Dot82290","Res40777","PRe33645","Res65623","Con72414","Con80513","Res99892","Dep9373","Add69280","Res42361","Fla95897","Glo96894","Con29211","Mul36968","Con95862","Ave11479"],Ave11479,"Ave11479")

Actual (Unparsed): [[1.7072449, 0.3773788, 0.7655548, 0.8068882, 0.6518888, 0.7109962, 0.4639666, 0.6972917, 0.5166367, 0.4150000, 0.6689000, 0.3927000, 0.3295992, 0.4002346, 0.4539184, 0.5582220, 0.6098726, 0.8513516, 0.6436364, 0.8839432, 0.2086000, 0.7267500, 0.8344000, 0.5061000, 0.6850780, 0.5919372, 0.7261296, 0.7205732, 0.5868211, 0.5865045, 0.5309976, 0.4941184, 0.5319000, 0.7023500, 0.8163500, 0.7197000, 0.6498790, 0.5734337, 0.5339676, 0.8688819, 0.5365813, 0.5803083, 0.7259832, 0.2581749, 0.3758500, 0.4243500, 0.4844500, 0.1801500, 0.5457889, 0.6320439, 0.3227302, 0.5531722, 0.2673824, 0.4589183, 0.2477319, 0.7512526, 0.7360500, 0.1773500, 0.5096500, 0.3121500, 1.0470640, 0.6383405, 0.5276352, 0.5833775, 0.3474628, 0.6537671, 0.9305631, 0.5933885, 0.2675000, 0.6064000, 0.6047500, 0.4398000, 0.6436688, 0.3990985, 0.6830789, 0.9351638, 0.7247378, 0.7688890, 0.7312936, 0.5202557, 0.4459500, 0.7626000, 0.3009500, 0.7987500, 0.6671514, 0.7625498, 0.7395049, 0.4931659, 0.3887037, 0.7431054, 0.1805937, 0.7252988, 0.5078500, 0.2544000, 0.5101500, 0.5185000, 0.7896652, 0.4351285, 0.7859413, 0.6339837, 0.5829297, 0.5331421, 0.4322847, 0.3725664, 0.2998500, 0.3737500, 0.5145500, 0.4747000]]

Expected (Unparsed): [[1.7072448450853885,0.3773787535943456,0.765554764975,0.80688817786,0.651888817375,0.7109961783500001,0.463966554075,0.697291653315,0.51663671,0.41500000000000004,0.6689,0.3927,0.329599185586,0.400234642446,0.453918375065,0.558222016164,0.609872624825,0.8513516242900001,0.6436363834050001,0.883943228781,0.2086,0.72675,0.8344,0.5061,0.685077971644,0.5919371420840001,0.72612962851,0.7205731728560001,0.58682111555,0.5865044616599999,0.53099757887,0.494118429174,0.5319,0.70235,0.81635,0.7197,0.649879047361,0.573433709471,0.5339675507525,0.868881932514,0.5365813345125,0.5803083446649999,0.7259831588425,0.2581749426185,0.37585,0.42435,0.48444999999999994,0.18015,0.5457889401530001,0.632043902183,0.32273019193249997,0.553172240722,0.26738245441249997,0.45891830254500005,0.24773191450249998,0.7512526549505001,0.7360500000000001,0.17735,0.5096499999999999,0.31215,1.047063973458,0.638340461038,0.527635211945,0.5833775442920001,0.34746283322500005,0.65376709837,0.930563059965,0.593388463293,0.2675,0.6064,0.60475,0.4398,0.6436687597249999,0.39909851947499997,0.6830789030625,0.93516377465,0.7247378090625001,0.768888977125,0.7312936383124999,0.5202556439125,0.44594999999999996,0.7626,0.30095,0.79875,0.667151435692,0.762549814612,0.73950491343,0.493165902808,0.38870365615,0.74310542638,0.18059372891,0.725298771982,0.50785,0.2544,0.51015,0.5185,0.789665210738,0.43512855111800003,0.785941233145,0.6339836470119999,0.5829296992249999,0.53314209757,0.432284724365,0.372566404173,0.29985,0.37374999999999997,0.51455,0.4747]]

Actual:   [[1.7073, 0.3774, 0.7656, 0.8069, 0.6519, 0.711, 0.464, 0.6973, 0.5167, 0.415, 0.6689, 0.3927, 0.3296, 0.4003, 0.454, 0.5583, 0.6099, 0.8514, 0.6437, 0.884, 0.2086, 0.7268, 0.8344, 0.5061, 0.6851, 0.592, 0.7262, 0.7206, 0.5869, 0.5866, 0.531, 0.4942, 0.5319, 0.7024, 0.8164, 0.7197, 0.6499, 0.5735, 0.534, 0.8689, 0.5366, 0.5804, 0.726, 0.2582, 0.3759, 0.4244, 0.4845, 0.1802, 0.5458, 0.6321, 0.3228, 0.5532, 0.2674, 0.459, 0.2478, 0.7513, 0.7361, 0.1774, 0.5097, 0.3122, 1.0471, 0.6384, 0.5277, 0.5834, 0.3475, 0.6538, 0.9306, 0.5934, 0.2675, 0.6064, 0.6048, 0.4398, 0.6437, 0.3991, 0.6831, 0.9352, 0.7248, 0.7689, 0.7313, 0.5203, 0.446, 0.7626, 0.301, 0.7988, 0.6672, 0.7626, 0.7396, 0.4932, 0.3888, 0.7432, 0.1806, 0.7253, 0.5079, 0.2544, 0.5102, 0.5185, 0.7897, 0.4352, 0.786, 0.634, 0.583, 0.5332, 0.4323, 0.3726, 0.2999, 0.3738, 0.5146, 0.4747]]

Expected: [[1.7073, 0.3774, 0.7656, 0.8069, 0.6519, 0.711, 0.464, 0.6973, 0.5167, 0.4151, 0.6689, 0.3927, 0.3296, 0.4003, 0.454, 0.5583, 0.6099, 0.8514, 0.6437, 0.884, 0.2086, 0.7268, 0.8344, 0.5061, 0.6851, 0.592, 0.7262, 0.7206, 0.5869, 0.5866, 0.531, 0.4942, 0.5319, 0.7024, 0.8164, 0.7197, 0.6499, 0.5735, 0.534, 0.8689, 0.5366, 0.5804, 0.726, 0.2582, 0.3759, 0.4244, 0.4845, 0.1802, 0.5458, 0.6321, 0.3228, 0.5532, 0.2674, 0.459, 0.2478, 0.7513, 0.7361, 0.1774, 0.5097, 0.3122, 1.0471, 0.6384, 0.5277, 0.5834, 0.3475, 0.6538, 0.9306, 0.5934, 0.2675, 0.6064, 0.6048, 0.4398, 0.6437, 0.3991, 0.6831, 0.9352, 0.7248, 0.7689, 0.7313, 0.5203, 0.446, 0.7626, 0.301, 0.7988, 0.6672, 0.7626, 0.7396, 0.4932, 0.3888, 0.7432, 0.1806, 0.7253, 0.5079, 0.2544, 0.5102, 0.5185, 0.7897, 0.4352, 0.786, 0.634, 0.583, 0.5332, 0.4323, 0.3726, 0.2999, 0.3738, 0.5146, 0.4747]]