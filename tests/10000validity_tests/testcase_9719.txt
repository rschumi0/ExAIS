import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add89586 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in1Add89586 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0Con69042 = tf.keras.layers.Input(shape=([143]))
in0Zer23918 = tf.keras.layers.Input(shape=([1, 4, 2, 2]))
in0Glo8043 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Con94868 = tf.keras.layers.Input(shape=([142]))

Add89586 = keras.layers.Add(name = 'Add89586', )([in0Add89586,in1Add89586])
Res56991 = keras.layers.Reshape((2, 2, 2), name = 'Res56991', )(Add89586)
Glo38175 = keras.layers.GlobalAveragePooling2D(name = 'Glo38175', )(Res56991)
Res52893 = keras.layers.Reshape((2, 1), name = 'Res52893', )(Glo38175)
Res10992 = keras.layers.Reshape((2, 1, 1), name = 'Res10992', )(Res52893)
Res20185 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res20185', )(Res10992)
Glo73786 = keras.layers.GlobalAveragePooling3D(name = 'Glo73786', )(Res20185)
Con69042 = keras.layers.Concatenate(axis=1, name = 'Con69042', )([Glo73786,in0Con69042])
Zer23918 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer23918', )(in0Zer23918)
Res33447 = keras.layers.Reshape((3, 6, 8), name = 'Res33447', )(Zer23918)
Res89238 = keras.layers.Reshape((3, 48), name = 'Res89238', )(Res33447)
Fla76329 = keras.layers.Flatten(name = 'Fla76329', )(Res89238)
Glo8043 = keras.layers.GlobalAveragePooling3D(name = 'Glo8043', )(in0Glo8043)
Con94868 = keras.layers.Concatenate(axis=1, name = 'Con94868', )([Glo8043,in0Con94868])
Ave25418 = keras.layers.Average(name = 'Ave25418', )([Fla76329,Con94868])
Add49901 = keras.layers.Add(name = 'Add49901', )([Con69042,Ave25418])
model = tf.keras.models.Model(inputs=[in0Add89586,in1Add89586,in0Con69042,in0Zer23918,in0Glo8043,in0Con94868], outputs=Add49901)
in0Add89586 = tf.constant([[[[[0.6144, 0.9792]], [[0.6095, 0.6087]]], [[[0.2504, 0.9614]], [[0.7319, 0.6119]]]]])
in1Add89586 = tf.constant([[[[[0.1655, 0.267]], [[0.018, 0.7895]]], [[[0.8196, 0.4916]], [[0.901, 0.7367]]]]])
in0Con69042 = tf.constant([[0.7753, 0.9404, 0.007, 0.7583, 0.8715, 0.8565, 0.3094, 0.785, 0.6375, 0.3647, 0.0752, 0.9551, 0.9666, 0.6498, 0.0498, 0.8806, 0.7743, 0.206, 0.6375, 0.2186, 0.4282, 0.5132, 0.3023, 0.2203, 0.8156, 0.3802, 0.4791, 0.2639, 0.5286, 0.954, 0.4004, 0.0881, 0.7268, 0.6128, 0.4083, 0.8553, 0.7302, 0.8286, 0.3857, 0.7553, 0.2862, 0.6181, 0.9157, 0.5863, 0.7607, 0.3807, 0.6585, 0.6415, 0.2082, 0.7673, 0.219, 0.2711, 0.3904, 0.7166, 0.4751, 0.691, 0.3368, 0.9532, 0.9289, 0.9662, 0.9609, 0.0478, 0.1552, 0.6078, 0.5859, 0.6075, 0.8262, 0.8932, 0.9677, 0.2855, 0.1133, 0.8446, 0.551, 0.0787, 0.4882, 0.7798, 0.2459, 0.8157, 0.0764, 0.4902, 0.9694, 0.8269, 0.7515, 0.392, 0.5612, 0.5404, 0.1023, 0.4494, 0.4543, 0.143, 0.2512, 0.2732, 0.6556, 0.5144, 0.2609, 0.5604, 0.1779, 0.3492, 0.5229, 0.963, 0.0499, 0.7611, 0.0925, 0.5437, 0.4304, 0.6874, 0.4076, 0.2134, 0.1523, 0.098, 0.2059, 0.9281, 0.2294, 0.3536, 0.7467, 0.9719, 0.4759, 0.0561, 0.6294, 0.3468, 0.4067, 0.3843, 0.6053, 0.1528, 0.0137, 0.2228, 0.7791, 0.8496, 0.8477, 0.3518, 0.5128, 0.4632, 0.0731, 0.5922, 0.1563, 0.1243, 0.809, 0.0769, 0.4586, 0.8067, 0.1212, 0.7534, 0.1382]])
in0Zer23918 = tf.constant([[[[[1.5212, 1.1041], [1.4714, 1.3514]], [[1.4865, 1.2165], [1.3769, 1.8438]], [[1.1567, 1.6519], [1.9203, 1.6528]], [[1.2926, 1.2416], [1.8142, 1.9429]]]]])
in0Glo8043 = tf.constant([[[[[1.1264, 1.4581], [1.7001, 1.0412]]]]])
in0Con94868 = tf.constant([[0.8389, 0.5426, 0.1954, 0.6483, 0.1302, 0.9238, 0.2819, 0.8588, 0.9384, 0.1297, 0.6754, 0.0473, 0.1869, 0.8017, 0.8194, 0.1148, 0.0549, 0.577, 0.2013, 0.4402, 0.3499, 0.3182, 0.7254, 0.495, 0.5378, 0.121, 0.4854, 0.7913, 0.9676, 0.0003, 0.6297, 0.9745, 0.0566, 0.9544, 0.7002, 0.2521, 0.5919, 0.3177, 0.1625, 0.6377, 0.8467, 0.9237, 0.8464, 0.6798, 0.9109, 0.6246, 0.6652, 0.4441, 0.4911, 0.1347, 0.2953, 0.5237, 0.448, 0.0048, 0.4603, 0.762, 0.5095, 0.7677, 0.0882, 0.1905, 0.9202, 0.9447, 0.8877, 0.4074, 0.2727, 0.6528, 0.8239, 0.2533, 0.4012, 0.0107, 0.5649, 0.1755, 0.013, 0.4061, 0.218, 0.116, 0.6838, 0.9568, 0.5771, 0.1049, 0.9491, 0.1768, 0.6633, 0.9988, 0.4854, 0.9374, 0.5549, 0.9616, 0.7964, 0.308, 0.3769, 0.3555, 0.3918, 0.7523, 0.8472, 0.6809, 0.1804, 0.4595, 0.9623, 0.0868, 0.6837, 0.2985, 0.2445, 0.7561, 0.7246, 0.9952, 0.4718, 0.1647, 0.4404, 0.6559, 0.9623, 0.8125, 0.8314, 0.6853, 0.2987, 0.5273, 0.5648, 0.4807, 0.8385, 0.8541, 0.425, 0.0234, 0.4832, 0.3621, 0.6252, 0.6344, 0.9546, 0.9216, 0.1776, 0.7111, 0.2625, 0.1365, 0.6573, 0.2234, 0.1368, 0.1507, 0.9869, 0.1082, 0.9486, 0.9926, 0.3222, 0.4738]])
print (np.array2string(model.predict([in0Add89586,in1Add89586,in0Con69042,in0Zer23918,in0Glo8043,in0Con94868],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add49901.png')

LAdd89586 = add_layer([[[[[[0.6144, 0.9792]], [[0.6095, 0.6087]]], [[[0.2504, 0.9614]], [[0.7319, 0.6119]]]]], [[[[[0.1655, 0.267]], [[0.018, 0.7895]]], [[[0.8196, 0.4916]], [[0.901, 0.7367]]]]]], Add89586), 
LRes56991 = reshape_layer(Add89586, [2, 2, 2], Res56991), 
LGlo38175 = global_average_pooling2D_layer(Res56991, Glo38175), 
LRes52893 = reshape_layer(Glo38175, [2, 1], Res52893), 
LRes10992 = reshape_layer(Res52893, [2, 1, 1], Res10992), 
LRes20185 = reshape_layer(Res10992, [2, 1, 1, 1], Res20185), 
LGlo73786 = global_average_pooling3D_layer(Res20185, Glo73786), 
LCon69042 = concatenate_layer([Glo73786,[[0.7753, 0.9404, 0.007, 0.7583, 0.8715, 0.8565, 0.3094, 0.785, 0.6375, 0.3647, 0.0752, 0.9551, 0.9666, 0.6498, 0.0498, 0.8806, 0.7743, 0.206, 0.6375, 0.2186, 0.4282, 0.5132, 0.3023, 0.2203, 0.8156, 0.3802, 0.4791, 0.2639, 0.5286, 0.954, 0.4004, 0.0881, 0.7268, 0.6128, 0.4083, 0.8553, 0.7302, 0.8286, 0.3857, 0.7553, 0.2862, 0.6181, 0.9157, 0.5863, 0.7607, 0.3807, 0.6585, 0.6415, 0.2082, 0.7673, 0.219, 0.2711, 0.3904, 0.7166, 0.4751, 0.691, 0.3368, 0.9532, 0.9289, 0.9662, 0.9609, 0.0478, 0.1552, 0.6078, 0.5859, 0.6075, 0.8262, 0.8932, 0.9677, 0.2855, 0.1133, 0.8446, 0.551, 0.0787, 0.4882, 0.7798, 0.2459, 0.8157, 0.0764, 0.4902, 0.9694, 0.8269, 0.7515, 0.392, 0.5612, 0.5404, 0.1023, 0.4494, 0.4543, 0.143, 0.2512, 0.2732, 0.6556, 0.5144, 0.2609, 0.5604, 0.1779, 0.3492, 0.5229, 0.963, 0.0499, 0.7611, 0.0925, 0.5437, 0.4304, 0.6874, 0.4076, 0.2134, 0.1523, 0.098, 0.2059, 0.9281, 0.2294, 0.3536, 0.7467, 0.9719, 0.4759, 0.0561, 0.6294, 0.3468, 0.4067, 0.3843, 0.6053, 0.1528, 0.0137, 0.2228, 0.7791, 0.8496, 0.8477, 0.3518, 0.5128, 0.4632, 0.0731, 0.5922, 0.1563, 0.1243, 0.809, 0.0769, 0.4586, 0.8067, 0.1212, 0.7534, 0.1382]]], 1, Con69042), 
LZer23918 = zero_padding3D_layer([[[[[1.5212, 1.1041], [1.4714, 1.3514]], [[1.4865, 1.2165], [1.3769, 1.8438]], [[1.1567, 1.6519], [1.9203, 1.6528]], [[1.2926, 1.2416], [1.8142, 1.9429]]]]], 1, 1, 1, 1, 1, 1, Zer23918), 
LRes33447 = reshape_layer(Zer23918, [3, 6, 8], Res33447), 
LRes89238 = reshape_layer(Res33447, [3, 48], Res89238), 
LFla76329 = flatten_layer(Res89238, Fla76329), 
LGlo8043 = global_average_pooling3D_layer([[[[[1.1264, 1.4581], [1.7001, 1.0412]]]]], Glo8043), 
LCon94868 = concatenate_layer([Glo8043,[[0.8389, 0.5426, 0.1954, 0.6483, 0.1302, 0.9238, 0.2819, 0.8588, 0.9384, 0.1297, 0.6754, 0.0473, 0.1869, 0.8017, 0.8194, 0.1148, 0.0549, 0.577, 0.2013, 0.4402, 0.3499, 0.3182, 0.7254, 0.495, 0.5378, 0.121, 0.4854, 0.7913, 0.9676, 0.0003, 0.6297, 0.9745, 0.0566, 0.9544, 0.7002, 0.2521, 0.5919, 0.3177, 0.1625, 0.6377, 0.8467, 0.9237, 0.8464, 0.6798, 0.9109, 0.6246, 0.6652, 0.4441, 0.4911, 0.1347, 0.2953, 0.5237, 0.448, 0.0048, 0.4603, 0.762, 0.5095, 0.7677, 0.0882, 0.1905, 0.9202, 0.9447, 0.8877, 0.4074, 0.2727, 0.6528, 0.8239, 0.2533, 0.4012, 0.0107, 0.5649, 0.1755, 0.013, 0.4061, 0.218, 0.116, 0.6838, 0.9568, 0.5771, 0.1049, 0.9491, 0.1768, 0.6633, 0.9988, 0.4854, 0.9374, 0.5549, 0.9616, 0.7964, 0.308, 0.3769, 0.3555, 0.3918, 0.7523, 0.8472, 0.6809, 0.1804, 0.4595, 0.9623, 0.0868, 0.6837, 0.2985, 0.2445, 0.7561, 0.7246, 0.9952, 0.4718, 0.1647, 0.4404, 0.6559, 0.9623, 0.8125, 0.8314, 0.6853, 0.2987, 0.5273, 0.5648, 0.4807, 0.8385, 0.8541, 0.425, 0.0234, 0.4832, 0.3621, 0.6252, 0.6344, 0.9546, 0.9216, 0.1776, 0.7111, 0.2625, 0.1365, 0.6573, 0.2234, 0.1368, 0.1507, 0.9869, 0.1082, 0.9486, 0.9926, 0.3222, 0.4738]]], 1, Con94868), 
LAve25418 = average_layer([Fla76329,Con94868], Ave25418), 
LAdd49901 = add_layer([Con69042,Ave25418], Add49901), 
exec_layers([LAdd89586,LRes56991,LGlo38175,LRes52893,LRes10992,LRes20185,LGlo73786,LCon69042,LZer23918,LRes33447,LRes89238,LFla76329,LGlo8043,LCon94868,LAve25418,LAdd49901],["Add89586","Res56991","Glo38175","Res52893","Res10992","Res20185","Glo73786","Con69042","Zer23918","Res33447","Res89238","Fla76329","Glo8043","Con94868","Ave25418","Add49901"],Add49901,"Add49901")

Actual (Unparsed): [[1.9011625, 1.4001250, 1.3598500, 0.2783000, 0.8560000, 1.1956500, 0.9216000, 0.7713000, 0.9259500, 1.0669000, 0.8339000, 0.1400500, 1.2928000, 0.9902500, 0.7432500, 0.4506500, 1.2903000, 0.8317000, 0.2334500, 0.9260000, 0.3192500, 0.6483000, 0.6881500, 0.4614000, 0.5830000, 1.0631000, 0.6491000, 0.5396000, 0.5066000, 0.9242500, 1.4378000, 0.4005500, 0.4029500, 1.2140500, 0.6411000, 0.8855000, 1.2054000, 0.8562500, 1.1245500, 0.5445500, 0.8365500, 0.6050500, 1.0414500, 1.3775500, 1.0095000, 1.1006000, 0.8361500, 0.9708000, 0.9741000, 0.4302500, 1.0128500, 0.2863500, 0.4187500, 0.6522500, 0.9406000, 0.4775000, 0.9211500, 0.7178000, 1.9685500, 1.8648000, 1.7460000, 1.7318500, 0.5079000, 0.6275500, 1.0516500, 0.7896000, 1.4871000, 1.7608500, 1.9936000, 2.0162500, 0.4861000, 0.1186500, 1.1270500, 0.6387500, 0.6635500, 1.5172000, 1.8489500, 1.1303000, 1.1576000, 0.5548000, 0.7787500, 1.0218500, 1.9477500, 1.4607000, 1.6307500, 2.0320500, 0.7831000, 0.5710000, 0.7268500, 0.9351000, 0.5412000, 0.4052000, 0.4616500, 0.8333500, 0.7103000, 0.6370500, 0.9840000, 0.5183500, 0.4394000, 0.7526500, 1.4441500, 0.0933000, 1.1029500, 0.2417500, 0.6659500, 0.8084500, 1.0497000, 0.9052000, 0.4493000, 0.2346500, 0.3182000, 0.5338500, 1.4092500, 0.6356500, 0.7693000, 1.0893500, 1.1212500, 0.7395500, 0.3385000, 0.8697500, 0.7660500, 0.8337500, 0.5968000, 0.6170000, 0.3944000, 0.1947500, 0.5354000, 1.0963000, 1.3269000, 1.3085000, 0.4406000, 0.8683500, 0.5944500, 0.1413500, 0.9208500, 0.2680000, 0.1927000, 0.8843500, 0.5703500, 0.5127000, 1.2810000, 0.6175000, 0.9145000, 0.3751000]]

Expected (Unparsed): [[1.9011625,1.400125,1.35985,0.2783,0.856,1.19565,0.9216000000000001,0.7713,0.92595,1.0669,0.8339000000000001,0.14005,1.2928,0.99025,0.7432500000000001,0.45065,1.2903,0.8317,0.23345,0.9259999999999999,0.31925,0.6483,0.68815,0.46140000000000003,0.583,1.0631,0.6491,0.5396000000000001,0.5066,0.92425,1.4378,0.40054999999999996,0.40295000000000003,1.21405,0.6411,0.8855,1.2054,0.85625,1.12455,0.54455,0.83655,0.6050500000000001,1.04145,1.3775499999999998,1.0095,1.1006,0.83615,0.9708,0.9741,0.43025,1.01285,0.28635,0.41875,0.65225,0.9406,0.47750000000000004,0.9211499999999999,0.7178,1.96855,1.8648,1.746,1.7318500000000001,0.5079,0.62755,1.05165,0.7896,1.4870999999999999,1.76085,1.9936,2.0162500000000003,0.4861,0.11864999999999999,1.12705,0.63875,0.66355,1.5171999999999999,1.84895,1.1303,1.1576,0.5548,0.77875,1.0218500000000001,1.9477499999999999,1.4607,1.63075,2.03205,0.7831,0.571,0.72685,0.9351,0.5412,0.4052,0.46165,0.8333499999999999,0.7102999999999999,0.63705,0.984,0.51835,0.4394,0.75265,1.44415,0.0933,1.1029499999999999,0.24175,0.6659499999999999,0.80845,1.0497,0.9052,0.44930000000000003,0.23465,0.31820000000000004,0.53385,1.4092500000000001,0.63565,0.7693000000000001,1.08935,1.12125,0.7395499999999999,0.33849999999999997,0.86975,0.76605,0.83375,0.5968,0.617,0.3944,0.19474999999999998,0.5354,1.0963,1.3269,1.3085,0.4406,0.86835,0.59445,0.14135,0.92085,0.268,0.19269999999999998,0.8843500000000001,0.57035,0.5127,1.281,0.6175,0.9145,0.3751]]

Actual:   [[1.9012, 1.4002, 1.3599, 0.2783, 0.856, 1.1957, 0.9216, 0.7713, 0.926, 1.0669, 0.8339, 0.1401, 1.2928, 0.9903, 0.7433, 0.4507, 1.2903, 0.8317, 0.2335, 0.926, 0.3193, 0.6483, 0.6882, 0.4614, 0.583, 1.0631, 0.6491, 0.5396, 0.5066, 0.9243, 1.4378, 0.4006, 0.403, 1.2141, 0.6411, 0.8855, 1.2054, 0.8563, 1.1246, 0.5446, 0.8366, 0.6051, 1.0415, 1.3776, 1.0095, 1.1006, 0.8362, 0.9708, 0.9741, 0.4303, 1.0129, 0.2864, 0.4188, 0.6523, 0.9406, 0.4775, 0.9212, 0.7178, 1.9686, 1.8648, 1.746, 1.7319, 0.5079, 0.6276, 1.0517, 0.7896, 1.4871, 1.7609, 1.9936, 2.0163, 0.4861, 0.1187, 1.1271, 0.6388, 0.6636, 1.5172, 1.849, 1.1303, 1.1576, 0.5548, 0.7788, 1.0219, 1.9478, 1.4607, 1.6308, 2.0321, 0.7831, 0.571, 0.7269, 0.9351, 0.5412, 0.4052, 0.4617, 0.8334, 0.7103, 0.6371, 0.984, 0.5184, 0.4394, 0.7527, 1.4442, 0.0933, 1.103, 0.2418, 0.666, 0.8085, 1.0497, 0.9052, 0.4493, 0.2347, 0.3182, 0.5339, 1.4093, 0.6357, 0.7693, 1.0894, 1.1213, 0.7396, 0.3385, 0.8698, 0.7661, 0.8338, 0.5968, 0.617, 0.3944, 0.1948, 0.5354, 1.0963, 1.3269, 1.3085, 0.4406, 0.8684, 0.5945, 0.1414, 0.9209, 0.268, 0.1927, 0.8844, 0.5704, 0.5127, 1.281, 0.6175, 0.9145, 0.3751]]

Expected: [[1.9012, 1.4002, 1.3599, 0.2783, 0.856, 1.1957, 0.9217, 0.7713, 0.926, 1.0669, 0.834, 0.1401, 1.2928, 0.9903, 0.7433, 0.4507, 1.2903, 0.8317, 0.2335, 0.926, 0.3193, 0.6483, 0.6882, 0.4615, 0.583, 1.0631, 0.6491, 0.5397, 0.5066, 0.9243, 1.4378, 0.4006, 0.403, 1.2141, 0.6411, 0.8855, 1.2054, 0.8563, 1.1246, 0.5446, 0.8366, 0.6051, 1.0415, 1.3776, 1.0095, 1.1006, 0.8362, 0.9708, 0.9741, 0.4303, 1.0129, 0.2864, 0.4188, 0.6523, 0.9406, 0.4776, 0.9212, 0.7178, 1.9686, 1.8648, 1.746, 1.7319, 0.5079, 0.6276, 1.0517, 0.7896, 1.4871, 1.7609, 1.9936, 2.0163, 0.4861, 0.1187, 1.1271, 0.6388, 0.6636, 1.5172, 1.849, 1.1303, 1.1576, 0.5548, 0.7788, 1.0219, 1.9478, 1.4607, 1.6308, 2.0321, 0.7831, 0.571, 0.7269, 0.9351, 0.5412, 0.4052, 0.4617, 0.8334, 0.7103, 0.6371, 0.984, 0.5184, 0.4394, 0.7527, 1.4442, 0.0933, 1.103, 0.2418, 0.666, 0.8085, 1.0497, 0.9052, 0.4494, 0.2347, 0.3183, 0.5339, 1.4093, 0.6357, 0.7694, 1.0894, 1.1213, 0.7396, 0.3385, 0.8698, 0.7661, 0.8338, 0.5968, 0.617, 0.3944, 0.1948, 0.5354, 1.0963, 1.3269, 1.3085, 0.4406, 0.8684, 0.5945, 0.1414, 0.9209, 0.268, 0.1927, 0.8844, 0.5704, 0.5127, 1.281, 0.6175, 0.9145, 0.3751]]