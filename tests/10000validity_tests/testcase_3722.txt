import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo30872 = tf.keras.layers.Input(shape=([2, 2]))
in0Sub73164 = tf.keras.layers.Input(shape=([2]))
in1Sub73164 = tf.keras.layers.Input(shape=([2]))
in0Glo50569 = tf.keras.layers.Input(shape=([1, 1]))

Glo30872 = keras.layers.GlobalMaxPool1D(name = 'Glo30872', )(in0Glo30872)
Mas78397 = keras.layers.Masking(mask_value=2, name = 'Mas78397', )(Glo30872)
Sub73164 = keras.layers.Subtract(name = 'Sub73164', )([in0Sub73164,in1Sub73164])
Max48290 = keras.layers.Maximum(name = 'Max48290', )([Mas78397,Sub73164])
Res10711 = keras.layers.Reshape((2, 1), name = 'Res10711', )(Max48290)
Res43223 = keras.layers.Reshape((2, 1, 1), name = 'Res43223', )(Res10711)
Con57757 = keras.layers.Conv2DTranspose(4, (2, 1),strides=(1, 1), padding='same', name = 'Con57757', )(Res43223)
Zer31186 = keras.layers.ZeroPadding2D(padding=((0, 0), (10, 0)), name = 'Zer31186', )(Con57757)
Glo50569 = keras.layers.GlobalMaxPool1D(name = 'Glo50569', )(in0Glo50569)
Bat48955 = keras.layers.BatchNormalization(axis=1, epsilon=0.4384493660071669,  name = 'Bat48955', )(Glo50569)
Res4937 = keras.layers.Reshape((1, 1), name = 'Res4937', )(Bat48955)
Res61094 = keras.layers.Reshape((1, 1, 1), name = 'Res61094', )(Res4937)
Con31991 = keras.layers.Conv2DTranspose(4, (1, 1),strides=(2, 11), padding='same', name = 'Con31991', )(Res61094)
Max39734 = keras.layers.Maximum(name = 'Max39734', )([Zer31186,Con31991])
model = tf.keras.models.Model(inputs=[in0Glo30872,in0Sub73164,in1Sub73164,in0Glo50569], outputs=Max39734)
w = model.get_layer('Con57757').get_weights() 
w[0] = np.array([[[[0.495], [0.133], [0.9247], [0.1505]]], [[[0.6355], [0.4311], [0.0223], [0.9031]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con57757').set_weights(w) 
w = model.get_layer('Bat48955').get_weights() 
w[0] = np.array([0.2118])
w[1] = np.array([0.2923])
w[2] = np.array([0.5583])
w[3] = np.array([0.6199])
model.get_layer('Bat48955').set_weights(w) 
w = model.get_layer('Con31991').get_weights() 
w[0] = np.array([[[[0.6692], [0.3745], [0.0476], [0.0003]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con31991').set_weights(w) 
in0Glo30872 = tf.constant([[[1.3149, 1.2538], [1.2365, 1.4347]]])
in0Sub73164 = tf.constant([[0.9053, 0.978]])
in1Sub73164 = tf.constant([[0.5426, 0.721]])
in0Glo50569 = tf.constant([[[1.3595]]])
print (np.array2string(model.predict([in0Glo30872,in0Sub73164,in1Sub73164,in0Glo50569],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max39734.png')

LGlo30872 = global_max_pool1D_layer([[[1.3149, 1.2538], [1.2365, 1.4347]]], Glo30872), 
LMas78397 = masking_layer(Glo30872, 2, Mas78397), 
LSub73164 = subtract_layer([[0.9053, 0.978]], [[0.5426, 0.721]], Sub73164), 
LMax48290 = maximum_layer([Mas78397,Sub73164], Max48290), 
LRes10711 = reshape_layer(Max48290, [2, 1], Res10711), 
LRes43223 = reshape_layer(Res10711, [2, 1, 1], Res43223), 
LCon57757 = conv2D_transpose_layer(Res43223, 2, 1,[[[[0.495], [0.133], [0.9247], [0.1505]]], [[[0.6355], [0.4311], [0.0223], [0.9031]]]],[0, 0, 0, 0], 1, 1, true, Con57757), 
LZer31186 = zero_padding2D_layer(Con57757, 0, 0, 10, 0, Zer31186), 
LGlo50569 = global_max_pool1D_layer([[[1.3595]]], Glo50569), 
LBat48955 = batch_normalization_layer(Glo50569, 1, 0.4384493660071669, [0.2118], [0.2923], [0.5583], [0.6199], Bat48955), 
LRes4937 = reshape_layer(Bat48955, [1, 1], Res4937), 
LRes61094 = reshape_layer(Res4937, [1, 1, 1], Res61094), 
LCon31991 = conv2D_transpose_layer(Res61094, 1, 1,[[[[0.6692], [0.3745], [0.0476], [0.0003]]]],[0, 0, 0, 0], 2, 11, true, Con31991), 
LMax39734 = maximum_layer([Zer31186,Con31991], Max39734), 
exec_layers([LGlo30872,LMas78397,LSub73164,LMax48290,LRes10711,LRes43223,LCon57757,LZer31186,LGlo50569,LBat48955,LRes4937,LRes61094,LCon31991,LMax39734],["Glo30872","Mas78397","Sub73164","Max48290","Res10711","Res43223","Con57757","Zer31186","Glo50569","Bat48955","Res4937","Res61094","Con31991","Max39734"],Max39734,"Max39734")

Actual (Unparsed): [[[[0.3059917, 0.1712401, 0.0217651, 0.0001372], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.6508755, 0.1748817, 1.2158881, 0.1978925]], [[0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.0000000, 0.0000000, 0.0000000, 0.0000000], [1.5457955, 0.7576685, 1.3559894, 1.4034086]]]]

Expected (Unparsed): [[[[0.30599171258712404,0.17124013204404953,0.021765100895318447,0.0001371750056427633],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0.6508754999999999,0.1748817,1.21588803,0.19789245]],[[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[1.54579545,0.75766849,1.35598936,1.40340854]]]]

Actual:   [[[[0.306, 0.1713, 0.0218, 0.0002], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0.6509, 0.1749, 1.2159, 0.1979]], [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1.5458, 0.7577, 1.356, 1.4035]]]]

Expected: [[[[0.306, 0.1713, 0.0218, 0.0002], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0.6509, 0.1749, 1.2159, 0.1979]], [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1.5458, 0.7577, 1.356, 1.4035]]]]