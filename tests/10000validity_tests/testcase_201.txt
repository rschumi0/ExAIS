import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul41250 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in1Mul41250 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in0Con90816 = tf.keras.layers.Input(shape=([4, 4, 1]))
in0Max21610 = tf.keras.layers.Input(shape=([2, 1, 2]))
in1Max21610 = tf.keras.layers.Input(shape=([2, 1, 2]))

Mul41250 = keras.layers.Multiply(name = 'Mul41250', )([in0Mul41250,in1Mul41250])
Res29972 = keras.layers.Reshape((2, 2, 2), name = 'Res29972', )(Mul41250)
Res3316 = keras.layers.Reshape((2, 4), name = 'Res3316', )(Res29972)
Up_56029 = keras.layers.UpSampling1D(size=(2), name = 'Up_56029', )(Res3316)
Res81150 = keras.layers.Reshape((4, 4, 1), name = 'Res81150', )(Up_56029)
Con90816 = keras.layers.Concatenate(axis=3, name = 'Con90816', )([Res81150,in0Con90816])
Max21610 = keras.layers.Maximum(name = 'Max21610', )([in0Max21610,in1Max21610])
Zer32971 = keras.layers.ZeroPadding2D(padding=((2, 0), (3, 0)), name = 'Zer32971', )(Max21610)
Sub4572 = keras.layers.Subtract(name = 'Sub4572', )([Con90816,Zer32971])
ELU23623 = keras.layers.ELU(alpha=3.479340570836788, name = 'ELU23623', )(Sub4572)
model = tf.keras.models.Model(inputs=[in0Mul41250,in1Mul41250,in0Con90816,in0Max21610,in1Max21610], outputs=ELU23623)
in0Mul41250 = tf.constant([[[[[0.6622], [0.7409]], [[0.2941], [0.2748]]], [[[0.7541], [0.4086]], [[0.6087], [0.0724]]]]])
in1Mul41250 = tf.constant([[[[[0.9803], [0.5888]], [[0.8946], [0.5953]]], [[[0.4944], [0.5456]], [[0.5824], [0.8369]]]]])
in0Con90816 = tf.constant([[[[0.77], [0.365], [0.8497], [0.4314]], [[0.0649], [0.181], [0.9566], [0.8444]], [[0.1934], [0.9513], [0.7193], [0.0627]], [[0.5829], [0.2863], [0.1951], [0.1723]]]])
in0Max21610 = tf.constant([[[[0.2544, 0.6304]], [[0.3939, 0.5557]]]])
in1Max21610 = tf.constant([[[[0.426, 0.2929]], [[0.2864, 0.0985]]]])
print (np.array2string(model.predict([in0Mul41250,in1Mul41250,in0Con90816,in0Max21610,in1Max21610],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='ELU23623.png')

LMul41250 = multiply_layer([[[[[[0.6622], [0.7409]], [[0.2941], [0.2748]]], [[[0.7541], [0.4086]], [[0.6087], [0.0724]]]]], [[[[[0.9803], [0.5888]], [[0.8946], [0.5953]]], [[[0.4944], [0.5456]], [[0.5824], [0.8369]]]]]], Mul41250), 
LRes29972 = reshape_layer(Mul41250, [2, 2, 2], Res29972), 
LRes3316 = reshape_layer(Res29972, [2, 4], Res3316), 
LUp_56029 = up_sampling1D_layer(Res3316, 2, Up_56029), 
LRes81150 = reshape_layer(Up_56029, [4, 4, 1], Res81150), 
LCon90816 = concatenate_layer([Res81150,[[[[0.77], [0.365], [0.8497], [0.4314]], [[0.0649], [0.181], [0.9566], [0.8444]], [[0.1934], [0.9513], [0.7193], [0.0627]], [[0.5829], [0.2863], [0.1951], [0.1723]]]]], 3, Con90816), 
LMax21610 = maximum_layer([[[[[0.2544, 0.6304]], [[0.3939, 0.5557]]]], [[[[0.426, 0.2929]], [[0.2864, 0.0985]]]]], Max21610), 
LZer32971 = zero_padding2D_layer(Max21610, 2, 0, 3, 0, Zer32971), 
LSub4572 = subtract_layer(Con90816,Zer32971, Sub4572), 
LELU23623 = elu_layer(Sub4572, 3.479340570836788, ELU23623), 
exec_layers([LMul41250,LRes29972,LRes3316,LUp_56029,LRes81150,LCon90816,LMax21610,LZer32971,LSub4572,LELU23623],["Mul41250","Res29972","Res3316","Up_56029","Res81150","Con90816","Max21610","Zer32971","Sub4572","ELU23623"],ELU23623,"ELU23623")

Actual (Unparsed): [[[[0.6491546, 0.7700000], [0.4362419, 0.3650000], [0.2631018, 0.8497000], [0.1635884, 0.4314000]], [[0.6491546, 0.0649000], [0.4362419, 0.1810000], [0.2631018, 0.9566000], [0.1635884, 0.8444000]], [[0.3728270, 0.1934000], [0.2229322, 0.9513000], [0.3545069, 0.7193000], [-1.0649803, -1.5071541]], [[0.3728270, 0.5829000], [0.2229322, 0.2863000], [0.3545069, 0.1951000], [-0.9862221, -1.1080300]]]]

Expected (Unparsed): [[[[0.64915466,0.77],[0.43624192,0.365],[0.26310185999999997,0.8497],[0.16358844,0.4314]],[[0.64915466,0.0649],[0.43624192,0.181],[0.26310185999999997,0.9566],[0.16358844,0.8444]],[[0.37282704,0.1934],[0.22293216,0.9513],[0.35450688,0.7193],[-1.064980322011158,-1.507154151801546]],[[0.37282704,0.5829],[0.22293216,0.2863],[0.35450688,0.1951],[-0.9862220504246391,-1.1080300025886254]]]]

Actual:   [[[[0.6492, 0.77], [0.4363, 0.365], [0.2632, 0.8497], [0.1636, 0.4314]], [[0.6492, 0.0649], [0.4363, 0.181], [0.2632, 0.9566], [0.1636, 0.8444]], [[0.3729, 0.1934], [0.223, 0.9513], [0.3546, 0.7193], [-1.0649, -1.5071]], [[0.3729, 0.5829], [0.223, 0.2863], [0.3546, 0.1951], [-0.9862, -1.108]]]]

Expected: [[[[0.6492, 0.77], [0.4363, 0.365], [0.2632, 0.8497], [0.1636, 0.4314]], [[0.6492, 0.0649], [0.4363, 0.181], [0.2632, 0.9566], [0.1636, 0.8444]], [[0.3729, 0.1934], [0.223, 0.9513], [0.3546, 0.7193], [-1.0649, -1.5071]], [[0.3729, 0.5829], [0.223, 0.2863], [0.3546, 0.1951], [-0.9862, -1.108]]]]