import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot91470 = tf.keras.layers.Input(shape=([2, 3]))
in1Dot91470 = tf.keras.layers.Input(shape=([2, 3]))
in0Con4932 = tf.keras.layers.Input(shape=([9, 3]))
in0Lea70547 = tf.keras.layers.Input(shape=([1, 2, 1, 2]))

Dot91470 = keras.layers.Dot(axes=(1, 1), name = 'Dot91470', )([in0Dot91470,in1Dot91470])
Fla1871 = keras.layers.Flatten(name = 'Fla1871', )(Dot91470)
Res17606 = keras.layers.Reshape((9, 1), name = 'Res17606', )(Fla1871)
Con4932 = keras.layers.Concatenate(axis=2, name = 'Con4932', )([Res17606,in0Con4932])
Lea70547 = keras.layers.LeakyReLU(alpha=7.589314632878566, name = 'Lea70547', input_shape=(1, 2, 1, 2))(in0Lea70547)
Res73179 = keras.layers.Reshape((1, 2, 2), name = 'Res73179', )(Lea70547)
Res36666 = keras.layers.Reshape((1, 4), name = 'Res36666', )(Res73179)
Max14706 = keras.layers.MaxPool1D(pool_size=(1), strides=(12), padding='same', name = 'Max14706', )(Res36666)
Up_40214 = keras.layers.UpSampling1D(size=(2), name = 'Up_40214', )(Max14706)
Lay83243 = keras.layers.LayerNormalization(axis=1, epsilon=1.248248020849406, name = 'Lay83243', )(Up_40214)
Dot82224 = keras.layers.Dot(axes=(2, 2), name = 'Dot82224', )([Con4932,Lay83243])
model = tf.keras.models.Model(inputs=[in0Dot91470,in1Dot91470,in0Con4932,in0Lea70547], outputs=Dot82224)
in0Dot91470 = tf.constant([[[0.0039, 0.0267, 0.3829], [0.0888, 0.6581, 0.2729]]])
in1Dot91470 = tf.constant([[[0.1167, 0.5608, 0.8089], [0.2213, 0.4581, 0.8747]]])
in0Con4932 = tf.constant([[[0.5014, 0.6225, 0.8536], [0.3167, 0.0052, 0.911], [0.9819, 0.443, 0.8368], [0.4927, 0.2004, 0.4919], [0.1941, 0.4737, 0.8655], [0.486, 0.0208, 0.2166], [0.373, 0.3026, 0.3703], [0.447, 0.3864, 0.526], [0.3681, 0.8626, 0.678]]])
in0Lea70547 = tf.constant([[[[[0.4707, 0.0731]], [[0.5838, 0.4925]]]]])
print (np.array2string(model.predict([in0Dot91470,in1Dot91470,in0Con4932,in0Lea70547],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot82224.png')

LDot91470 = dot_layer([[[0.0039, 0.0267, 0.3829], [0.0888, 0.6581, 0.2729]]], [[[0.1167, 0.5608, 0.8089], [0.2213, 0.4581, 0.8747]]], 1, 1, Dot91470), 
LFla1871 = flatten_layer(Dot91470, Fla1871), 
LRes17606 = reshape_layer(Fla1871, [9, 1], Res17606), 
LCon4932 = concatenate_layer([Res17606,[[[0.5014, 0.6225, 0.8536], [0.3167, 0.0052, 0.911], [0.9819, 0.443, 0.8368], [0.4927, 0.2004, 0.4919], [0.1941, 0.4737, 0.8655], [0.486, 0.0208, 0.2166], [0.373, 0.3026, 0.3703], [0.447, 0.3864, 0.526], [0.3681, 0.8626, 0.678]]]], 2, Con4932), 
LLea70547 = leaky_relu_layer([[[[[0.4707, 0.0731]], [[0.5838, 0.4925]]]]], 7.589314632878566, Lea70547), 
LRes73179 = reshape_layer(Lea70547, [1, 2, 2], Res73179), 
LRes36666 = reshape_layer(Res73179, [1, 4], Res36666), 
LMax14706 = max_pool1D_layer(Res36666, 1, 12, true, Max14706), 
LUp_40214 = up_sampling1D_layer(Max14706, 2, Up_40214), 
LLay83243 = layer_normalization_layer(Up_40214, 1, 1.248248020849406, Lay83243), 
LDot82224 = dot_layer(Con4932,Lay83243, 2, 2, Dot82224), 
exec_layers([LDot91470,LFla1871,LRes17606,LCon4932,LLea70547,LRes73179,LRes36666,LMax14706,LUp_40214,LLay83243,LDot82224],["Dot91470","Fla1871","Res17606","Con4932","Lea70547","Res73179","Res36666","Max14706","Up_40214","Lay83243","Dot82224"],Dot82224,"Dot82224")

Actual (Unparsed): [[[0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.0000000, 0.0000000]]]

Expected (Unparsed): [[[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0]]]

Actual:   [[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]]

Expected: [[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]]