import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min12749 = tf.keras.layers.Input(shape=([1, 1]))
in1Min12749 = tf.keras.layers.Input(shape=([1, 1]))
in0Con80651 = tf.keras.layers.Input(shape=([2, 3, 2]))
in0Sub4250 = tf.keras.layers.Input(shape=([2, 3, 3]))
in1Sub4250 = tf.keras.layers.Input(shape=([2, 3, 3]))

Min12749 = keras.layers.Minimum(name = 'Min12749', )([in0Min12749,in1Min12749])
Res47645 = keras.layers.Reshape((1, 1, 1), name = 'Res47645', )(Min12749)
Zer66563 = keras.layers.ZeroPadding2D(padding=((1, 0), (2, 0)), name = 'Zer66563', )(Res47645)
Con80651 = keras.layers.Concatenate(axis=3, name = 'Con80651', )([Zer66563,in0Con80651])
Sub4250 = keras.layers.Subtract(name = 'Sub4250', )([in0Sub4250,in1Sub4250])
Max8513 = keras.layers.Maximum(name = 'Max8513', )([Con80651,Sub4250])
Con75846 = keras.layers.Conv2D(4, (2, 2),strides=(1, 1), padding='same', dilation_rate=(1, 1), name = 'Con75846', )(Max8513)
Up_46749 = keras.layers.UpSampling2D(size=(1, 2), name = 'Up_46749', )(Con75846)
model = tf.keras.models.Model(inputs=[in0Min12749,in1Min12749,in0Con80651,in0Sub4250,in1Sub4250], outputs=Up_46749)
w = model.get_layer('Con75846').get_weights() 
w[0] = np.array([[[[0.5641, 0.7452, 0.4728, 0.6144], [0.7349, 0.1236, 0.8004, 0.3766], [0.8869, 0.3594, 0.7874, 0.3142]], [[0.9306, 0.5147, 0.5305, 0.8652], [0.1236, 0.5092, 0.5829, 0.1745], [0.9099, 0.3272, 0.0352, 0.7277]]], [[[0.2469, 0.6165, 0.1722, 0.2814], [0.856, 0.0124, 0.0231, 0.6195], [0.137, 0.5223, 0.1353, 0.5045]], [[0.4554, 0.2192, 0.0724, 0.4271], [0.133, 0.3074, 0.4608, 0.4066], [0.7491, 0.3509, 0.8909, 0.1428]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con75846').set_weights(w) 
in0Min12749 = tf.constant([[[0.7648]]])
in1Min12749 = tf.constant([[[0.3066]]])
in0Con80651 = tf.constant([[[[0.3419, 0.5895], [0.7271, 0.1196], [0.5626, 0.406]], [[0.1262, 0.2519], [0.4569, 0.4204], [0.4478, 0.2365]]]])
in0Sub4250 = tf.constant([[[[0.7725, 0.3558, 0.0338], [0.9778, 0.7045, 0.8369], [0.7141, 0.6437, 0.9197]], [[0.915, 0.1485, 0.9351], [0.1709, 0.3404, 0.3542], [0.5964, 0.626, 0.0969]]]])
in1Sub4250 = tf.constant([[[[0.8955, 0.5015, 0.9775], [0.951, 0.5864, 0.8236], [0.1321, 0.9465, 0.8958]], [[0.5544, 0.9745, 0.5547], [0.9902, 0.7359, 0.5273], [0.7513, 0.1918, 0.9617]]]])
print (np.array2string(model.predict([in0Min12749,in1Min12749,in0Con80651,in0Sub4250,in1Sub4250],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Up_46749.png')

LMin12749 = minimum_layer([[[[0.7648]]], [[[0.3066]]]], Min12749), 
LRes47645 = reshape_layer(Min12749, [1, 1, 1], Res47645), 
LZer66563 = zero_padding2D_layer(Res47645, 1, 0, 2, 0, Zer66563), 
LCon80651 = concatenate_layer([Zer66563,[[[[0.3419, 0.5895], [0.7271, 0.1196], [0.5626, 0.406]], [[0.1262, 0.2519], [0.4569, 0.4204], [0.4478, 0.2365]]]]], 3, Con80651), 
LSub4250 = subtract_layer([[[[0.7725, 0.3558, 0.0338], [0.9778, 0.7045, 0.8369], [0.7141, 0.6437, 0.9197]], [[0.915, 0.1485, 0.9351], [0.1709, 0.3404, 0.3542], [0.5964, 0.626, 0.0969]]]], [[[[0.8955, 0.5015, 0.9775], [0.951, 0.5864, 0.8236], [0.1321, 0.9465, 0.8958]], [[0.5544, 0.9745, 0.5547], [0.9902, 0.7359, 0.5273], [0.7513, 0.1918, 0.9617]]]], Sub4250), 
LMax8513 = maximum_layer([Con80651,Sub4250], Max8513), 
LCon75846 = conv2D_layer(Max8513, 2, 2,[[[[0.5641, 0.7452, 0.4728, 0.6144], [0.7349, 0.1236, 0.8004, 0.3766], [0.8869, 0.3594, 0.7874, 0.3142]], [[0.9306, 0.5147, 0.5305, 0.8652], [0.1236, 0.5092, 0.5829, 0.1745], [0.9099, 0.3272, 0.0352, 0.7277]]], [[[0.2469, 0.6165, 0.1722, 0.2814], [0.856, 0.0124, 0.0231, 0.6195], [0.137, 0.5223, 0.1353, 0.5045]], [[0.4554, 0.2192, 0.0724, 0.4271], [0.133, 0.3074, 0.4608, 0.4066], [0.7491, 0.3509, 0.8909, 0.1428]]]],[0, 0, 0, 0], 1, 1, true, 1, 1, Con75846), 
LUp_46749 = up_sampling2D_layer(Con75846, 1, 2, Up_46749), 
exec_layers([LMin12749,LRes47645,LZer66563,LCon80651,LSub4250,LMax8513,LCon75846,LUp_46749],["Min12749","Res47645","Zer66563","Con80651","Sub4250","Max8513","Con75846","Up_46749"],Up_46749,"Up_46749")

Actual (Unparsed): [[[[1.6225871, 1.3878187, 1.8816355, 1.1684539], [1.6225871, 1.3878187, 1.8816355, 1.1684539], [2.4611493, 1.3847885, 1.8464731, 2.0669743], [2.4611493, 1.3847885, 1.8464731, 2.0669743], [1.5932592, 0.9672557, 1.1402982, 1.1800248], [1.5932592, 0.9672557, 1.1402982, 1.1800248]], [[1.0725304, 0.7912416, 0.8521542, 0.7742554], [1.0725304, 0.7912416, 0.8521542, 0.7742554], [1.2644900, 0.6707742, 1.1287244, 0.8196707], [1.2644900, 0.6707742, 1.1287244, 0.8196707], [0.7117931, 0.3688245, 0.6895997, 0.4313248], [0.7117931, 0.3688245, 0.6895997, 0.4313248]]]]

Expected (Unparsed): [[[[1.62258702,1.3878186600000002,1.88163551,1.16845387],[1.62258702,1.3878186600000002,1.88163551,1.16845387],[2.46114926,1.38478845,1.8464731,2.06697429],[2.46114926,1.38478845,1.8464731,2.06697429],[1.5932591800000002,0.96725573,1.14029819,1.1800247499999998],[1.5932591800000002,0.96725573,1.14029819,1.1800247499999998]],[[1.0725304,0.79124156,0.8521542100000001,0.77425537],[1.0725304,0.79124156,0.8521542100000001,0.77425537],[1.2644899600000001,0.67077418,1.12872444,0.8196706899999999],[1.2644899600000001,0.67077418,1.12872444,0.8196706899999999],[0.71179313,0.3688245,0.6895996999999999,0.43132481999999994],[0.71179313,0.3688245,0.6895996999999999,0.43132481999999994]]]]

Actual:   [[[[1.6226, 1.3879, 1.8817, 1.1685], [1.6226, 1.3879, 1.8817, 1.1685], [2.4612, 1.3848, 1.8465, 2.067], [2.4612, 1.3848, 1.8465, 2.067], [1.5933, 0.9673, 1.1403, 1.1801], [1.5933, 0.9673, 1.1403, 1.1801]], [[1.0726, 0.7913, 0.8522, 0.7743], [1.0726, 0.7913, 0.8522, 0.7743], [1.2645, 0.6708, 1.1288, 0.8197], [1.2645, 0.6708, 1.1288, 0.8197], [0.7118, 0.3689, 0.6896, 0.4314], [0.7118, 0.3689, 0.6896, 0.4314]]]]

Expected: [[[[1.6226, 1.3879, 1.8817, 1.1685], [1.6226, 1.3879, 1.8817, 1.1685], [2.4612, 1.3848, 1.8465, 2.067], [2.4612, 1.3848, 1.8465, 2.067], [1.5933, 0.9673, 1.1403, 1.1801], [1.5933, 0.9673, 1.1403, 1.1801]], [[1.0726, 0.7913, 0.8522, 0.7743], [1.0726, 0.7913, 0.8522, 0.7743], [1.2645, 0.6708, 1.1288, 0.8197], [1.2645, 0.6708, 1.1288, 0.8197], [0.7118, 0.3689, 0.6896, 0.4314], [0.7118, 0.3689, 0.6896, 0.4314]]]]