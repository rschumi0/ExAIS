import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max11319 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in1Max11319 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))

Max11319 = keras.layers.Maximum(name = 'Max11319', )([in0Max11319,in1Max11319])
ReL40224 = keras.layers.ReLU(max_value=7.93808736595126, negative_slope=0.8359694552563863, threshold=8.243824948443573, name = 'ReL40224', )(Max11319)
Res48623 = keras.layers.Reshape((2, 1, 2), name = 'Res48623', )(ReL40224)
Res15337 = keras.layers.Reshape((2, 2), name = 'Res15337', )(Res48623)
Sim16976 = keras.layers.SimpleRNN(1,name = 'Sim16976', )(Res15337)
model = tf.keras.models.Model(inputs=[in0Max11319,in1Max11319], outputs=Sim16976)
w = model.get_layer('Sim16976').get_weights() 
w[0] = np.array([[7], [4]])
w[1] = np.array([[1]])
w[2] = np.array([1])
model.get_layer('Sim16976').set_weights(w) 
in0Max11319 = tf.constant([[[[[0.1179], [0.1356]]], [[[0.1554], [0.4208]]]]])
in1Max11319 = tf.constant([[[[[0.3723], [0.9091]]], [[[0.7277], [0.5062]]]]])
print (np.array2string(model.predict([in0Max11319,in1Max11319],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sim16976.png')

LMax11319 = maximum_layer([[[[[[0.1179], [0.1356]]], [[[0.1554], [0.4208]]]]], [[[[[0.3723], [0.9091]]], [[[0.7277], [0.5062]]]]]], Max11319), 
LReL40224 = relu_layer(Max11319, 7.93808736595126, 0.8359694552563863, 8.243824948443573, ReL40224), 
LRes48623 = reshape_layer(ReL40224, [2, 1, 2], Res48623), 
LRes15337 = reshape_layer(Res48623, [2, 2], Res15337), 
LSim16976 = simple_rnn_layer(Res15337,[[7], [4]],[[1]],[1], Sim16976), 
exec_layers([LMax11319,LReL40224,LRes48623,LRes15337,LSim16976],["Max11319","ReL40224","Res48623","Res15337","Sim16976"],Sim16976,"Sim16976")

Actual (Unparsed): [[-1.0000000]]

Expected (Unparsed): [[-1.0]]

Actual:   [[-1]]

Expected: [[-1]]