import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min14111 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Min14111 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Mas83913 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Con50075 = tf.keras.layers.Input(shape=([2, 2, 3]))
in0Sub67148 = tf.keras.layers.Input(shape=([3]))
in1Sub67148 = tf.keras.layers.Input(shape=([3]))
in0Con96061 = tf.keras.layers.Input(shape=([3, 1]))
in0Ave43254 = tf.keras.layers.Input(shape=([2, 2]))
in1Ave43254 = tf.keras.layers.Input(shape=([2, 2]))
in0Con91182 = tf.keras.layers.Input(shape=([3, 6]))

Min14111 = keras.layers.Minimum(name = 'Min14111', )([in0Min14111,in1Min14111])
Res30818 = keras.layers.Reshape((2, 2, 4), name = 'Res30818', )(Min14111)
Mas83913 = keras.layers.Masking(mask_value=2, name = 'Mas83913', )(in0Mas83913)
Con50075 = keras.layers.Concatenate(axis=3, name = 'Con50075', )([Mas83913,in0Con50075])
Add62595 = keras.layers.Add(name = 'Add62595', )([Res30818,Con50075])
Res28036 = keras.layers.Reshape((2, 8), name = 'Res28036', )(Add62595)
Zer76954 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer76954', )(Res28036)
Sub67148 = keras.layers.Subtract(name = 'Sub67148', )([in0Sub67148,in1Sub67148])
Res30338 = keras.layers.Reshape((3, 1), name = 'Res30338', )(Sub67148)
Con96061 = keras.layers.Concatenate(axis=2, name = 'Con96061', )([Res30338,in0Con96061])
Ave43254 = keras.layers.Average(name = 'Ave43254', )([in0Ave43254,in1Ave43254])
Dot83272 = keras.layers.Dot(axes=(2, 2), name = 'Dot83272', )([Con96061,Ave43254])
Con91182 = keras.layers.Concatenate(axis=2, name = 'Con91182', )([Dot83272,in0Con91182])
Mul11564 = keras.layers.Multiply(name = 'Mul11564', )([Zer76954,Con91182])
model = tf.keras.models.Model(inputs=[in0Min14111,in1Min14111,in0Mas83913,in0Con50075,in0Sub67148,in1Sub67148,in0Con96061,in0Ave43254,in1Ave43254,in0Con91182], outputs=Mul11564)
in0Min14111 = tf.constant([[[[[0.5648, 0.5268], [0.7541, 0.7654]], [[0.7693, 0.4329], [0.2599, 1]]], [[[0.8126, 0.8528], [0.5645, 0.3478]], [[0.0031, 0.5385], [0.6089, 0.6878]]]]])
in1Min14111 = tf.constant([[[[[0.8829, 0.5814], [0.0058, 0.8802]], [[0.8498, 0.4068], [0.3507, 0.6204]]], [[[0.7021, 0.3666], [0.4112, 0.7287]], [[0.7116, 0.8642], [0.0237, 0.6914]]]]])
in0Mas83913 = tf.constant([[[[1.2593], [1.2525]], [[1.537], [1.2863]]]])
in0Con50075 = tf.constant([[[[0.9686, 0.8995, 0.2102], [0.3536, 0.4182, 0.9535]], [[0.3155, 0.5777, 0.7823], [0.0675, 0.1339, 0.0378]]]])
in0Sub67148 = tf.constant([[0.8989, 0.7148, 0.5474]])
in1Sub67148 = tf.constant([[0.2908, 0.9542, 0.958]])
in0Con96061 = tf.constant([[[0.2331], [0.1377], [0.8124]]])
in0Ave43254 = tf.constant([[[0.4921, 0.5985], [0.3998, 0.8258]]])
in1Ave43254 = tf.constant([[[0.3882, 0.5494], [0.8307, 0.8769]]])
in0Con91182 = tf.constant([[[0.8255, 0.6006, 0.3481, 0.6196, 0.8147, 0.8097], [0.9635, 0.0756, 0.5656, 0.5904, 0.2748, 0.1938], [0.2362, 0.0584, 0.0163, 0.1475, 0.3839, 0.803]]])
print (np.array2string(model.predict([in0Min14111,in1Min14111,in0Mas83913,in0Con50075,in0Sub67148,in1Sub67148,in0Con96061,in0Ave43254,in1Ave43254,in0Con91182],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul11564.png')

LMin14111 = minimum_layer([[[[[[0.5648, 0.5268], [0.7541, 0.7654]], [[0.7693, 0.4329], [0.2599, 1]]], [[[0.8126, 0.8528], [0.5645, 0.3478]], [[0.0031, 0.5385], [0.6089, 0.6878]]]]], [[[[[0.8829, 0.5814], [0.0058, 0.8802]], [[0.8498, 0.4068], [0.3507, 0.6204]]], [[[0.7021, 0.3666], [0.4112, 0.7287]], [[0.7116, 0.8642], [0.0237, 0.6914]]]]]], Min14111), 
LRes30818 = reshape_layer(Min14111, [2, 2, 4], Res30818), 
LMas83913 = masking_layer([[[[1.2593], [1.2525]], [[1.537], [1.2863]]]], 2, Mas83913), 
LCon50075 = concatenate_layer([Mas83913,[[[[0.9686, 0.8995, 0.2102], [0.3536, 0.4182, 0.9535]], [[0.3155, 0.5777, 0.7823], [0.0675, 0.1339, 0.0378]]]]], 3, Con50075), 
LAdd62595 = add_layer([Res30818,Con50075], Add62595), 
LRes28036 = reshape_layer(Add62595, [2, 8], Res28036), 
LZer76954 = zero_padding1D_layer(Res28036, 1, 0, Zer76954), 
LSub67148 = subtract_layer([[0.8989, 0.7148, 0.5474]], [[0.2908, 0.9542, 0.958]], Sub67148), 
LRes30338 = reshape_layer(Sub67148, [3, 1], Res30338), 
LCon96061 = concatenate_layer([Res30338,[[[0.2331], [0.1377], [0.8124]]]], 2, Con96061), 
LAve43254 = average_layer([[[[0.4921, 0.5985], [0.3998, 0.8258]]], [[[0.3882, 0.5494], [0.8307, 0.8769]]]], Ave43254), 
LDot83272 = dot_layer(Con96061,Ave43254, 2, 2, Dot83272), 
LCon91182 = concatenate_layer([Dot83272,[[[0.8255, 0.6006, 0.3481, 0.6196, 0.8147, 0.8097], [0.9635, 0.0756, 0.5656, 0.5904, 0.2748, 0.1938], [0.2362, 0.0584, 0.0163, 0.1475, 0.3839, 0.803]]]], 2, Con91182), 
LMul11564 = multiply_layer([Zer76954,Con91182], Mul11564), 
exec_layers([LMin14111,LRes30818,LMas83913,LCon50075,LAdd62595,LRes28036,LZer76954,LSub67148,LRes30338,LCon96061,LAve43254,LDot83272,LCon91182,LMul11564],["Min14111","Res30818","Mas83913","Con50075","Add62595","Res28036","Zer76954","Sub67148","Res30338","Con96061","Ave43254","Dot83272","Con91182","Mul11564"],Mul11564,"Mul11564")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [-0.0480450, -0.0449517, 0.8722566, 0.0737554, 1.1435301, 0.4489401, 0.1863419, 0.3050218], [0.6393780, 0.2994522, 0.2335782, 0.0659978, 0.0210172, 0.0893850, 0.0605026, 0.5826568]]]

Expected (Unparsed): [[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.04804496077950009,-0.04495165670700004,0.87225655,0.07375536,1.14353008,0.44894016000000003,0.18634188000000002,0.30502182],[0.6393781173489999,0.29945219288900005,0.23357818,0.06599784,0.02101722,0.08938499999999999,0.060502639999999996,0.5826568000000001]]]

Actual:   [[[0, 0, 0, 0, 0, 0, 0, 0], [-0.048, -0.0449, 0.8723, 0.0738, 1.1436, 0.449, 0.1864, 0.3051], [0.6394, 0.2995, 0.2336, 0.066, 0.0211, 0.0894, 0.0606, 0.5827]]]

Expected: [[[0, 0, 0, 0, 0, 0, 0, 0], [-0.048, -0.0449, 0.8723, 0.0738, 1.1436, 0.449, 0.1864, 0.3051], [0.6394, 0.2995, 0.2336, 0.066, 0.0211, 0.0894, 0.0606, 0.5827]]]