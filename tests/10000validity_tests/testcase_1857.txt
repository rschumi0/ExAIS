import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo47046 = tf.keras.layers.Input(shape=([1, 2]))
in0Add50873 = tf.keras.layers.Input(shape=([1, 2]))
in1Add50873 = tf.keras.layers.Input(shape=([1, 2]))

Glo47046 = keras.layers.GlobalMaxPool1D(name = 'Glo47046', )(in0Glo47046)
Res95139 = keras.layers.Reshape((2, 1), name = 'Res95139', )(Glo47046)
Res81308 = keras.layers.Reshape((2, 1, 1), name = 'Res81308', )(Res95139)
Res79959 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res79959', )(Res81308)
Glo79837 = keras.layers.GlobalAveragePooling3D(name = 'Glo79837', )(Res79959)
ELU15190 = keras.layers.ELU(alpha=3.3618038550204936, name = 'ELU15190', )(Glo79837)
Add50873 = keras.layers.Add(name = 'Add50873', )([in0Add50873,in1Add50873])
Sim84583 = keras.layers.SimpleRNN(1,name = 'Sim84583', )(Add50873)
Sof51642 = keras.layers.Softmax(axis=1, name = 'Sof51642', )(Sim84583)
Max6755 = keras.layers.Maximum(name = 'Max6755', )([ELU15190,Sof51642])
model = tf.keras.models.Model(inputs=[in0Glo47046,in0Add50873,in1Add50873], outputs=Max6755)
w = model.get_layer('Sim84583').get_weights() 
w[0] = np.array([[6], [5]])
w[1] = np.array([[4]])
w[2] = np.array([1])
model.get_layer('Sim84583').set_weights(w) 
in0Glo47046 = tf.constant([[[1.285, 1.4729]]])
in0Add50873 = tf.constant([[[0.9915, 0.5911]]])
in1Add50873 = tf.constant([[[0.167, 0.1475]]])
print (np.array2string(model.predict([in0Glo47046,in0Add50873,in1Add50873],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max6755.png')

LGlo47046 = global_max_pool1D_layer([[[1.285, 1.4729]]], Glo47046), 
LRes95139 = reshape_layer(Glo47046, [2, 1], Res95139), 
LRes81308 = reshape_layer(Res95139, [2, 1, 1], Res81308), 
LRes79959 = reshape_layer(Res81308, [2, 1, 1, 1], Res79959), 
LGlo79837 = global_average_pooling3D_layer(Res79959, Glo79837), 
LELU15190 = elu_layer(Glo79837, 3.3618038550204936, ELU15190), 
LAdd50873 = add_layer([[[[0.9915, 0.5911]]], [[[0.167, 0.1475]]]], Add50873), 
LSim84583 = simple_rnn_layer(Add50873,[[6], [5]],[[4]],[1], Sim84583), 
LSof51642 = softmax_layer(Sim84583, 1, Sof51642), 
LMax6755 = maximum_layer([ELU15190,Sof51642], Max6755), 
exec_layers([LGlo47046,LRes95139,LRes81308,LRes79959,LGlo79837,LELU15190,LAdd50873,LSim84583,LSof51642,LMax6755],["Glo47046","Res95139","Res81308","Res79959","Glo79837","ELU15190","Add50873","Sim84583","Sof51642","Max6755"],Max6755,"Max6755")

Actual (Unparsed): [[1.3789500]]

Expected (Unparsed): [[1.3789500000000001]]

Actual:   [[1.379]]

Expected: [[1.379]]