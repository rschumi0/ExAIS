import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub31656 = tf.keras.layers.Input(shape=([3, 3, 2, 3]))
in1Sub31656 = tf.keras.layers.Input(shape=([3, 3, 2, 3]))
in0Ave20873 = tf.keras.layers.Input(shape=([2, 1]))
in1Ave20873 = tf.keras.layers.Input(shape=([2, 1]))
in0Con34710 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Sub15415 = tf.keras.layers.Input(shape=([2]))
in1Sub15415 = tf.keras.layers.Input(shape=([2]))
in0Con71164 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Min73130 = tf.keras.layers.Input(shape=([1, 1, 2]))
in1Min73130 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Mul50763 = tf.keras.layers.Input(shape=([1, 2, 2]))
in1Mul50763 = tf.keras.layers.Input(shape=([1, 2, 2]))
in0Con11718 = tf.keras.layers.Input(shape=([2]))
in0Con96519 = tf.keras.layers.Input(shape=([296]))

Sub31656 = keras.layers.Subtract(name = 'Sub31656', )([in0Sub31656,in1Sub31656])
Zer37746 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer37746', )(Sub31656)
Res32208 = keras.layers.Reshape((5, 5, 12), name = 'Res32208', )(Zer37746)
Res88516 = keras.layers.Reshape((5, 60), name = 'Res88516', )(Res32208)
Fla33874 = keras.layers.Flatten(name = 'Fla33874', )(Res88516)
Ave20873 = keras.layers.Average(name = 'Ave20873', )([in0Ave20873,in1Ave20873])
Res22430 = keras.layers.Reshape((2, 1, 1), name = 'Res22430', )(Ave20873)
Con34710 = keras.layers.Concatenate(axis=3, name = 'Con34710', )([Res22430,in0Con34710])
Sub15415 = keras.layers.Subtract(name = 'Sub15415', )([in0Sub15415,in1Sub15415])
Res67133 = keras.layers.Reshape((2, 1), name = 'Res67133', )(Sub15415)
Res76486 = keras.layers.Reshape((2, 1, 1), name = 'Res76486', )(Res67133)
Con71164 = keras.layers.Concatenate(axis=3, name = 'Con71164', )([Res76486,in0Con71164])
Min73130 = keras.layers.Minimum(name = 'Min73130', )([in0Min73130,in1Min73130])
Zer49624 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer49624', )(Min73130)
Min80989 = keras.layers.Minimum(name = 'Min80989', )([Con71164,Zer49624])
Add98004 = keras.layers.Add(name = 'Add98004', )([Con34710,Min80989])
Res94663 = keras.layers.Reshape((2, 2), name = 'Res94663', )(Add98004)
Fla17894 = keras.layers.Flatten(name = 'Fla17894', )(Res94663)
Mul50763 = keras.layers.Multiply(name = 'Mul50763', )([in0Mul50763,in1Mul50763])
Res14302 = keras.layers.Reshape((1, 4), name = 'Res14302', )(Mul50763)
LST59245 = keras.layers.LSTM(2,recurrent_activation='sigmoid', name = 'LST59245', )(Res14302)
Con11718 = keras.layers.Concatenate(axis=1, name = 'Con11718', )([LST59245,in0Con11718])
Mul9904 = keras.layers.Multiply(name = 'Mul9904', )([Fla17894,Con11718])
Con96519 = keras.layers.Concatenate(axis=1, name = 'Con96519', )([Mul9904,in0Con96519])
Add8900 = keras.layers.Add(name = 'Add8900', )([Fla33874,Con96519])
model = tf.keras.models.Model(inputs=[in0Sub31656,in1Sub31656,in0Ave20873,in1Ave20873,in0Con34710,in0Sub15415,in1Sub15415,in0Con71164,in0Min73130,in1Min73130,in0Mul50763,in1Mul50763,in0Con11718,in0Con96519], outputs=Add8900)
w = model.get_layer('LST59245').get_weights() 
w[0] = np.array([[3, 6, 1, 5, 4, 3, 3, 4], [9, 8, 1, 10, 4, 6, 5, 2], [7, 9, 8, 3, 7, 9, 5, 1], [1, 4, 1, 2, 3, 1, 2, 4]])
w[1] = np.array([[1, 4, 1, 10, 3, 4, 4, 5], [2, 4, 7, 7, 10, 10, 8, 7]])
w[2] = np.array([2, 2, 6, 6, 1, 8, 9, 8])
model.get_layer('LST59245').set_weights(w) 
in0Sub31656 = tf.constant([[[[[0.6022, 0.3144, 0.0706], [0.7439, 0.0568, 0.5703]], [[0.4465, 0.4212, 0.6729], [0.3397, 0.2611, 0.3976]], [[0.9732, 0.401, 0.5808], [0.7676, 0.5063, 0.1336]]], [[[0.4154, 0.5811, 0.6439], [0.4057, 0.2367, 0.829]], [[0.589, 0.9984, 0.7698], [0.4287, 0.6958, 0.8778]], [[0.375, 0.5872, 0.4833], [0.1693, 0.9484, 0.9142]]], [[[0.9197, 0.3904, 0.2923], [0.3115, 0.6537, 0.3522]], [[0.3313, 0.9764, 0.8717], [0.1564, 0.3849, 0.818]], [[0.3724, 0.8791, 0.9451], [0.2141, 0.2677, 0.8608]]]]])
in1Sub31656 = tf.constant([[[[[0.0536, 0.3077, 0.4421], [0.0032, 0.4256, 0.9818]], [[0.5323, 0.1096, 0.9244], [0.2405, 0.7255, 0.1011]], [[0.8543, 0.9688, 0.1176], [0.8908, 0.8132, 0.9526]]], [[[0.7188, 0.8033, 0.5185], [0.5935, 0.4535, 0.6915]], [[0.1071, 0.9736, 0.6571], [0.3208, 0.8966, 0.7953]], [[0.6439, 0.1647, 0.4912], [0.2502, 0.8918, 0.4895]]], [[[0.4193, 0.055, 0.2709], [0.4923, 0.1942, 0.7348]], [[0.5261, 0.2999, 0.8071], [0.7279, 0.9218, 0.8375]], [[0.1801, 0.0449, 0.5482], [0.9327, 0.0345, 0.0186]]]]])
in0Ave20873 = tf.constant([[[0.3008], [0.5307]]])
in1Ave20873 = tf.constant([[[0.9615], [0.1505]]])
in0Con34710 = tf.constant([[[[0.8164]], [[0.4524]]]])
in0Sub15415 = tf.constant([[0.9501, 0.5697]])
in1Sub15415 = tf.constant([[0.2235, 0.1825]])
in0Con71164 = tf.constant([[[[0.8295]], [[0.8244]]]])
in0Min73130 = tf.constant([[[[0.0396, 0.8851]]]])
in1Min73130 = tf.constant([[[[0.9592, 0.2966]]]])
in0Mul50763 = tf.constant([[[[0.571, 0.4994], [0.0146, 0.7845]]]])
in1Mul50763 = tf.constant([[[[0.5694, 0.7848], [0.5859, 0.6179]]]])
in0Con11718 = tf.constant([[0.7963, 0.2164]])
in0Con96519 = tf.constant([[0.9541, 0.9911, 0.9816, 0.601, 0.3542, 0.6776, 0.3391, 0.777, 0.0706, 0.3437, 0.073, 0.0864, 0.6761, 0.879, 0.0017, 0.9759, 0.2832, 0.2639, 0.133, 0.6653, 0.3718, 0.4509, 0.4615, 0.4374, 0.8535, 0.9048, 0.4729, 0.6752, 0.57, 0.4973, 0.6021, 0.5711, 0.1525, 0.3491, 0.0092, 0.3342, 0.9276, 0.3792, 0.6857, 0.4123, 0.3437, 0.7789, 0.0879, 0.7177, 0.2157, 0.3632, 0.2011, 0.0916, 0.9353, 0.7667, 0.1861, 0.2784, 0.6821, 0.7516, 0.5298, 0.4927, 0.5799, 0.4727, 0.9322, 0.2578, 0.6956, 0.4054, 0.9933, 0.5681, 0.7504, 0.784, 0.1367, 0.5881, 0.424, 0.8206, 0.1025, 0.0372, 0.1725, 0.6797, 0.7748, 0.1297, 0.5516, 0.1666, 0.0712, 0.4395, 0.1397, 0.3583, 0.1117, 0.3444, 0.2882, 0.9484, 0.9141, 0.7636, 0.0931, 0.912, 0.413, 0.7505, 0.1759, 0.2017, 0.6919, 0.1277, 0.0927, 0.5827, 0.9304, 0.7575, 0.4451, 0.3817, 0.7235, 0.2313, 0.06, 0.8858, 0.1056, 0.729, 0.9252, 0.3551, 0.8287, 0.5529, 0.9198, 0.1361, 0.1821, 0.3705, 0.7635, 0.1561, 0.9201, 0.5155, 0.0224, 0.161, 0.6673, 0.7904, 0.4566, 0.4164, 0.5084, 0.0916, 0.4719, 0.2372, 0.3372, 0.831, 0.9462, 0.629, 0.9405, 0.5729, 0.2422, 0.5342, 0.7221, 0.5183, 0.7873, 0.6559, 0.433, 0.4746, 0.2084, 0.6021, 0.269, 0.7275, 0.6374, 0.1412, 0.2211, 0.7985, 0.4727, 0.6863, 0.6177, 0.412, 0.576, 0.7377, 0.3871, 0.1275, 0.6132, 0.9063, 0.6854, 0.9936, 0.0036, 0.3085, 0.1852, 0.2737, 0.7359, 0.5832, 0.4996, 0.7613, 0.1275, 0.5133, 0.9304, 0.4525, 0.4573, 0.2501, 0.9705, 0.3775, 0.2867, 0.4404, 0.7655, 0.2064, 0.1971, 0.1316, 0.0456, 0.8369, 0.6198, 0.1925, 0.8752, 0.5505, 0.4103, 0.1279, 0.9365, 0.4789, 0.8303, 0.5894, 0.9617, 0.0619, 0.6368, 0.5871, 0.3603, 0.8977, 0.0534, 0.3945, 0.0492, 0.8864, 0.4982, 0.4023, 0.9863, 0.8514, 0.0775, 0.7284, 0.9335, 0.8854, 0.0205, 0.2178, 0.5299, 0.5141, 0.4245, 0.5771, 0.8431, 0.3942, 0.9104, 0.7805, 0.1852, 0.672, 0.0432, 0.5569, 0.1283, 0.3162, 0.6666, 0.7205, 0.3369, 0.7082, 0.6193, 0.345, 0.0442, 0.5243, 0.6527, 0.2964, 0.744, 0.4766, 0.7567, 0.4366, 0.9447, 0.7928, 0.5115, 0.8918, 0.6355, 0.4099, 0.5322, 0.1376, 0.4539, 0.7322, 0.5496, 0.2952, 0.411, 0.462, 0.1795, 0.9554, 0.4303, 0.4497, 0.9719, 0.0525, 0.8862, 0.7297, 0.9057, 0.7946, 0.7916, 0.9082, 0.0928, 0.4227, 0.2752, 0.8544, 0.0935, 0.6208, 0.5154, 0.2058, 0.9059, 0.7262, 0.3517, 0.548, 0.3939, 0.5012, 0.3829, 0.2492, 0.6385, 0.1179, 0.479, 0.8442, 0.4633, 0.1818, 0.2816, 0.5436]])
print (np.array2string(model.predict([in0Sub31656,in1Sub31656,in0Ave20873,in1Ave20873,in0Con34710,in0Sub15415,in1Sub15415,in0Con71164,in0Min73130,in1Min73130,in0Mul50763,in1Mul50763,in0Con11718,in0Con96519],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add8900.png')

LSub31656 = subtract_layer([[[[[0.6022, 0.3144, 0.0706], [0.7439, 0.0568, 0.5703]], [[0.4465, 0.4212, 0.6729], [0.3397, 0.2611, 0.3976]], [[0.9732, 0.401, 0.5808], [0.7676, 0.5063, 0.1336]]], [[[0.4154, 0.5811, 0.6439], [0.4057, 0.2367, 0.829]], [[0.589, 0.9984, 0.7698], [0.4287, 0.6958, 0.8778]], [[0.375, 0.5872, 0.4833], [0.1693, 0.9484, 0.9142]]], [[[0.9197, 0.3904, 0.2923], [0.3115, 0.6537, 0.3522]], [[0.3313, 0.9764, 0.8717], [0.1564, 0.3849, 0.818]], [[0.3724, 0.8791, 0.9451], [0.2141, 0.2677, 0.8608]]]]], [[[[[0.0536, 0.3077, 0.4421], [0.0032, 0.4256, 0.9818]], [[0.5323, 0.1096, 0.9244], [0.2405, 0.7255, 0.1011]], [[0.8543, 0.9688, 0.1176], [0.8908, 0.8132, 0.9526]]], [[[0.7188, 0.8033, 0.5185], [0.5935, 0.4535, 0.6915]], [[0.1071, 0.9736, 0.6571], [0.3208, 0.8966, 0.7953]], [[0.6439, 0.1647, 0.4912], [0.2502, 0.8918, 0.4895]]], [[[0.4193, 0.055, 0.2709], [0.4923, 0.1942, 0.7348]], [[0.5261, 0.2999, 0.8071], [0.7279, 0.9218, 0.8375]], [[0.1801, 0.0449, 0.5482], [0.9327, 0.0345, 0.0186]]]]], Sub31656), 
LZer37746 = zero_padding3D_layer(Sub31656, 1, 1, 1, 1, 1, 1, Zer37746), 
LRes32208 = reshape_layer(Zer37746, [5, 5, 12], Res32208), 
LRes88516 = reshape_layer(Res32208, [5, 60], Res88516), 
LFla33874 = flatten_layer(Res88516, Fla33874), 
LAve20873 = average_layer([[[[0.3008], [0.5307]]], [[[0.9615], [0.1505]]]], Ave20873), 
LRes22430 = reshape_layer(Ave20873, [2, 1, 1], Res22430), 
LCon34710 = concatenate_layer([Res22430,[[[[0.8164]], [[0.4524]]]]], 3, Con34710), 
LSub15415 = subtract_layer([[0.9501, 0.5697]], [[0.2235, 0.1825]], Sub15415), 
LRes67133 = reshape_layer(Sub15415, [2, 1], Res67133), 
LRes76486 = reshape_layer(Res67133, [2, 1, 1], Res76486), 
LCon71164 = concatenate_layer([Res76486,[[[[0.8295]], [[0.8244]]]]], 3, Con71164), 
LMin73130 = minimum_layer([[[[[0.0396, 0.8851]]]], [[[[0.9592, 0.2966]]]]], Min73130), 
LZer49624 = zero_padding2D_layer(Min73130, 1, 0, 0, 0, Zer49624), 
LMin80989 = minimum_layer([Con71164,Zer49624], Min80989), 
LAdd98004 = add_layer([Con34710,Min80989], Add98004), 
LRes94663 = reshape_layer(Add98004, [2, 2], Res94663), 
LFla17894 = flatten_layer(Res94663, Fla17894), 
LMul50763 = multiply_layer([[[[[0.571, 0.4994], [0.0146, 0.7845]]]], [[[[0.5694, 0.7848], [0.5859, 0.6179]]]]], Mul50763), 
LRes14302 = reshape_layer(Mul50763, [1, 4], Res14302), 
LLST59245 = lstm_layer(Res14302,[[3, 6, 1, 5, 4, 3, 3, 4], [9, 8, 1, 10, 4, 6, 5, 2], [7, 9, 8, 3, 7, 9, 5, 1], [1, 4, 1, 2, 3, 1, 2, 4]],[[1, 4, 1, 10, 3, 4, 4, 5], [2, 4, 7, 7, 10, 10, 8, 7]],[2, 2, 6, 6, 1, 8, 9, 8], LST59245), 
LCon11718 = concatenate_layer([LST59245,[[0.7963, 0.2164]]], 1, Con11718), 
LMul9904 = multiply_layer([Fla17894,Con11718], Mul9904), 
LCon96519 = concatenate_layer([Mul9904,[[0.9541, 0.9911, 0.9816, 0.601, 0.3542, 0.6776, 0.3391, 0.777, 0.0706, 0.3437, 0.073, 0.0864, 0.6761, 0.879, 0.0017, 0.9759, 0.2832, 0.2639, 0.133, 0.6653, 0.3718, 0.4509, 0.4615, 0.4374, 0.8535, 0.9048, 0.4729, 0.6752, 0.57, 0.4973, 0.6021, 0.5711, 0.1525, 0.3491, 0.0092, 0.3342, 0.9276, 0.3792, 0.6857, 0.4123, 0.3437, 0.7789, 0.0879, 0.7177, 0.2157, 0.3632, 0.2011, 0.0916, 0.9353, 0.7667, 0.1861, 0.2784, 0.6821, 0.7516, 0.5298, 0.4927, 0.5799, 0.4727, 0.9322, 0.2578, 0.6956, 0.4054, 0.9933, 0.5681, 0.7504, 0.784, 0.1367, 0.5881, 0.424, 0.8206, 0.1025, 0.0372, 0.1725, 0.6797, 0.7748, 0.1297, 0.5516, 0.1666, 0.0712, 0.4395, 0.1397, 0.3583, 0.1117, 0.3444, 0.2882, 0.9484, 0.9141, 0.7636, 0.0931, 0.912, 0.413, 0.7505, 0.1759, 0.2017, 0.6919, 0.1277, 0.0927, 0.5827, 0.9304, 0.7575, 0.4451, 0.3817, 0.7235, 0.2313, 0.06, 0.8858, 0.1056, 0.729, 0.9252, 0.3551, 0.8287, 0.5529, 0.9198, 0.1361, 0.1821, 0.3705, 0.7635, 0.1561, 0.9201, 0.5155, 0.0224, 0.161, 0.6673, 0.7904, 0.4566, 0.4164, 0.5084, 0.0916, 0.4719, 0.2372, 0.3372, 0.831, 0.9462, 0.629, 0.9405, 0.5729, 0.2422, 0.5342, 0.7221, 0.5183, 0.7873, 0.6559, 0.433, 0.4746, 0.2084, 0.6021, 0.269, 0.7275, 0.6374, 0.1412, 0.2211, 0.7985, 0.4727, 0.6863, 0.6177, 0.412, 0.576, 0.7377, 0.3871, 0.1275, 0.6132, 0.9063, 0.6854, 0.9936, 0.0036, 0.3085, 0.1852, 0.2737, 0.7359, 0.5832, 0.4996, 0.7613, 0.1275, 0.5133, 0.9304, 0.4525, 0.4573, 0.2501, 0.9705, 0.3775, 0.2867, 0.4404, 0.7655, 0.2064, 0.1971, 0.1316, 0.0456, 0.8369, 0.6198, 0.1925, 0.8752, 0.5505, 0.4103, 0.1279, 0.9365, 0.4789, 0.8303, 0.5894, 0.9617, 0.0619, 0.6368, 0.5871, 0.3603, 0.8977, 0.0534, 0.3945, 0.0492, 0.8864, 0.4982, 0.4023, 0.9863, 0.8514, 0.0775, 0.7284, 0.9335, 0.8854, 0.0205, 0.2178, 0.5299, 0.5141, 0.4245, 0.5771, 0.8431, 0.3942, 0.9104, 0.7805, 0.1852, 0.672, 0.0432, 0.5569, 0.1283, 0.3162, 0.6666, 0.7205, 0.3369, 0.7082, 0.6193, 0.345, 0.0442, 0.5243, 0.6527, 0.2964, 0.744, 0.4766, 0.7567, 0.4366, 0.9447, 0.7928, 0.5115, 0.8918, 0.6355, 0.4099, 0.5322, 0.1376, 0.4539, 0.7322, 0.5496, 0.2952, 0.411, 0.462, 0.1795, 0.9554, 0.4303, 0.4497, 0.9719, 0.0525, 0.8862, 0.7297, 0.9057, 0.7946, 0.7916, 0.9082, 0.0928, 0.4227, 0.2752, 0.8544, 0.0935, 0.6208, 0.5154, 0.2058, 0.9059, 0.7262, 0.3517, 0.548, 0.3939, 0.5012, 0.3829, 0.2492, 0.6385, 0.1179, 0.479, 0.8442, 0.4633, 0.1818, 0.2816, 0.5436]]], 1, Con96519), 
LAdd8900 = add_layer([Fla33874,Con96519], Add8900), 
exec_layers([LSub31656,LZer37746,LRes32208,LRes88516,LFla33874,LAve20873,LRes22430,LCon34710,LSub15415,LRes67133,LRes76486,LCon71164,LMin73130,LZer49624,LMin80989,LAdd98004,LRes94663,LFla17894,LMul50763,LRes14302,LLST59245,LCon11718,LMul9904,LCon96519,LAdd8900],["Sub31656","Zer37746","Res32208","Res88516","Fla33874","Ave20873","Res22430","Con34710","Sub15415","Res67133","Res76486","Con71164","Min73130","Zer49624","Min80989","Add98004","Res94663","Fla17894","Mul50763","Res14302","LST59245","Con11718","Mul9904","Con96519","Add8900"],Add8900,"Add8900")

Actual (Unparsed): [[0.4804373, 0.6217236, 0.3027533, 0.1620836, 0.9541000, 0.9911000, 0.9816000, 0.6010000, 0.3542000, 0.6776000, 0.3391000, 0.7770000, 0.0706000, 0.3437000, 0.0730000, 0.0864000, 0.6761000, 0.8790000, 0.0017000, 0.9759000, 0.2832000, 0.2639000, 0.1330000, 0.6653000, 0.3718000, 0.4509000, 0.4615000, 0.4374000, 0.8535000, 0.9048000, 0.4729000, 0.6752000, 0.5700000, 0.4973000, 0.6021000, 0.5711000, 0.1525000, 0.3491000, 0.0092000, 0.3342000, 0.9276000, 0.3792000, 0.6857000, 0.4123000, 0.3437000, 0.7789000, 0.0879000, 0.7177000, 0.2157000, 0.3632000, 0.2011000, 0.0916000, 0.9353000, 0.7667000, 0.1861000, 0.2784000, 0.6821000, 0.7516000, 0.5298000, 0.4927000, 0.5799000, 0.4727000, 0.9322000, 0.2578000, 0.6956000, 0.4054000, 0.9933000, 0.5681000, 0.7504000, 0.7840000, 0.1367000, 0.5881000, 0.4240000, 0.8206000, 0.1025000, 0.5858000, 0.1792000, 0.3082000, 1.5155000, -0.2391000, 0.1400999, 0.1666000, 0.0712000, 0.4395000, 0.1397000, 0.3583000, 0.1117000, 0.2586000, 0.5998000, 0.6969001, 1.0133000, 0.2992000, 0.3896000, 0.9120000, 0.4130000, 0.7505000, 0.1759000, 0.2017000, 0.6919000, 0.2466000, -0.4751000, 1.0459000, 0.8072000, 0.4506000, -0.3739000, 0.3817000, 0.7235000, 0.2313000, 0.0600000, 0.8858000, 0.1056000, 0.7290000, 0.9252000, 0.3551000, 0.8287000, 0.5529000, 0.9198000, 0.1361000, 0.1821000, 0.3705000, 0.7635000, 0.1561000, 0.9201000, 0.5155000, 0.0224000, 0.1610000, 0.6673000, 0.7904000, 0.4566000, 0.4164000, 0.5084000, 0.0916000, 0.4719000, 0.2372000, 0.3372000, 0.5276000, 0.7240000, 0.7544000, 0.7527000, 0.3561000, 0.3797000, 0.5342000, 0.7221000, 0.5183000, 0.7873000, 0.6559000, 0.4330000, 0.9565000, 0.2332000, 0.7148000, 0.3769000, 0.5267000, 0.7199000, 0.1412000, 0.2211000, 0.7985000, 0.4727000, 0.6863000, 0.6177000, 0.1431000, 0.9985000, 0.7298000, 0.3062000, 0.1841000, 1.0379000, 0.9063000, 0.6854000, 0.9936000, 0.0036000, 0.3085000, 0.1852000, 0.2737000, 0.7359000, 0.5832000, 0.4996000, 0.7613000, 0.1275000, 0.5133000, 0.9304000, 0.4525000, 0.4573000, 0.2501000, 0.9705000, 0.3775000, 0.2867000, 0.4404000, 0.7655000, 0.2064000, 0.1971000, 0.1316000, 0.0456000, 0.8369000, 0.6198000, 0.1925000, 0.8752000, 1.0509000, 0.7457000, 0.1493000, 0.7557000, 0.9384000, 0.4477000, 0.5894000, 0.9617000, 0.0619000, 0.6368000, 0.5871000, 0.3603000, 0.7029000, 0.7299000, 0.4591000, -0.5223000, 0.3495000, 0.4787000, 0.4023000, 0.9863000, 0.8514000, 0.0775000, 0.7284000, 0.9335000, 1.0777000, 0.8547000, 0.6147000, -0.1887000, 0.7473000, 1.2667000, 0.5771000, 0.8431000, 0.3942000, 0.9104000, 0.7805000, 0.1852000, 0.6720000, 0.0432000, 0.5569000, 0.1283000, 0.3162000, 0.6666000, 0.7205000, 0.3369000, 0.7082000, 0.6193000, 0.3450000, 0.0442000, 0.5243000, 0.6527000, 0.2964000, 0.7440000, 0.4766000, 0.7567000, 0.4366000, 0.9447000, 0.7928000, 0.5115000, 0.8918000, 0.6355000, 0.4099000, 0.5322000, 0.1376000, 0.4539000, 0.7322000, 0.5496000, 0.2952000, 0.4110000, 0.4620000, 0.1795000, 0.9554000, 0.4303000, 0.4497000, 0.9719000, 0.0525000, 0.8862000, 0.7297000, 0.9057000, 0.7946000, 0.7916000, 0.9082000, 0.0928000, 0.4227000, 0.2752000, 0.8544000, 0.0935000, 0.6208000, 0.5154000, 0.2058000, 0.9059000, 0.7262000, 0.3517000, 0.5480000, 0.3939000, 0.5012000, 0.3829000, 0.2492000, 0.6385000, 0.1179000, 0.4790000, 0.8442000, 0.4633000, 0.1818000, 0.2816000, 0.5436000]]

Expected (Unparsed): [[0.4804373182431009,0.6217235656944462,0.30275325999999997,0.1620836,0.9541,0.9911,0.9816,0.601,0.3542,0.6776,0.3391,0.777,0.0706,0.3437,0.073,0.0864,0.6761,0.879,0.0017,0.9759,0.2832,0.2639,0.133,0.6653,0.3718,0.4509,0.4615,0.4374,0.8535,0.9048,0.4729,0.6752,0.57,0.4973,0.6021,0.5711,0.1525,0.3491,0.0092,0.3342,0.9276,0.3792,0.6857,0.4123,0.3437,0.7789,0.0879,0.7177,0.2157,0.3632,0.2011,0.0916,0.9353,0.7667,0.1861,0.2784,0.6821,0.7516,0.5298,0.4927,0.5799,0.4727,0.9322,0.2578,0.6956,0.4054,0.9933,0.5681,0.7504,0.784,0.1367,0.5881,0.424,0.8206,0.1025,0.5858,0.17920000000000003,0.3082,1.5155,-0.23909999999999995,0.1401,0.1666,0.0712,0.4395,0.1397,0.3583,0.1117,0.2586,0.5998,0.6969000000000001,1.0133,0.2991999999999999,0.3896,0.912,0.413,0.7505,0.1759,0.2017,0.6919,0.2466,-0.47509999999999997,1.0459,0.8071999999999999,0.4505999999999999,-0.37389999999999995,0.3817,0.7235,0.2313,0.06,0.8858,0.1056,0.729,0.9252,0.3551,0.8287,0.5529,0.9198,0.1361,0.1821,0.3705,0.7635,0.1561,0.9201,0.5155,0.0224,0.161,0.6673,0.7904,0.4566,0.4164,0.5084,0.0916,0.4719,0.2372,0.3372,0.5276,0.724,0.7544000000000001,0.7526999999999999,0.35609999999999997,0.3796999999999999,0.5342,0.7221,0.5183,0.7873,0.6559,0.433,0.9565,0.23319999999999994,0.7148,0.37690000000000007,0.5267000000000001,0.7199,0.1412,0.2211,0.7985,0.4727,0.6863,0.6177,0.14309999999999995,0.9984999999999999,0.7298,0.3062,0.18409999999999999,1.0379,0.9063,0.6854,0.9936,0.0036,0.3085,0.1852,0.2737,0.7359,0.5832,0.4996,0.7613,0.1275,0.5133,0.9304,0.4525,0.4573,0.2501,0.9705,0.3775,0.2867,0.4404,0.7655,0.2064,0.1971,0.1316,0.0456,0.8369,0.6198,0.1925,0.8752,1.0509,0.7457,0.14930000000000004,0.7557,0.9383999999999999,0.44770000000000004,0.5894,0.9617,0.0619,0.6368,0.5871,0.3603,0.7029000000000001,0.7299000000000001,0.4591,-0.5223,0.34950000000000003,0.4786999999999999,0.4023,0.9863,0.8514,0.0775,0.7284,0.9335,1.0776999999999999,0.8546999999999999,0.6147,-0.18869999999999987,0.7473,1.2667000000000002,0.5771,0.8431,0.3942,0.9104,0.7805,0.1852,0.672,0.0432,0.5569,0.1283,0.3162,0.6666,0.7205,0.3369,0.7082,0.6193,0.345,0.0442,0.5243,0.6527,0.2964,0.744,0.4766,0.7567,0.4366,0.9447,0.7928,0.5115,0.8918,0.6355,0.4099,0.5322,0.1376,0.4539,0.7322,0.5496,0.2952,0.411,0.462,0.1795,0.9554,0.4303,0.4497,0.9719,0.0525,0.8862,0.7297,0.9057,0.7946,0.7916,0.9082,0.0928,0.4227,0.2752,0.8544,0.0935,0.6208,0.5154,0.2058,0.9059,0.7262,0.3517,0.548,0.3939,0.5012,0.3829,0.2492,0.6385,0.1179,0.479,0.8442,0.4633,0.1818,0.2816,0.5436]]

Actual:   [[0.4805, 0.6218, 0.3028, 0.1621, 0.9541, 0.9911, 0.9816, 0.601, 0.3542, 0.6776, 0.3391, 0.777, 0.0706, 0.3437, 0.073, 0.0864, 0.6761, 0.879, 0.0017, 0.9759, 0.2832, 0.2639, 0.133, 0.6653, 0.3718, 0.4509, 0.4615, 0.4374, 0.8535, 0.9048, 0.4729, 0.6752, 0.57, 0.4973, 0.6021, 0.5711, 0.1525, 0.3491, 0.0092, 0.3342, 0.9276, 0.3792, 0.6857, 0.4123, 0.3437, 0.7789, 0.0879, 0.7177, 0.2157, 0.3632, 0.2011, 0.0916, 0.9353, 0.7667, 0.1861, 0.2784, 0.6821, 0.7516, 0.5298, 0.4927, 0.5799, 0.4727, 0.9322, 0.2578, 0.6956, 0.4054, 0.9933, 0.5681, 0.7504, 0.784, 0.1367, 0.5881, 0.424, 0.8206, 0.1025, 0.5858, 0.1792, 0.3082, 1.5155, -0.2391, 0.1401, 0.1666, 0.0712, 0.4395, 0.1397, 0.3583, 0.1117, 0.2586, 0.5998, 0.697, 1.0133, 0.2992, 0.3896, 0.912, 0.413, 0.7505, 0.1759, 0.2017, 0.6919, 0.2466, -0.4751, 1.0459, 0.8072, 0.4506, -0.3739, 0.3817, 0.7235, 0.2313, 0.06, 0.8858, 0.1056, 0.729, 0.9252, 0.3551, 0.8287, 0.5529, 0.9198, 0.1361, 0.1821, 0.3705, 0.7635, 0.1561, 0.9201, 0.5155, 0.0224, 0.161, 0.6673, 0.7904, 0.4566, 0.4164, 0.5084, 0.0916, 0.4719, 0.2372, 0.3372, 0.5276, 0.724, 0.7544, 0.7527, 0.3561, 0.3797, 0.5342, 0.7221, 0.5183, 0.7873, 0.6559, 0.433, 0.9565, 0.2332, 0.7148, 0.3769, 0.5267, 0.7199, 0.1412, 0.2211, 0.7985, 0.4727, 0.6863, 0.6177, 0.1431, 0.9985, 0.7298, 0.3062, 0.1841, 1.0379, 0.9063, 0.6854, 0.9936, 0.0036, 0.3085, 0.1852, 0.2737, 0.7359, 0.5832, 0.4996, 0.7613, 0.1275, 0.5133, 0.9304, 0.4525, 0.4573, 0.2501, 0.9705, 0.3775, 0.2867, 0.4404, 0.7655, 0.2064, 0.1971, 0.1316, 0.0456, 0.8369, 0.6198, 0.1925, 0.8752, 1.0509, 0.7457, 0.1493, 0.7557, 0.9384, 0.4477, 0.5894, 0.9617, 0.0619, 0.6368, 0.5871, 0.3603, 0.7029, 0.7299, 0.4591, -0.5223, 0.3495, 0.4787, 0.4023, 0.9863, 0.8514, 0.0775, 0.7284, 0.9335, 1.0777, 0.8547, 0.6147, -0.1887, 0.7473, 1.2667, 0.5771, 0.8431, 0.3942, 0.9104, 0.7805, 0.1852, 0.672, 0.0432, 0.5569, 0.1283, 0.3162, 0.6666, 0.7205, 0.3369, 0.7082, 0.6193, 0.345, 0.0442, 0.5243, 0.6527, 0.2964, 0.744, 0.4766, 0.7567, 0.4366, 0.9447, 0.7928, 0.5115, 0.8918, 0.6355, 0.4099, 0.5322, 0.1376, 0.4539, 0.7322, 0.5496, 0.2952, 0.411, 0.462, 0.1795, 0.9554, 0.4303, 0.4497, 0.9719, 0.0525, 0.8862, 0.7297, 0.9057, 0.7946, 0.7916, 0.9082, 0.0928, 0.4227, 0.2752, 0.8544, 0.0935, 0.6208, 0.5154, 0.2058, 0.9059, 0.7262, 0.3517, 0.548, 0.3939, 0.5012, 0.3829, 0.2492, 0.6385, 0.1179, 0.479, 0.8442, 0.4633, 0.1818, 0.2816, 0.5436]]

Expected: [[0.4805, 0.6218, 0.3028, 0.1621, 0.9541, 0.9911, 0.9816, 0.601, 0.3542, 0.6776, 0.3391, 0.777, 0.0706, 0.3437, 0.073, 0.0864, 0.6761, 0.879, 0.0017, 0.9759, 0.2832, 0.2639, 0.133, 0.6653, 0.3718, 0.4509, 0.4615, 0.4374, 0.8535, 0.9048, 0.4729, 0.6752, 0.57, 0.4973, 0.6021, 0.5711, 0.1525, 0.3491, 0.0092, 0.3342, 0.9276, 0.3792, 0.6857, 0.4123, 0.3437, 0.7789, 0.0879, 0.7177, 0.2157, 0.3632, 0.2011, 0.0916, 0.9353, 0.7667, 0.1861, 0.2784, 0.6821, 0.7516, 0.5298, 0.4927, 0.5799, 0.4727, 0.9322, 0.2578, 0.6956, 0.4054, 0.9933, 0.5681, 0.7504, 0.784, 0.1367, 0.5881, 0.424, 0.8206, 0.1025, 0.5858, 0.1793, 0.3082, 1.5155, -0.239, 0.1401, 0.1666, 0.0712, 0.4395, 0.1397, 0.3583, 0.1117, 0.2586, 0.5998, 0.697, 1.0133, 0.2992, 0.3896, 0.912, 0.413, 0.7505, 0.1759, 0.2017, 0.6919, 0.2466, -0.475, 1.0459, 0.8072, 0.4506, -0.3738, 0.3817, 0.7235, 0.2313, 0.06, 0.8858, 0.1056, 0.729, 0.9252, 0.3551, 0.8287, 0.5529, 0.9198, 0.1361, 0.1821, 0.3705, 0.7635, 0.1561, 0.9201, 0.5155, 0.0224, 0.161, 0.6673, 0.7904, 0.4566, 0.4164, 0.5084, 0.0916, 0.4719, 0.2372, 0.3372, 0.5276, 0.724, 0.7545, 0.7527, 0.3561, 0.3797, 0.5342, 0.7221, 0.5183, 0.7873, 0.6559, 0.433, 0.9565, 0.2332, 0.7148, 0.377, 0.5268, 0.7199, 0.1412, 0.2211, 0.7985, 0.4727, 0.6863, 0.6177, 0.1431, 0.9985, 0.7298, 0.3062, 0.1841, 1.0379, 0.9063, 0.6854, 0.9936, 0.0036, 0.3085, 0.1852, 0.2737, 0.7359, 0.5832, 0.4996, 0.7613, 0.1275, 0.5133, 0.9304, 0.4525, 0.4573, 0.2501, 0.9705, 0.3775, 0.2867, 0.4404, 0.7655, 0.2064, 0.1971, 0.1316, 0.0456, 0.8369, 0.6198, 0.1925, 0.8752, 1.0509, 0.7457, 0.1494, 0.7557, 0.9384, 0.4478, 0.5894, 0.9617, 0.0619, 0.6368, 0.5871, 0.3603, 0.703, 0.73, 0.4591, -0.5223, 0.3496, 0.4787, 0.4023, 0.9863, 0.8514, 0.0775, 0.7284, 0.9335, 1.0777, 0.8547, 0.6147, -0.1886, 0.7473, 1.2668, 0.5771, 0.8431, 0.3942, 0.9104, 0.7805, 0.1852, 0.672, 0.0432, 0.5569, 0.1283, 0.3162, 0.6666, 0.7205, 0.3369, 0.7082, 0.6193, 0.345, 0.0442, 0.5243, 0.6527, 0.2964, 0.744, 0.4766, 0.7567, 0.4366, 0.9447, 0.7928, 0.5115, 0.8918, 0.6355, 0.4099, 0.5322, 0.1376, 0.4539, 0.7322, 0.5496, 0.2952, 0.411, 0.462, 0.1795, 0.9554, 0.4303, 0.4497, 0.9719, 0.0525, 0.8862, 0.7297, 0.9057, 0.7946, 0.7916, 0.9082, 0.0928, 0.4227, 0.2752, 0.8544, 0.0935, 0.6208, 0.5154, 0.2058, 0.9059, 0.7262, 0.3517, 0.548, 0.3939, 0.5012, 0.3829, 0.2492, 0.6385, 0.1179, 0.479, 0.8442, 0.4633, 0.1818, 0.2816, 0.5436]]