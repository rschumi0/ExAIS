import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Loc58734 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con25122 = tf.keras.layers.Input(shape=([3, 3, 1]))
in0ReL17203 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))
in0Con87567 = tf.keras.layers.Input(shape=([3, 3, 3]))
in0Zer1963 = tf.keras.layers.Input(shape=([1, 1, 4]))
in0Con10767 = tf.keras.layers.Input(shape=([2, 1]))
in0Con28885 = tf.keras.layers.Input(shape=([269]))

Loc58734 = keras.layers.LocallyConnected2D(3, (1, 1),strides=(1, 1), name = 'Loc58734', )(in0Loc58734)
Zer51603 = keras.layers.ZeroPadding2D(padding=((2, 0), (2, 0)), name = 'Zer51603', )(Loc58734)
Con25122 = keras.layers.Concatenate(axis=3, name = 'Con25122', )([Zer51603,in0Con25122])
ReL17203 = keras.layers.ReLU(max_value=6.830876603605193, negative_slope=8.022245676724504, threshold=8.968117709638642, name = 'ReL17203', input_shape=(1, 1, 1, 1))(in0ReL17203)
Res36533 = keras.layers.Reshape((1, 1, 1), name = 'Res36533', )(ReL17203)
Zer9706 = keras.layers.ZeroPadding2D(padding=((2, 0), (2, 0)), name = 'Zer9706', )(Res36533)
Con87567 = keras.layers.Concatenate(axis=3, name = 'Con87567', )([Zer9706,in0Con87567])
Zer1963 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer1963', )(in0Zer1963)
Add10100 = keras.layers.Add(name = 'Add10100', )([Con87567,Zer1963])
Max94256 = keras.layers.Maximum(name = 'Max94256', )([Con25122,Add10100])
Con10901 = keras.layers.Conv2DTranspose(3, (2, 1),strides=(2, 5), padding='valid', name = 'Con10901', )(Max94256)
Res30035 = keras.layers.Reshape((6, 45), name = 'Res30035', )(Con10901)
Fla30597 = keras.layers.Flatten(name = 'Fla30597', )(Res30035)
Con10767 = keras.layers.Conv1D(3, (2),strides=(1), padding='same', dilation_rate=(1), name = 'Con10767', )(in0Con10767)
Res40323 = keras.layers.Reshape((2, 3, 1), name = 'Res40323', )(Con10767)
Glo74431 = keras.layers.GlobalAveragePooling2D(name = 'Glo74431', )(Res40323)
Con28885 = keras.layers.Concatenate(axis=1, name = 'Con28885', )([Glo74431,in0Con28885])
Sub40612 = keras.layers.Subtract(name = 'Sub40612', )([Fla30597,Con28885])
model = tf.keras.models.Model(inputs=[in0Loc58734,in0Con25122,in0ReL17203,in0Con87567,in0Zer1963,in0Con10767,in0Con28885], outputs=Sub40612)
w = model.get_layer('Loc58734').get_weights() 
w[0] = np.array([[[0.2022, 0.9287, 0.4215], [0.5777, 0.2142, 0.1772]]])
w[1] = np.array([[[0, 0, 0]]])
model.get_layer('Loc58734').set_weights(w) 
w = model.get_layer('Con10901').get_weights() 
w[0] = np.array([[[[0.9139, 0.0116, 0.2612, 0.1171], [0.2638, 0.3913, 0.0318, 0.2917], [0.1848, 0.3837, 0.4735, 0.9203]]], [[[0.5988, 0.4638, 0.5954, 0.0157], [0.2968, 0.2981, 0.0511, 0.3561], [0.7697, 0.3411, 0.4978, 0.7641]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con10901').set_weights(w) 
w = model.get_layer('Con10767').get_weights() 
w[0] = np.array([[[0.2325, 0.8135, 0.4448]], [[0.1929, 0.1616, 0.6295]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con10767').set_weights(w) 
in0Loc58734 = tf.constant([[[[0.0416, 0.3521]]]])
in0Con25122 = tf.constant([[[[0.515], [0.5018], [0.0169]], [[0.5563], [0.8002], [0.0042]], [[0.0022], [0.2192], [0.5892]]]])
in0ReL17203 = tf.constant([[[[[0.5222]]]]])
in0Con87567 = tf.constant([[[[0.3856, 0.8599, 0.6058], [0.8159, 0.0725, 0.5478], [0.998, 0.2219, 0.2945]], [[0.2933, 0.6871, 0.8985], [0.0779, 0.8841, 0.5003], [0.0514, 0.1442, 0.677]], [[0.6568, 0.9452, 0.1663], [0.0009, 0.665, 0.4404], [0.7371, 0.1285, 0.3367]]]])
in0Zer1963 = tf.constant([[[[1.0764, 1.8867, 1.2326, 1.0571]]]])
in0Con10767 = tf.constant([[[0.568], [0.0077]]])
in0Con28885 = tf.constant([[0.4153, 0.5791, 0.0514, 0.8303, 0.1216, 0.6773, 0.864, 0.7475, 0.0169, 0.1556, 0.8395, 0.5548, 0.204, 0.8303, 0.9581, 0.3332, 0.6468, 0.6536, 0.2413, 0.4404, 0.1046, 0.2086, 0.7787, 0.9677, 0.6746, 0.649, 0.6777, 0.0246, 0.4462, 0.1727, 0.5953, 0.6486, 0.4641, 0.7257, 0.0988, 0.2591, 0.9276, 0.5267, 0.2183, 0.4867, 0.3115, 0.1759, 0.2064, 0.8909, 0.882, 0.5623, 0.698, 0.5573, 0.9065, 0.5235, 0.1773, 0.8076, 0.7039, 0.2255, 0.9013, 0.2954, 0.57, 0.5292, 0.2034, 0.5695, 0.5242, 0.1889, 0.4071, 0.7826, 0.773, 0.5888, 0.4153, 0.6007, 0.761, 0.8652, 0.4117, 0.5229, 0.69, 0.684, 0.0055, 0.7624, 0.4267, 0.6482, 0.5869, 0.5568, 0.7909, 0.2961, 0.618, 0.2803, 0.3183, 0.9145, 0.08, 0.0079, 0.7258, 0.9433, 0.3202, 0.2496, 0.4726, 0.5731, 0.0991, 0.4141, 0.0063, 0.2507, 0.7239, 0.1898, 0.5117, 0.1967, 0.7741, 0.4367, 0.2364, 0.714, 0.072, 0.3716, 0.761, 0.0196, 0.2353, 0.7988, 0.8987, 0.5664, 0.3565, 0.8899, 0.2663, 0.3396, 0.1005, 0.5477, 0.9479, 0.4102, 0.7849, 0.7035, 0.0904, 0.1057, 0.812, 0.9908, 0.7169, 0.5209, 0.1613, 0.1161, 0.5169, 0.7298, 0.5159, 0.9021, 0.8887, 0.9867, 0.9988, 0.4203, 0.0409, 0.4053, 0.4237, 0.8467, 0.5382, 0.0911, 0.4281, 0.6772, 0.2755, 0.4697, 0.8484, 0.7212, 0.4979, 0.6006, 0.222, 0.8543, 0.1526, 0.5949, 0.3571, 0.8578, 0.5506, 0.8668, 0.4979, 0.7954, 0.047, 0.8402, 0.7295, 0.2896, 0.2053, 0.9025, 0.9187, 0.743, 0.7032, 0.8553, 0.6659, 0.0246, 0.0566, 0.8437, 0.4555, 0.3882, 0.0926, 0.7654, 0.4354, 0.4259, 0.9852, 0.4557, 0.0309, 0.669, 0.5822, 0.5263, 0.9045, 0.0472, 0.7006, 0.5947, 0.6071, 0.7908, 0.0405, 0.7826, 0.6396, 0.5185, 0.3818, 0.785, 0.5369, 0.191, 0.7632, 0.5157, 0.023, 0.3327, 0.4186, 0.3207, 0.2431, 0.4208, 0.3443, 0.0156, 0.5747, 0.6285, 0.5082, 0.5544, 0.5432, 0.1666, 0.8738, 0.9624, 0.9217, 0.3185, 0.6108, 0.2801, 0.1855, 0.8839, 0.0896, 0.6522, 0.1049, 0.1593, 0.5175, 0.3734, 0.4131, 0.7661, 0.363, 0.6529, 0.1663, 0.6123, 0.0361, 0.097, 0.6218, 0.0209, 0.6471, 0.425, 0.2079, 0.5918, 0.0464, 0.7324, 0.4296, 0.6776, 0.7662, 0.6921, 0.3624, 0.4485, 0.9305, 0.4486, 0.7223, 0.3964, 0.6752, 0.5971, 0.3684, 0.7866, 0.1321, 0.5667, 0.4936, 0.0043, 0.5686]])
print (np.array2string(model.predict([in0Loc58734,in0Con25122,in0ReL17203,in0Con87567,in0Zer1963,in0Con10767,in0Con28885],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub40612.png')

LLoc58734 = locally_connected2D_layer([[[[0.0416, 0.3521]]]], 1, 1,[[[0.2022, 0.9287, 0.4215], [0.5777, 0.2142, 0.1772]]],[[[0, 0, 0]]], 1, 1, Loc58734), 
LZer51603 = zero_padding2D_layer(Loc58734, 2, 0, 2, 0, Zer51603), 
LCon25122 = concatenate_layer([Zer51603,[[[[0.515], [0.5018], [0.0169]], [[0.5563], [0.8002], [0.0042]], [[0.0022], [0.2192], [0.5892]]]]], 3, Con25122), 
LReL17203 = relu_layer([[[[[0.5222]]]]], 6.830876603605193, 8.022245676724504, 8.968117709638642, ReL17203), 
LRes36533 = reshape_layer(ReL17203, [1, 1, 1], Res36533), 
LZer9706 = zero_padding2D_layer(Res36533, 2, 0, 2, 0, Zer9706), 
LCon87567 = concatenate_layer([Zer9706,[[[[0.3856, 0.8599, 0.6058], [0.8159, 0.0725, 0.5478], [0.998, 0.2219, 0.2945]], [[0.2933, 0.6871, 0.8985], [0.0779, 0.8841, 0.5003], [0.0514, 0.1442, 0.677]], [[0.6568, 0.9452, 0.1663], [0.0009, 0.665, 0.4404], [0.7371, 0.1285, 0.3367]]]]], 3, Con87567), 
LZer1963 = zero_padding2D_layer([[[[1.0764, 1.8867, 1.2326, 1.0571]]]], 1, 1, 1, 1, Zer1963), 
LAdd10100 = add_layer([Con87567,Zer1963], Add10100), 
LMax94256 = maximum_layer([Con25122,Add10100], Max94256), 
LCon10901 = conv2D_transpose_layer(Max94256, 2, 1,[[[[0.9139, 0.0116, 0.2612, 0.1171], [0.2638, 0.3913, 0.0318, 0.2917], [0.1848, 0.3837, 0.4735, 0.9203]]], [[[0.5988, 0.4638, 0.5954, 0.0157], [0.2968, 0.2981, 0.0511, 0.3561], [0.7697, 0.3411, 0.4978, 0.7641]]]],[0, 0, 0], 2, 5, false, Con10901), 
LRes30035 = reshape_layer(Con10901, [6, 45], Res30035), 
LFla30597 = flatten_layer(Res30035, Fla30597), 
LCon10767 = conv1D_layer([[[0.568], [0.0077]]], 2,[[[0.2325, 0.8135, 0.4448]], [[0.1929, 0.1616, 0.6295]]],[0, 0, 0], 1, true, 1, Con10767), 
LRes40323 = reshape_layer(Con10767, [2, 3, 1], Res40323), 
LGlo74431 = global_average_pooling2D_layer(Res40323, Glo74431), 
LCon28885 = concatenate_layer([Glo74431,[[0.4153, 0.5791, 0.0514, 0.8303, 0.1216, 0.6773, 0.864, 0.7475, 0.0169, 0.1556, 0.8395, 0.5548, 0.204, 0.8303, 0.9581, 0.3332, 0.6468, 0.6536, 0.2413, 0.4404, 0.1046, 0.2086, 0.7787, 0.9677, 0.6746, 0.649, 0.6777, 0.0246, 0.4462, 0.1727, 0.5953, 0.6486, 0.4641, 0.7257, 0.0988, 0.2591, 0.9276, 0.5267, 0.2183, 0.4867, 0.3115, 0.1759, 0.2064, 0.8909, 0.882, 0.5623, 0.698, 0.5573, 0.9065, 0.5235, 0.1773, 0.8076, 0.7039, 0.2255, 0.9013, 0.2954, 0.57, 0.5292, 0.2034, 0.5695, 0.5242, 0.1889, 0.4071, 0.7826, 0.773, 0.5888, 0.4153, 0.6007, 0.761, 0.8652, 0.4117, 0.5229, 0.69, 0.684, 0.0055, 0.7624, 0.4267, 0.6482, 0.5869, 0.5568, 0.7909, 0.2961, 0.618, 0.2803, 0.3183, 0.9145, 0.08, 0.0079, 0.7258, 0.9433, 0.3202, 0.2496, 0.4726, 0.5731, 0.0991, 0.4141, 0.0063, 0.2507, 0.7239, 0.1898, 0.5117, 0.1967, 0.7741, 0.4367, 0.2364, 0.714, 0.072, 0.3716, 0.761, 0.0196, 0.2353, 0.7988, 0.8987, 0.5664, 0.3565, 0.8899, 0.2663, 0.3396, 0.1005, 0.5477, 0.9479, 0.4102, 0.7849, 0.7035, 0.0904, 0.1057, 0.812, 0.9908, 0.7169, 0.5209, 0.1613, 0.1161, 0.5169, 0.7298, 0.5159, 0.9021, 0.8887, 0.9867, 0.9988, 0.4203, 0.0409, 0.4053, 0.4237, 0.8467, 0.5382, 0.0911, 0.4281, 0.6772, 0.2755, 0.4697, 0.8484, 0.7212, 0.4979, 0.6006, 0.222, 0.8543, 0.1526, 0.5949, 0.3571, 0.8578, 0.5506, 0.8668, 0.4979, 0.7954, 0.047, 0.8402, 0.7295, 0.2896, 0.2053, 0.9025, 0.9187, 0.743, 0.7032, 0.8553, 0.6659, 0.0246, 0.0566, 0.8437, 0.4555, 0.3882, 0.0926, 0.7654, 0.4354, 0.4259, 0.9852, 0.4557, 0.0309, 0.669, 0.5822, 0.5263, 0.9045, 0.0472, 0.7006, 0.5947, 0.6071, 0.7908, 0.0405, 0.7826, 0.6396, 0.5185, 0.3818, 0.785, 0.5369, 0.191, 0.7632, 0.5157, 0.023, 0.3327, 0.4186, 0.3207, 0.2431, 0.4208, 0.3443, 0.0156, 0.5747, 0.6285, 0.5082, 0.5544, 0.5432, 0.1666, 0.8738, 0.9624, 0.9217, 0.3185, 0.6108, 0.2801, 0.1855, 0.8839, 0.0896, 0.6522, 0.1049, 0.1593, 0.5175, 0.3734, 0.4131, 0.7661, 0.363, 0.6529, 0.1663, 0.6123, 0.0361, 0.097, 0.6218, 0.0209, 0.6471, 0.425, 0.2079, 0.5918, 0.0464, 0.7324, 0.4296, 0.6776, 0.7662, 0.6921, 0.3624, 0.4485, 0.9305, 0.4486, 0.7223, 0.3964, 0.6752, 0.5971, 0.3684, 0.7866, 0.1321, 0.5667, 0.4936, 0.0043, 0.5686]]], 1, Con28885), 
LSub40612 = subtract_layer(Fla30597,Con28885, Sub40612), 
exec_layers([LLoc58734,LZer51603,LCon25122,LReL17203,LRes36533,LZer9706,LCon87567,LZer1963,LAdd10100,LMax94256,LCon10901,LRes30035,LFla30597,LCon10767,LRes40323,LGlo74431,LCon28885,LSub40612],["Loc58734","Zer51603","Con25122","ReL17203","Res36533","Zer9706","Con87567","Zer1963","Add10100","Max94256","Con10901","Res30035","Fla30597","Con10767","Res40323","Glo74431","Con28885","Sub40612"],Sub40612,"Sub40612")

Actual (Unparsed): [[0.1557130, -0.0603581, 0.5335351, -0.0514000, -0.8303000, -0.1216000, -0.6773000, -0.8640000, -0.7475000, -0.0169000, -0.1556000, -0.8395000, -0.5548000, -0.2040000, -0.8303000, -0.8655512, 0.1481604, 0.2047300, -0.6536000, -0.2413000, -0.4404000, -0.1046000, -0.2086000, -0.7787000, -0.9677000, -0.6746000, -0.6490000, -0.6777000, -0.0246000, -0.4462000, -0.0686770, -0.1118205, 0.1104306, -0.4641000, -0.7257000, -0.0988000, -0.2591000, -0.9276000, -0.5267000, -0.2183000, -0.4867000, -0.3115000, -0.1759000, -0.2064000, -0.8909000, -0.1816632, -0.1876864, 0.3244781, -0.5573000, -0.9065000, -0.5235000, -0.1773000, -0.8076000, -0.7039000, -0.2255000, -0.9013000, -0.2954000, -0.5700000, -0.5292000, -0.2034000, -0.1393186, -0.0822039, 0.5440680, -0.4071000, -0.7826000, -0.7730000, -0.5888000, -0.4153000, -0.6007000, -0.7610000, -0.8652000, -0.4117000, -0.5229000, -0.6900000, -0.6840000, 0.5941153, -0.3486856, 0.2492071, -0.6482000, -0.5869000, -0.5568000, -0.7909000, -0.2961000, -0.6180000, -0.2803000, -0.3183000, -0.9145000, -0.0800000, -0.0079000, -0.7258000, -0.6552129, 0.0785105, 1.0151706, -0.4726000, -0.5731000, -0.0991000, -0.4141000, -0.0063000, -0.2507000, -0.7239000, -0.1898000, -0.5117000, -0.1967000, -0.7741000, -0.4367000, 1.5053649, 0.8603070, 3.3162685, -0.3716000, -0.7610000, -0.0196000, -0.2353000, -0.7988000, -0.8987000, -0.5664000, -0.3565000, -0.8899000, -0.2663000, -0.3396000, -0.1005000, -0.4301620, -0.7257207, 0.3008440, -0.7849000, -0.7035000, -0.0904000, -0.1057000, -0.8120000, -0.9908000, -0.7169000, -0.5209000, -0.1613000, -0.1161000, -0.5169000, -0.7298000, 0.0433383, -0.4596006, 0.2399269, -0.9867000, -0.9988000, -0.4203000, -0.0409000, -0.4053000, -0.4237000, -0.8467000, -0.5382000, -0.0911000, -0.4281000, -0.6772000, -0.2755000, 2.3707642, 0.7194763, 3.0211328, -0.4979000, -0.6006000, -0.2220000, -0.8543000, -0.1526000, -0.5949000, -0.3571000, -0.8578000, -0.5506000, -0.8668000, -0.4979000, -0.7954000, 0.0733249, -0.5764294, -0.1228890, -0.2896000, -0.2053000, -0.9025000, -0.9187000, -0.7430000, -0.7032000, -0.8553000, -0.6659000, -0.0246000, -0.0566000, -0.8437000, -0.4555000, -0.1142212, 0.2429729, 0.0872123, -0.4354000, -0.4259000, -0.9852000, -0.4557000, -0.0309000, -0.6690000, -0.5822000, -0.5263000, -0.9045000, -0.0472000, -0.7006000, -0.5947000, -0.3818207, -0.6408361, 0.6800230, -0.7826000, -0.6396000, -0.5185000, -0.3818000, -0.7850000, -0.5369000, -0.1910000, -0.7632000, -0.5157000, -0.0230000, -0.3327000, -0.4186000, -0.0160081, 0.2771612, 0.5042551, -0.3443000, -0.0156000, -0.5747000, -0.6285000, -0.5082000, -0.5544000, -0.5432000, -0.1666000, -0.8738000, -0.9624000, -0.9217000, -0.3185000, 0.2592068, 0.0232112, 0.6361249, -0.8839000, -0.0896000, -0.6522000, -0.1049000, -0.1593000, -0.5175000, -0.3734000, -0.4131000, -0.7661000, -0.3630000, -0.6529000, -0.1663000, -0.2090273, 0.1549762, 0.5708536, -0.6218000, -0.0209000, -0.6471000, -0.4250000, -0.2079000, -0.5918000, -0.0464000, -0.7324000, -0.4296000, -0.6776000, -0.7662000, -0.6921000, 0.1920640, 0.0504781, -0.0018625, -0.4486000, -0.7223000, -0.3964000, -0.6752000, -0.5971000, -0.3684000, -0.7866000, -0.1321000, -0.5667000, -0.4936000, -0.0043000, -0.5686000]]

Expected (Unparsed): [[0.15571295999999998,-0.06035804,0.5335351099999999,-0.0514,-0.8303,-0.1216,-0.6773,-0.864,-0.7475,-0.0169,-0.1556,-0.8395,-0.5548,-0.204,-0.8303,-0.86555118,0.14816042999999995,0.2047299199999999,-0.6536,-0.2413,-0.4404,-0.1046,-0.2086,-0.7787,-0.9677,-0.6746,-0.649,-0.6777,-0.0246,-0.4462,-0.06867697,-0.11182053000000008,0.11043060000000005,-0.4641,-0.7257,-0.0988,-0.2591,-0.9276,-0.5267,-0.2183,-0.4867,-0.3115,-0.1759,-0.2064,-0.8909,-0.1816631999999999,-0.18768637,0.3244781600000002,-0.5573,-0.9065,-0.5235,-0.1773,-0.8076,-0.7039,-0.2255,-0.9013,-0.2954,-0.57,-0.5292,-0.2034,-0.13931862000000006,-0.08220388000000001,0.54406797,-0.4071,-0.7826,-0.773,-0.5888,-0.4153,-0.6007,-0.761,-0.8652,-0.4117,-0.5229,-0.69,-0.684,0.59411531,-0.34868566,0.24920706999999992,-0.6482,-0.5869,-0.5568,-0.7909,-0.2961,-0.618,-0.2803,-0.3183,-0.9145,-0.08,-0.0079,-0.7258,-0.6552128500000001,0.07851051999999997,1.01517061,-0.4726,-0.5731,-0.0991,-0.4141,-0.0063,-0.2507,-0.7239,-0.1898,-0.5117,-0.1967,-0.7741,-0.4367,1.5053649,0.8603069400000001,3.3162684099999997,-0.3716,-0.761,-0.0196,-0.2353,-0.7988,-0.8987,-0.5664,-0.3565,-0.8899,-0.2663,-0.3396,-0.1005,-0.43016202,-0.72572072,0.3008439800000001,-0.7849,-0.7035,-0.0904,-0.1057,-0.812,-0.9908,-0.7169,-0.5209,-0.1613,-0.1161,-0.5169,-0.7298,0.04333832999999998,-0.45960061,0.23992685999999996,-0.9867,-0.9988,-0.4203,-0.0409,-0.4053,-0.4237,-0.8467,-0.5382,-0.0911,-0.4281,-0.6772,-0.2755,2.37076416,0.71947629,3.02113274,-0.4979,-0.6006,-0.222,-0.8543,-0.1526,-0.5949,-0.3571,-0.8578,-0.5506,-0.8668,-0.4979,-0.7954,0.0733249,-0.5764293399999999,-0.12288900000000003,-0.2896,-0.2053,-0.9025,-0.9187,-0.743,-0.7032,-0.8553,-0.6659,-0.0246,-0.0566,-0.8437,-0.4555,-0.11422114999999994,0.24297290999999993,0.08721224999999999,-0.4354,-0.4259,-0.9852,-0.4557,-0.0309,-0.669,-0.5822,-0.5263,-0.9045,-0.0472,-0.7006,-0.5947,-0.38182072,-0.6408361499999999,0.68002295,-0.7826,-0.6396,-0.5185,-0.3818,-0.785,-0.5369,-0.191,-0.7632,-0.5157,-0.023,-0.3327,-0.4186,-0.016008105308999987,0.27716120422199997,0.5042550587119998,-0.3443,-0.0156,-0.5747,-0.6285,-0.5082,-0.5544,-0.5432,-0.1666,-0.8738,-0.9624,-0.9217,-0.3185,0.2592068300000001,0.023211230000000027,0.63612487,-0.8839,-0.0896,-0.6522,-0.1049,-0.1593,-0.5175,-0.3734,-0.4131,-0.7661,-0.363,-0.6529,-0.1663,-0.20902729999999992,0.15497623000000002,0.57085363,-0.6218,-0.0209,-0.6471,-0.425,-0.2079,-0.5918,-0.0464,-0.7324,-0.4296,-0.6776,-0.7662,-0.6921,0.19206395037199991,0.050478063992,-0.001862554607000022,-0.4486,-0.7223,-0.3964,-0.6752,-0.5971,-0.3684,-0.7866,-0.1321,-0.5667,-0.4936,-0.0043,-0.5686]]

Actual:   [[0.1558, -0.0603, 0.5336, -0.0514, -0.8303, -0.1216, -0.6773, -0.864, -0.7475, -0.0169, -0.1556, -0.8395, -0.5548, -0.204, -0.8303, -0.8655, 0.1482, 0.2048, -0.6536, -0.2413, -0.4404, -0.1046, -0.2086, -0.7787, -0.9677, -0.6746, -0.649, -0.6777, -0.0246, -0.4462, -0.0686, -0.1118, 0.1105, -0.4641, -0.7257, -0.0988, -0.2591, -0.9276, -0.5267, -0.2183, -0.4867, -0.3115, -0.1759, -0.2064, -0.8909, -0.1816, -0.1876, 0.3245, -0.5573, -0.9065, -0.5235, -0.1773, -0.8076, -0.7039, -0.2255, -0.9013, -0.2954, -0.57, -0.5292, -0.2034, -0.1393, -0.0822, 0.5441, -0.4071, -0.7826, -0.773, -0.5888, -0.4153, -0.6007, -0.761, -0.8652, -0.4117, -0.5229, -0.69, -0.684, 0.5942, -0.3486, 0.2493, -0.6482, -0.5869, -0.5568, -0.7909, -0.2961, -0.618, -0.2803, -0.3183, -0.9145, -0.08, -0.0079, -0.7258, -0.6552, 0.0786, 1.0152, -0.4726, -0.5731, -0.0991, -0.4141, -0.0063, -0.2507, -0.7239, -0.1898, -0.5117, -0.1967, -0.7741, -0.4367, 1.5054, 0.8604, 3.3163, -0.3716, -0.761, -0.0196, -0.2353, -0.7988, -0.8987, -0.5664, -0.3565, -0.8899, -0.2663, -0.3396, -0.1005, -0.4301, -0.7257, 0.3009, -0.7849, -0.7035, -0.0904, -0.1057, -0.812, -0.9908, -0.7169, -0.5209, -0.1613, -0.1161, -0.5169, -0.7298, 0.0434, -0.4596, 0.24, -0.9867, -0.9988, -0.4203, -0.0409, -0.4053, -0.4237, -0.8467, -0.5382, -0.0911, -0.4281, -0.6772, -0.2755, 2.3708, 0.7195, 3.0212, -0.4979, -0.6006, -0.222, -0.8543, -0.1526, -0.5949, -0.3571, -0.8578, -0.5506, -0.8668, -0.4979, -0.7954, 0.0734, -0.5764, -0.1228, -0.2896, -0.2053, -0.9025, -0.9187, -0.743, -0.7032, -0.8553, -0.6659, -0.0246, -0.0566, -0.8437, -0.4555, -0.1142, 0.243, 0.0873, -0.4354, -0.4259, -0.9852, -0.4557, -0.0309, -0.669, -0.5822, -0.5263, -0.9045, -0.0472, -0.7006, -0.5947, -0.3818, -0.6408, 0.6801, -0.7826, -0.6396, -0.5185, -0.3818, -0.785, -0.5369, -0.191, -0.7632, -0.5157, -0.023, -0.3327, -0.4186, -0.016, 0.2772, 0.5043, -0.3443, -0.0156, -0.5747, -0.6285, -0.5082, -0.5544, -0.5432, -0.1666, -0.8738, -0.9624, -0.9217, -0.3185, 0.2593, 0.0233, 0.6362, -0.8839, -0.0896, -0.6522, -0.1049, -0.1593, -0.5175, -0.3734, -0.4131, -0.7661, -0.363, -0.6529, -0.1663, -0.209, 0.155, 0.5709, -0.6218, -0.0209, -0.6471, -0.425, -0.2079, -0.5918, -0.0464, -0.7324, -0.4296, -0.6776, -0.7662, -0.6921, 0.1921, 0.0505, -0.0018, -0.4486, -0.7223, -0.3964, -0.6752, -0.5971, -0.3684, -0.7866, -0.1321, -0.5667, -0.4936, -0.0043, -0.5686]]

Expected: [[0.1558, -0.0603, 0.5336, -0.0514, -0.8303, -0.1216, -0.6773, -0.864, -0.7475, -0.0169, -0.1556, -0.8395, -0.5548, -0.204, -0.8303, -0.8655, 0.1482, 0.2048, -0.6536, -0.2413, -0.4404, -0.1046, -0.2086, -0.7787, -0.9677, -0.6746, -0.649, -0.6777, -0.0246, -0.4462, -0.0686, -0.1118, 0.1105, -0.4641, -0.7257, -0.0988, -0.2591, -0.9276, -0.5267, -0.2183, -0.4867, -0.3115, -0.1759, -0.2064, -0.8909, -0.1816, -0.1876, 0.3245, -0.5573, -0.9065, -0.5235, -0.1773, -0.8076, -0.7039, -0.2255, -0.9013, -0.2954, -0.57, -0.5292, -0.2034, -0.1393, -0.0822, 0.5441, -0.4071, -0.7826, -0.773, -0.5888, -0.4153, -0.6007, -0.761, -0.8652, -0.4117, -0.5229, -0.69, -0.684, 0.5942, -0.3486, 0.2493, -0.6482, -0.5869, -0.5568, -0.7909, -0.2961, -0.618, -0.2803, -0.3183, -0.9145, -0.08, -0.0079, -0.7258, -0.6552, 0.0786, 1.0152, -0.4726, -0.5731, -0.0991, -0.4141, -0.0063, -0.2507, -0.7239, -0.1898, -0.5117, -0.1967, -0.7741, -0.4367, 1.5054, 0.8604, 3.3163, -0.3716, -0.761, -0.0196, -0.2353, -0.7988, -0.8987, -0.5664, -0.3565, -0.8899, -0.2663, -0.3396, -0.1005, -0.4301, -0.7257, 0.3009, -0.7849, -0.7035, -0.0904, -0.1057, -0.812, -0.9908, -0.7169, -0.5209, -0.1613, -0.1161, -0.5169, -0.7298, 0.0434, -0.4596, 0.24, -0.9867, -0.9988, -0.4203, -0.0409, -0.4053, -0.4237, -0.8467, -0.5382, -0.0911, -0.4281, -0.6772, -0.2755, 2.3708, 0.7195, 3.0212, -0.4979, -0.6006, -0.222, -0.8543, -0.1526, -0.5949, -0.3571, -0.8578, -0.5506, -0.8668, -0.4979, -0.7954, 0.0734, -0.5764, -0.1228, -0.2896, -0.2053, -0.9025, -0.9187, -0.743, -0.7032, -0.8553, -0.6659, -0.0246, -0.0566, -0.8437, -0.4555, -0.1142, 0.243, 0.0873, -0.4354, -0.4259, -0.9852, -0.4557, -0.0309, -0.669, -0.5822, -0.5263, -0.9045, -0.0472, -0.7006, -0.5947, -0.3818, -0.6408, 0.6801, -0.7826, -0.6396, -0.5185, -0.3818, -0.785, -0.5369, -0.191, -0.7632, -0.5157, -0.023, -0.3327, -0.4186, -0.016, 0.2772, 0.5043, -0.3443, -0.0156, -0.5747, -0.6285, -0.5082, -0.5544, -0.5432, -0.1666, -0.8738, -0.9624, -0.9217, -0.3185, 0.2593, 0.0233, 0.6362, -0.8839, -0.0896, -0.6522, -0.1049, -0.1593, -0.5175, -0.3734, -0.4131, -0.7661, -0.363, -0.6529, -0.1663, -0.209, 0.155, 0.5709, -0.6218, -0.0209, -0.6471, -0.425, -0.2079, -0.5918, -0.0464, -0.7324, -0.4296, -0.6776, -0.7662, -0.6921, 0.1921, 0.0505, -0.0018, -0.4486, -0.7223, -0.3964, -0.6752, -0.5971, -0.3684, -0.7866, -0.1321, -0.5667, -0.4936, -0.0043, -0.5686]]