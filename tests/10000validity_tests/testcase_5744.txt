import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot65178 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot65178 = tf.keras.layers.Input(shape=([3, 3]))
in0Con15665 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0Con7527 = tf.keras.layers.Input(shape=([8]))

Dot65178 = keras.layers.Dot(axes=(1, 1), name = 'Dot65178', )([in0Dot65178,in1Dot65178])
PRe10799 = keras.layers.PReLU(name = 'PRe10799', )(Dot65178)
Fla9172 = keras.layers.Flatten(name = 'Fla9172', )(PRe10799)
Con15665 = keras.layers.Conv3DTranspose(2, (1, 1, 1),strides=(1, 1, 1), padding='same', name = 'Con15665', )(in0Con15665)
Res4895 = keras.layers.Reshape((1, 2, 2), name = 'Res4895', )(Con15665)
Glo13665 = keras.layers.GlobalAveragePooling2D(name = 'Glo13665', )(Res4895)
Res68403 = keras.layers.Reshape((2, 1), name = 'Res68403', )(Glo13665)
Glo44664 = keras.layers.GlobalMaxPool1D(name = 'Glo44664', )(Res68403)
Con7527 = keras.layers.Concatenate(axis=1, name = 'Con7527', )([Glo44664,in0Con7527])
Max91699 = keras.layers.Maximum(name = 'Max91699', )([Fla9172,Con7527])
model = tf.keras.models.Model(inputs=[in0Dot65178,in1Dot65178,in0Con15665,in0Con7527], outputs=Max91699)
w = model.get_layer('PRe10799').get_weights() 
w[0] = np.array([[0.9015, 0.2849, 0.168], [0.9469, 0.372, 0.2061], [0.4904, 0.7962, 0.1598]])
model.get_layer('PRe10799').set_weights(w) 
w = model.get_layer('Con15665').get_weights() 
w[0] = np.array([[[[[0.5936], [0.549]]]]])
w[1] = np.array([0, 0])
model.get_layer('Con15665').set_weights(w) 
in0Dot65178 = tf.constant([[[0.8451, 0.7269, 0.9948], [0.2156, 0.5007, 0.8857], [0.8812, 0.8051, 0.403]]])
in1Dot65178 = tf.constant([[[0.4843, 0.345, 0.064], [0.2137, 0.2609, 0.1765], [0.1843, 0.7061, 0.1814]]])
in0Con15665 = tf.constant([[[[[0.3488]], [[0.0271]]]]])
in0Con7527 = tf.constant([[0.8404, 0.0787, 0.5663, 0.9303, 0.9991, 0.7107, 0.012, 0.6443]])
print (np.array2string(model.predict([in0Dot65178,in1Dot65178,in0Con15665,in0Con7527],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max91699.png')

LDot65178 = dot_layer([[[0.8451, 0.7269, 0.9948], [0.2156, 0.5007, 0.8857], [0.8812, 0.8051, 0.403]]], [[[0.4843, 0.345, 0.064], [0.2137, 0.2609, 0.1765], [0.1843, 0.7061, 0.1814]]], 1, 1, Dot65178), 
LPRe10799 = prelu_layer(Dot65178, [[0.9015, 0.2849, 0.168], [0.9469, 0.372, 0.2061], [0.4904, 0.7962, 0.1598]], PRe10799), 
LFla9172 = flatten_layer(PRe10799, Fla9172), 
LCon15665 = conv3D_transpose_layer([[[[[0.3488]], [[0.0271]]]]], 1, 1, 1,[[[[[0.5936], [0.549]]]]],[0, 0], 1, 1, 1, true, Con15665), 
LRes4895 = reshape_layer(Con15665, [1, 2, 2], Res4895), 
LGlo13665 = global_average_pooling2D_layer(Res4895, Glo13665), 
LRes68403 = reshape_layer(Glo13665, [2, 1], Res68403), 
LGlo44664 = global_max_pool1D_layer(Res68403, Glo44664), 
LCon7527 = concatenate_layer([Glo44664,[[0.8404, 0.0787, 0.5663, 0.9303, 0.9991, 0.7107, 0.012, 0.6443]]], 1, Con7527), 
LMax91699 = maximum_layer([Fla9172,Con7527], Max91699), 
exec_layers([LDot65178,LPRe10799,LFla9172,LCon15665,LRes4895,LGlo13665,LRes68403,LGlo44664,LCon7527,LMax91699],["Dot65178","PRe10799","Fla9172","Con15665","Res4895","Glo13665","Res68403","Glo44664","Con7527","Max91699"],Max91699,"Max91699")

Actual (Unparsed): [[0.6177608, 0.9700249, 0.2519895, 0.6074172, 0.9498942, 0.9991000, 0.7453286, 0.8588434, 0.6443000]]

Expected (Unparsed): [[0.61776081,0.9700248599999999,0.25198948,0.60741719,0.94989424,0.9991,0.7453286299999999,0.8588434300000001,0.6443]]

Actual:   [[0.6178, 0.9701, 0.252, 0.6075, 0.9499, 0.9991, 0.7454, 0.8589, 0.6443]]

Expected: [[0.6178, 0.9701, 0.252, 0.6075, 0.9499, 0.9991, 0.7454, 0.8589, 0.6443]]