import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot4665 = tf.keras.layers.Input(shape=([3]))
in1Dot4665 = tf.keras.layers.Input(shape=([3]))
in0Con3722 = tf.keras.layers.Input(shape=([4, 3]))
in0Glo9592 = tf.keras.layers.Input(shape=([1, 2]))
in0Con89710 = tf.keras.layers.Input(shape=([3, 3]))
in0Den59957 = tf.keras.layers.Input(shape=([3, 5]))

Dot4665 = keras.layers.Dot(axes=(1, 1), name = 'Dot4665', )([in0Dot4665,in1Dot4665])
Fla84240 = keras.layers.Flatten(name = 'Fla84240', )(Dot4665)
Res14496 = keras.layers.Reshape((1, 1), name = 'Res14496', )(Fla84240)
Ave44014 = keras.layers.AveragePooling1D(pool_size=(1), strides=(1), padding='valid', name = 'Ave44014', )(Res14496)
Zer62470 = keras.layers.ZeroPadding1D(padding=((3, 0)), name = 'Zer62470', )(Ave44014)
Con3722 = keras.layers.Concatenate(axis=2, name = 'Con3722', )([Zer62470,in0Con3722])
Glo9592 = keras.layers.GlobalAveragePooling1D(name = 'Glo9592', )(in0Glo9592)
Res7218 = keras.layers.Reshape((2, 1), name = 'Res7218', )(Glo9592)
Zer68573 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer68573', )(Res7218)
Con89710 = keras.layers.Concatenate(axis=2, name = 'Con89710', )([Zer68573,in0Con89710])
Den59957 = keras.layers.Dense(4,name = 'Den59957', )(in0Den59957)
Min28050 = keras.layers.Minimum(name = 'Min28050', )([Con89710,Den59957])
Dot87895 = keras.layers.Dot(axes=(2, 2), name = 'Dot87895', )([Con3722,Min28050])
model = tf.keras.models.Model(inputs=[in0Dot4665,in1Dot4665,in0Con3722,in0Glo9592,in0Con89710,in0Den59957], outputs=Dot87895)
w = model.get_layer('Den59957').get_weights() 
w[0] = np.array([[0.7995, 0.8924, 0.7403, 0.6877], [0.733, 0.812, 0.227, 0.1443], [0.2494, 0.6212, 0.2687, 0.9557], [0.1255, 0.2988, 0.1473, 0.94], [0.7616, 0.2137, 0.6053, 0.0228]])
w[1] = np.array([0.0523, 0.378, 0.9685, 0.7521])
model.get_layer('Den59957').set_weights(w) 
in0Dot4665 = tf.constant([[0.8506, 0.8854, 0.1626]])
in1Dot4665 = tf.constant([[0.0408, 0.792, 0.5425]])
in0Con3722 = tf.constant([[[0.6924, 0.0916, 0.6445], [0.6196, 0.1567, 0.9351], [0.2245, 0.4843, 0.8473], [0.1703, 0.4267, 0.0216]]])
in0Glo9592 = tf.constant([[[1.028, 1.9505]]])
in0Con89710 = tf.constant([[[0.4713, 0.022, 0.1177], [0.4103, 0.4954, 0.9762], [0.413, 0.5807, 0.1283]]])
in0Den59957 = tf.constant([[[0.7238, 0.1482, 0.1707, 0.0076, 0.0031], [0.0688, 0.0318, 0.9182, 0.3857, 0.249], [0.1494, 0.1301, 0.8263, 0.4498, 0.5405]]])
print (np.array2string(model.predict([in0Dot4665,in1Dot4665,in0Con3722,in0Glo9592,in0Con89710,in0Den59957],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot87895.png')

LDot4665 = dot_layer([[0.8506, 0.8854, 0.1626]], [[0.0408, 0.792, 0.5425]], 1, 1, Dot4665), 
LFla84240 = flatten_layer(Dot4665, Fla84240), 
LRes14496 = reshape_layer(Fla84240, [1, 1], Res14496), 
LAve44014 = average_pooling1D_layer(Res14496, 1, 1, false, Ave44014), 
LZer62470 = zero_padding1D_layer(Ave44014, 3, 0, Zer62470), 
LCon3722 = concatenate_layer([Zer62470,[[[0.6924, 0.0916, 0.6445], [0.6196, 0.1567, 0.9351], [0.2245, 0.4843, 0.8473], [0.1703, 0.4267, 0.0216]]]], 2, Con3722), 
LGlo9592 = global_average_pooling1D_layer([[[1.028, 1.9505]]], Glo9592), 
LRes7218 = reshape_layer(Glo9592, [2, 1], Res7218), 
LZer68573 = zero_padding1D_layer(Res7218, 1, 0, Zer68573), 
LCon89710 = concatenate_layer([Zer68573,[[[0.4713, 0.022, 0.1177], [0.4103, 0.4954, 0.9762], [0.413, 0.5807, 0.1283]]]], 2, Con89710), 
LDen59957 = dense_layer([[[0.7238, 0.1482, 0.1707, 0.0076, 0.0031], [0.0688, 0.0318, 0.9182, 0.3857, 0.249], [0.1494, 0.1301, 0.8263, 0.4498, 0.5405]]], [[0.7995, 0.8924, 0.7403, 0.6877], [0.733, 0.812, 0.227, 0.1443], [0.2494, 0.6212, 0.2687, 0.9557], [0.1255, 0.2988, 0.1473, 0.94], [0.7616, 0.2137, 0.6053, 0.0228]],[0.0523, 0.378, 0.9685, 0.7521], Den59957), 
LMin28050 = minimum_layer([Con89710,Den59957], Min28050), 
LDot87895 = dot_layer(Con3722,Min28050, 2, 2, Dot87895), 
exec_layers([LDot4665,LFla84240,LRes14496,LAve44014,LZer62470,LCon3722,LGlo9592,LRes7218,LZer68573,LCon89710,LDen59957,LMin28050,LDot87895],["Dot4665","Fla84240","Res14496","Ave44014","Zer62470","Con3722","Glo9592","Res7218","Zer68573","Con89710","Den59957","Min28050","Dot87895"],Dot87895,"Dot87895")

Actual (Unparsed): [[[0.4042010, 0.9586313, 0.4218427], [0.4055262, 1.2446957, 0.4668638], [0.2161887, 1.1591688, 0.4826601], [0.0921921, 0.7949080, 1.0966495]]]

Expected (Unparsed): [[[0.40420097,0.9586312599999999,0.42184267],[0.40552615,1.24469568,0.46686382],[0.21618866000000003,1.15916883,0.4826601],[0.09219211000000001,0.7949079544254374,1.0966495343408855]]]

Actual:   [[[0.4043, 0.9587, 0.4219], [0.4056, 1.2447, 0.4669], [0.2162, 1.1592, 0.4827], [0.0922, 0.795, 1.0967]]]

Expected: [[[0.4043, 0.9587, 0.4219], [0.4056, 1.2447, 0.4669], [0.2162, 1.1592, 0.4827], [0.0922, 0.795, 1.0967]]]