import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min16069 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in1Min16069 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0Mul50668 = tf.keras.layers.Input(shape=([1, 2]))
in1Mul50668 = tf.keras.layers.Input(shape=([1, 2]))
in0Up_4590 = tf.keras.layers.Input(shape=([3, 2]))
in0Con21662 = tf.keras.layers.Input(shape=([6, 2]))

Min16069 = keras.layers.Minimum(name = 'Min16069', )([in0Min16069,in1Min16069])
Lay56533 = keras.layers.LayerNormalization(axis=1, epsilon=2.072761634285862, name = 'Lay56533', )(Min16069)
ELU82003 = keras.layers.ELU(alpha=6.3428732695404335, name = 'ELU82003', )(Lay56533)
Res27610 = keras.layers.Reshape((2, 2, 2), name = 'Res27610', )(ELU82003)
Res21000 = keras.layers.Reshape((2, 4), name = 'Res21000', )(Res27610)
Zer31633 = keras.layers.ZeroPadding1D(padding=((4, 0)), name = 'Zer31633', )(Res21000)
Mul50668 = keras.layers.Multiply(name = 'Mul50668', )([in0Mul50668,in1Mul50668])
Zer56011 = keras.layers.ZeroPadding1D(padding=((5, 0)), name = 'Zer56011', )(Mul50668)
Up_4590 = keras.layers.UpSampling1D(size=(2), name = 'Up_4590', )(in0Up_4590)
Sub79149 = keras.layers.Subtract(name = 'Sub79149', )([Zer56011,Up_4590])
Con21662 = keras.layers.Concatenate(axis=2, name = 'Con21662', )([Sub79149,in0Con21662])
Add91426 = keras.layers.Add(name = 'Add91426', )([Zer31633,Con21662])
model = tf.keras.models.Model(inputs=[in0Min16069,in1Min16069,in0Mul50668,in1Mul50668,in0Up_4590,in0Con21662], outputs=Add91426)
in0Min16069 = tf.constant([[[[[0.6409, 0.7932]], [[0.119, 0.3089]]], [[[0.238, 0.6842]], [[0.4695, 0.2474]]]]])
in1Min16069 = tf.constant([[[[[0.4679, 0.4373]], [[0.7225, 0.4805]]], [[[0.9182, 0.3645]], [[0.5337, 0.6124]]]]])
in0Mul50668 = tf.constant([[[0.703, 0.0438]]])
in1Mul50668 = tf.constant([[[0.2166, 0.9747]]])
in0Up_4590 = tf.constant([[[1.103, 1.6933], [1.2507, 1.0765], [1.3881, 1.6813]]])
in0Con21662 = tf.constant([[[0.034, 0.5685], [0.0628, 0.6426], [0.3291, 0.6704], [0.7593, 0.1633], [0.8785, 0.7431], [0.5893, 0.6717]]])
print (np.array2string(model.predict([in0Min16069,in1Min16069,in0Mul50668,in1Mul50668,in0Up_4590,in0Con21662],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add91426.png')

LMin16069 = minimum_layer([[[[[[0.6409, 0.7932]], [[0.119, 0.3089]]], [[[0.238, 0.6842]], [[0.4695, 0.2474]]]]], [[[[[0.4679, 0.4373]], [[0.7225, 0.4805]]], [[[0.9182, 0.3645]], [[0.5337, 0.6124]]]]]], Min16069), 
LLay56533 = layer_normalization_layer(Min16069, 1, 2.072761634285862, Lay56533), 
LELU82003 = elu_layer(Lay56533, 6.3428732695404335, ELU82003), 
LRes27610 = reshape_layer(ELU82003, [2, 2, 2], Res27610), 
LRes21000 = reshape_layer(Res27610, [2, 4], Res21000), 
LZer31633 = zero_padding1D_layer(Res21000, 4, 0, Zer31633), 
LMul50668 = multiply_layer([[[[0.703, 0.0438]]], [[[0.2166, 0.9747]]]], Mul50668), 
LZer56011 = zero_padding1D_layer(Mul50668, 5, 0, Zer56011), 
LUp_4590 = up_sampling1D_layer([[[1.103, 1.6933], [1.2507, 1.0765], [1.3881, 1.6813]]], 2, Up_4590), 
LSub79149 = subtract_layer(Zer56011,Up_4590, Sub79149), 
LCon21662 = concatenate_layer([Sub79149,[[[0.034, 0.5685], [0.0628, 0.6426], [0.3291, 0.6704], [0.7593, 0.1633], [0.8785, 0.7431], [0.5893, 0.6717]]]], 2, Con21662), 
LAdd91426 = add_layer([Zer31633,Con21662], Add91426), 
exec_layers([LMin16069,LLay56533,LELU82003,LRes27610,LRes21000,LZer31633,LMul50668,LZer56011,LUp_4590,LSub79149,LCon21662,LAdd91426],["Min16069","Lay56533","ELU82003","Res27610","Res21000","Zer31633","Mul50668","Zer56011","Up_4590","Sub79149","Con21662","Add91426"],Add91426,"Add91426")

Actual (Unparsed): [[[-1.1030000, -1.6933000, 0.0340000, 0.5685000], [-1.1030000, -1.6933000, 0.0628000, 0.6426000], [-1.2507000, -1.0765001, 0.3291000, 0.6704000], [-1.2507000, -1.0765001, 0.7593000, 0.1633000], [-1.3085108, -1.6560252, 0.1565604, 0.7644536], [-1.7210880, -1.7969141, 0.7101341, 0.5376926]]]

Expected (Unparsed): [[[-1.103,-1.6933,0.034,0.5685],[-1.103,-1.6933,0.0628,0.6426],[-1.2507,-1.0765,0.3291,0.6704],[-1.2507,-1.0765,0.7593,0.1633],[-1.3085107500780275,-1.6560251875621848,0.15656040856078213,0.764453614725771],[-1.7210879494048492,-1.7969140686023453,0.7101340778745656,0.5376925912210206]]]

Actual:   [[[-1.103, -1.6933, 0.034, 0.5685], [-1.103, -1.6933, 0.0628, 0.6426], [-1.2507, -1.0765, 0.3291, 0.6704], [-1.2507, -1.0765, 0.7593, 0.1633], [-1.3085, -1.656, 0.1566, 0.7645], [-1.721, -1.7969, 0.7102, 0.5377]]]

Expected: [[[-1.103, -1.6933, 0.034, 0.5685], [-1.103, -1.6933, 0.0628, 0.6426], [-1.2507, -1.0765, 0.3291, 0.6704], [-1.2507, -1.0765, 0.7593, 0.1633], [-1.3085, -1.656, 0.1566, 0.7645], [-1.721, -1.7969, 0.7102, 0.5377]]]