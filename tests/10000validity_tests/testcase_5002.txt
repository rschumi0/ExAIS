import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot39621 = tf.keras.layers.Input(shape=([3]))
in1Dot39621 = tf.keras.layers.Input(shape=([3]))
in0Con10353 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Add27993 = tf.keras.layers.Input(shape=([2, 2]))
in1Add27993 = tf.keras.layers.Input(shape=([2, 2]))
in0Con26219 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Dep62002 = tf.keras.layers.Input(shape=([2, 2, 2]))

Dot39621 = keras.layers.Dot(axes=(1, 1), name = 'Dot39621', )([in0Dot39621,in1Dot39621])
Res1180 = keras.layers.Reshape((1, 1), name = 'Res1180', )(Dot39621)
Up_55630 = keras.layers.UpSampling1D(size=(2), name = 'Up_55630', )(Res1180)
Res35392 = keras.layers.Reshape((2, 1, 1), name = 'Res35392', )(Up_55630)
Zer30370 = keras.layers.ZeroPadding2D(padding=((0, 0), (1, 0)), name = 'Zer30370', )(Res35392)
Con10353 = keras.layers.Concatenate(axis=3, name = 'Con10353', )([Zer30370,in0Con10353])
Add27993 = keras.layers.Add(name = 'Add27993', )([in0Add27993,in1Add27993])
Res13426 = keras.layers.Reshape((2, 2, 1), name = 'Res13426', )(Add27993)
Con26219 = keras.layers.Concatenate(axis=3, name = 'Con26219', )([Res13426,in0Con26219])
Dep62002 = keras.layers.DepthwiseConv2D((1, 1),strides=(2, 2), padding='valid', name = 'Dep62002', )(in0Dep62002)
Zer52884 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer52884', )(Dep62002)
Max39196 = keras.layers.Maximum(name = 'Max39196', )([Con26219,Zer52884])
Add33646 = keras.layers.Add(name = 'Add33646', )([Con10353,Max39196])
model = tf.keras.models.Model(inputs=[in0Dot39621,in1Dot39621,in0Con10353,in0Add27993,in1Add27993,in0Con26219,in0Dep62002], outputs=Add33646)
w = model.get_layer('Dep62002').get_weights() 
w[0] = np.array([[[[0.4715], [0.2288]]]])
w[1] = np.array([0, 0])
model.get_layer('Dep62002').set_weights(w) 
in0Dot39621 = tf.constant([[0.0598, 0.631, 0.6018]])
in1Dot39621 = tf.constant([[0.2246, 0.6752, 0.734]])
in0Con10353 = tf.constant([[[[0.6606], [0.7256]], [[0.99], [0.1717]]]])
in0Add27993 = tf.constant([[[0.8185, 0.2946], [0.8983, 0.6073]]])
in1Add27993 = tf.constant([[[0.1502, 0.0426], [0.7756, 0.0929]]])
in0Con26219 = tf.constant([[[[0.8387], [0.4579]], [[0.9866], [0.3429]]]])
in0Dep62002 = tf.constant([[[[0.1481, 0.1319], [0.3937, 0.3378]], [[0.7143, 0.1608], [0.8747, 0.1251]]]])
print (np.array2string(model.predict([in0Dot39621,in1Dot39621,in0Con10353,in0Add27993,in1Add27993,in0Con26219,in0Dep62002],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add33646.png')

LDot39621 = dot_layer([[0.0598, 0.631, 0.6018]], [[0.2246, 0.6752, 0.734]], 1, 1, Dot39621), 
LRes1180 = reshape_layer(Dot39621, [1, 1], Res1180), 
LUp_55630 = up_sampling1D_layer(Res1180, 2, Up_55630), 
LRes35392 = reshape_layer(Up_55630, [2, 1, 1], Res35392), 
LZer30370 = zero_padding2D_layer(Res35392, 0, 0, 1, 0, Zer30370), 
LCon10353 = concatenate_layer([Zer30370,[[[[0.6606], [0.7256]], [[0.99], [0.1717]]]]], 3, Con10353), 
LAdd27993 = add_layer([[[[0.8185, 0.2946], [0.8983, 0.6073]]], [[[0.1502, 0.0426], [0.7756, 0.0929]]]], Add27993), 
LRes13426 = reshape_layer(Add27993, [2, 2, 1], Res13426), 
LCon26219 = concatenate_layer([Res13426,[[[[0.8387], [0.4579]], [[0.9866], [0.3429]]]]], 3, Con26219), 
LDep62002 = depthwise_conv2D_layer([[[[0.1481, 0.1319], [0.3937, 0.3378]], [[0.7143, 0.1608], [0.8747, 0.1251]]]], 1, 1,[[[[0.4715], [0.2288]]]],[0, 0], 2, 2, false, Dep62002), 
LZer52884 = zero_padding2D_layer(Dep62002, 1, 0, 1, 0, Zer52884), 
LMax39196 = maximum_layer([Con26219,Zer52884], Max39196), 
LAdd33646 = add_layer([Con10353,Max39196], Add33646), 
exec_layers([LDot39621,LRes1180,LUp_55630,LRes35392,LZer30370,LCon10353,LAdd27993,LRes13426,LCon26219,LDep62002,LZer52884,LMax39196,LAdd33646],["Dot39621","Res1180","Up_55630","Res35392","Zer30370","Con10353","Add27993","Res13426","Con26219","Dep62002","Zer52884","Max39196","Add33646"],Add33646,"Add33646")

Actual (Unparsed): [[[[0.9687000, 1.4993000], [1.2184035, 1.1835000]], [[1.6739000, 1.9766000], [1.5814035, 0.5146000]]]]

Expected (Unparsed): [[[[0.9687,1.4992999999999999],[1.2184034799999999,1.1835]],[[1.6739,1.9766],[1.5814034799999999,0.5146]]]]

Actual:   [[[[0.9687, 1.4993], [1.2185, 1.1835]], [[1.6739, 1.9766], [1.5815, 0.5146]]]]

Expected: [[[[0.9687, 1.4993], [1.2185, 1.1835]], [[1.6739, 1.9766], [1.5815, 0.5146]]]]