import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Den4743 = tf.keras.layers.Input(shape=([4, 5, 2]))
in0Up_63457 = tf.keras.layers.Input(shape=([3, 2]))
in0Con18855 = tf.keras.layers.Input(shape=([4, 18]))

Den4743 = keras.layers.Dense(4,name = 'Den4743', )(in0Den4743)
Mas70421 = keras.layers.Masking(mask_value=1, name = 'Mas70421', )(Den4743)
Res38797 = keras.layers.Reshape((4, 20), name = 'Res38797', )(Mas70421)
Up_63457 = keras.layers.UpSampling1D(size=(1), name = 'Up_63457', )(in0Up_63457)
Zer85602 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer85602', )(Up_63457)
Con18855 = keras.layers.Concatenate(axis=2, name = 'Con18855', )([Zer85602,in0Con18855])
Ave83286 = keras.layers.Average(name = 'Ave83286', )([Res38797,Con18855])
model = tf.keras.models.Model(inputs=[in0Den4743,in0Up_63457,in0Con18855], outputs=Ave83286)
w = model.get_layer('Den4743').get_weights() 
w[0] = np.array([[0.8173, 0.6353, 0.0028, 0.2442], [0.4824, 0.859, 0.8705, 0.7328]])
w[1] = np.array([0.939, 0.6639, 0.9488, 0.046])
model.get_layer('Den4743').set_weights(w) 
in0Den4743 = tf.constant([[[[0.592, 0.6913], [0.8203, 0.7279], [0.0409, 0.0936], [0.0888, 0.8239], [0.3675, 0.7282]], [[0.2032, 0.4584], [0.1804, 0.0654], [0.2788, 0.4999], [0.0667, 0.902], [0.3412, 0.5373]], [[0.2882, 0.4872], [0.6395, 0.745], [0.1935, 0.9726], [0.008, 0.5465], [0.2466, 0.5894]], [[0.0414, 0.8152], [0.3956, 0.287], [0.4878, 0.6251], [0.2239, 0.0421], [0.3196, 0.5015]]]])
in0Up_63457 = tf.constant([[[1.9613, 1.6919], [1.4002, 1.713], [1.9626, 1.933]]])
in0Con18855 = tf.constant([[[0.2169, 0.7126, 0.3835, 0.5578, 0.317, 0.3164, 0.8633, 0.068, 0.259, 0.0682, 0.1176, 0.8612, 0.4642, 0.1218, 0.2478, 0.8259, 0.3386, 0.7328], [0.9346, 0.1611, 0.4439, 0.73, 0.8476, 0.0035, 0.8082, 0.8004, 0.1036, 0.6127, 0.5278, 0.99, 0.078, 0.6117, 0.9048, 0.8598, 0.1675, 0.1402], [0.1087, 0.6793, 0.5502, 0.5515, 0.7585, 0.8843, 0.5971, 0.4592, 0.8762, 0.7877, 0.3536, 0.5236, 0.3819, 0.1861, 0.4233, 0.3556, 0.6717, 0.0768], [0.6687, 0.3141, 0.8475, 0.1724, 0.3674, 0.7712, 0.8532, 0.2793, 0.8568, 0.6307, 0.1113, 0.8922, 0.2387, 0.4972, 0.2534, 0.5523, 0.4203, 0.9157]]])
print (np.array2string(model.predict([in0Den4743,in0Up_63457,in0Con18855],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave83286.png')

LDen4743 = dense_layer([[[[0.592, 0.6913], [0.8203, 0.7279], [0.0409, 0.0936], [0.0888, 0.8239], [0.3675, 0.7282]], [[0.2032, 0.4584], [0.1804, 0.0654], [0.2788, 0.4999], [0.0667, 0.902], [0.3412, 0.5373]], [[0.2882, 0.4872], [0.6395, 0.745], [0.1935, 0.9726], [0.008, 0.5465], [0.2466, 0.5894]], [[0.0414, 0.8152], [0.3956, 0.287], [0.4878, 0.6251], [0.2239, 0.0421], [0.3196, 0.5015]]]], [[0.8173, 0.6353, 0.0028, 0.2442], [0.4824, 0.859, 0.8705, 0.7328]],[0.939, 0.6639, 0.9488, 0.046], Den4743), 
LMas70421 = masking_layer(Den4743, 1, Mas70421), 
LRes38797 = reshape_layer(Mas70421, [4, 20], Res38797), 
LUp_63457 = up_sampling1D_layer([[[1.9613, 1.6919], [1.4002, 1.713], [1.9626, 1.933]]], 1, Up_63457), 
LZer85602 = zero_padding1D_layer(Up_63457, 1, 0, Zer85602), 
LCon18855 = concatenate_layer([Zer85602,[[[0.2169, 0.7126, 0.3835, 0.5578, 0.317, 0.3164, 0.8633, 0.068, 0.259, 0.0682, 0.1176, 0.8612, 0.4642, 0.1218, 0.2478, 0.8259, 0.3386, 0.7328], [0.9346, 0.1611, 0.4439, 0.73, 0.8476, 0.0035, 0.8082, 0.8004, 0.1036, 0.6127, 0.5278, 0.99, 0.078, 0.6117, 0.9048, 0.8598, 0.1675, 0.1402], [0.1087, 0.6793, 0.5502, 0.5515, 0.7585, 0.8843, 0.5971, 0.4592, 0.8762, 0.7877, 0.3536, 0.5236, 0.3819, 0.1861, 0.4233, 0.3556, 0.6717, 0.0768], [0.6687, 0.3141, 0.8475, 0.1724, 0.3674, 0.7712, 0.8532, 0.2793, 0.8568, 0.6307, 0.1113, 0.8922, 0.2387, 0.4972, 0.2534, 0.5523, 0.4203, 0.9157]]]], 2, Con18855), 
LAve83286 = average_layer([Res38797,Con18855], Ave83286), 
exec_layers([LDen4743,LMas70421,LRes38797,LUp_63457,LZer85602,LCon18855,LAve83286],["Den4743","Mas70421","Res38797","Up_63457","Zer85602","Con18855","Ave83286"],Ave83286,"Ave83286")

Actual (Unparsed): [[[0.8781624, 0.8169121, 0.8845671, 0.7048755, 1.1720351, 1.1840513, 0.9508669, 0.5480612, 0.9404401, 0.4191431, 0.6446967, 0.0963889, 0.7633128, 1.1446224, 1.0652268, 0.3966194, 0.9192207, 1.1743983, 0.9611636, 0.7010842], [1.6437538, 1.4393293, 1.1415031, 0.2963185, 0.7809449, 0.7823434, 0.9269179, 0.0707394, 1.1081075, 1.0354179, 0.7441718, 0.5465548, 0.9782194, 1.2355463, 0.9060889, 0.6674869, 1.1909281, 1.1010025, 0.7924875, 0.3316272], [1.4048856, 1.4892492, 0.7412073, 0.5763493, 1.1856257, 1.1308147, 1.1788065, 0.8162010, 1.0817149, 1.0407470, 1.3360951, 0.7968370, 0.7813850, 0.8310130, 0.9032253, 0.3172644, 0.9240864, 0.8412298, 1.0671316, 0.3074660], [1.6643443, 1.6617291, 1.1636237, 0.4837942, 1.1241363, 0.6670788, 0.7835706, 0.5620596, 1.2462136, 0.8950301, 1.1755577, 0.6269470, 0.6268013, 0.8672538, 0.6123875, 0.3143636, 0.8477663, 0.9250152, 0.9032753, 0.7036228]]]

Expected (Unparsed): [[[0.8781623599999999,0.8169121500000001,0.8845671250000001,0.7048755200000001,1.1720350750000001,1.184051345,0.950866895,0.54806119,0.940440105,0.41914308499999997,0.6446966599999999,0.09638893,0.7633127999999999,1.14462237,1.065226795,0.39661944,0.9192207149999999,1.174398275,0.96116355,0.70108423],[1.64375376,1.43932928,1.14150308,0.29631848,0.78094494,0.78234336,0.92691791,0.07073940000000001,1.1081075,1.0354178699999999,0.744171795,0.54655484,0.978219355,1.235546255,0.9060888800000001,0.6674868700000001,1.19092814,1.10100253,0.792487505,0.33162724],[1.40488557,1.4892491300000001,0.74120728,0.5763493,1.1856256749999998,1.1308146749999999,1.17880655,0.81620095,1.081714895,1.040746975,1.33609505,0.79683699,0.781385,0.8310129500000001,0.903225325,0.3172644,0.9240863699999999,0.8412297900000001,1.06713159,0.30746602],[1.66434435,1.66172911,1.16362376,0.48379422000000005,1.12413634,0.6670788400000001,0.78357059,0.56205956,1.24621359,0.8950301199999999,1.175557695,0.62694702,0.626801255,0.8672537849999999,0.612387485,0.31436363,0.8477663400000001,0.92501519,0.9032753149999999,0.70362276]]]

Actual:   [[[0.8782, 0.817, 0.8846, 0.7049, 1.1721, 1.1841, 0.9509, 0.5481, 0.9405, 0.4192, 0.6447, 0.0964, 0.7634, 1.1447, 1.0653, 0.3967, 0.9193, 1.1744, 0.9612, 0.7011], [1.6438, 1.4394, 1.1416, 0.2964, 0.781, 0.7824, 0.927, 0.0708, 1.1082, 1.0355, 0.7442, 0.5466, 0.9783, 1.2356, 0.9061, 0.6675, 1.191, 1.1011, 0.7925, 0.3317], [1.4049, 1.4893, 0.7413, 0.5764, 1.1857, 1.1309, 1.1789, 0.8163, 1.0818, 1.0408, 1.3361, 0.7969, 0.7814, 0.8311, 0.9033, 0.3173, 0.9241, 0.8413, 1.0672, 0.3075], [1.6644, 1.6618, 1.1637, 0.4838, 1.1242, 0.6671, 0.7836, 0.5621, 1.2463, 0.8951, 1.1756, 0.627, 0.6269, 0.8673, 0.6124, 0.3144, 0.8478, 0.9251, 0.9033, 0.7037]]]

Expected: [[[0.8782, 0.817, 0.8846, 0.7049, 1.1721, 1.1841, 0.9509, 0.5481, 0.9405, 0.4192, 0.6447, 0.0964, 0.7634, 1.1447, 1.0653, 0.3967, 0.9193, 1.1744, 0.9612, 0.7011], [1.6438, 1.4394, 1.1416, 0.2964, 0.781, 0.7824, 0.927, 0.0708, 1.1082, 1.0355, 0.7442, 0.5466, 0.9783, 1.2356, 0.9061, 0.6675, 1.191, 1.1011, 0.7925, 0.3317], [1.4049, 1.4893, 0.7413, 0.5764, 1.1857, 1.1309, 1.1789, 0.8163, 1.0818, 1.0408, 1.3361, 0.7969, 0.7814, 0.8311, 0.9033, 0.3173, 0.9241, 0.8413, 1.0672, 0.3075], [1.6644, 1.6618, 1.1637, 0.4838, 1.1242, 0.6671, 0.7836, 0.5621, 1.2463, 0.8951, 1.1756, 0.627, 0.6269, 0.8673, 0.6124, 0.3144, 0.8478, 0.9251, 0.9033, 0.7037]]]