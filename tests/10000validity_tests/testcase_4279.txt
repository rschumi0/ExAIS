import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer921 = tf.keras.layers.Input(shape=([1, 2, 1, 4]))
in0Lay12711 = tf.keras.layers.Input(shape=([3, 2]))
in0Con24465 = tf.keras.layers.Input(shape=([3, 1]))
in0Sub31501 = tf.keras.layers.Input(shape=([2, 3]))
in1Sub31501 = tf.keras.layers.Input(shape=([2, 3]))
in0Min46573 = tf.keras.layers.Input(shape=([1, 1]))
in1Min46573 = tf.keras.layers.Input(shape=([1, 1]))
in0Con5583 = tf.keras.layers.Input(shape=([3, 2]))
in0Con60945 = tf.keras.layers.Input(shape=([3, 45]))

Zer921 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer921', )(in0Zer921)
Res23903 = keras.layers.Reshape((3, 4, 12), name = 'Res23903', )(Zer921)
Res59033 = keras.layers.Reshape((3, 48), name = 'Res59033', )(Res23903)
Lay12711 = keras.layers.LayerNormalization(axis=1, epsilon=2.7489190439035776, name = 'Lay12711', )(in0Lay12711)
Con24465 = keras.layers.Concatenate(axis=2, name = 'Con24465', )([Lay12711,in0Con24465])
Sub31501 = keras.layers.Subtract(name = 'Sub31501', )([in0Sub31501,in1Sub31501])
Zer1829 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer1829', )(Sub31501)
Min92951 = keras.layers.Minimum(name = 'Min92951', )([Con24465,Zer1829])
Per76121 = keras.layers.Permute((1,2), name = 'Per76121',)(Min92951)
Min46573 = keras.layers.Minimum(name = 'Min46573', )([in0Min46573,in1Min46573])
Zer26755 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer26755', )(Min46573)
Con5583 = keras.layers.Concatenate(axis=2, name = 'Con5583', )([Zer26755,in0Con5583])
Ave12815 = keras.layers.Average(name = 'Ave12815', )([Per76121,Con5583])
Con60945 = keras.layers.Concatenate(axis=2, name = 'Con60945', )([Ave12815,in0Con60945])
Add75972 = keras.layers.Add(name = 'Add75972', )([Res59033,Con60945])
model = tf.keras.models.Model(inputs=[in0Zer921,in0Lay12711,in0Con24465,in0Sub31501,in1Sub31501,in0Min46573,in1Min46573,in0Con5583,in0Con60945], outputs=Add75972)
in0Zer921 = tf.constant([[[[[1.3582, 1.3246, 1.2307, 1.7553]], [[1.7521, 1.978, 1.3264, 1.4916]]]]])
in0Lay12711 = tf.constant([[[1.9312, 1.4455], [1.606, 1.2257], [1.2194, 1.3609]]])
in0Con24465 = tf.constant([[[0.4481], [0.64], [0.1569]]])
in0Sub31501 = tf.constant([[[0.3351, 0.8257, 0.9052], [0.0431, 0.1171, 0.4593]]])
in1Sub31501 = tf.constant([[[0.8285, 0.3346, 0.8673], [0.8125, 0.0149, 0.6658]]])
in0Min46573 = tf.constant([[[0.6274]]])
in1Min46573 = tf.constant([[[0.7225]]])
in0Con5583 = tf.constant([[[0.7324, 0.3983], [0.1067, 0.0607], [0.29, 0.6392]]])
in0Con60945 = tf.constant([[[0.5194, 0.0606, 0.0395, 0.9594, 0.245, 0.9028, 0.7473, 0.4732, 0.6641, 0.0189, 0.799, 0.9876, 0.4498, 0.1306, 0.0963, 0.6, 0.6433, 0.9154, 0.652, 0.2986, 0.6356, 0.2171, 0.2909, 0.2277, 0.6994, 0.5294, 0.4801, 0.5036, 0.4813, 0.0186, 0.4404, 0.2875, 0.6386, 0.5776, 0.6737, 0.3685, 0.2447, 0.5329, 0.1786, 0.472, 0.6729, 0.6614, 0.92, 0.8723, 0.4191], [0.1188, 0.5693, 0.6552, 0.7249, 0.7258, 0.1375, 0.1589, 0.9241, 0.8178, 0.8868, 0.6998, 0.1498, 0.5211, 0.8257, 0.6813, 0.4122, 0.889, 0.1655, 0.5781, 0.0849, 0.8027, 0.351, 0.0917, 0.5238, 0.9221, 0.6634, 0.9798, 0.8804, 0.2599, 0.9371, 0.6756, 0.1721, 0.1407, 0.6349, 0.836, 0.3213, 0.4102, 0.3796, 0.3827, 0.19, 0.7599, 0.0548, 0.4322, 0.5954, 0.948], [0.7549, 0.7542, 0.9216, 0.511, 0.1915, 0.0373, 0.2151, 0.2865, 0.6426, 0.2981, 0.5891, 0.697, 0.1711, 0.2249, 0.3514, 0.2797, 0.6305, 0.1121, 0.5189, 0.3916, 0.9285, 0.3117, 0.2839, 0.3648, 0.1229, 0.8064, 0.557, 0.646, 0.1898, 0.589, 0.9279, 0.6109, 0.7202, 0.0259, 0.2575, 0.8152, 0.3792, 0.2736, 0.6418, 0.4146, 0.6903, 0.1235, 0.6746, 0.3689, 0.5977]]])
print (np.array2string(model.predict([in0Zer921,in0Lay12711,in0Con24465,in0Sub31501,in1Sub31501,in0Min46573,in1Min46573,in0Con5583,in0Con60945],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add75972.png')

LZer921 = zero_padding3D_layer([[[[[1.3582, 1.3246, 1.2307, 1.7553]], [[1.7521, 1.978, 1.3264, 1.4916]]]]], 1, 1, 1, 1, 1, 1, Zer921), 
LRes23903 = reshape_layer(Zer921, [3, 4, 12], Res23903), 
LRes59033 = reshape_layer(Res23903, [3, 48], Res59033), 
LLay12711 = layer_normalization_layer([[[1.9312, 1.4455], [1.606, 1.2257], [1.2194, 1.3609]]], 1, 2.7489190439035776, Lay12711), 
LCon24465 = concatenate_layer([Lay12711,[[[0.4481], [0.64], [0.1569]]]], 2, Con24465), 
LSub31501 = subtract_layer([[[0.3351, 0.8257, 0.9052], [0.0431, 0.1171, 0.4593]]], [[[0.8285, 0.3346, 0.8673], [0.8125, 0.0149, 0.6658]]], Sub31501), 
LZer1829 = zero_padding1D_layer(Sub31501, 1, 0, Zer1829), 
LMin92951 = minimum_layer([Con24465,Zer1829], Min92951), 
LPer76121 = permute_layer(Min92951, 1,2, Per76121), 
LMin46573 = minimum_layer([[[[0.6274]]], [[[0.7225]]]], Min46573), 
LZer26755 = zero_padding1D_layer(Min46573, 2, 0, Zer26755), 
LCon5583 = concatenate_layer([Zer26755,[[[0.7324, 0.3983], [0.1067, 0.0607], [0.29, 0.6392]]]], 2, Con5583), 
LAve12815 = average_layer([Per76121,Con5583], Ave12815), 
LCon60945 = concatenate_layer([Ave12815,[[[0.5194, 0.0606, 0.0395, 0.9594, 0.245, 0.9028, 0.7473, 0.4732, 0.6641, 0.0189, 0.799, 0.9876, 0.4498, 0.1306, 0.0963, 0.6, 0.6433, 0.9154, 0.652, 0.2986, 0.6356, 0.2171, 0.2909, 0.2277, 0.6994, 0.5294, 0.4801, 0.5036, 0.4813, 0.0186, 0.4404, 0.2875, 0.6386, 0.5776, 0.6737, 0.3685, 0.2447, 0.5329, 0.1786, 0.472, 0.6729, 0.6614, 0.92, 0.8723, 0.4191], [0.1188, 0.5693, 0.6552, 0.7249, 0.7258, 0.1375, 0.1589, 0.9241, 0.8178, 0.8868, 0.6998, 0.1498, 0.5211, 0.8257, 0.6813, 0.4122, 0.889, 0.1655, 0.5781, 0.0849, 0.8027, 0.351, 0.0917, 0.5238, 0.9221, 0.6634, 0.9798, 0.8804, 0.2599, 0.9371, 0.6756, 0.1721, 0.1407, 0.6349, 0.836, 0.3213, 0.4102, 0.3796, 0.3827, 0.19, 0.7599, 0.0548, 0.4322, 0.5954, 0.948], [0.7549, 0.7542, 0.9216, 0.511, 0.1915, 0.0373, 0.2151, 0.2865, 0.6426, 0.2981, 0.5891, 0.697, 0.1711, 0.2249, 0.3514, 0.2797, 0.6305, 0.1121, 0.5189, 0.3916, 0.9285, 0.3117, 0.2839, 0.3648, 0.1229, 0.8064, 0.557, 0.646, 0.1898, 0.589, 0.9279, 0.6109, 0.7202, 0.0259, 0.2575, 0.8152, 0.3792, 0.2736, 0.6418, 0.4146, 0.6903, 0.1235, 0.6746, 0.3689, 0.5977]]]], 2, Con60945), 
LAdd75972 = add_layer([Res59033,Con60945], Add75972), 
exec_layers([LZer921,LRes23903,LRes59033,LLay12711,LCon24465,LSub31501,LZer1829,LMin92951,LPer76121,LMin46573,LZer26755,LCon5583,LAve12815,LCon60945,LAdd75972],["Zer921","Res23903","Res59033","Lay12711","Con24465","Sub31501","Zer1829","Min92951","Per76121","Min46573","Zer26755","Con5583","Ave12815","Con60945","Add75972"],Add75972,"Add75972")

Actual (Unparsed): [[[0.0000000, 0.3662000, 0.1991500, 0.5194000, 0.0606000, 0.0395000, 0.9594000, 0.2450000, 0.9028000, 0.7473000, 0.4732000, 0.6641000, 0.0189000, 0.7990000, 0.9876000, 0.4498000, 0.1306000, 0.0963000, 0.6000000, 0.6433000, 0.9154000, 0.6520000, 0.2986000, 0.6356000, 0.2171000, 0.2909000, 0.2277000, 0.6994000, 0.5294000, 0.4801000, 0.5036000, 0.4813000, 0.0186000, 0.4404000, 0.2875000, 0.6386000, 0.5776000, 0.6737000, 0.3685000, 0.2447000, 0.5329000, 0.1786000, 0.4720000, 0.6729000, 0.6614000, 0.9200000, 0.8723000, 0.4191000], [-0.2467000, 0.0177172, 0.0493000, 0.1188000, 0.5693000, 0.6552000, 0.7249000, 0.7258000, 0.1375000, 0.1589000, 0.9241000, 0.8178000, 0.8868000, 0.6998000, 0.1498000, 0.5211000, 2.1838999, 2.0059000, 1.6429000, 2.6443000, 0.1655000, 0.5781000, 0.0849000, 0.8027000, 0.3510000, 0.0917000, 0.5238000, 0.9221000, 2.4155000, 2.9578000, 2.2068000, 1.7515000, 0.9371000, 0.6756000, 0.1721000, 0.1407000, 0.6349000, 0.8360000, 0.3213000, 0.4102000, 0.3796000, 0.3827000, 0.1900000, 0.7599000, 0.0548000, 0.4322000, 0.5954000, 0.9480000], [-0.0710000, 0.1500789, 0.2163500, 0.7549000, 0.7542000, 0.9216000, 0.5110000, 0.1915000, 0.0373000, 0.2151000, 0.2865000, 0.6426000, 0.2981000, 0.5891000, 0.6970000, 0.1711000, 0.2249000, 0.3514000, 0.2797000, 0.6305000, 0.1121000, 0.5189000, 0.3916000, 0.9285000, 0.3117000, 0.2839000, 0.3648000, 0.1229000, 0.8064000, 0.5570000, 0.6460000, 0.1898000, 0.5890000, 0.9279000, 0.6109000, 0.7202000, 0.0259000, 0.2575000, 0.8152000, 0.3792000, 0.2736000, 0.6418000, 0.4146000, 0.6903000, 0.1235000, 0.6746000, 0.3689000, 0.5977000]]]

Expected (Unparsed): [[[0,0.3662,0.19915,0.5194,0.0606,0.0395,0.9594,0.245,0.9028,0.7473,0.4732,0.6641,0.0189,0.799,0.9876,0.4498,0.1306,0.0963,0.6,0.6433,0.9154,0.652,0.2986,0.6356,0.2171,0.2909,0.2277,0.6994,0.5294,0.4801,0.5036,0.4813,0.0186,0.4404,0.2875,0.6386,0.5776,0.6737,0.3685,0.2447,0.5329,0.1786,0.472,0.6729,0.6614,0.92,0.8723,0.4191],[-0.2467,0.017717212604485215,0.049300000000000024,0.1188,0.5693,0.6552,0.7249,0.7258,0.1375,0.1589,0.9241,0.8178,0.8868,0.6998,0.1498,0.5211,2.1839,2.0059,1.6429,2.6443000000000003,0.1655,0.5781,0.0849,0.8027,0.351,0.0917,0.5238,0.9221,2.4154999999999998,2.9577999999999998,2.2068,1.7515,0.9371,0.6756,0.1721,0.1407,0.6349,0.836,0.3213,0.4102,0.3796,0.3827,0.19,0.7599,0.0548,0.4322,0.5954,0.948],[-0.07100000000000001,0.1500789268794734,0.21635000000000001,0.7549,0.7542,0.9216,0.511,0.1915,0.0373,0.2151,0.2865,0.6426,0.2981,0.5891,0.697,0.1711,0.2249,0.3514,0.2797,0.6305,0.1121,0.5189,0.3916,0.9285,0.3117,0.2839,0.3648,0.1229,0.8064,0.557,0.646,0.1898,0.589,0.9279,0.6109,0.7202,0.0259,0.2575,0.8152,0.3792,0.2736,0.6418,0.4146,0.6903,0.1235,0.6746,0.3689,0.5977]]]

Actual:   [[[0, 0.3662, 0.1992, 0.5194, 0.0606, 0.0395, 0.9594, 0.245, 0.9028, 0.7473, 0.4732, 0.6641, 0.0189, 0.799, 0.9876, 0.4498, 0.1306, 0.0963, 0.6, 0.6433, 0.9154, 0.652, 0.2986, 0.6356, 0.2171, 0.2909, 0.2277, 0.6994, 0.5294, 0.4801, 0.5036, 0.4813, 0.0186, 0.4404, 0.2875, 0.6386, 0.5776, 0.6737, 0.3685, 0.2447, 0.5329, 0.1786, 0.472, 0.6729, 0.6614, 0.92, 0.8723, 0.4191], [-0.2467, 0.0178, 0.0493, 0.1188, 0.5693, 0.6552, 0.7249, 0.7258, 0.1375, 0.1589, 0.9241, 0.8178, 0.8868, 0.6998, 0.1498, 0.5211, 2.1839, 2.0059, 1.6429, 2.6443, 0.1655, 0.5781, 0.0849, 0.8027, 0.351, 0.0917, 0.5238, 0.9221, 2.4155, 2.9578, 2.2068, 1.7515, 0.9371, 0.6756, 0.1721, 0.1407, 0.6349, 0.836, 0.3213, 0.4102, 0.3796, 0.3827, 0.19, 0.7599, 0.0548, 0.4322, 0.5954, 0.948], [-0.071, 0.1501, 0.2164, 0.7549, 0.7542, 0.9216, 0.511, 0.1915, 0.0373, 0.2151, 0.2865, 0.6426, 0.2981, 0.5891, 0.697, 0.1711, 0.2249, 0.3514, 0.2797, 0.6305, 0.1121, 0.5189, 0.3916, 0.9285, 0.3117, 0.2839, 0.3648, 0.1229, 0.8064, 0.557, 0.646, 0.1898, 0.589, 0.9279, 0.6109, 0.7202, 0.0259, 0.2575, 0.8152, 0.3792, 0.2736, 0.6418, 0.4146, 0.6903, 0.1235, 0.6746, 0.3689, 0.5977]]]

Expected: [[[0, 0.3662, 0.1992, 0.5194, 0.0606, 0.0395, 0.9594, 0.245, 0.9028, 0.7473, 0.4732, 0.6641, 0.0189, 0.799, 0.9876, 0.4498, 0.1306, 0.0963, 0.6, 0.6433, 0.9154, 0.652, 0.2986, 0.6356, 0.2171, 0.2909, 0.2277, 0.6994, 0.5294, 0.4801, 0.5036, 0.4813, 0.0186, 0.4404, 0.2875, 0.6386, 0.5776, 0.6737, 0.3685, 0.2447, 0.5329, 0.1786, 0.472, 0.6729, 0.6614, 0.92, 0.8723, 0.4191], [-0.2467, 0.0178, 0.0494, 0.1188, 0.5693, 0.6552, 0.7249, 0.7258, 0.1375, 0.1589, 0.9241, 0.8178, 0.8868, 0.6998, 0.1498, 0.5211, 2.1839, 2.0059, 1.6429, 2.6444, 0.1655, 0.5781, 0.0849, 0.8027, 0.351, 0.0917, 0.5238, 0.9221, 2.4155, 2.9578, 2.2068, 1.7515, 0.9371, 0.6756, 0.1721, 0.1407, 0.6349, 0.836, 0.3213, 0.4102, 0.3796, 0.3827, 0.19, 0.7599, 0.0548, 0.4322, 0.5954, 0.948], [-0.071, 0.1501, 0.2164, 0.7549, 0.7542, 0.9216, 0.511, 0.1915, 0.0373, 0.2151, 0.2865, 0.6426, 0.2981, 0.5891, 0.697, 0.1711, 0.2249, 0.3514, 0.2797, 0.6305, 0.1121, 0.5189, 0.3916, 0.9285, 0.3117, 0.2839, 0.3648, 0.1229, 0.8064, 0.557, 0.646, 0.1898, 0.589, 0.9279, 0.6109, 0.7202, 0.0259, 0.2575, 0.8152, 0.3792, 0.2736, 0.6418, 0.4146, 0.6903, 0.1235, 0.6746, 0.3689, 0.5977]]]