import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add40918 = tf.keras.layers.Input(shape=([1, 1]))
in1Add40918 = tf.keras.layers.Input(shape=([1, 1]))
in0Con52990 = tf.keras.layers.Input(shape=([3, 4, 1]))
in0Bat22733 = tf.keras.layers.Input(shape=([3, 4, 2]))

Add40918 = keras.layers.Add(name = 'Add40918', )([in0Add40918,in1Add40918])
ReL72388 = keras.layers.ReLU(max_value=4.43561445363952, negative_slope=6.460122162597501, threshold=4.782109989767285, name = 'ReL72388', )(Add40918)
Res36778 = keras.layers.Reshape((1, 1, 1), name = 'Res36778', )(ReL72388)
Zer72220 = keras.layers.ZeroPadding2D(padding=((2, 0), (3, 0)), name = 'Zer72220', )(Res36778)
Con52990 = keras.layers.Concatenate(axis=3, name = 'Con52990', )([Zer72220,in0Con52990])
Bat22733 = keras.layers.BatchNormalization(axis=1, epsilon=0.3816268856749959,  name = 'Bat22733', )(in0Bat22733)
Min52238 = keras.layers.Minimum(name = 'Min52238', )([Con52990,Bat22733])
model = tf.keras.models.Model(inputs=[in0Add40918,in1Add40918,in0Con52990,in0Bat22733], outputs=Min52238)
w = model.get_layer('Bat22733').get_weights() 
w[0] = np.array([0.5913, 0.8468, 0.3297])
w[1] = np.array([0.7422, 0.1812, 0.7521])
w[2] = np.array([0.3468, 0.2831, 0.5116])
w[3] = np.array([0.285, 0.5522, 0.3125])
model.get_layer('Bat22733').set_weights(w) 
in0Add40918 = tf.constant([[[0.3498]]])
in1Add40918 = tf.constant([[[0.695]]])
in0Con52990 = tf.constant([[[[0.9229], [0.8136], [0.5579], [0.769]], [[0.22], [0.9436], [0.3635], [0.389]], [[0.5059], [0.0212], [0.7741], [0.2736]]]])
in0Bat22733 = tf.constant([[[[1.6249, 1.0367], [1.167, 1.7113], [1.3582, 1.0578], [1.4357, 1.901]], [[1.4291, 1.8158], [1.6203, 1.969], [1.453, 1.3771], [1.1749, 1.4187]], [[1.0533, 1.4123], [1.084, 1.2746], [1.9277, 1.4393], [1.7079, 1.8753]]]])
print (np.array2string(model.predict([in0Add40918,in1Add40918,in0Con52990,in0Bat22733],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min52238.png')

LAdd40918 = add_layer([[[[0.3498]]], [[[0.695]]]], Add40918), 
LReL72388 = relu_layer(Add40918, 4.43561445363952, 6.460122162597501, 4.782109989767285, ReL72388), 
LRes36778 = reshape_layer(ReL72388, [1, 1, 1], Res36778), 
LZer72220 = zero_padding2D_layer(Res36778, 2, 0, 3, 0, Zer72220), 
LCon52990 = concatenate_layer([Zer72220,[[[[0.9229], [0.8136], [0.5579], [0.769]], [[0.22], [0.9436], [0.3635], [0.389]], [[0.5059], [0.0212], [0.7741], [0.2736]]]]], 3, Con52990), 
LBat22733 = batch_normalization_layer([[[[1.6249, 1.0367], [1.167, 1.7113], [1.3582, 1.0578], [1.4357, 1.901]], [[1.4291, 1.8158], [1.6203, 1.969], [1.453, 1.3771], [1.1749, 1.4187]], [[1.0533, 1.4123], [1.084, 1.2746], [1.9277, 1.4393], [1.7079, 1.8753]]]], 1, 0.3816268856749959, [0.5913, 0.8468, 0.3297], [0.7422, 0.1812, 0.7521], [0.3468, 0.2831, 0.5116], [0.285, 0.5522, 0.3125], Bat22733), 
LMin52238 = minimum_layer([Con52990,Bat22733], Min52238), 
exec_layers([LAdd40918,LReL72388,LRes36778,LZer72220,LCon52990,LBat22733,LMin52238],["Add40918","ReL72388","Res36778","Zer72220","Con52990","Bat22733","Min52238"],Min52238,"Min52238")

Actual (Unparsed): [[[[0.0000000, 0.9229000], [0.0000000, 0.8136000], [0.0000000, 0.5579000], [0.0000000, 0.7690000]], [[0.0000000, 0.2200000], [0.0000000, 0.9436000], [0.0000000, 0.3635000], [0.0000000, 0.3890000]], [[0.0000000, 0.5059000], [0.0000000, 0.0212000], [0.0000000, 0.7741000], [-24.1434792, 0.2736000]]]]

Expected (Unparsed): [[[[0,0.9229],[0,0.8136],[0,0.5579],[0,0.769]],[[0,0.22],[0,0.9436],[0,0.3635],[0,0.389]],[[0,0.5059],[0,0.0212],[0,0.7741],[-24.143479093392678,0.2736]]]]

Actual:   [[[[0, 0.9229], [0, 0.8136], [0, 0.5579], [0, 0.769]], [[0, 0.22], [0, 0.9436], [0, 0.3635], [0, 0.389]], [[0, 0.5059], [0, 0.0212], [0, 0.7741], [-24.1434, 0.2736]]]]

Expected: [[[[0, 0.9229], [0, 0.8136], [0, 0.5579], [0, 0.769]], [[0, 0.22], [0, 0.9436], [0, 0.3635], [0, 0.389]], [[0, 0.5059], [0, 0.0212], [0, 0.7741], [-24.1434, 0.2736]]]]