import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave29849 = tf.keras.layers.Input(shape=([2, 2]))
in1Ave29849 = tf.keras.layers.Input(shape=([2, 2]))
in0Glo31346 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con76706 = tf.keras.layers.Input(shape=([2, 1]))

Ave29849 = keras.layers.Average(name = 'Ave29849', )([in0Ave29849,in1Ave29849])
ELU67558 = keras.layers.ELU(alpha=-8.760845910306028, name = 'ELU67558', )(Ave29849)
Glo31346 = keras.layers.GlobalAveragePooling2D(name = 'Glo31346', )(in0Glo31346)
Res45628 = keras.layers.Reshape((2, 1), name = 'Res45628', )(Glo31346)
GRU21179 = keras.layers.GRU(2,reset_after=False, recurrent_activation='sigmoid', name = 'GRU21179', )(Res45628)
Lea54034 = keras.layers.LeakyReLU(alpha=9.882911624245018, name = 'Lea54034', )(GRU21179)
Res45153 = keras.layers.Reshape((2, 1), name = 'Res45153', )(Lea54034)
Max57464 = keras.layers.MaxPool1D(pool_size=(2), name = 'Max57464', )(Res45153)
Zer16747 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer16747', )(Max57464)
Con76706 = keras.layers.Concatenate(axis=2, name = 'Con76706', )([Zer16747,in0Con76706])
Ave3304 = keras.layers.Average(name = 'Ave3304', )([ELU67558,Con76706])
model = tf.keras.models.Model(inputs=[in0Ave29849,in1Ave29849,in0Glo31346,in0Con76706], outputs=Ave3304)
w = model.get_layer('GRU21179').get_weights() 
w[0] = np.array([[5, 7, 2, 5, 3, 8]])
w[1] = np.array([[1, 6, 7, 9, 6, 7], [5, 3, 5, 8, 1, 9]])
w[2] = np.array([10, 6, 7, 10, 5, 5])
model.get_layer('GRU21179').set_weights(w) 
in0Ave29849 = tf.constant([[[0.803, 0.5507], [0.756, 0.2237]]])
in1Ave29849 = tf.constant([[[0.9735, 0.6196], [0.572, 0.2591]]])
in0Glo31346 = tf.constant([[[[1.7943, 1.1979], [1.2802, 1.5685]], [[1.158, 1.6949], [1.6261, 1.1811]]]])
in0Con76706 = tf.constant([[[0.0777], [0.0896]]])
print (np.array2string(model.predict([in0Ave29849,in1Ave29849,in0Glo31346,in0Con76706],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave3304.png')

LAve29849 = average_layer([[[[0.803, 0.5507], [0.756, 0.2237]]], [[[0.9735, 0.6196], [0.572, 0.2591]]]], Ave29849), 
LELU67558 = elu_layer(Ave29849, -8.760845910306028, ELU67558), 
LGlo31346 = global_average_pooling2D_layer([[[[1.7943, 1.1979], [1.2802, 1.5685]], [[1.158, 1.6949], [1.6261, 1.1811]]]], Glo31346), 
LRes45628 = reshape_layer(Glo31346, [2, 1], Res45628), 
LGRU21179 = gru_layer(Res45628,[[5, 7, 2, 5, 3, 8]],[[1, 6, 7, 9, 6, 7], [5, 3, 5, 8, 1, 9]],[10, 6, 7, 10, 5, 5], false, GRU21179), 
LLea54034 = leaky_relu_layer(GRU21179, 9.882911624245018, Lea54034), 
LRes45153 = reshape_layer(Lea54034, [2, 1], Res45153), 
LMax57464 = max_pool1D_layer(Res45153, 2, Max57464), 
LZer16747 = zero_padding1D_layer(Max57464, 1, 0, Zer16747), 
LCon76706 = concatenate_layer([Zer16747,[[[0.0777], [0.0896]]]], 2, Con76706), 
LAve3304 = average_layer([ELU67558,Con76706], Ave3304), 
exec_layers([LAve29849,LELU67558,LGlo31346,LRes45628,LGRU21179,LLea54034,LRes45153,LMax57464,LZer16747,LCon76706,LAve3304],["Ave29849","ELU67558","Glo31346","Res45628","GRU21179","Lea54034","Res45153","Max57464","Zer16747","Con76706","Ave3304"],Ave3304,"Ave3304")

Actual (Unparsed): [[[0.4441250, 0.3314250], [0.3320001, 0.1655000]]]

Expected (Unparsed): [[[0.444125,0.331425],[0.3320001075201511,0.1655]]]

Actual:   [[[0.4442, 0.3315], [0.3321, 0.1655]]]

Expected: [[[0.4442, 0.3315], [0.3321, 0.1655]]]