import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Up_83546 = tf.keras.layers.Input(shape=([3, 1, 2, 2]))
in0Ave7399 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Ave7399 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con74385 = tf.keras.layers.Input(shape=([6, 2, 7]))
in0Dot72056 = tf.keras.layers.Input(shape=([3]))
in1Dot72056 = tf.keras.layers.Input(shape=([3]))
in0Con32833 = tf.keras.layers.Input(shape=([191]))

Up_83546 = keras.layers.UpSampling3D(size=(2, 2, 2), name = 'Up_83546', )(in0Up_83546)
Res78773 = keras.layers.Reshape((6, 2, 8), name = 'Res78773', )(Up_83546)
Ave7399 = keras.layers.Average(name = 'Ave7399', )([in0Ave7399,in1Ave7399])
Zer41152 = keras.layers.ZeroPadding2D(padding=((4, 0), (1, 0)), name = 'Zer41152', )(Ave7399)
Con74385 = keras.layers.Concatenate(axis=3, name = 'Con74385', )([Zer41152,in0Con74385])
Max75570 = keras.layers.Maximum(name = 'Max75570', )([Res78773,Con74385])
Res27231 = keras.layers.Reshape((6, 16), name = 'Res27231', )(Max75570)
Up_52007 = keras.layers.UpSampling1D(size=(2), name = 'Up_52007', )(Res27231)
Fla68191 = keras.layers.Flatten(name = 'Fla68191', )(Up_52007)
Dot72056 = keras.layers.Dot(axes=(1, 1), name = 'Dot72056', )([in0Dot72056,in1Dot72056])
Res18452 = keras.layers.Reshape((1, 1), name = 'Res18452', )(Dot72056)
Res34498 = keras.layers.Reshape((1, 1, 1), name = 'Res34498', )(Res18452)
Glo15656 = keras.layers.GlobalAveragePooling2D(name = 'Glo15656', )(Res34498)
Con32833 = keras.layers.Concatenate(axis=1, name = 'Con32833', )([Glo15656,in0Con32833])
Ave39035 = keras.layers.Average(name = 'Ave39035', )([Fla68191,Con32833])
model = tf.keras.models.Model(inputs=[in0Up_83546,in0Ave7399,in1Ave7399,in0Con74385,in0Dot72056,in1Dot72056,in0Con32833], outputs=Ave39035)
in0Up_83546 = tf.constant([[[[[1.4141, 1.9573], [1.0915, 1.2371]]], [[[1.3377, 1.5161], [1.743, 1.5703]]], [[[1.5842, 1.0331], [1.1955, 1.683]]]]])
in0Ave7399 = tf.constant([[[[0.5687]], [[0.6093]]]])
in1Ave7399 = tf.constant([[[[0.2247]], [[0.4804]]]])
in0Con74385 = tf.constant([[[[0.5348, 0.4891, 0.5208, 0.1009, 0.0384, 0.1348, 0.7171], [0.0123, 0.9664, 0.9539, 0.533, 0.8094, 0.2111, 0.3439]], [[0.5266, 0.7257, 0.4769, 0.2413, 0.0584, 0.4502, 0.8841], [0.9989, 0.0619, 0.5893, 0.2285, 0.3375, 0.1317, 0.1862]], [[0.0059, 0.6381, 0.6459, 0.851, 0.1626, 0.854, 0.887], [0.0802, 0.4178, 0.6228, 0.8961, 0.1645, 0.918, 0.7357]], [[0.1029, 0.6732, 0.9291, 0.9825, 0.6109, 0.8835, 0.2519], [0.5334, 0.3838, 0.6763, 0.0522, 0.4379, 0.481, 0.3635]], [[0.8402, 0.5301, 0.9179, 0.6251, 0.4014, 0.012, 0.6916], [0.2431, 0.5879, 0.2522, 0.0029, 0.5933, 0.009, 0.8895]], [[0.7324, 0.9272, 0.8276, 0.154, 0.7818, 0.314, 0.0635], [0.4344, 0.9813, 0.7452, 0.0345, 0.5082, 0.8789, 0.3055]]]])
in0Dot72056 = tf.constant([[0.2142, 0.4995, 0.2537]])
in1Dot72056 = tf.constant([[0.8681, 0.7595, 0.6068]])
in0Con32833 = tf.constant([[0.1516, 0.1679, 0.9253, 0.0615, 0.8641, 0.604, 0.8989, 0.6468, 0.4812, 0.4147, 0.9569, 0.3021, 0.3918, 0.9823, 0.5853, 0.0563, 0.0175, 0.6129, 0.3846, 0.2704, 0.4766, 0.2698, 0.911, 0.022, 0.5953, 0.8186, 0.3917, 0.6503, 0.8785, 0.7804, 0.1545, 0.7478, 0.5458, 0.2761, 0.8103, 0.4119, 0.8951, 0.4479, 0.5856, 0.4892, 0.0634, 0.1482, 0.7142, 0.8835, 0.7218, 0.094, 0.464, 0.7363, 0.3615, 0.0075, 0.2043, 0.4324, 0.6102, 0.4829, 0.8962, 0.9379, 0.447, 0.4513, 0.5292, 0.9327, 0.2805, 0.1513, 0.3192, 0.5676, 0.5976, 0.4553, 0.9358, 0.4426, 0.2961, 0.2504, 0.6294, 0.583, 0.873, 0.327, 0.8953, 0.7706, 0.3565, 0.8898, 0.2285, 0.5786, 0.2416, 0.3739, 0.5983, 0.8527, 0.7168, 0.7206, 0.5044, 0.1827, 0.1561, 0.6493, 0.8633, 0.1192, 0.1889, 0.7469, 0.5166, 0.5, 0.6584, 0.3885, 0.8549, 0.2761, 0.4336, 0.6028, 0.9066, 0.6501, 0.347, 0.999, 0.2531, 0.1756, 0.4989, 0.7842, 0.3018, 0.7027, 0.7885, 0.7179, 0.7721, 0.7036, 0.8126, 0.5728, 0.7334, 0.5604, 0.2054, 0.3008, 0.1692, 0.8584, 0.0857, 0.6421, 0.8366, 0.5899, 0.5221, 0.353, 0.1416, 0.4466, 0.8338, 0.5813, 0.8542, 0.0522, 0.1005, 0.1692, 0.7539, 0.0732, 0.4734, 0.8279, 0.7115, 0.6329, 0.7493, 0.1931, 0.2907, 0.3497, 0.2005, 0.7455, 0.6833, 0.623, 0.8358, 0.4603, 0.68, 0.4977, 0.1081, 0.8354, 0.4219, 0.5515, 0.5856, 0.6392, 0.8806, 0.7729, 0.2498, 0.3217, 0.3658, 0.3198, 0.9001, 0.5311, 0.8797, 0.3859, 0.6064, 0.5958, 0.7986, 0.1395, 0.2738, 0.1443, 0.1931, 0.8441, 0.1633, 0.2607, 0.0774, 0.8239, 0.6451, 0.7054, 0.0143, 0.8929, 0.554, 0.7621, 0.801]])
print (np.array2string(model.predict([in0Up_83546,in0Ave7399,in1Ave7399,in0Con74385,in0Dot72056,in1Dot72056,in0Con32833],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave39035.png')

LUp_83546 = up_sampling3D_layer([[[[[1.4141, 1.9573], [1.0915, 1.2371]]], [[[1.3377, 1.5161], [1.743, 1.5703]]], [[[1.5842, 1.0331], [1.1955, 1.683]]]]], 2, 2, 2, Up_83546), 
LRes78773 = reshape_layer(Up_83546, [6, 2, 8], Res78773), 
LAve7399 = average_layer([[[[[0.5687]], [[0.6093]]]], [[[[0.2247]], [[0.4804]]]]], Ave7399), 
LZer41152 = zero_padding2D_layer(Ave7399, 4, 0, 1, 0, Zer41152), 
LCon74385 = concatenate_layer([Zer41152,[[[[0.5348, 0.4891, 0.5208, 0.1009, 0.0384, 0.1348, 0.7171], [0.0123, 0.9664, 0.9539, 0.533, 0.8094, 0.2111, 0.3439]], [[0.5266, 0.7257, 0.4769, 0.2413, 0.0584, 0.4502, 0.8841], [0.9989, 0.0619, 0.5893, 0.2285, 0.3375, 0.1317, 0.1862]], [[0.0059, 0.6381, 0.6459, 0.851, 0.1626, 0.854, 0.887], [0.0802, 0.4178, 0.6228, 0.8961, 0.1645, 0.918, 0.7357]], [[0.1029, 0.6732, 0.9291, 0.9825, 0.6109, 0.8835, 0.2519], [0.5334, 0.3838, 0.6763, 0.0522, 0.4379, 0.481, 0.3635]], [[0.8402, 0.5301, 0.9179, 0.6251, 0.4014, 0.012, 0.6916], [0.2431, 0.5879, 0.2522, 0.0029, 0.5933, 0.009, 0.8895]], [[0.7324, 0.9272, 0.8276, 0.154, 0.7818, 0.314, 0.0635], [0.4344, 0.9813, 0.7452, 0.0345, 0.5082, 0.8789, 0.3055]]]]], 3, Con74385), 
LMax75570 = maximum_layer([Res78773,Con74385], Max75570), 
LRes27231 = reshape_layer(Max75570, [6, 16], Res27231), 
LUp_52007 = up_sampling1D_layer(Res27231, 2, Up_52007), 
LFla68191 = flatten_layer(Up_52007, Fla68191), 
LDot72056 = dot_layer([[0.2142, 0.4995, 0.2537]], [[0.8681, 0.7595, 0.6068]], 1, 1, Dot72056), 
LRes18452 = reshape_layer(Dot72056, [1, 1], Res18452), 
LRes34498 = reshape_layer(Res18452, [1, 1, 1], Res34498), 
LGlo15656 = global_average_pooling2D_layer(Res34498, Glo15656), 
LCon32833 = concatenate_layer([Glo15656,[[0.1516, 0.1679, 0.9253, 0.0615, 0.8641, 0.604, 0.8989, 0.6468, 0.4812, 0.4147, 0.9569, 0.3021, 0.3918, 0.9823, 0.5853, 0.0563, 0.0175, 0.6129, 0.3846, 0.2704, 0.4766, 0.2698, 0.911, 0.022, 0.5953, 0.8186, 0.3917, 0.6503, 0.8785, 0.7804, 0.1545, 0.7478, 0.5458, 0.2761, 0.8103, 0.4119, 0.8951, 0.4479, 0.5856, 0.4892, 0.0634, 0.1482, 0.7142, 0.8835, 0.7218, 0.094, 0.464, 0.7363, 0.3615, 0.0075, 0.2043, 0.4324, 0.6102, 0.4829, 0.8962, 0.9379, 0.447, 0.4513, 0.5292, 0.9327, 0.2805, 0.1513, 0.3192, 0.5676, 0.5976, 0.4553, 0.9358, 0.4426, 0.2961, 0.2504, 0.6294, 0.583, 0.873, 0.327, 0.8953, 0.7706, 0.3565, 0.8898, 0.2285, 0.5786, 0.2416, 0.3739, 0.5983, 0.8527, 0.7168, 0.7206, 0.5044, 0.1827, 0.1561, 0.6493, 0.8633, 0.1192, 0.1889, 0.7469, 0.5166, 0.5, 0.6584, 0.3885, 0.8549, 0.2761, 0.4336, 0.6028, 0.9066, 0.6501, 0.347, 0.999, 0.2531, 0.1756, 0.4989, 0.7842, 0.3018, 0.7027, 0.7885, 0.7179, 0.7721, 0.7036, 0.8126, 0.5728, 0.7334, 0.5604, 0.2054, 0.3008, 0.1692, 0.8584, 0.0857, 0.6421, 0.8366, 0.5899, 0.5221, 0.353, 0.1416, 0.4466, 0.8338, 0.5813, 0.8542, 0.0522, 0.1005, 0.1692, 0.7539, 0.0732, 0.4734, 0.8279, 0.7115, 0.6329, 0.7493, 0.1931, 0.2907, 0.3497, 0.2005, 0.7455, 0.6833, 0.623, 0.8358, 0.4603, 0.68, 0.4977, 0.1081, 0.8354, 0.4219, 0.5515, 0.5856, 0.6392, 0.8806, 0.7729, 0.2498, 0.3217, 0.3658, 0.3198, 0.9001, 0.5311, 0.8797, 0.3859, 0.6064, 0.5958, 0.7986, 0.1395, 0.2738, 0.1443, 0.1931, 0.8441, 0.1633, 0.2607, 0.0774, 0.8239, 0.6451, 0.7054, 0.0143, 0.8929, 0.554, 0.7621, 0.801]]], 1, Con32833), 
LAve39035 = average_layer([Fla68191,Con32833], Ave39035), 
exec_layers([LUp_83546,LRes78773,LAve7399,LZer41152,LCon74385,LMax75570,LRes27231,LUp_52007,LFla68191,LDot72056,LRes18452,LRes34498,LGlo15656,LCon32833,LAve39035],["Up_83546","Res78773","Ave7399","Zer41152","Con74385","Max75570","Res27231","Up_52007","Fla68191","Dot72056","Res18452","Res34498","Glo15656","Con32833","Ave39035"],Ave39035,"Ave39035")

Actual (Unparsed): [[1.0666812, 1.0544500, 0.7910000, 1.4413000, 0.5765000, 1.0506000, 0.8477500, 1.0680000, 1.0304500, 1.2192500, 0.9144000, 1.4571000, 0.6968000, 0.8144500, 1.0369000, 0.9112000, 0.7352000, 0.9874000, 1.0135000, 1.1709500, 0.6809500, 0.8568500, 0.6806500, 1.0740500, 0.7180500, 1.2763000, 1.1163500, 1.1745000, 0.8709000, 1.0578000, 0.9359500, 0.6958000, 1.0809500, 1.2515500, 0.8451000, 1.3838000, 0.7517000, 1.0661000, 0.7697000, 0.9113500, 0.9516500, 1.0103500, 0.7811500, 1.3357500, 0.9875000, 0.9794500, 0.5927500, 0.8505500, 1.0752000, 1.1594000, 0.7108000, 1.0808000, 0.7619500, 0.9236500, 0.7872000, 1.0666500, 1.1760000, 1.2021500, 0.9327000, 1.2432500, 1.0121000, 0.7588000, 0.6214000, 0.7781500, 0.9526500, 1.0568500, 0.8965000, 1.2259500, 1.0928000, 0.9332000, 0.9967000, 1.0998500, 0.9603500, 1.1945500, 0.8323500, 1.2057000, 1.2568000, 0.9634000, 1.3164000, 0.8994000, 0.9581500, 0.8788500, 0.8558000, 1.0572000, 1.2978500, 1.1435500, 1.2318000, 1.0373500, 0.7602000, 0.8361000, 0.9935000, 1.1897000, 0.9311000, 0.8796000, 1.2449500, 1.0434500, 0.9188500, 1.0872500, 0.8631000, 1.1855000, 1.0095500, 1.0019500, 1.1729000, 1.2384500, 0.9939000, 0.9315500, 1.1683500, 0.8846000, 0.9593000, 1.0346000, 1.2636000, 0.9360500, 1.0202000, 1.1523000, 1.0278000, 1.1441000, 1.2233000, 1.1914500, 1.1579000, 1.1518500, 0.9490500, 0.8607500, 0.8192500, 0.8426500, 1.3007000, 0.8280000, 1.1925500, 1.2034500, 1.0870500, 0.7776000, 0.9686000, 0.5873500, 0.8210500, 1.2584000, 0.8884000, 1.2686000, 0.8182000, 0.5668000, 0.8767000, 0.8935000, 0.6343500, 1.0782000, 1.0117000, 1.1972500, 1.1085500, 0.8912000, 0.8886500, 0.6619000, 0.7726000, 0.9417500, 0.9705000, 1.1831500, 1.1036000, 0.9344500, 1.0222500, 0.8565500, 0.8466000, 0.8955500, 1.0154500, 1.0524500, 1.0678500, 0.8093500, 1.1117000, 0.9568500, 0.9842000, 0.9664000, 0.7586000, 1.0244000, 0.9520000, 0.9666000, 1.0576500, 0.9564000, 0.7907000, 1.1447000, 0.8956500, 1.2408000, 0.8618500, 0.6534500, 0.8642500, 0.6131000, 1.0198000, 0.9231500, 0.7281000, 0.8802000, 1.2040500, 0.8391000, 1.1448000, 0.5237000, 1.0442000, 1.1185000, 0.9788000, 1.2420000]]

Expected (Unparsed): [[1.066681215,1.05445,0.7909999999999999,1.4413,0.5765,1.0506,0.84775,1.068,1.03045,1.21925,0.9144,1.4571,0.6968,0.81445,1.0369,0.9112,0.7352,0.9874,1.0135,1.17095,0.6809499999999999,0.8568500000000001,0.68065,1.0740500000000002,0.71805,1.2763,1.11635,1.1745,0.8709,1.0578,0.93595,0.6958000000000001,1.08095,1.25155,0.8451,1.3838,0.7516999999999999,1.0661,0.7696999999999999,0.9113500000000001,0.95165,1.01035,0.78115,1.33575,0.9874999999999999,0.97945,0.59275,0.85055,1.0752,1.1594,0.7108,1.0808,0.7619499999999999,0.9236500000000001,0.7871999999999999,1.06665,1.176,1.20215,0.9327,1.24325,1.0121,0.7588,0.6214,0.77815,0.95265,1.05685,0.8965,1.22595,1.0928,0.9332,0.9967,1.09985,0.9603499999999999,1.19455,0.8323499999999999,1.2057,1.2568000000000001,0.9634,1.3164,0.8994,0.95815,0.87885,0.8557999999999999,1.0572,1.29785,1.14355,1.2318,1.03735,0.7602,0.8361,0.9934999999999999,1.1897,0.9311,0.8796,1.24495,1.04345,0.91885,1.08725,0.8631,1.1855,1.00955,1.00195,1.1729,1.23845,0.9939,0.93155,1.16835,0.8846,0.9593,1.0346,1.2636,0.93605,1.0202,1.1522999999999999,1.0278,1.1441,1.2233,1.1914500000000001,1.1579000000000002,1.15185,0.94905,0.86075,0.8192499999999999,0.84265,1.3007,0.8280000000000001,1.19255,1.2034500000000001,1.08705,0.7776,0.9686,0.5873499999999999,0.8210500000000001,1.2584,0.8884000000000001,1.2686,0.8182,0.5668,0.8767,0.8935,0.63435,1.0782,1.0117,1.19725,1.1085500000000001,0.8912,0.88865,0.6618999999999999,0.7726,0.9417500000000001,0.9705,1.18315,1.1036000000000001,0.93445,1.02225,0.8565499999999999,0.8466,0.8955500000000001,1.01545,1.05245,1.06785,0.80935,1.1117,0.95685,0.9842,0.9664,0.7585999999999999,1.0244,0.952,0.9665999999999999,1.05765,0.9563999999999999,0.7907,1.1447,0.8956500000000001,1.2408000000000001,0.86185,0.65345,0.8642500000000001,0.6131,1.0198,0.92315,0.7281,0.8802,1.20405,0.8391,1.1448,0.5236999999999999,1.0442,1.1185,0.9788,1.242]]

Actual:   [[1.0667, 1.0545, 0.791, 1.4413, 0.5765, 1.0506, 0.8478, 1.068, 1.0305, 1.2193, 0.9144, 1.4571, 0.6968, 0.8145, 1.0369, 0.9112, 0.7352, 0.9874, 1.0135, 1.171, 0.681, 0.8569, 0.6807, 1.0741, 0.7181, 1.2763, 1.1164, 1.1745, 0.8709, 1.0578, 0.936, 0.6958, 1.081, 1.2516, 0.8451, 1.3838, 0.7517, 1.0661, 0.7697, 0.9114, 0.9517, 1.0104, 0.7812, 1.3358, 0.9875, 0.9795, 0.5928, 0.8506, 1.0752, 1.1594, 0.7108, 1.0808, 0.762, 0.9237, 0.7872, 1.0667, 1.176, 1.2022, 0.9327, 1.2433, 1.0121, 0.7588, 0.6214, 0.7782, 0.9527, 1.0569, 0.8965, 1.226, 1.0928, 0.9332, 0.9967, 1.0999, 0.9604, 1.1946, 0.8324, 1.2057, 1.2568, 0.9634, 1.3164, 0.8994, 0.9582, 0.8789, 0.8558, 1.0572, 1.2979, 1.1436, 1.2318, 1.0374, 0.7602, 0.8361, 0.9935, 1.1897, 0.9311, 0.8796, 1.245, 1.0435, 0.9189, 1.0873, 0.8631, 1.1855, 1.0096, 1.002, 1.1729, 1.2385, 0.9939, 0.9316, 1.1684, 0.8846, 0.9593, 1.0346, 1.2636, 0.9361, 1.0202, 1.1523, 1.0278, 1.1441, 1.2233, 1.1915, 1.1579, 1.1519, 0.9491, 0.8608, 0.8193, 0.8427, 1.3007, 0.828, 1.1926, 1.2035, 1.0871, 0.7776, 0.9686, 0.5874, 0.8211, 1.2584, 0.8884, 1.2686, 0.8182, 0.5668, 0.8767, 0.8935, 0.6344, 1.0782, 1.0117, 1.1973, 1.1086, 0.8912, 0.8887, 0.6619, 0.7726, 0.9418, 0.9705, 1.1832, 1.1036, 0.9345, 1.0223, 0.8566, 0.8466, 0.8956, 1.0155, 1.0525, 1.0679, 0.8094, 1.1117, 0.9569, 0.9842, 0.9664, 0.7586, 1.0244, 0.952, 0.9666, 1.0577, 0.9564, 0.7907, 1.1447, 0.8957, 1.2408, 0.8619, 0.6535, 0.8643, 0.6131, 1.0198, 0.9232, 0.7281, 0.8802, 1.2041, 0.8391, 1.1448, 0.5237, 1.0442, 1.1185, 0.9788, 1.242]]

Expected: [[1.0667, 1.0545, 0.791, 1.4413, 0.5765, 1.0506, 0.8478, 1.068, 1.0305, 1.2193, 0.9144, 1.4571, 0.6968, 0.8145, 1.0369, 0.9112, 0.7352, 0.9874, 1.0135, 1.171, 0.681, 0.8569, 0.6807, 1.0741, 0.7181, 1.2763, 1.1164, 1.1745, 0.8709, 1.0578, 0.936, 0.6959, 1.081, 1.2516, 0.8451, 1.3838, 0.7517, 1.0661, 0.7697, 0.9114, 0.9517, 1.0104, 0.7812, 1.3358, 0.9875, 0.9795, 0.5928, 0.8506, 1.0752, 1.1594, 0.7108, 1.0808, 0.762, 0.9237, 0.7872, 1.0667, 1.176, 1.2022, 0.9327, 1.2433, 1.0121, 0.7588, 0.6214, 0.7782, 0.9527, 1.0569, 0.8965, 1.226, 1.0928, 0.9332, 0.9967, 1.0999, 0.9604, 1.1946, 0.8324, 1.2057, 1.2569, 0.9634, 1.3164, 0.8994, 0.9582, 0.8789, 0.8558, 1.0572, 1.2979, 1.1436, 1.2318, 1.0374, 0.7602, 0.8361, 0.9935, 1.1897, 0.9311, 0.8796, 1.245, 1.0435, 0.9189, 1.0873, 0.8631, 1.1855, 1.0096, 1.002, 1.1729, 1.2385, 0.9939, 0.9316, 1.1684, 0.8846, 0.9593, 1.0346, 1.2636, 0.9361, 1.0202, 1.1523, 1.0278, 1.1441, 1.2233, 1.1915, 1.158, 1.1519, 0.9491, 0.8608, 0.8193, 0.8427, 1.3007, 0.8281, 1.1926, 1.2035, 1.0871, 0.7776, 0.9686, 0.5874, 0.8211, 1.2584, 0.8885, 1.2686, 0.8182, 0.5668, 0.8767, 0.8935, 0.6344, 1.0782, 1.0117, 1.1973, 1.1086, 0.8912, 0.8887, 0.6619, 0.7726, 0.9418, 0.9705, 1.1832, 1.1037, 0.9345, 1.0223, 0.8566, 0.8466, 0.8956, 1.0155, 1.0525, 1.0679, 0.8094, 1.1117, 0.9569, 0.9842, 0.9664, 0.7586, 1.0244, 0.952, 0.9666, 1.0577, 0.9564, 0.7907, 1.1447, 0.8957, 1.2409, 0.8619, 0.6535, 0.8643, 0.6131, 1.0198, 0.9232, 0.7281, 0.8802, 1.2041, 0.8391, 1.1448, 0.5237, 1.0442, 1.1185, 0.9788, 1.242]]