import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer38110 = tf.keras.layers.Input(shape=([3, 3, 2, 1]))

Zer38110 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer38110', )(in0Zer38110)
ReL83560 = keras.layers.ReLU(max_value=3.217973599374375, negative_slope=4.29363305020405, threshold=5.333572791798278, name = 'ReL83560', )(Zer38110)
Res48124 = keras.layers.Reshape((5, 5, 4), name = 'Res48124', )(ReL83560)
Res63247 = keras.layers.Reshape((5, 20), name = 'Res63247', )(Res48124)
Con86554 = keras.layers.Conv1D(4, (5),strides=(2), padding='valid', dilation_rate=(1), name = 'Con86554', )(Res63247)
Res20613 = keras.layers.Reshape((1, 4, 1), name = 'Res20613', )(Con86554)
Res71336 = keras.layers.Reshape((1, 4, 1, 1), name = 'Res71336', )(Res20613)
Glo99219 = keras.layers.GlobalMaxPool3D(name = 'Glo99219', )(Res71336)
model = tf.keras.models.Model(inputs=[in0Zer38110], outputs=Glo99219)
w = model.get_layer('Con86554').get_weights() 
w[0] = np.array([[[0.3255, 0.8028, 0.1926, 0.7569], [0.0234, 0.1611, 0.7135, 0.329], [0.5136, 0.3138, 0.9672, 0.4751], [0.1943, 0.4341, 0.1797, 0.1375], [0.217, 0.1609, 0.7685, 0.0494], [0.4731, 0.8802, 0.9027, 0.2852], [0.5704, 0.5224, 0.0922, 0.4263], [0.8255, 0.9958, 0.6228, 0.2315], [0.9884, 0.579, 0.1815, 0.8543], [0.0149, 0.9468, 0.9372, 0.4585], [0.7092, 0.0226, 0.6776, 0.55], [0.4657, 0.5143, 0.3435, 0.4635], [0.6621, 0.8188, 0.443, 0.2241], [0.4749, 0.9603, 0.3864, 0.4332], [0.0206, 0.3671, 0.7324, 0.9252], [0.7616, 0.5818, 0.7093, 0.6829], [0.0572, 0.4549, 0.1375, 0.9069], [0.5915, 0.9744, 0.0615, 0.1916], [0.1603, 0.648, 0.9813, 0.4768], [0.9654, 0.2743, 0.5608, 0.8164]], [[0.1283, 0.0132, 0.0881, 0.0337], [0.6099, 0.8976, 0.7642, 0.0169], [0.1042, 0.3172, 0.1036, 0.7503], [0.758, 0.5473, 0.3452, 0.1724], [0.7621, 0.0969, 0.7928, 0.6074], [0.9584, 0.5075, 0.4302, 0.8233], [0.6113, 0.2443, 0.9902, 0.7387], [0.4027, 0.4936, 0.8945, 0.4201], [0.5301, 0.0022, 0.1287, 0.2913], [0.5061, 0.5788, 0.1673, 0.4101], [0.8923, 0.5136, 0.5217, 0.2595], [0.733, 0.9659, 0.3486, 0.7454], [0.9, 0.321, 0.8269, 0.9997], [0.9036, 0.624, 0.6875, 0.1432], [0.9865, 0.4585, 0.3643, 0.3822], [0.4707, 0.0608, 0.7224, 0.6816], [0.4019, 0.0325, 0.2167, 0.7883], [0.5049, 0.7474, 0.6348, 0.5614], [0.3449, 0.4348, 0.2868, 0.4077], [0.3766, 0.968, 0.6174, 0.117]], [[0.2539, 0.5829, 0.7386, 0.546], [0.3722, 0.1125, 0.3062, 0.4087], [0.121, 0.832, 0.4962, 0.8969], [0.734, 0.6813, 0.5785, 0.977], [0.9425, 0.4534, 0.7282, 0.9871], [0.8617, 0.523, 0.2678, 0.5927], [0.6678, 0.8231, 0.4928, 0.2515], [0.6628, 0.0737, 0.5946, 0.0833], [0.2618, 0.7166, 0.9681, 0.4445], [0.2922, 0.6169, 0.366, 0.5685], [0.7427, 0.3525, 0.9456, 0.3451], [0.7668, 0.8355, 0.2439, 0.6876], [0.3088, 0.0811, 0.5105, 0.9635], [0.1956, 0.1731, 0.632, 0.6483], [0.9186, 0.8619, 0.0865, 0.7044], [0.6125, 0.7757, 0.9841, 0.1823], [0.9356, 0.9242, 0.2689, 0.1965], [0.6493, 0.0327, 0.5822, 0.7368], [0.7029, 0.2555, 0.1241, 0.7423], [0.54, 0.9868, 0.087, 0.486]], [[0.1596, 0.8131, 0.8791, 0.5986], [0.1904, 0.1325, 0.4116, 0.9929], [0.8631, 0.6021, 0.1777, 0.5412], [0.3061, 0.3726, 0.717, 0.6054], [0.0298, 0.0147, 0.3301, 0.4238], [0.8125, 0.1521, 0.5835, 0.9164], [0.4588, 0.0765, 0.2297, 0.6867], [0.0593, 0.0395, 0.6552, 0.8725], [0.4502, 0.4925, 0.8646, 0.022], [0.5441, 0.2745, 0.3121, 0.3608], [0.0822, 0.6388, 0.5986, 0.6532], [0.1465, 0.0514, 0.167, 0.3581], [0.4608, 0.8935, 0.6484, 0.9365], [0.1089, 0.5595, 0.4407, 0.9724], [0.8041, 0.9522, 0.4311, 0.239], [0.2528, 0.0471, 0.515, 0.9608], [0.4754, 0.022, 0.7101, 0.3032], [0.1691, 0.4311, 0.214, 0.5542], [0.328, 0.0386, 0.7133, 0.5531], [0.3716, 0.2213, 0.6161, 0.6716]], [[0.9758, 0.3019, 0.65, 0.0497], [0.6492, 0.7773, 0.445, 0.8562], [0.8508, 0.1729, 0.3025, 0.0525], [0.1086, 0.1697, 0.3431, 0.5146], [0.1641, 0.7282, 0.6182, 0.3951], [0.643, 0.1638, 0.5762, 0.2917], [0.1304, 0.5156, 0.4774, 0.1299], [0.8167, 0.0958, 0.9709, 0.6634], [0.0714, 0.8056, 0.063, 0.1514], [0.4026, 0.6609, 0.1359, 0.0787], [0.2607, 0.9835, 0.5084, 0.7529], [0.0628, 0.8827, 0.2673, 0.2333], [0.6233, 0.9762, 0.7479, 0.3252], [0.9083, 0.7836, 0.0887, 0.3075], [0.6534, 0.8588, 0.7475, 0.6534], [0.9276, 0.5264, 0.7281, 0.249], [0.1631, 0.0349, 0.5392, 0.5198], [0.5222, 0.0448, 0.5803, 0.4341], [0.7267, 0.636, 0.7375, 0.5681], [0.6366, 0.4343, 0.4572, 0.2885]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con86554').set_weights(w) 
in0Zer38110 = tf.constant([[[[[1.6805], [1.9925]], [[1.7029], [1.1764]], [[1.894], [1.2368]]], [[[1.3712], [1.7637]], [[1.4556], [1.6685]], [[1.5234], [1.0689]]], [[[1.2783], [1.5269]], [[1.0083], [1.3517]], [[1.7023], [1.7882]]]]])
print (np.array2string(model.predict([in0Zer38110],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Glo99219.png')

LZer38110 = zero_padding3D_layer([[[[[1.6805], [1.9925]], [[1.7029], [1.1764]], [[1.894], [1.2368]]], [[[1.3712], [1.7637]], [[1.4556], [1.6685]], [[1.5234], [1.0689]]], [[[1.2783], [1.5269]], [[1.0083], [1.3517]], [[1.7023], [1.7882]]]]], 1, 1, 1, 1, 1, 1, Zer38110), 
LReL83560 = relu_layer(Zer38110, 3.217973599374375, 4.29363305020405, 5.333572791798278, ReL83560), 
LRes48124 = reshape_layer(ReL83560, [5, 5, 4], Res48124), 
LRes63247 = reshape_layer(Res48124, [5, 20], Res63247), 
LCon86554 = conv1D_layer(Res63247, 5,[[[0.3255, 0.8028, 0.1926, 0.7569], [0.0234, 0.1611, 0.7135, 0.329], [0.5136, 0.3138, 0.9672, 0.4751], [0.1943, 0.4341, 0.1797, 0.1375], [0.217, 0.1609, 0.7685, 0.0494], [0.4731, 0.8802, 0.9027, 0.2852], [0.5704, 0.5224, 0.0922, 0.4263], [0.8255, 0.9958, 0.6228, 0.2315], [0.9884, 0.579, 0.1815, 0.8543], [0.0149, 0.9468, 0.9372, 0.4585], [0.7092, 0.0226, 0.6776, 0.55], [0.4657, 0.5143, 0.3435, 0.4635], [0.6621, 0.8188, 0.443, 0.2241], [0.4749, 0.9603, 0.3864, 0.4332], [0.0206, 0.3671, 0.7324, 0.9252], [0.7616, 0.5818, 0.7093, 0.6829], [0.0572, 0.4549, 0.1375, 0.9069], [0.5915, 0.9744, 0.0615, 0.1916], [0.1603, 0.648, 0.9813, 0.4768], [0.9654, 0.2743, 0.5608, 0.8164]], [[0.1283, 0.0132, 0.0881, 0.0337], [0.6099, 0.8976, 0.7642, 0.0169], [0.1042, 0.3172, 0.1036, 0.7503], [0.758, 0.5473, 0.3452, 0.1724], [0.7621, 0.0969, 0.7928, 0.6074], [0.9584, 0.5075, 0.4302, 0.8233], [0.6113, 0.2443, 0.9902, 0.7387], [0.4027, 0.4936, 0.8945, 0.4201], [0.5301, 0.0022, 0.1287, 0.2913], [0.5061, 0.5788, 0.1673, 0.4101], [0.8923, 0.5136, 0.5217, 0.2595], [0.733, 0.9659, 0.3486, 0.7454], [0.9, 0.321, 0.8269, 0.9997], [0.9036, 0.624, 0.6875, 0.1432], [0.9865, 0.4585, 0.3643, 0.3822], [0.4707, 0.0608, 0.7224, 0.6816], [0.4019, 0.0325, 0.2167, 0.7883], [0.5049, 0.7474, 0.6348, 0.5614], [0.3449, 0.4348, 0.2868, 0.4077], [0.3766, 0.968, 0.6174, 0.117]], [[0.2539, 0.5829, 0.7386, 0.546], [0.3722, 0.1125, 0.3062, 0.4087], [0.121, 0.832, 0.4962, 0.8969], [0.734, 0.6813, 0.5785, 0.977], [0.9425, 0.4534, 0.7282, 0.9871], [0.8617, 0.523, 0.2678, 0.5927], [0.6678, 0.8231, 0.4928, 0.2515], [0.6628, 0.0737, 0.5946, 0.0833], [0.2618, 0.7166, 0.9681, 0.4445], [0.2922, 0.6169, 0.366, 0.5685], [0.7427, 0.3525, 0.9456, 0.3451], [0.7668, 0.8355, 0.2439, 0.6876], [0.3088, 0.0811, 0.5105, 0.9635], [0.1956, 0.1731, 0.632, 0.6483], [0.9186, 0.8619, 0.0865, 0.7044], [0.6125, 0.7757, 0.9841, 0.1823], [0.9356, 0.9242, 0.2689, 0.1965], [0.6493, 0.0327, 0.5822, 0.7368], [0.7029, 0.2555, 0.1241, 0.7423], [0.54, 0.9868, 0.087, 0.486]], [[0.1596, 0.8131, 0.8791, 0.5986], [0.1904, 0.1325, 0.4116, 0.9929], [0.8631, 0.6021, 0.1777, 0.5412], [0.3061, 0.3726, 0.717, 0.6054], [0.0298, 0.0147, 0.3301, 0.4238], [0.8125, 0.1521, 0.5835, 0.9164], [0.4588, 0.0765, 0.2297, 0.6867], [0.0593, 0.0395, 0.6552, 0.8725], [0.4502, 0.4925, 0.8646, 0.022], [0.5441, 0.2745, 0.3121, 0.3608], [0.0822, 0.6388, 0.5986, 0.6532], [0.1465, 0.0514, 0.167, 0.3581], [0.4608, 0.8935, 0.6484, 0.9365], [0.1089, 0.5595, 0.4407, 0.9724], [0.8041, 0.9522, 0.4311, 0.239], [0.2528, 0.0471, 0.515, 0.9608], [0.4754, 0.022, 0.7101, 0.3032], [0.1691, 0.4311, 0.214, 0.5542], [0.328, 0.0386, 0.7133, 0.5531], [0.3716, 0.2213, 0.6161, 0.6716]], [[0.9758, 0.3019, 0.65, 0.0497], [0.6492, 0.7773, 0.445, 0.8562], [0.8508, 0.1729, 0.3025, 0.0525], [0.1086, 0.1697, 0.3431, 0.5146], [0.1641, 0.7282, 0.6182, 0.3951], [0.643, 0.1638, 0.5762, 0.2917], [0.1304, 0.5156, 0.4774, 0.1299], [0.8167, 0.0958, 0.9709, 0.6634], [0.0714, 0.8056, 0.063, 0.1514], [0.4026, 0.6609, 0.1359, 0.0787], [0.2607, 0.9835, 0.5084, 0.7529], [0.0628, 0.8827, 0.2673, 0.2333], [0.6233, 0.9762, 0.7479, 0.3252], [0.9083, 0.7836, 0.0887, 0.3075], [0.6534, 0.8588, 0.7475, 0.6534], [0.9276, 0.5264, 0.7281, 0.249], [0.1631, 0.0349, 0.5392, 0.5198], [0.5222, 0.0448, 0.5803, 0.4341], [0.7267, 0.636, 0.7375, 0.5681], [0.6366, 0.4343, 0.4572, 0.2885]]],[0, 0, 0, 0], 2, false, 1, Con86554), 
LRes20613 = reshape_layer(Con86554, [1, 4, 1], Res20613), 
LRes71336 = reshape_layer(Res20613, [1, 4, 1, 1], Res71336), 
LGlo99219 = global_max_pool3D_layer(Res71336, Glo99219), 
exec_layers([LZer38110,LReL83560,LRes48124,LRes63247,LCon86554,LRes20613,LRes71336,LGlo99219],["Zer38110","ReL83560","Res48124","Res63247","Con86554","Res20613","Res71336","Glo99219"],Glo99219,"Glo99219")

Actual (Unparsed): [[-1047.8500163]]

Expected (Unparsed): [[-1047.850016048393]]

Actual:   [[-1047.85]]

Expected: [[-1047.85]]