import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave43467 = tf.keras.layers.Input(shape=([1, 2]))
in1Ave43467 = tf.keras.layers.Input(shape=([1, 2]))
in0Zer43530 = tf.keras.layers.Input(shape=([3, 3, 1, 4]))
in0Con22906 = tf.keras.layers.Input(shape=([2]))

Ave43467 = keras.layers.Average(name = 'Ave43467', )([in0Ave43467,in1Ave43467])
Con81733 = keras.layers.Conv1D(4, (1),strides=(1), padding='valid', dilation_rate=(1), name = 'Con81733', )(Ave43467)
Fla77728 = keras.layers.Flatten(name = 'Fla77728', )(Con81733)
Zer43530 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer43530', )(in0Zer43530)
Res44653 = keras.layers.Reshape((5, 5, 12), name = 'Res44653', )(Zer43530)
Res11207 = keras.layers.Reshape((5, 60), name = 'Res11207', )(Res44653)
Sep5138 = keras.layers.SeparableConv1D(2, (4),strides=(1), padding='valid', name = 'Sep5138', )(Res11207)
GRU30647 = keras.layers.GRU(2,reset_after=False, recurrent_activation='sigmoid', name = 'GRU30647', )(Sep5138)
Con22906 = keras.layers.Concatenate(axis=1, name = 'Con22906', )([GRU30647,in0Con22906])
Add10182 = keras.layers.Add(name = 'Add10182', )([Fla77728,Con22906])
model = tf.keras.models.Model(inputs=[in0Ave43467,in1Ave43467,in0Zer43530,in0Con22906], outputs=Add10182)
w = model.get_layer('Con81733').get_weights() 
w[0] = np.array([[[0.7977, 0.6571, 0.3438, 0.176], [0.4345, 0.2485, 0.1065, 0.375]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con81733').set_weights(w) 
w = model.get_layer('Sep5138').get_weights() 
w[0] = np.array([[[0.1622], [0.7794], [0.2157], [0.7319], [0.3787], [0.5301], [0.0108], [0.1466], [0.2913], [0.6661], [0.579], [0.8769], [0.6948], [0.617], [0.0438], [0.7197], [0.8934], [0.7701], [0.658], [0.7746], [0.2234], [0.377], [0.431], [0.9073], [0.1249], [0.4646], [0.1817], [0.4352], [0.7695], [0.4964], [0.5341], [0.8108], [0.3426], [0.9731], [0.7343], [0.416], [0.957], [0.6425], [0.8066], [0.4498], [0.8305], [0.4953], [0.4926], [0.2895], [0.7991], [0.2639], [0.6181], [0.6366], [0.4572], [0.7141], [0.0204], [0.2222], [0.2171], [0.6187], [0.9338], [0.8373], [0.3621], [0.9401], [0.7794], [0.9792]], [[0.731], [0.4102], [0.6345], [0.4617], [0.0174], [0.3951], [0.2671], [0.9214], [0.7921], [0.6579], [0.5126], [0.2729], [0.2638], [0.3911], [0.9426], [0.8129], [0.4838], [0.6839], [0.2296], [0.8574], [0.1675], [0.4055], [0.3486], [0.5024], [0.5594], [0.3425], [0.7687], [0.3484], [0.7963], [0.3101], [0.0919], [0.7977], [0.043], [0.8727], [0.1695], [0.8426], [0.2624], [0.2547], [0.5909], [0.0983], [0.8641], [0.0021], [0.5791], [0.2023], [0.6293], [0.9608], [0.7511], [0.6024], [0.2486], [0.1815], [0.9045], [0.1846], [0.531], [0.429], [0.9785], [0.1557], [0.8403], [0.0783], [0.602], [0.0881]], [[0.6007], [0.3136], [0.1914], [0.0572], [0.7737], [0.7088], [0.3886], [0.36], [0.0563], [0.4693], [0.7401], [0.389], [0.1725], [0.837], [0.9103], [0.853], [0.042], [0.4227], [0.3948], [0.6873], [0.7948], [0.52], [0.6526], [0.6758], [0.5712], [0.7732], [0.813], [0.0191], [0.7992], [0.9284], [0.6288], [0.8264], [0.1705], [0.7771], [0.1448], [0.7829], [0.8532], [0.8195], [0.6307], [0.0509], [0.5712], [0.6186], [0.6872], [0.7984], [0.0576], [0.295], [0.0763], [0.6189], [0.0469], [0.1223], [0.7478], [0.5031], [0.4084], [0.719], [0.7417], [0.9571], [0.2435], [0.91], [0.1273], [0.3202]], [[0.7701], [0.9271], [0.91], [0.3315], [0.6007], [0.2567], [0.8818], [0.5162], [0.5822], [0.1049], [0.7236], [0.0212], [0.7121], [0.1486], [0.274], [0.1133], [0.7716], [0.9653], [0.7752], [0.6742], [0.2209], [0.299], [0.075], [0.6739], [0.5945], [0.1023], [0.2221], [0.7864], [0.1001], [0.1233], [0.6246], [0.0223], [0.3787], [0.6518], [0.9587], [0.496], [0.4137], [0.9294], [0.3131], [0.2218], [0.3909], [0.6371], [0.6335], [0.1343], [0.9074], [0.8259], [0.3918], [0.3721], [0.3001], [0.6284], [0.545], [0.224], [0.026], [0.1028], [0.275], [0.0442], [0.9609], [0.5958], [0.7009], [0.8671]]])
w[1] = np.array([[[0.2741, 0.3136], [0.128, 0.0133], [0.6386, 0.0351], [0.6508, 0.4085], [0.8176, 0.4833], [0.8609, 0.5541], [0.1424, 0.4718], [0.0528, 0.2783], [0.7173, 0.8754], [0.6929, 0.9323], [0.7434, 0.8201], [0.2589, 0.8883], [0.2855, 0.0618], [0.5485, 0.6302], [0.9266, 0.4422], [0.9438, 0.141], [0.4125, 0.8166], [0.0424, 0.6839], [0.826, 0.3908], [0.272, 0.008], [0.0513, 0.974], [0.5855, 0.472], [0.2895, 0.257], [0.1077, 0.5697], [0.1682, 0.8608], [0.6448, 0.8678], [0.5523, 0.5627], [0.3029, 0.4218], [0.5069, 0.8061], [0.0685, 0.3215], [0.9909, 0.326], [0.0981, 0.1378], [0.7639, 0.4819], [0.6345, 0.6894], [0.6818, 0.6791], [0.9228, 0.7312], [0.0227, 0.0808], [0.2353, 0.8762], [0.7362, 0.6676], [0.1285, 0.3069], [0.5446, 0.5815], [0.3566, 0.6063], [0.633, 0.6098], [0.4412, 0.3443], [0.2636, 0.6088], [0.7616, 0.8918], [0.025, 0.6449], [0.1673, 0.3037], [0.5829, 0.6402], [0.5406, 0.0115], [0.7385, 0.3491], [0.4394, 0.4956], [0.3212, 0.5637], [0.9362, 0.0701], [0.9402, 0.5489], [0.0358, 0.4073], [0.9062, 0.8411], [0.6032, 0.4511], [0.6937, 0.7099], [0.5592, 0.9253]]])
w[2] = np.array([0, 0])
model.get_layer('Sep5138').set_weights(w) 
w = model.get_layer('GRU30647').get_weights() 
w[0] = np.array([[2, 2, 9, 2, 6, 2], [7, 10, 1, 3, 1, 7]])
w[1] = np.array([[8, 9, 8, 7, 2, 9], [8, 4, 5, 10, 8, 1]])
w[2] = np.array([8, 8, 5, 6, 2, 1])
model.get_layer('GRU30647').set_weights(w) 
in0Ave43467 = tf.constant([[[0.3954, 0.7683]]])
in1Ave43467 = tf.constant([[[0.9572, 0.8341]]])
in0Zer43530 = tf.constant([[[[[1.7207, 1.5977, 1.2552, 1.9882]], [[1.6323, 1.5789, 1.6504, 1.7893]], [[1.8047, 1.613, 1.8564, 1.6864]]], [[[1.7248, 1.7849, 1.8254, 1.2814]], [[1.9354, 1.0161, 1.5427, 1.148]], [[1.3861, 1.3511, 1.2688, 1.569]]], [[[1.0992, 1.0706, 1.6361, 1.809]], [[1.3606, 1.8377, 1.8414, 1.5065]], [[1.5593, 1.2512, 1.4157, 1.3892]]]]])
in0Con22906 = tf.constant([[0.9114, 0.3008]])
print (np.array2string(model.predict([in0Ave43467,in1Ave43467,in0Zer43530,in0Con22906],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add10182.png')

LAve43467 = average_layer([[[[0.3954, 0.7683]]], [[[0.9572, 0.8341]]]], Ave43467), 
LCon81733 = conv1D_layer(Ave43467, 1,[[[0.7977, 0.6571, 0.3438, 0.176], [0.4345, 0.2485, 0.1065, 0.375]]],[0, 0, 0, 0], 1, false, 1, Con81733), 
LFla77728 = flatten_layer(Con81733, Fla77728), 
LZer43530 = zero_padding3D_layer([[[[[1.7207, 1.5977, 1.2552, 1.9882]], [[1.6323, 1.5789, 1.6504, 1.7893]], [[1.8047, 1.613, 1.8564, 1.6864]]], [[[1.7248, 1.7849, 1.8254, 1.2814]], [[1.9354, 1.0161, 1.5427, 1.148]], [[1.3861, 1.3511, 1.2688, 1.569]]], [[[1.0992, 1.0706, 1.6361, 1.809]], [[1.3606, 1.8377, 1.8414, 1.5065]], [[1.5593, 1.2512, 1.4157, 1.3892]]]]], 1, 1, 1, 1, 1, 1, Zer43530), 
LRes44653 = reshape_layer(Zer43530, [5, 5, 12], Res44653), 
LRes11207 = reshape_layer(Res44653, [5, 60], Res11207), 
LSep5138 = separable_conv1D_layer(Res11207, 4,[[[[0.1622], [0.7794], [0.2157], [0.7319], [0.3787], [0.5301], [0.0108], [0.1466], [0.2913], [0.6661], [0.579], [0.8769], [0.6948], [0.617], [0.0438], [0.7197], [0.8934], [0.7701], [0.658], [0.7746], [0.2234], [0.377], [0.431], [0.9073], [0.1249], [0.4646], [0.1817], [0.4352], [0.7695], [0.4964], [0.5341], [0.8108], [0.3426], [0.9731], [0.7343], [0.416], [0.957], [0.6425], [0.8066], [0.4498], [0.8305], [0.4953], [0.4926], [0.2895], [0.7991], [0.2639], [0.6181], [0.6366], [0.4572], [0.7141], [0.0204], [0.2222], [0.2171], [0.6187], [0.9338], [0.8373], [0.3621], [0.9401], [0.7794], [0.9792]], [[0.731], [0.4102], [0.6345], [0.4617], [0.0174], [0.3951], [0.2671], [0.9214], [0.7921], [0.6579], [0.5126], [0.2729], [0.2638], [0.3911], [0.9426], [0.8129], [0.4838], [0.6839], [0.2296], [0.8574], [0.1675], [0.4055], [0.3486], [0.5024], [0.5594], [0.3425], [0.7687], [0.3484], [0.7963], [0.3101], [0.0919], [0.7977], [0.043], [0.8727], [0.1695], [0.8426], [0.2624], [0.2547], [0.5909], [0.0983], [0.8641], [0.0021], [0.5791], [0.2023], [0.6293], [0.9608], [0.7511], [0.6024], [0.2486], [0.1815], [0.9045], [0.1846], [0.531], [0.429], [0.9785], [0.1557], [0.8403], [0.0783], [0.602], [0.0881]], [[0.6007], [0.3136], [0.1914], [0.0572], [0.7737], [0.7088], [0.3886], [0.36], [0.0563], [0.4693], [0.7401], [0.389], [0.1725], [0.837], [0.9103], [0.853], [0.042], [0.4227], [0.3948], [0.6873], [0.7948], [0.52], [0.6526], [0.6758], [0.5712], [0.7732], [0.813], [0.0191], [0.7992], [0.9284], [0.6288], [0.8264], [0.1705], [0.7771], [0.1448], [0.7829], [0.8532], [0.8195], [0.6307], [0.0509], [0.5712], [0.6186], [0.6872], [0.7984], [0.0576], [0.295], [0.0763], [0.6189], [0.0469], [0.1223], [0.7478], [0.5031], [0.4084], [0.719], [0.7417], [0.9571], [0.2435], [0.91], [0.1273], [0.3202]], [[0.7701], [0.9271], [0.91], [0.3315], [0.6007], [0.2567], [0.8818], [0.5162], [0.5822], [0.1049], [0.7236], [0.0212], [0.7121], [0.1486], [0.274], [0.1133], [0.7716], [0.9653], [0.7752], [0.6742], [0.2209], [0.299], [0.075], [0.6739], [0.5945], [0.1023], [0.2221], [0.7864], [0.1001], [0.1233], [0.6246], [0.0223], [0.3787], [0.6518], [0.9587], [0.496], [0.4137], [0.9294], [0.3131], [0.2218], [0.3909], [0.6371], [0.6335], [0.1343], [0.9074], [0.8259], [0.3918], [0.3721], [0.3001], [0.6284], [0.545], [0.224], [0.026], [0.1028], [0.275], [0.0442], [0.9609], [0.5958], [0.7009], [0.8671]]],[[[0.2741, 0.3136], [0.128, 0.0133], [0.6386, 0.0351], [0.6508, 0.4085], [0.8176, 0.4833], [0.8609, 0.5541], [0.1424, 0.4718], [0.0528, 0.2783], [0.7173, 0.8754], [0.6929, 0.9323], [0.7434, 0.8201], [0.2589, 0.8883], [0.2855, 0.0618], [0.5485, 0.6302], [0.9266, 0.4422], [0.9438, 0.141], [0.4125, 0.8166], [0.0424, 0.6839], [0.826, 0.3908], [0.272, 0.008], [0.0513, 0.974], [0.5855, 0.472], [0.2895, 0.257], [0.1077, 0.5697], [0.1682, 0.8608], [0.6448, 0.8678], [0.5523, 0.5627], [0.3029, 0.4218], [0.5069, 0.8061], [0.0685, 0.3215], [0.9909, 0.326], [0.0981, 0.1378], [0.7639, 0.4819], [0.6345, 0.6894], [0.6818, 0.6791], [0.9228, 0.7312], [0.0227, 0.0808], [0.2353, 0.8762], [0.7362, 0.6676], [0.1285, 0.3069], [0.5446, 0.5815], [0.3566, 0.6063], [0.633, 0.6098], [0.4412, 0.3443], [0.2636, 0.6088], [0.7616, 0.8918], [0.025, 0.6449], [0.1673, 0.3037], [0.5829, 0.6402], [0.5406, 0.0115], [0.7385, 0.3491], [0.4394, 0.4956], [0.3212, 0.5637], [0.9362, 0.0701], [0.9402, 0.5489], [0.0358, 0.4073], [0.9062, 0.8411], [0.6032, 0.4511], [0.6937, 0.7099], [0.5592, 0.9253]]]],[0, 0], 1, false, Sep5138), 
LGRU30647 = gru_layer(Sep5138,[[2, 2, 9, 2, 6, 2], [7, 10, 1, 3, 1, 7]],[[8, 9, 8, 7, 2, 9], [8, 4, 5, 10, 8, 1]],[8, 8, 5, 6, 2, 1], false, GRU30647), 
LCon22906 = concatenate_layer([GRU30647,[[0.9114, 0.3008]]], 1, Con22906), 
LAdd10182 = add_layer([Fla77728,Con22906], Add10182), 
exec_layers([LAve43467,LCon81733,LFla77728,LZer43530,LRes44653,LRes11207,LSep5138,LGRU30647,LCon22906,LAdd10182],["Ave43467","Con81733","Fla77728","Zer43530","Res44653","Res11207","Sep5138","GRU30647","Con22906","Add10182"],Add10182,"Add10182")

Actual (Unparsed): [[0.8876059, 0.6434949, 1.2292398, 0.7202788]]

Expected (Unparsed): [[0.88760591,0.64349493,1.22923974,0.7202788]]

Actual:   [[0.8877, 0.6435, 1.2293, 0.7203]]

Expected: [[0.8877, 0.6435, 1.2293, 0.7203]]