import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul34587 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in1Mul34587 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Ave13333 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Ave13333 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con21570 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Max81815 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in1Max81815 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))

Mul34587 = keras.layers.Multiply(name = 'Mul34587', )([in0Mul34587,in1Mul34587])
Res89290 = keras.layers.Reshape((1, 1, 4), name = 'Res89290', )(Mul34587)
Zer63989 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer63989', )(Res89290)
Ave13333 = keras.layers.Average(name = 'Ave13333', )([in0Ave13333,in1Ave13333])
Con21570 = keras.layers.Concatenate(axis=3, name = 'Con21570', )([Ave13333,in0Con21570])
Max42648 = keras.layers.Maximum(name = 'Max42648', )([Zer63989,Con21570])
Res3520 = keras.layers.Reshape((2, 2, 4, 1), name = 'Res3520', )(Max42648)
Max81815 = keras.layers.Maximum(name = 'Max81815', )([in0Max81815,in1Max81815])
Lea83346 = keras.layers.LeakyReLU(alpha=2.266873636212545, name = 'Lea83346', )(Max81815)
ReL86948 = keras.layers.ReLU(max_value=1.0235339119189582, negative_slope=6.350711399116871, threshold=5.3607250240408035, name = 'ReL86948', )(Lea83346)
Zer35371 = keras.layers.ZeroPadding3D(padding=((1, 0), (0, 0), (3, 0)), name = 'Zer35371', )(ReL86948)
Max82469 = keras.layers.Maximum(name = 'Max82469', )([Res3520,Zer35371])
model = tf.keras.models.Model(inputs=[in0Mul34587,in1Mul34587,in0Ave13333,in1Ave13333,in0Con21570,in0Max81815,in1Max81815], outputs=Max82469)
in0Mul34587 = tf.constant([[[[[0.7353, 0.8801], [0.6342, 0.2647]]]]])
in1Mul34587 = tf.constant([[[[[0.1859, 0.7683], [0.3308, 0.8112]]]]])
in0Ave13333 = tf.constant([[[[0.6077, 0.5439], [0.9308, 0.7793]], [[0.3006, 0.5124], [0.531, 0.4656]]]])
in1Ave13333 = tf.constant([[[[0.7288, 0.1937], [0.2485, 0.0093]], [[0.5669, 0.9841], [0.3737, 0.7886]]]])
in0Con21570 = tf.constant([[[[0.1768, 0.7459], [0.4451, 0.8528]], [[0.3648, 0.9094], [0.8519, 0.1141]]]])
in0Max81815 = tf.constant([[[[[0.8423]], [[0.3094]]]]])
in1Max81815 = tf.constant([[[[[0.7061]], [[0.1191]]]]])
print (np.array2string(model.predict([in0Mul34587,in1Mul34587,in0Ave13333,in1Ave13333,in0Con21570,in0Max81815,in1Max81815],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max82469.png')

LMul34587 = multiply_layer([[[[[[0.7353, 0.8801], [0.6342, 0.2647]]]]], [[[[[0.1859, 0.7683], [0.3308, 0.8112]]]]]], Mul34587), 
LRes89290 = reshape_layer(Mul34587, [1, 1, 4], Res89290), 
LZer63989 = zero_padding2D_layer(Res89290, 1, 0, 1, 0, Zer63989), 
LAve13333 = average_layer([[[[[0.6077, 0.5439], [0.9308, 0.7793]], [[0.3006, 0.5124], [0.531, 0.4656]]]], [[[[0.7288, 0.1937], [0.2485, 0.0093]], [[0.5669, 0.9841], [0.3737, 0.7886]]]]], Ave13333), 
LCon21570 = concatenate_layer([Ave13333,[[[[0.1768, 0.7459], [0.4451, 0.8528]], [[0.3648, 0.9094], [0.8519, 0.1141]]]]], 3, Con21570), 
LMax42648 = maximum_layer([Zer63989,Con21570], Max42648), 
LRes3520 = reshape_layer(Max42648, [2, 2, 4, 1], Res3520), 
LMax81815 = maximum_layer([[[[[[0.8423]], [[0.3094]]]]], [[[[[0.7061]], [[0.1191]]]]]], Max81815), 
LLea83346 = leaky_relu_layer(Max81815, 2.266873636212545, Lea83346), 
LReL86948 = relu_layer(Lea83346, 1.0235339119189582, 6.350711399116871, 5.3607250240408035, ReL86948), 
LZer35371 = zero_padding3D_layer(ReL86948, 1, 0, 0, 0, 3, 0, Zer35371), 
LMax82469 = maximum_layer([Res3520,Zer35371], Max82469), 
exec_layers([LMul34587,LRes89290,LZer63989,LAve13333,LCon21570,LMax42648,LRes3520,LMax81815,LLea83346,LReL86948,LZer35371,LMax82469],["Mul34587","Res89290","Zer63989","Ave13333","Con21570","Max42648","Res3520","Max81815","Lea83346","ReL86948","Zer35371","Max82469"],Max82469,"Max82469")

Actual (Unparsed): [[[[[0.6682500], [0.3688000], [0.1768000], [0.7459000]], [[0.5896500], [0.3943000], [0.4451000], [0.8528000]]], [[[0.4337500], [0.7482500], [0.3648000], [0.9094000]], [[0.4523500], [0.6761808], [0.8519000], [0.2147246]]]]]

Expected (Unparsed): [[[[[0.66825],[0.3688],[0.1768],[0.7459]],[[0.58965],[0.3943],[0.4451],[0.8528]]],[[[0.43374999999999997],[0.74825],[0.3648],[0.9094]],[[0.45235000000000003],[0.67618083],[0.8519],[0.21472464]]]]]

Actual:   [[[[[0.6683], [0.3688], [0.1768], [0.7459]], [[0.5897], [0.3943], [0.4451], [0.8528]]], [[[0.4338], [0.7483], [0.3648], [0.9094]], [[0.4524], [0.6762], [0.8519], [0.2148]]]]]

Expected: [[[[[0.6683], [0.3688], [0.1768], [0.7459]], [[0.5897], [0.3943], [0.4451], [0.8528]]], [[[0.4338], [0.7483], [0.3648], [0.9094]], [[0.4524], [0.6762], [0.8519], [0.2148]]]]]