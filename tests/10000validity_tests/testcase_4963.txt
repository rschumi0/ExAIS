import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Lay32869 = tf.keras.layers.Input(shape=([2, 4]))
in0Ave83713 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in1Ave83713 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in0Con31569 = tf.keras.layers.Input(shape=([4, 7]))

Lay32869 = keras.layers.LayerNormalization(axis=1, epsilon=1.8689288814733938, name = 'Lay32869', )(in0Lay32869)
Res13506 = keras.layers.Reshape((2, 4, 1), name = 'Res13506', )(Lay32869)
Up_54269 = keras.layers.UpSampling2D(size=(2, 2), name = 'Up_54269', )(Res13506)
Res32103 = keras.layers.Reshape((4, 8), name = 'Res32103', )(Up_54269)
Ave83713 = keras.layers.Average(name = 'Ave83713', )([in0Ave83713,in1Ave83713])
Res99875 = keras.layers.Reshape((2, 1, 2), name = 'Res99875', )(Ave83713)
Res64121 = keras.layers.Reshape((2, 2), name = 'Res64121', )(Res99875)
Glo1310 = keras.layers.GlobalMaxPool1D(name = 'Glo1310', )(Res64121)
Res26278 = keras.layers.Reshape((2, 1), name = 'Res26278', )(Glo1310)
PRe38680 = keras.layers.PReLU(name = 'PRe38680', )(Res26278)
Zer35415 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer35415', )(PRe38680)
Con31569 = keras.layers.Concatenate(axis=2, name = 'Con31569', )([Zer35415,in0Con31569])
Max24546 = keras.layers.Maximum(name = 'Max24546', )([Res32103,Con31569])
model = tf.keras.models.Model(inputs=[in0Lay32869,in0Ave83713,in1Ave83713,in0Con31569], outputs=Max24546)
w = model.get_layer('PRe38680').get_weights() 
w[0] = np.array([[0.8961], [0.4663]])
model.get_layer('PRe38680').set_weights(w) 
in0Lay32869 = tf.constant([[[1.9954, 1.2656, 1.2735, 1.8061], [1.4134, 1.7847, 1.8017, 1.1724]]])
in0Ave83713 = tf.constant([[[[[0.2064], [0.2816]]], [[[0.8207], [0.3712]]]]])
in1Ave83713 = tf.constant([[[[[0.8444], [0.2696]]], [[[0.3088], [0.4866]]]]])
in0Con31569 = tf.constant([[[0.0897, 0.7373, 0.7804, 0.6557, 0.7867, 0.5858, 0.0897], [0.3367, 0.9997, 0.154, 0.0899, 0.5681, 0.1708, 0.4398], [0.9069, 0.2812, 0.867, 0.4202, 0.7743, 0.9579, 0.5765], [0.0138, 0.1921, 0.7349, 0.527, 0.5187, 0.6387, 0.9264]]])
print (np.array2string(model.predict([in0Lay32869,in0Ave83713,in1Ave83713,in0Con31569],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max24546.png')

LLay32869 = layer_normalization_layer([[[1.9954, 1.2656, 1.2735, 1.8061], [1.4134, 1.7847, 1.8017, 1.1724]]], 1, 1.8689288814733938, Lay32869), 
LRes13506 = reshape_layer(Lay32869, [2, 4, 1], Res13506), 
LUp_54269 = up_sampling2D_layer(Res13506, 2, 2, Up_54269), 
LRes32103 = reshape_layer(Up_54269, [4, 8], Res32103), 
LAve83713 = average_layer([[[[[[0.2064], [0.2816]]], [[[0.8207], [0.3712]]]]], [[[[[0.8444], [0.2696]]], [[[0.3088], [0.4866]]]]]], Ave83713), 
LRes99875 = reshape_layer(Ave83713, [2, 1, 2], Res99875), 
LRes64121 = reshape_layer(Res99875, [2, 2], Res64121), 
LGlo1310 = global_max_pool1D_layer(Res64121, Glo1310), 
LRes26278 = reshape_layer(Glo1310, [2, 1], Res26278), 
LPRe38680 = prelu_layer(Res26278, [[0.8961], [0.4663]], PRe38680), 
LZer35415 = zero_padding1D_layer(PRe38680, 2, 0, Zer35415), 
LCon31569 = concatenate_layer([Zer35415,[[[0.0897, 0.7373, 0.7804, 0.6557, 0.7867, 0.5858, 0.0897], [0.3367, 0.9997, 0.154, 0.0899, 0.5681, 0.1708, 0.4398], [0.9069, 0.2812, 0.867, 0.4202, 0.7743, 0.9579, 0.5765], [0.0138, 0.1921, 0.7349, 0.527, 0.5187, 0.6387, 0.9264]]]], 2, Con31569), 
LMax24546 = maximum_layer([Res32103,Con31569], Max24546), 
exec_layers([LLay32869,LRes13506,LUp_54269,LRes32103,LAve83713,LRes99875,LRes64121,LGlo1310,LRes26278,LPRe38680,LZer35415,LCon31569,LMax24546],["Lay32869","Res13506","Up_54269","Res32103","Ave83713","Res99875","Res64121","Glo1310","Res26278","PRe38680","Zer35415","Con31569","Max24546"],Max24546,"Max24546")

Actual (Unparsed): [[[0.2081968, 0.2081968, 0.7373000, 0.7804000, 0.6557000, 0.7867000, 0.5858000, 0.2257851], [0.2081968, 0.3367000, 0.9997000, 0.1540000, 0.0899000, 0.5681000, 0.2257851, 0.4398000], [0.5647500, 0.9069000, 0.2812000, 0.8670000, 0.4202000, 0.7743000, 0.9579000, 0.5765000], [0.4289000, 0.0138000, 0.1921000, 0.7349000, 0.5270000, 0.5187000, 0.6387000, 0.9264000]]]

Expected (Unparsed): [[[0.20819680827010903,0.20819680827010903,0.7373,0.7804,0.6557,0.7867,0.5858,0.22578508852302373],[0.20819680827010903,0.3367,0.9997,0.154,0.0899,0.5681,0.22578508852302373,0.4398],[0.56475,0.9069,0.2812,0.867,0.4202,0.7743,0.9579,0.5765],[0.42889999999999995,0.0138,0.1921,0.7349,0.527,0.5187,0.6387,0.9264]]]

Actual:   [[[0.2082, 0.2082, 0.7373, 0.7804, 0.6557, 0.7867, 0.5858, 0.2258], [0.2082, 0.3367, 0.9997, 0.154, 0.0899, 0.5681, 0.2258, 0.4398], [0.5648, 0.9069, 0.2812, 0.867, 0.4202, 0.7743, 0.9579, 0.5765], [0.4289, 0.0138, 0.1921, 0.7349, 0.527, 0.5187, 0.6387, 0.9264]]]

Expected: [[[0.2082, 0.2082, 0.7373, 0.7804, 0.6557, 0.7867, 0.5858, 0.2258], [0.2082, 0.3367, 0.9997, 0.154, 0.0899, 0.5681, 0.2258, 0.4398], [0.5648, 0.9069, 0.2812, 0.867, 0.4202, 0.7743, 0.9579, 0.5765], [0.4289, 0.0138, 0.1921, 0.7349, 0.527, 0.5187, 0.6387, 0.9264]]]