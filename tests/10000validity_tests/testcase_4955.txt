import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add80233 = tf.keras.layers.Input(shape=([1, 2]))
in1Add80233 = tf.keras.layers.Input(shape=([1, 2]))
in0Dot77844 = tf.keras.layers.Input(shape=([2]))
in1Dot77844 = tf.keras.layers.Input(shape=([2]))
in0Con86216 = tf.keras.layers.Input(shape=([3, 1]))
in0Con63188 = tf.keras.layers.Input(shape=([16, 10]))
in0Max23572 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Max23572 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0GRU99621 = tf.keras.layers.Input(shape=([1, 2]))
in0Con98524 = tf.keras.layers.Input(shape=([13]))
in0Con83656 = tf.keras.layers.Input(shape=([16, 11]))
in0Bat50287 = tf.keras.layers.Input(shape=([3, 3, 4]))

Add80233 = keras.layers.Add(name = 'Add80233', )([in0Add80233,in1Add80233])
Zer43137 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer43137', )(Add80233)
Dot77844 = keras.layers.Dot(axes=(1, 1), name = 'Dot77844', )([in0Dot77844,in1Dot77844])
Res15350 = keras.layers.Reshape((1, 1), name = 'Res15350', )(Dot77844)
Zer69729 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer69729', )(Res15350)
Con86216 = keras.layers.Concatenate(axis=2, name = 'Con86216', )([Zer69729,in0Con86216])
Max43667 = keras.layers.Maximum(name = 'Max43667', )([Zer43137,Con86216])
Zer77056 = keras.layers.ZeroPadding1D(padding=((13, 0)), name = 'Zer77056', )(Max43667)
Con63188 = keras.layers.Concatenate(axis=2, name = 'Con63188', )([Zer77056,in0Con63188])
Max23572 = keras.layers.Maximum(name = 'Max23572', )([in0Max23572,in1Max23572])
Res68038 = keras.layers.Reshape((2, 2, 4), name = 'Res68038', )(Max23572)
Res75280 = keras.layers.Reshape((2, 8), name = 'Res75280', )(Res68038)
Fla64490 = keras.layers.Flatten(name = 'Fla64490', )(Res75280)
GRU99621 = keras.layers.GRU(3,reset_after=False, recurrent_activation='sigmoid', name = 'GRU99621', )(in0GRU99621)
Con98524 = keras.layers.Concatenate(axis=1, name = 'Con98524', )([GRU99621,in0Con98524])
Sub82102 = keras.layers.Subtract(name = 'Sub82102', )([Fla64490,Con98524])
Res55245 = keras.layers.Reshape((16, 1), name = 'Res55245', )(Sub82102)
Con83656 = keras.layers.Concatenate(axis=2, name = 'Con83656', )([Res55245,in0Con83656])
Bat50287 = keras.layers.BatchNormalization(axis=3, epsilon=0.8039190117466181,  name = 'Bat50287', )(in0Bat50287)
Res96345 = keras.layers.Reshape((3, 12), name = 'Res96345', )(Bat50287)
Zer55362 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer55362', )(Res96345)
Zer70944 = keras.layers.ZeroPadding1D(padding=((11, 0)), name = 'Zer70944', )(Zer55362)
Min93049 = keras.layers.Minimum(name = 'Min93049', )([Con83656,Zer70944])
Sub75603 = keras.layers.Subtract(name = 'Sub75603', )([Con63188,Min93049])
model = tf.keras.models.Model(inputs=[in0Add80233,in1Add80233,in0Dot77844,in1Dot77844,in0Con86216,in0Con63188,in0Max23572,in1Max23572,in0GRU99621,in0Con98524,in0Con83656,in0Bat50287], outputs=Sub75603)
w = model.get_layer('GRU99621').get_weights() 
w[0] = np.array([[8, 5, 7, 6, 3, 9, 9, 6, 9], [9, 3, 8, 2, 5, 1, 9, 7, 9]])
w[1] = np.array([[2, 2, 3, 9, 6, 7, 7, 3, 2], [1, 2, 4, 5, 8, 4, 2, 2, 10], [4, 6, 8, 2, 1, 2, 6, 5, 3]])
w[2] = np.array([8, 6, 10, 7, 2, 9, 5, 4, 3])
model.get_layer('GRU99621').set_weights(w) 
w = model.get_layer('Bat50287').get_weights() 
w[0] = np.array([0.9707, 0.3001, 0.7833, 0.3761])
w[1] = np.array([0.7567, 0.3396, 0.0838, 0.645])
w[2] = np.array([0.7579, 0.9702, 0.2488, 0.7482])
w[3] = np.array([0.5516, 0.4928, 0.061, 0.183])
model.get_layer('Bat50287').set_weights(w) 
in0Add80233 = tf.constant([[[0.3462, 0.1394]]])
in1Add80233 = tf.constant([[[0.7048, 0.0739]]])
in0Dot77844 = tf.constant([[0.7385, 0.8386]])
in1Dot77844 = tf.constant([[0.9401, 0.4411]])
in0Con86216 = tf.constant([[[0.5624], [0.104], [0.4804]]])
in0Con63188 = tf.constant([[[0.3995, 0.8379, 0.7966, 0.1859, 0.6778, 0.6072, 0.2999, 0.2149, 0.6567, 0.2243], [0.9051, 0.7056, 0.3475, 0.5036, 0.8975, 0.5067, 0.1444, 0.6914, 0.7546, 0.6685], [0.9863, 0.4257, 0.3266, 0.5875, 0.4635, 0.4277, 0.0336, 0.6062, 0.3897, 0.8103], [0.3614, 0.2377, 0.9562, 0.8353, 0.7999, 0.0169, 0.9584, 0.9284, 0.5079, 0.3513], [0.7448, 0.7692, 0.414, 0.6432, 0.4732, 0.3154, 0.1636, 0.3849, 0.9844, 0.6894], [0.3103, 0.8909, 0.0982, 0.9598, 0.4154, 0.8252, 0.4239, 0.9819, 0.2666, 0.7049], [0.8374, 0.6306, 0.2582, 0.1162, 0.6249, 0.9493, 0.0817, 0.47, 0.9154, 0.9718], [0.2715, 0.7363, 0.4354, 0.2287, 0.8211, 0.7514, 0.8054, 0.2429, 0.0376, 0.3693], [0.5662, 0.6375, 0.0424, 0.9424, 0.8787, 0.8343, 0.8374, 0.3581, 0.3672, 0.7027], [0.6578, 0.1348, 0.8951, 0.9364, 0.409, 0.8834, 0.1521, 0.3778, 0.3471, 0.7796], [0.8108, 0.9922, 0.8038, 0.56, 0.6682, 0.6996, 0.6784, 0.9532, 0.6226, 0.8108], [0.6253, 0.3899, 0.5603, 0.3913, 0.3491, 0.296, 0.2245, 0.4716, 0.1867, 0.2659], [0.9238, 0.6631, 0.2053, 0.9404, 0.4965, 0.3986, 0.3702, 0.4648, 0.2983, 0.7163], [0.9516, 0.9934, 0.1003, 0.2321, 0.2266, 0.8237, 0.6961, 0.7035, 0.7098, 0.3911], [0.7035, 0.3791, 0.5964, 0.5397, 0.515, 0.1498, 0.8381, 0.1914, 0.6053, 0.3681], [0.2912, 0.7842, 0.4324, 0.088, 0.6696, 0.6206, 0.986, 0.3909, 0.6181, 0.5743]]])
in0Max23572 = tf.constant([[[[[0.0854, 0.2804], [0.4624, 0.231]], [[0.675, 0.9309], [0.589, 0.9002]]], [[[0.9726, 0.7399], [0.9206, 0.6741]], [[0.7679, 0.4923], [0.6959, 0.7864]]]]])
in1Max23572 = tf.constant([[[[[0.9265, 0.6862], [0.3609, 0.8733]], [[0.8529, 0.9492], [0.3628, 0.5809]]], [[[0.8999, 0.7318], [0.072, 0.562]], [[0.8636, 0.7756], [0.9061, 0.6895]]]]])
in0GRU99621 = tf.constant([[[5, 2]]])
in0Con98524 = tf.constant([[0.2149, 0.2448, 0.2413, 0.6656, 0.1515, 0.721, 0.7396, 0.6386, 0.0057, 0.8133, 0.2797, 0.8094, 0.6477]])
in0Con83656 = tf.constant([[[0.6883, 0.0385, 0.1356, 0.3996, 0.5084, 0.4618, 0.703, 0.5749, 0.658, 0.5123, 0.3194], [0.7385, 0.5828, 0.2413, 0.4785, 0.5302, 0.8256, 0.6375, 0.2674, 0.0654, 0.8705, 0.185], [0.142, 0.7856, 0.5254, 0.3985, 0.7846, 0.8922, 0.5817, 0.2866, 0.3975, 0.0114, 0.4102], [0.0919, 0.2209, 0.2752, 0.361, 0.5893, 0.2866, 0.5767, 0.3147, 0.6844, 0.4183, 0.3582], [0.5048, 0.0462, 0.2711, 0.9274, 0.7735, 0.0362, 0.7674, 0.9596, 0.7572, 0.2467, 0.6307], [0.5407, 0.1038, 0.5533, 0.8444, 0.8339, 0.7192, 0.6998, 0.7707, 0.2119, 0.2118, 0.0871], [0.3522, 0.4846, 0.1561, 0.6161, 0.2894, 0.6767, 0.5355, 0.1467, 0.3379, 0.6588, 0.7387], [0.3798, 0.9013, 0.8225, 0.7809, 0.7408, 0.9092, 0.9017, 0.0038, 0.1522, 0.5649, 0.993], [0.3644, 0.4159, 0.9227, 0.8001, 0.5679, 0.2981, 0.4124, 0.1411, 0.72, 0.3058, 0.3669], [0.7944, 0.8803, 0.5758, 0.3285, 0.8313, 0.882, 0.2605, 0.4113, 0.6862, 0.0509, 0.2837], [0.2765, 0.3482, 0.0038, 0.3702, 0.3463, 0.2234, 0.5367, 0.8029, 0.7194, 0.4141, 0.7215], [0.4506, 0.8849, 0.3881, 0.7236, 0.2293, 0.7328, 0.2686, 0.5244, 0.3056, 0.5496, 0.2693], [0.6874, 0.0347, 0.659, 0.1154, 0.541, 0.8355, 0.1164, 0.6479, 0.67, 0.9495, 0.3978], [0.1902, 0.4014, 0.3044, 0.3405, 0.6724, 0.0555, 0.5079, 0.6831, 0.9525, 0.086, 0.3362], [0.4332, 0.2557, 0.882, 0.9477, 0.9428, 0.1561, 0.9211, 0.4532, 0.0161, 0.0706, 0.1727], [0.4046, 0.589, 0.8021, 0.1304, 0.2245, 0.5225, 0.2736, 0.6238, 0.5944, 0.8368, 0.2282]]])
in0Bat50287 = tf.constant([[[[1.6427, 1.1853, 1.4925, 1.6293], [1.4174, 1.9837, 1.5344, 1.5717], [1.5399, 1.2575, 1.6943, 1.8429]], [[1.6178, 1.8288, 1.0888, 1.1583], [1.9756, 1.3836, 1.676, 1.5449], [1.6493, 1.5012, 1.4196, 1.6583]], [[1.509, 1.8767, 1.2628, 1.7221], [1.2044, 1.3171, 1.0547, 1.5556], [1.6636, 1.8, 1.0105, 1.8676]]]])
print (np.array2string(model.predict([in0Add80233,in1Add80233,in0Dot77844,in1Dot77844,in0Con86216,in0Con63188,in0Max23572,in1Max23572,in0GRU99621,in0Con98524,in0Con83656,in0Bat50287],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub75603.png')

LAdd80233 = add_layer([[[[0.3462, 0.1394]]], [[[0.7048, 0.0739]]]], Add80233), 
LZer43137 = zero_padding1D_layer(Add80233, 2, 0, Zer43137), 
LDot77844 = dot_layer([[0.7385, 0.8386]], [[0.9401, 0.4411]], 1, 1, Dot77844), 
LRes15350 = reshape_layer(Dot77844, [1, 1], Res15350), 
LZer69729 = zero_padding1D_layer(Res15350, 1, 1, Zer69729), 
LCon86216 = concatenate_layer([Zer69729,[[[0.5624], [0.104], [0.4804]]]], 2, Con86216), 
LMax43667 = maximum_layer([Zer43137,Con86216], Max43667), 
LZer77056 = zero_padding1D_layer(Max43667, 13, 0, Zer77056), 
LCon63188 = concatenate_layer([Zer77056,[[[0.3995, 0.8379, 0.7966, 0.1859, 0.6778, 0.6072, 0.2999, 0.2149, 0.6567, 0.2243], [0.9051, 0.7056, 0.3475, 0.5036, 0.8975, 0.5067, 0.1444, 0.6914, 0.7546, 0.6685], [0.9863, 0.4257, 0.3266, 0.5875, 0.4635, 0.4277, 0.0336, 0.6062, 0.3897, 0.8103], [0.3614, 0.2377, 0.9562, 0.8353, 0.7999, 0.0169, 0.9584, 0.9284, 0.5079, 0.3513], [0.7448, 0.7692, 0.414, 0.6432, 0.4732, 0.3154, 0.1636, 0.3849, 0.9844, 0.6894], [0.3103, 0.8909, 0.0982, 0.9598, 0.4154, 0.8252, 0.4239, 0.9819, 0.2666, 0.7049], [0.8374, 0.6306, 0.2582, 0.1162, 0.6249, 0.9493, 0.0817, 0.47, 0.9154, 0.9718], [0.2715, 0.7363, 0.4354, 0.2287, 0.8211, 0.7514, 0.8054, 0.2429, 0.0376, 0.3693], [0.5662, 0.6375, 0.0424, 0.9424, 0.8787, 0.8343, 0.8374, 0.3581, 0.3672, 0.7027], [0.6578, 0.1348, 0.8951, 0.9364, 0.409, 0.8834, 0.1521, 0.3778, 0.3471, 0.7796], [0.8108, 0.9922, 0.8038, 0.56, 0.6682, 0.6996, 0.6784, 0.9532, 0.6226, 0.8108], [0.6253, 0.3899, 0.5603, 0.3913, 0.3491, 0.296, 0.2245, 0.4716, 0.1867, 0.2659], [0.9238, 0.6631, 0.2053, 0.9404, 0.4965, 0.3986, 0.3702, 0.4648, 0.2983, 0.7163], [0.9516, 0.9934, 0.1003, 0.2321, 0.2266, 0.8237, 0.6961, 0.7035, 0.7098, 0.3911], [0.7035, 0.3791, 0.5964, 0.5397, 0.515, 0.1498, 0.8381, 0.1914, 0.6053, 0.3681], [0.2912, 0.7842, 0.4324, 0.088, 0.6696, 0.6206, 0.986, 0.3909, 0.6181, 0.5743]]]], 2, Con63188), 
LMax23572 = maximum_layer([[[[[[0.0854, 0.2804], [0.4624, 0.231]], [[0.675, 0.9309], [0.589, 0.9002]]], [[[0.9726, 0.7399], [0.9206, 0.6741]], [[0.7679, 0.4923], [0.6959, 0.7864]]]]], [[[[[0.9265, 0.6862], [0.3609, 0.8733]], [[0.8529, 0.9492], [0.3628, 0.5809]]], [[[0.8999, 0.7318], [0.072, 0.562]], [[0.8636, 0.7756], [0.9061, 0.6895]]]]]], Max23572), 
LRes68038 = reshape_layer(Max23572, [2, 2, 4], Res68038), 
LRes75280 = reshape_layer(Res68038, [2, 8], Res75280), 
LFla64490 = flatten_layer(Res75280, Fla64490), 
LGRU99621 = gru_layer([[[5, 2]]],[[8, 5, 7, 6, 3, 9, 9, 6, 9], [9, 3, 8, 2, 5, 1, 9, 7, 9]],[[2, 2, 3, 9, 6, 7, 7, 3, 2], [1, 2, 4, 5, 8, 4, 2, 2, 10], [4, 6, 8, 2, 1, 2, 6, 5, 3]],[8, 6, 10, 7, 2, 9, 5, 4, 3], false, GRU99621), 
LCon98524 = concatenate_layer([GRU99621,[[0.2149, 0.2448, 0.2413, 0.6656, 0.1515, 0.721, 0.7396, 0.6386, 0.0057, 0.8133, 0.2797, 0.8094, 0.6477]]], 1, Con98524), 
LSub82102 = subtract_layer(Fla64490,Con98524, Sub82102), 
LRes55245 = reshape_layer(Sub82102, [16, 1], Res55245), 
LCon83656 = concatenate_layer([Res55245,[[[0.6883, 0.0385, 0.1356, 0.3996, 0.5084, 0.4618, 0.703, 0.5749, 0.658, 0.5123, 0.3194], [0.7385, 0.5828, 0.2413, 0.4785, 0.5302, 0.8256, 0.6375, 0.2674, 0.0654, 0.8705, 0.185], [0.142, 0.7856, 0.5254, 0.3985, 0.7846, 0.8922, 0.5817, 0.2866, 0.3975, 0.0114, 0.4102], [0.0919, 0.2209, 0.2752, 0.361, 0.5893, 0.2866, 0.5767, 0.3147, 0.6844, 0.4183, 0.3582], [0.5048, 0.0462, 0.2711, 0.9274, 0.7735, 0.0362, 0.7674, 0.9596, 0.7572, 0.2467, 0.6307], [0.5407, 0.1038, 0.5533, 0.8444, 0.8339, 0.7192, 0.6998, 0.7707, 0.2119, 0.2118, 0.0871], [0.3522, 0.4846, 0.1561, 0.6161, 0.2894, 0.6767, 0.5355, 0.1467, 0.3379, 0.6588, 0.7387], [0.3798, 0.9013, 0.8225, 0.7809, 0.7408, 0.9092, 0.9017, 0.0038, 0.1522, 0.5649, 0.993], [0.3644, 0.4159, 0.9227, 0.8001, 0.5679, 0.2981, 0.4124, 0.1411, 0.72, 0.3058, 0.3669], [0.7944, 0.8803, 0.5758, 0.3285, 0.8313, 0.882, 0.2605, 0.4113, 0.6862, 0.0509, 0.2837], [0.2765, 0.3482, 0.0038, 0.3702, 0.3463, 0.2234, 0.5367, 0.8029, 0.7194, 0.4141, 0.7215], [0.4506, 0.8849, 0.3881, 0.7236, 0.2293, 0.7328, 0.2686, 0.5244, 0.3056, 0.5496, 0.2693], [0.6874, 0.0347, 0.659, 0.1154, 0.541, 0.8355, 0.1164, 0.6479, 0.67, 0.9495, 0.3978], [0.1902, 0.4014, 0.3044, 0.3405, 0.6724, 0.0555, 0.5079, 0.6831, 0.9525, 0.086, 0.3362], [0.4332, 0.2557, 0.882, 0.9477, 0.9428, 0.1561, 0.9211, 0.4532, 0.0161, 0.0706, 0.1727], [0.4046, 0.589, 0.8021, 0.1304, 0.2245, 0.5225, 0.2736, 0.6238, 0.5944, 0.8368, 0.2282]]]], 2, Con83656), 
LBat50287 = batch_normalization_layer([[[[1.6427, 1.1853, 1.4925, 1.6293], [1.4174, 1.9837, 1.5344, 1.5717], [1.5399, 1.2575, 1.6943, 1.8429]], [[1.6178, 1.8288, 1.0888, 1.1583], [1.9756, 1.3836, 1.676, 1.5449], [1.6493, 1.5012, 1.4196, 1.6583]], [[1.509, 1.8767, 1.2628, 1.7221], [1.2044, 1.3171, 1.0547, 1.5556], [1.6636, 1.8, 1.0105, 1.8676]]]], 3, 0.8039190117466181, [0.9707, 0.3001, 0.7833, 0.3761], [0.7567, 0.3396, 0.0838, 0.645], [0.7579, 0.9702, 0.2488, 0.7482], [0.5516, 0.4928, 0.061, 0.183], Bat50287), 
LRes96345 = reshape_layer(Bat50287, [3, 12], Res96345), 
LZer55362 = zero_padding1D_layer(Res96345, 1, 1, Zer55362), 
LZer70944 = zero_padding1D_layer(Zer55362, 11, 0, Zer70944), 
LMin93049 = minimum_layer([Con83656,Zer70944], Min93049), 
LSub75603 = subtract_layer(Con63188,Min93049, Sub75603), 
exec_layers([LAdd80233,LZer43137,LDot77844,LRes15350,LZer69729,LCon86216,LMax43667,LZer77056,LCon63188,LMax23572,LRes68038,LRes75280,LFla64490,LGRU99621,LCon98524,LSub82102,LRes55245,LCon83656,LBat50287,LRes96345,LZer55362,LZer70944,LMin93049,LSub75603],["Add80233","Zer43137","Dot77844","Res15350","Zer69729","Con86216","Max43667","Zer77056","Con63188","Max23572","Res68038","Res75280","Fla64490","GRU99621","Con98524","Sub82102","Res55245","Con83656","Bat50287","Res96345","Zer55362","Zer70944","Min93049","Sub75603"],Sub75603,"Sub75603")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.3995000, 0.8379000, 0.7966000, 0.1859000, 0.6778000, 0.6072000, 0.2999000, 0.2149000, 0.6567000, 0.2243000], [0.0000000, 0.0000000, 0.9051000, 0.7056000, 0.3475000, 0.5036000, 0.8975000, 0.5067000, 0.1444000, 0.6914000, 0.7546000, 0.6685000], [0.0000000, 0.0000000, 0.9863000, 0.4257000, 0.3266000, 0.5875000, 0.4635000, 0.4277000, 0.0336000, 0.6062000, 0.3897000, 0.8103000], [0.0000000, 0.0000000, 0.3614000, 0.2377000, 0.9562000, 0.8353000, 0.7999000, 0.0169000, 0.9584000, 0.9284000, 0.5079000, 0.3513000], [0.0000000, 0.0000000, 0.7448000, 0.7692000, 0.4140000, 0.6432000, 0.4732000, 0.3154000, 0.1636000, 0.3849000, 0.9844000, 0.6894000], [0.0000000, 0.0000000, 0.3103000, 0.8909000, 0.0982000, 0.9598000, 0.4154000, 0.8252000, 0.4239000, 0.9819000, 0.2666000, 0.7049000], [0.0766000, 0.0000000, 0.8374000, 0.6306000, 0.2582000, 0.1162000, 0.6249000, 0.9493000, 0.0817000, 0.4700000, 0.9154000, 0.9718000], [0.0000000, 0.0000000, 0.2715000, 0.7363000, 0.4354000, 0.2287000, 0.8211000, 0.7514000, 0.8054000, 0.2429000, 0.0376000, 0.3693000], [0.0000000, 0.0000000, 0.5662000, 0.6375000, 0.0424000, 0.9424000, 0.8787000, 0.8343000, 0.8374000, 0.3581000, 0.3672000, 0.7027000], [0.0000000, 0.0000000, 0.6578000, 0.1348000, 0.8951000, 0.9364000, 0.4090000, 0.8834000, 0.1521000, 0.3778000, 0.3471000, 0.7796000], [0.0000000, 0.0000000, 0.8108000, 0.9922000, 0.8038000, 0.5600000, 0.6682000, 0.6996000, 0.6784000, 0.9532000, 0.6226000, 0.8108000], [0.0000000, 0.0000000, 0.6253000, 0.3899000, 0.5603000, 0.3913000, 0.3491000, 0.2960000, 0.2245000, 0.4716000, 0.1867000, 0.2659000], [-0.0503000, -0.3962870, 0.8891000, 0.0041000, 0.0899000, 0.3994000, -0.3390000, 0.2822000, -0.2777000, 0.0494856, -0.6512000, 0.3185000], [-0.4959000, 0.3722000, 0.5502000, 0.6890000, -0.2402000, -0.2164466, 0.1711000, 0.3158000, 0.0130000, 0.2239614, 0.6238000, 0.0549000], [0.9674704, -0.3292000, 0.4478000, -0.5029000, -0.3513000, 0.1086787, 0.3589000, -0.7713000, 0.3849000, 0.1753000, 0.5347000, 0.1954000], [1.0510000, 0.4804000, 0.2912000, 0.7842000, 0.4324000, 0.0880000, 0.6696000, 0.6206000, 0.9860000, 0.3909000, 0.6181000, 0.5743000]]]

Expected (Unparsed): [[[0,0,0.3995,0.8379,0.7966,0.1859,0.6778,0.6072,0.2999,0.2149,0.6567,0.2243],[0,0,0.9051,0.7056,0.3475,0.5036,0.8975,0.5067,0.1444,0.6914,0.7546,0.6685],[0,0,0.9863,0.4257,0.3266,0.5875,0.4635,0.4277,0.0336,0.6062,0.3897,0.8103],[0,0,0.3614,0.2377,0.9562,0.8353,0.7999,0.0169,0.9584,0.9284,0.5079,0.3513],[0,0,0.7448,0.7692,0.414,0.6432,0.4732,0.3154,0.1636,0.3849,0.9844,0.6894],[0,0,0.3103,0.8909,0.0982,0.9598,0.4154,0.8252,0.4239,0.9819,0.2666,0.7049],[0.0766,0,0.8374,0.6306,0.2582,0.1162,0.6249,0.9493,0.0817,0.47,0.9154,0.9718],[0,0,0.2715,0.7363,0.4354,0.2287,0.8211,0.7514,0.8054,0.2429,0.0376,0.3693],[0,0,0.5662,0.6375,0.0424,0.9424,0.8787,0.8343,0.8374,0.3581,0.3672,0.7027],[0,0,0.6578,0.1348,0.8951,0.9364,0.409,0.8834,0.1521,0.3778,0.3471,0.7796],[0,0,0.8108,0.9922,0.8038,0.56,0.6682,0.6996,0.6784,0.9532,0.6226,0.8108],[0,0,0.6253,0.3899,0.5603,0.3913,0.3491,0.296,0.2245,0.4716,0.1867,0.2659],[-0.05030000000000001,-0.3962869990723865,0.8891,0.0040999999999999925,0.08990000000000001,0.3994,-0.339,0.2822,-0.27770000000000006,0.04948556562763068,-0.6512,0.31850000000000006],[-0.49589999999999995,0.3722,0.5502,0.689,-0.24020000000000002,-0.21644656167607887,0.1711,0.31579999999999997,0.013000000000000012,0.22396138304306268,0.6238,0.054900000000000004],[0.9674703100000002,-0.3292,0.44780000000000003,-0.5029,-0.35129999999999995,0.10867870767916843,0.3589,-0.7713000000000001,0.38489999999999996,0.17529999999999998,0.5347,0.1954],[1.051,0.4804,0.2912,0.7842,0.4324,0.088,0.6696,0.6206,0.986,0.3909,0.6181,0.5743]]]

Actual:   [[[0, 0, 0.3995, 0.8379, 0.7966, 0.1859, 0.6778, 0.6072, 0.2999, 0.2149, 0.6567, 0.2243], [0, 0, 0.9051, 0.7056, 0.3475, 0.5036, 0.8975, 0.5067, 0.1444, 0.6914, 0.7546, 0.6685], [0, 0, 0.9863, 0.4257, 0.3266, 0.5875, 0.4635, 0.4277, 0.0336, 0.6062, 0.3897, 0.8103], [0, 0, 0.3614, 0.2377, 0.9562, 0.8353, 0.7999, 0.0169, 0.9584, 0.9284, 0.5079, 0.3513], [0, 0, 0.7448, 0.7692, 0.414, 0.6432, 0.4732, 0.3154, 0.1636, 0.3849, 0.9844, 0.6894], [0, 0, 0.3103, 0.8909, 0.0982, 0.9598, 0.4154, 0.8252, 0.4239, 0.9819, 0.2666, 0.7049], [0.0766, 0, 0.8374, 0.6306, 0.2582, 0.1162, 0.6249, 0.9493, 0.0817, 0.47, 0.9154, 0.9718], [0, 0, 0.2715, 0.7363, 0.4354, 0.2287, 0.8211, 0.7514, 0.8054, 0.2429, 0.0376, 0.3693], [0, 0, 0.5662, 0.6375, 0.0424, 0.9424, 0.8787, 0.8343, 0.8374, 0.3581, 0.3672, 0.7027], [0, 0, 0.6578, 0.1348, 0.8951, 0.9364, 0.409, 0.8834, 0.1521, 0.3778, 0.3471, 0.7796], [0, 0, 0.8108, 0.9922, 0.8038, 0.56, 0.6682, 0.6996, 0.6784, 0.9532, 0.6226, 0.8108], [0, 0, 0.6253, 0.3899, 0.5603, 0.3913, 0.3491, 0.296, 0.2245, 0.4716, 0.1867, 0.2659], [-0.0503, -0.3962, 0.8891, 0.0041, 0.0899, 0.3994, -0.339, 0.2822, -0.2777, 0.0495, -0.6512, 0.3185], [-0.4959, 0.3722, 0.5502, 0.689, -0.2402, -0.2164, 0.1711, 0.3158, 0.013, 0.224, 0.6238, 0.0549], [0.9675, -0.3292, 0.4478, -0.5029, -0.3513, 0.1087, 0.3589, -0.7713, 0.3849, 0.1753, 0.5347, 0.1954], [1.051, 0.4804, 0.2912, 0.7842, 0.4324, 0.088, 0.6696, 0.6206, 0.986, 0.3909, 0.6181, 0.5743]]]

Expected: [[[0, 0, 0.3995, 0.8379, 0.7966, 0.1859, 0.6778, 0.6072, 0.2999, 0.2149, 0.6567, 0.2243], [0, 0, 0.9051, 0.7056, 0.3475, 0.5036, 0.8975, 0.5067, 0.1444, 0.6914, 0.7546, 0.6685], [0, 0, 0.9863, 0.4257, 0.3266, 0.5875, 0.4635, 0.4277, 0.0336, 0.6062, 0.3897, 0.8103], [0, 0, 0.3614, 0.2377, 0.9562, 0.8353, 0.7999, 0.0169, 0.9584, 0.9284, 0.5079, 0.3513], [0, 0, 0.7448, 0.7692, 0.414, 0.6432, 0.4732, 0.3154, 0.1636, 0.3849, 0.9844, 0.6894], [0, 0, 0.3103, 0.8909, 0.0982, 0.9598, 0.4154, 0.8252, 0.4239, 0.9819, 0.2666, 0.7049], [0.0766, 0, 0.8374, 0.6306, 0.2582, 0.1162, 0.6249, 0.9493, 0.0817, 0.47, 0.9154, 0.9718], [0, 0, 0.2715, 0.7363, 0.4354, 0.2287, 0.8211, 0.7514, 0.8054, 0.2429, 0.0376, 0.3693], [0, 0, 0.5662, 0.6375, 0.0424, 0.9424, 0.8787, 0.8343, 0.8374, 0.3581, 0.3672, 0.7027], [0, 0, 0.6578, 0.1348, 0.8951, 0.9364, 0.409, 0.8834, 0.1521, 0.3778, 0.3471, 0.7796], [0, 0, 0.8108, 0.9922, 0.8038, 0.56, 0.6682, 0.6996, 0.6784, 0.9532, 0.6226, 0.8108], [0, 0, 0.6253, 0.3899, 0.5603, 0.3913, 0.3491, 0.296, 0.2245, 0.4716, 0.1867, 0.2659], [-0.0503, -0.3962, 0.8891, 0.0041, 0.09, 0.3994, -0.339, 0.2822, -0.2777, 0.0495, -0.6512, 0.3186], [-0.4958, 0.3722, 0.5502, 0.689, -0.2402, -0.2164, 0.1711, 0.3158, 0.0131, 0.224, 0.6238, 0.055], [0.9675, -0.3292, 0.4479, -0.5029, -0.3512, 0.1087, 0.3589, -0.7713, 0.3849, 0.1753, 0.5347, 0.1954], [1.051, 0.4804, 0.2912, 0.7842, 0.4324, 0.088, 0.6696, 0.6206, 0.986, 0.3909, 0.6181, 0.5743]]]