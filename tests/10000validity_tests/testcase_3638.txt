import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub79685 = tf.keras.layers.Input(shape=([2, 3, 2]))
in1Sub79685 = tf.keras.layers.Input(shape=([2, 3, 2]))
in0Min56798 = tf.keras.layers.Input(shape=([1, 1, 1]))
in1Min56798 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con57510 = tf.keras.layers.Input(shape=([2, 3, 1]))
in0Con37677 = tf.keras.layers.Input(shape=([2, 4]))
in0Dot48897 = tf.keras.layers.Input(shape=([2, 3]))
in1Dot48897 = tf.keras.layers.Input(shape=([2, 3]))
in0Con16516 = tf.keras.layers.Input(shape=([10, 10, 1]))
in0Min9628 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in1Min9628 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in0Dot84750 = tf.keras.layers.Input(shape=([2, 3]))
in1Dot84750 = tf.keras.layers.Input(shape=([2, 3]))
in0Con11795 = tf.keras.layers.Input(shape=([3, 6, 1]))

Sub79685 = keras.layers.Subtract(name = 'Sub79685', )([in0Sub79685,in1Sub79685])
Min56798 = keras.layers.Minimum(name = 'Min56798', )([in0Min56798,in1Min56798])
Zer68329 = keras.layers.ZeroPadding2D(padding=((1, 0), (2, 0)), name = 'Zer68329', )(Min56798)
Con57510 = keras.layers.Concatenate(axis=3, name = 'Con57510', )([Zer68329,in0Con57510])
Ave30732 = keras.layers.Average(name = 'Ave30732', )([Sub79685,Con57510])
Res10514 = keras.layers.Reshape((2, 6), name = 'Res10514', )(Ave30732)
Con37677 = keras.layers.Concatenate(axis=2, name = 'Con37677', )([Res10514,in0Con37677])
Dot48897 = keras.layers.Dot(axes=(2, 2), name = 'Dot48897', )([in0Dot48897,in1Dot48897])
Res77978 = keras.layers.Reshape((2, 2, 1), name = 'Res77978', )(Dot48897)
PRe60174 = keras.layers.PReLU(name = 'PRe60174', )(Res77978)
Res87762 = keras.layers.Reshape((2, 2), name = 'Res87762', )(PRe60174)
Dot87725 = keras.layers.Dot(axes=(1, 1), name = 'Dot87725', )([Con37677,Res87762])
Res99792 = keras.layers.Reshape((10, 2, 1), name = 'Res99792', )(Dot87725)
Zer9942 = keras.layers.ZeroPadding2D(padding=((0, 0), (8, 0)), name = 'Zer9942', )(Res99792)
Con16516 = keras.layers.Concatenate(axis=3, name = 'Con16516', )([Zer9942,in0Con16516])
Min9628 = keras.layers.Minimum(name = 'Min9628', )([in0Min9628,in1Min9628])
Res2886 = keras.layers.Reshape((2, 1, 2), name = 'Res2886', )(Min9628)
Zer38468 = keras.layers.ZeroPadding2D(padding=((1, 0), (5, 0)), name = 'Zer38468', )(Res2886)
Dot84750 = keras.layers.Dot(axes=(1, 1), name = 'Dot84750', )([in0Dot84750,in1Dot84750])
Res76651 = keras.layers.Reshape((3, 3, 1), name = 'Res76651', )(Dot84750)
Up_14551 = keras.layers.UpSampling2D(size=(1, 2), name = 'Up_14551', )(Res76651)
Con11795 = keras.layers.Concatenate(axis=3, name = 'Con11795', )([Up_14551,in0Con11795])
Sub6162 = keras.layers.Subtract(name = 'Sub6162', )([Zer38468,Con11795])
Zer54940 = keras.layers.ZeroPadding2D(padding=((7, 0), (4, 0)), name = 'Zer54940', )(Sub6162)
Add33558 = keras.layers.Add(name = 'Add33558', )([Con16516,Zer54940])
model = tf.keras.models.Model(inputs=[in0Sub79685,in1Sub79685,in0Min56798,in1Min56798,in0Con57510,in0Con37677,in0Dot48897,in1Dot48897,in0Con16516,in0Min9628,in1Min9628,in0Dot84750,in1Dot84750,in0Con11795], outputs=Add33558)
w = model.get_layer('PRe60174').get_weights() 
w[0] = np.array([[[0.8603], [0.0292]], [[0.7032], [0.121]]])
model.get_layer('PRe60174').set_weights(w) 
in0Sub79685 = tf.constant([[[[0.1347, 0.4824], [0.3186, 0.7451], [0.263, 0.2498]], [[0.6974, 0.6651], [0.3836, 0.8987], [0.271, 0.9073]]]])
in1Sub79685 = tf.constant([[[[0.6948, 0.5824], [0.0174, 0.5354], [0.1503, 0.9809]], [[0.667, 0.3949], [0.1753, 0.627], [0.9513, 0.4066]]]])
in0Min56798 = tf.constant([[[[0.6484]]]])
in1Min56798 = tf.constant([[[[0.0173]]]])
in0Con57510 = tf.constant([[[[0.2044], [0.0703], [0.7778]], [[0.333], [0.7928], [0.2442]]]])
in0Con37677 = tf.constant([[[0.4891, 0.3858, 0.4246, 0.2466], [0.4172, 0.2469, 0.4575, 0.4998]]])
in0Dot48897 = tf.constant([[[0.0199, 0.4736, 0.8118], [0.0388, 0.2642, 0.9219]]])
in1Dot48897 = tf.constant([[[0.4574, 0.6224, 0.1688], [0.6045, 0.0786, 0.8185]]])
in0Con16516 = tf.constant([[[[0.1128], [0.6412], [0.6974], [0.4942], [0.8888], [0.2271], [0.5838], [0.034], [0.0317], [0.9282]], [[0.3265], [0.8474], [0.9392], [0.0572], [0.5231], [0.4635], [0.7325], [0.9172], [0.9209], [0.8247]], [[0.1506], [0.9254], [0.8033], [0.1636], [0.3399], [0.2451], [0.0349], [0.9622], [0.2157], [0.3119]], [[0.0559], [0.0768], [0.9935], [0.0405], [0.5529], [0.6526], [0.6919], [0.4331], [0.7532], [0.0228]], [[0.8972], [0.7645], [0.2921], [0.3888], [0.8412], [0.5217], [0.3835], [0.7145], [0.8973], [0.7908]], [[0.5875], [0.9281], [0.9242], [0.848], [0.815], [0.2271], [0.5005], [0.2911], [0.3335], [0.004]], [[0.9825], [0.1731], [0.4458], [0.6729], [0.4919], [0.2416], [0.2041], [0.4658], [0.3941], [0.5759]], [[0.9874], [0.0876], [0.5619], [0.6182], [0.0252], [0.9743], [0.7377], [0.8452], [0.9805], [0.7798]], [[0.604], [0.0956], [0.5195], [0.6323], [0.7511], [0.8777], [0.3891], [0.6502], [0.5925], [0.8175]], [[0.9], [0.1797], [0.4181], [0.7745], [0.8719], [0.232], [0.2001], [0.0545], [0.0314], [0.6308]]]])
in0Min9628 = tf.constant([[[[[0.3615], [0.4074]]], [[[0.6714], [0.6853]]]]])
in1Min9628 = tf.constant([[[[[0.7261], [0.9241]]], [[[0.5266], [0.4766]]]]])
in0Dot84750 = tf.constant([[[0.3053, 0.485, 0.6588], [0.6215, 0.7288, 0.5649]]])
in1Dot84750 = tf.constant([[[0.4894, 0.9014, 0.0734], [0.8319, 0.0172, 0.0423]]])
in0Con11795 = tf.constant([[[[0.5761], [0.2778], [0.7489], [0.8031], [0.5694], [0.2247]], [[0.4006], [0.9254], [0.9797], [0.8594], [0.8659], [0.4519]], [[0.4014], [0.9189], [0.4779], [0.798], [0.7725], [0.0661]]]])
print (np.array2string(model.predict([in0Sub79685,in1Sub79685,in0Min56798,in1Min56798,in0Con57510,in0Con37677,in0Dot48897,in1Dot48897,in0Con16516,in0Min9628,in1Min9628,in0Dot84750,in1Dot84750,in0Con11795],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add33558.png')

LSub79685 = subtract_layer([[[[0.1347, 0.4824], [0.3186, 0.7451], [0.263, 0.2498]], [[0.6974, 0.6651], [0.3836, 0.8987], [0.271, 0.9073]]]], [[[[0.6948, 0.5824], [0.0174, 0.5354], [0.1503, 0.9809]], [[0.667, 0.3949], [0.1753, 0.627], [0.9513, 0.4066]]]], Sub79685), 
LMin56798 = minimum_layer([[[[[0.6484]]]], [[[[0.0173]]]]], Min56798), 
LZer68329 = zero_padding2D_layer(Min56798, 1, 0, 2, 0, Zer68329), 
LCon57510 = concatenate_layer([Zer68329,[[[[0.2044], [0.0703], [0.7778]], [[0.333], [0.7928], [0.2442]]]]], 3, Con57510), 
LAve30732 = average_layer([Sub79685,Con57510], Ave30732), 
LRes10514 = reshape_layer(Ave30732, [2, 6], Res10514), 
LCon37677 = concatenate_layer([Res10514,[[[0.4891, 0.3858, 0.4246, 0.2466], [0.4172, 0.2469, 0.4575, 0.4998]]]], 2, Con37677), 
LDot48897 = dot_layer([[[0.0199, 0.4736, 0.8118], [0.0388, 0.2642, 0.9219]]], [[[0.4574, 0.6224, 0.1688], [0.6045, 0.0786, 0.8185]]], 2, 2, Dot48897), 
LRes77978 = reshape_layer(Dot48897, [2, 2, 1], Res77978), 
LPRe60174 = prelu_layer(Res77978, [[[0.8603], [0.0292]], [[0.7032], [0.121]]], PRe60174), 
LRes87762 = reshape_layer(PRe60174, [2, 2], Res87762), 
LDot87725 = dot_layer(Con37677,Res87762, 1, 1, Dot87725), 
LRes99792 = reshape_layer(Dot87725, [10, 2, 1], Res99792), 
LZer9942 = zero_padding2D_layer(Res99792, 0, 0, 8, 0, Zer9942), 
LCon16516 = concatenate_layer([Zer9942,[[[[0.1128], [0.6412], [0.6974], [0.4942], [0.8888], [0.2271], [0.5838], [0.034], [0.0317], [0.9282]], [[0.3265], [0.8474], [0.9392], [0.0572], [0.5231], [0.4635], [0.7325], [0.9172], [0.9209], [0.8247]], [[0.1506], [0.9254], [0.8033], [0.1636], [0.3399], [0.2451], [0.0349], [0.9622], [0.2157], [0.3119]], [[0.0559], [0.0768], [0.9935], [0.0405], [0.5529], [0.6526], [0.6919], [0.4331], [0.7532], [0.0228]], [[0.8972], [0.7645], [0.2921], [0.3888], [0.8412], [0.5217], [0.3835], [0.7145], [0.8973], [0.7908]], [[0.5875], [0.9281], [0.9242], [0.848], [0.815], [0.2271], [0.5005], [0.2911], [0.3335], [0.004]], [[0.9825], [0.1731], [0.4458], [0.6729], [0.4919], [0.2416], [0.2041], [0.4658], [0.3941], [0.5759]], [[0.9874], [0.0876], [0.5619], [0.6182], [0.0252], [0.9743], [0.7377], [0.8452], [0.9805], [0.7798]], [[0.604], [0.0956], [0.5195], [0.6323], [0.7511], [0.8777], [0.3891], [0.6502], [0.5925], [0.8175]], [[0.9], [0.1797], [0.4181], [0.7745], [0.8719], [0.232], [0.2001], [0.0545], [0.0314], [0.6308]]]]], 3, Con16516), 
LMin9628 = minimum_layer([[[[[[0.3615], [0.4074]]], [[[0.6714], [0.6853]]]]], [[[[[0.7261], [0.9241]]], [[[0.5266], [0.4766]]]]]], Min9628), 
LRes2886 = reshape_layer(Min9628, [2, 1, 2], Res2886), 
LZer38468 = zero_padding2D_layer(Res2886, 1, 0, 5, 0, Zer38468), 
LDot84750 = dot_layer([[[0.3053, 0.485, 0.6588], [0.6215, 0.7288, 0.5649]]], [[[0.4894, 0.9014, 0.0734], [0.8319, 0.0172, 0.0423]]], 1, 1, Dot84750), 
LRes76651 = reshape_layer(Dot84750, [3, 3, 1], Res76651), 
LUp_14551 = up_sampling2D_layer(Res76651, 1, 2, Up_14551), 
LCon11795 = concatenate_layer([Up_14551,[[[[0.5761], [0.2778], [0.7489], [0.8031], [0.5694], [0.2247]], [[0.4006], [0.9254], [0.9797], [0.8594], [0.8659], [0.4519]], [[0.4014], [0.9189], [0.4779], [0.798], [0.7725], [0.0661]]]]], 3, Con11795), 
LSub6162 = subtract_layer(Zer38468,Con11795, Sub6162), 
LZer54940 = zero_padding2D_layer(Sub6162, 7, 0, 4, 0, Zer54940), 
LAdd33558 = add_layer([Con16516,Zer54940], Add33558), 
exec_layers([LSub79685,LMin56798,LZer68329,LCon57510,LAve30732,LRes10514,LCon37677,LDot48897,LRes77978,LPRe60174,LRes87762,LDot87725,LRes99792,LZer9942,LCon16516,LMin9628,LRes2886,LZer38468,LDot84750,LRes76651,LUp_14551,LCon11795,LSub6162,LZer54940,LAdd33558],["Sub79685","Min56798","Zer68329","Con57510","Ave30732","Res10514","Con37677","Dot48897","Res77978","PRe60174","Res87762","Dot87725","Res99792","Zer9942","Con16516","Min9628","Res2886","Zer38468","Dot84750","Res76651","Up_14551","Con11795","Sub6162","Zer54940","Add33558"],Add33558,"Add33558")

Actual (Unparsed): [[[[0.0000000, 0.1128000], [0.0000000, 0.6412000], [0.0000000, 0.6974000], [0.0000000, 0.4942000], [0.0000000, 0.8888000], [0.0000000, 0.2271000], [0.0000000, 0.5838000], [0.0000000, 0.0340000], [-0.1183402, 0.0317000], [-0.1877336, 0.9282000]], [[0.0000000, 0.3265000], [0.0000000, 0.8474000], [0.0000000, 0.9392000], [0.0000000, 0.0572000], [0.0000000, 0.5231000], [0.0000000, 0.4635000], [0.0000000, 0.7325000], [0.0000000, 0.9172000], [0.1248962, 0.9209000], [0.2781726, 0.8247000]], [[0.0000000, 0.1506000], [0.0000000, 0.9254000], [0.0000000, 0.8033000], [0.0000000, 0.1636000], [0.0000000, 0.3399000], [0.0000000, 0.2451000], [0.0000000, 0.0349000], [0.0000000, 0.9622000], [0.1015820, 0.2157000], [0.1906797, 0.3119000]], [[0.0000000, 0.0559000], [0.0000000, 0.0768000], [0.0000000, 0.9935000], [0.0000000, 0.0405000], [0.0000000, 0.5529000], [0.0000000, 0.6526000], [0.0000000, 0.6919000], [0.0000000, 0.4331000], [0.2415215, 0.7532000], [0.5250789, 0.0228000]], [[0.0000000, 0.8972000], [0.0000000, 0.7645000], [0.0000000, 0.2921000], [0.0000000, 0.3888000], [0.0000000, 0.8412000], [0.0000000, 0.5217000], [0.0000000, 0.3835000], [0.0000000, 0.7145000], [-0.0871365, 0.8973000], [-0.2245831, 0.7908000]], [[0.0000000, 0.5875000], [0.0000000, 0.9281000], [0.0000000, 0.9242000], [0.0000000, 0.8480000], [0.0000000, 0.8150000], [0.0000000, 0.2271000], [0.0000000, 0.5005000], [0.0000000, 0.2911000], [0.1361094, 0.3335000], [0.3141767, 0.0040000]], [[0.0000000, 0.9825000], [0.0000000, 0.1731000], [0.0000000, 0.4458000], [0.0000000, 0.6729000], [0.0000000, 0.4919000], [0.0000000, 0.2416000], [0.0000000, 0.2041000], [0.0000000, 0.4658000], [0.3565765, 0.3941000], [0.6823346, 0.5759000]], [[0.0000000, 0.9874000], [0.0000000, 0.0876000], [0.0000000, 0.5619000], [0.0000000, 0.6182000], [-0.6664397, -0.5509000], [-0.6664397, 0.6965000], [-0.2858872, -0.0112000], [-0.2858872, 0.0421000], [0.2048051, 0.4111000], [0.4238746, 0.5551000]], [[0.0000000, 0.6040000], [0.0000000, 0.0956000], [0.0000000, 0.5195000], [0.0000000, 0.6323000], [-0.8436477, 0.3505000], [-0.8436477, -0.0477000], [-0.4497144, -0.5906000], [-0.4497144, -0.2092000], [0.2753244, -0.2734000], [0.9635643, 0.7730000]], [[0.0000000, 0.9000000], [0.0000000, 0.1797000], [0.0000000, 0.4181000], [0.0000000, 0.7745000], [-0.7923570, 0.4705000], [-0.7923570, -0.6869000], [-0.6035586, -0.2778000], [-0.6035586, -0.7435000], [0.2053088, -0.7411000], [1.0295885, 1.0413000]]]]

Expected (Unparsed): [[[[0,0.1128],[0,0.6412],[0,0.6974],[0,0.4942],[0,0.8888],[0,0.2271],[0,0.5838],[0,0.034],[-0.11834022315300001,0.0317],[-0.18773357521650003,0.9282]],[[0,0.3265],[0,0.8474],[0,0.9392],[0,0.0572],[0,0.5231],[0,0.4635],[0,0.7325],[0,0.9172],[0.12489618209999999,0.9209],[0.278172643074,0.8247]],[[0,0.1506],[0,0.9254],[0,0.8033],[0,0.1636],[0,0.3399],[0,0.2451],[0,0.0349],[0,0.9622],[0.101582022612,0.2157],[0.1906797390465,0.3119]],[[0,0.0559],[0,0.0768],[0,0.9935],[0,0.0405],[0,0.5529],[0,0.6526],[0,0.6919],[0,0.4331],[0.24152145551999998,0.7532],[0.5250788952075001,0.0228]],[[0,0.8972],[0,0.7645],[0,0.2921],[0,0.3888],[0,0.8412],[0,0.5217],[0,0.3835],[0,0.7145],[-0.087136467081,0.8973],[-0.22458311406150006,0.7908]],[[0,0.5875],[0,0.9281],[0,0.9242],[0,0.848],[0,0.815],[0,0.2271],[0,0.5005],[0,0.2911],[0.13610940408299999,0.3335],[0.314176715895,0.004]],[[0,0.9825],[0,0.1731],[0,0.4458],[0,0.6729],[0,0.4919],[0,0.2416],[0,0.2041],[0,0.4658],[0.35657649115799994,0.3941],[0.6823345723350001,0.5759]],[[0,0.9874],[0,0.0876],[0,0.5619],[0,0.6182],[-0.66643967,-0.5509],[-0.66643967,0.6965000000000001],[-0.28588722000000005,-0.011199999999999988],[-0.28588722000000005,0.042099999999999915],[0.20480510114,0.4111],[0.42387463240100004,0.5551]],[[0,0.604],[0,0.0956],[0,0.5195],[0,0.6323],[-0.84364772,0.3505],[-0.84364772,-0.047699999999999965],[-0.44971436,-0.5906],[-0.44971436,-0.20920000000000005],[0.27532444180399995,-0.2734],[0.9635643296510001,0.7729999999999999]],[[0,0.9],[0,0.1797],[0,0.4181],[0,0.7745],[-0.79235703,0.47050000000000003],[-0.79235703,-0.6869000000000001],[-0.6035586000000001,-0.2778],[-0.6035586000000001,-0.7435],[0.20530882529999994,-0.7411],[1.029588564772,1.0413000000000001]]]]

Actual:   [[[[0, 0.1128], [0, 0.6412], [0, 0.6974], [0, 0.4942], [0, 0.8888], [0, 0.2271], [0, 0.5838], [0, 0.034], [-0.1183, 0.0317], [-0.1877, 0.9282]], [[0, 0.3265], [0, 0.8474], [0, 0.9392], [0, 0.0572], [0, 0.5231], [0, 0.4635], [0, 0.7325], [0, 0.9172], [0.1249, 0.9209], [0.2782, 0.8247]], [[0, 0.1506], [0, 0.9254], [0, 0.8033], [0, 0.1636], [0, 0.3399], [0, 0.2451], [0, 0.0349], [0, 0.9622], [0.1016, 0.2157], [0.1907, 0.3119]], [[0, 0.0559], [0, 0.0768], [0, 0.9935], [0, 0.0405], [0, 0.5529], [0, 0.6526], [0, 0.6919], [0, 0.4331], [0.2416, 0.7532], [0.5251, 0.0228]], [[0, 0.8972], [0, 0.7645], [0, 0.2921], [0, 0.3888], [0, 0.8412], [0, 0.5217], [0, 0.3835], [0, 0.7145], [-0.0871, 0.8973], [-0.2245, 0.7908]], [[0, 0.5875], [0, 0.9281], [0, 0.9242], [0, 0.848], [0, 0.815], [0, 0.2271], [0, 0.5005], [0, 0.2911], [0.1362, 0.3335], [0.3142, 0.004]], [[0, 0.9825], [0, 0.1731], [0, 0.4458], [0, 0.6729], [0, 0.4919], [0, 0.2416], [0, 0.2041], [0, 0.4658], [0.3566, 0.3941], [0.6824, 0.5759]], [[0, 0.9874], [0, 0.0876], [0, 0.5619], [0, 0.6182], [-0.6664, -0.5509], [-0.6664, 0.6965], [-0.2858, -0.0112], [-0.2858, 0.0421], [0.2049, 0.4111], [0.4239, 0.5551]], [[0, 0.604], [0, 0.0956], [0, 0.5195], [0, 0.6323], [-0.8436, 0.3505], [-0.8436, -0.0477], [-0.4497, -0.5906], [-0.4497, -0.2092], [0.2754, -0.2734], [0.9636, 0.773]], [[0, 0.9], [0, 0.1797], [0, 0.4181], [0, 0.7745], [-0.7923, 0.4705], [-0.7923, -0.6869], [-0.6035, -0.2778], [-0.6035, -0.7435], [0.2054, -0.7411], [1.0296, 1.0413]]]]

Expected: [[[[0, 0.1128], [0, 0.6412], [0, 0.6974], [0, 0.4942], [0, 0.8888], [0, 0.2271], [0, 0.5838], [0, 0.034], [-0.1183, 0.0317], [-0.1877, 0.9282]], [[0, 0.3265], [0, 0.8474], [0, 0.9392], [0, 0.0572], [0, 0.5231], [0, 0.4635], [0, 0.7325], [0, 0.9172], [0.1249, 0.9209], [0.2782, 0.8247]], [[0, 0.1506], [0, 0.9254], [0, 0.8033], [0, 0.1636], [0, 0.3399], [0, 0.2451], [0, 0.0349], [0, 0.9622], [0.1016, 0.2157], [0.1907, 0.3119]], [[0, 0.0559], [0, 0.0768], [0, 0.9935], [0, 0.0405], [0, 0.5529], [0, 0.6526], [0, 0.6919], [0, 0.4331], [0.2416, 0.7532], [0.5251, 0.0228]], [[0, 0.8972], [0, 0.7645], [0, 0.2921], [0, 0.3888], [0, 0.8412], [0, 0.5217], [0, 0.3835], [0, 0.7145], [-0.0871, 0.8973], [-0.2245, 0.7908]], [[0, 0.5875], [0, 0.9281], [0, 0.9242], [0, 0.848], [0, 0.815], [0, 0.2271], [0, 0.5005], [0, 0.2911], [0.1362, 0.3335], [0.3142, 0.004]], [[0, 0.9825], [0, 0.1731], [0, 0.4458], [0, 0.6729], [0, 0.4919], [0, 0.2416], [0, 0.2041], [0, 0.4658], [0.3566, 0.3941], [0.6824, 0.5759]], [[0, 0.9874], [0, 0.0876], [0, 0.5619], [0, 0.6182], [-0.6664, -0.5509], [-0.6664, 0.6966], [-0.2858, -0.0111], [-0.2858, 0.0421], [0.2049, 0.4111], [0.4239, 0.5551]], [[0, 0.604], [0, 0.0956], [0, 0.5195], [0, 0.6323], [-0.8436, 0.3505], [-0.8436, -0.0476], [-0.4497, -0.5906], [-0.4497, -0.2092], [0.2754, -0.2734], [0.9636, 0.773]], [[0, 0.9], [0, 0.1797], [0, 0.4181], [0, 0.7745], [-0.7923, 0.4706], [-0.7923, -0.6869], [-0.6035, -0.2778], [-0.6035, -0.7435], [0.2054, -0.7411], [1.0296, 1.0414]]]]