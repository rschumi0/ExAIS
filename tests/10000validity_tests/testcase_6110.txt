import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add83371 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in1Add83371 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Mas65846 = tf.keras.layers.Input(shape=([3, 1, 3]))
in0Con21819 = tf.keras.layers.Input(shape=([5, 1]))
in0Con11095 = tf.keras.layers.Input(shape=([20, 5, 1]))
in0Mul53507 = tf.keras.layers.Input(shape=([1, 2, 1, 2]))
in1Mul53507 = tf.keras.layers.Input(shape=([1, 2, 1, 2]))
in0Max12606 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Max12606 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con91686 = tf.keras.layers.Input(shape=([2, 3, 1]))

Add83371 = keras.layers.Add(name = 'Add83371', )([in0Add83371,in1Add83371])
Res3419 = keras.layers.Reshape((1, 1, 4), name = 'Res3419', )(Add83371)
Res35819 = keras.layers.Reshape((1, 4), name = 'Res35819', )(Res3419)
Zer32989 = keras.layers.ZeroPadding1D(padding=((4, 0)), name = 'Zer32989', )(Res35819)
Mas65846 = keras.layers.Masking(mask_value=1, name = 'Mas65846', )(in0Mas65846)
Res69840 = keras.layers.Reshape((3, 3), name = 'Res69840', )(Mas65846)
Zer75746 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer75746', )(Res69840)
Con21819 = keras.layers.Concatenate(axis=2, name = 'Con21819', )([Zer75746,in0Con21819])
Min26135 = keras.layers.Minimum(name = 'Min26135', )([Zer32989,Con21819])
Fla7909 = keras.layers.Flatten(name = 'Fla7909', )(Min26135)
Res90937 = keras.layers.Reshape((20, 1), name = 'Res90937', )(Fla7909)
Res36289 = keras.layers.Reshape((20, 1, 1), name = 'Res36289', )(Res90937)
Zer67089 = keras.layers.ZeroPadding2D(padding=((0, 0), (4, 0)), name = 'Zer67089', )(Res36289)
Con11095 = keras.layers.Concatenate(axis=3, name = 'Con11095', )([Zer67089,in0Con11095])
Mul53507 = keras.layers.Multiply(name = 'Mul53507', )([in0Mul53507,in1Mul53507])
Res4464 = keras.layers.Reshape((1, 2, 2), name = 'Res4464', )(Mul53507)
Zer49717 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer49717', )(Res4464)
Max12606 = keras.layers.Maximum(name = 'Max12606', )([in0Max12606,in1Max12606])
Zer66695 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer66695', )(Max12606)
Con91686 = keras.layers.Concatenate(axis=3, name = 'Con91686', )([Zer66695,in0Con91686])
Sub13363 = keras.layers.Subtract(name = 'Sub13363', )([Zer49717,Con91686])
Zer94815 = keras.layers.ZeroPadding2D(padding=((18, 0), (2, 0)), name = 'Zer94815', )(Sub13363)
Max79860 = keras.layers.Maximum(name = 'Max79860', )([Con11095,Zer94815])
model = tf.keras.models.Model(inputs=[in0Add83371,in1Add83371,in0Mas65846,in0Con21819,in0Con11095,in0Mul53507,in1Mul53507,in0Max12606,in1Max12606,in0Con91686], outputs=Max79860)
in0Add83371 = tf.constant([[[[[0.9508, 0.0129], [0.3114, 0.5126]]]]])
in1Add83371 = tf.constant([[[[[0.2117, 0.1073], [0.19, 0.0152]]]]])
in0Mas65846 = tf.constant([[[[1.1899, 1.8055, 1.9713]], [[1.4173, 1.207, 1.8243]], [[1.4625, 1.039, 1.5185]]]])
in0Con21819 = tf.constant([[[0.9678], [0.1198], [0.8902], [0.5194], [0.7551]]])
in0Con11095 = tf.constant([[[[0.237], [0.5218], [0.6748], [0.9514], [0.4373]], [[0.4447], [0.0855], [0.7201], [0.4935], [0.1033]], [[0.432], [0.1699], [0.103], [0.5876], [0.7978]], [[0.5484], [0.6775], [0.6125], [0.695], [0.5837]], [[0.788], [0.1209], [0.7096], [0.8774], [0.6643]], [[0.7674], [0.344], [0.4665], [0.9852], [0.971]], [[0.7867], [0.2242], [0.9352], [0.762], [0.7184]], [[0.5706], [0.782], [0.9579], [0.681], [0.0417]], [[0.0296], [0.3009], [0.9816], [0.6247], [0.5442]], [[0.0625], [0.5814], [0.4111], [0.9141], [0.2809]], [[0.9272], [0.0413], [0.7057], [0.2331], [0.2259]], [[0.6167], [0.2099], [0.9649], [0.2293], [0.2436]], [[0.7309], [0.7018], [0.2044], [0.1384], [0.4689]], [[0.7469], [0.3925], [0.2703], [0.5654], [0.0349]], [[0.931], [0.8487], [0.9414], [0.8558], [0.9037]], [[0.5721], [0.1427], [0.3894], [0.9148], [0.4466]], [[0.525], [0.5954], [0.3415], [0.1556], [0.7618]], [[0.6981], [0.2077], [0.4157], [0.8379], [0.9675]], [[0.4452], [0.489], [0.4035], [0.7561], [0.159]], [[0.0409], [0.6071], [0.7776], [0.3989], [0.8261]]]])
in0Mul53507 = tf.constant([[[[[0.5696, 0.2241]], [[0.7058, 0.4942]]]]])
in1Mul53507 = tf.constant([[[[[0.0951, 0.7398]], [[0.4046, 0.0687]]]]])
in0Max12606 = tf.constant([[[[0.6028]], [[0.9795]]]])
in1Max12606 = tf.constant([[[[0.6048]], [[0.0328]]]])
in0Con91686 = tf.constant([[[[0.8501], [0.1849], [0.1317]], [[0.2289], [0.4576], [0.7087]]]])
print (np.array2string(model.predict([in0Add83371,in1Add83371,in0Mas65846,in0Con21819,in0Con11095,in0Mul53507,in1Mul53507,in0Max12606,in1Max12606,in0Con91686],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max79860.png')

LAdd83371 = add_layer([[[[[[0.9508, 0.0129], [0.3114, 0.5126]]]]], [[[[[0.2117, 0.1073], [0.19, 0.0152]]]]]], Add83371), 
LRes3419 = reshape_layer(Add83371, [1, 1, 4], Res3419), 
LRes35819 = reshape_layer(Res3419, [1, 4], Res35819), 
LZer32989 = zero_padding1D_layer(Res35819, 4, 0, Zer32989), 
LMas65846 = masking_layer([[[[1.1899, 1.8055, 1.9713]], [[1.4173, 1.207, 1.8243]], [[1.4625, 1.039, 1.5185]]]], 1, Mas65846), 
LRes69840 = reshape_layer(Mas65846, [3, 3], Res69840), 
LZer75746 = zero_padding1D_layer(Res69840, 1, 1, Zer75746), 
LCon21819 = concatenate_layer([Zer75746,[[[0.9678], [0.1198], [0.8902], [0.5194], [0.7551]]]], 2, Con21819), 
LMin26135 = minimum_layer([Zer32989,Con21819], Min26135), 
LFla7909 = flatten_layer(Min26135, Fla7909), 
LRes90937 = reshape_layer(Fla7909, [20, 1], Res90937), 
LRes36289 = reshape_layer(Res90937, [20, 1, 1], Res36289), 
LZer67089 = zero_padding2D_layer(Res36289, 0, 0, 4, 0, Zer67089), 
LCon11095 = concatenate_layer([Zer67089,[[[[0.237], [0.5218], [0.6748], [0.9514], [0.4373]], [[0.4447], [0.0855], [0.7201], [0.4935], [0.1033]], [[0.432], [0.1699], [0.103], [0.5876], [0.7978]], [[0.5484], [0.6775], [0.6125], [0.695], [0.5837]], [[0.788], [0.1209], [0.7096], [0.8774], [0.6643]], [[0.7674], [0.344], [0.4665], [0.9852], [0.971]], [[0.7867], [0.2242], [0.9352], [0.762], [0.7184]], [[0.5706], [0.782], [0.9579], [0.681], [0.0417]], [[0.0296], [0.3009], [0.9816], [0.6247], [0.5442]], [[0.0625], [0.5814], [0.4111], [0.9141], [0.2809]], [[0.9272], [0.0413], [0.7057], [0.2331], [0.2259]], [[0.6167], [0.2099], [0.9649], [0.2293], [0.2436]], [[0.7309], [0.7018], [0.2044], [0.1384], [0.4689]], [[0.7469], [0.3925], [0.2703], [0.5654], [0.0349]], [[0.931], [0.8487], [0.9414], [0.8558], [0.9037]], [[0.5721], [0.1427], [0.3894], [0.9148], [0.4466]], [[0.525], [0.5954], [0.3415], [0.1556], [0.7618]], [[0.6981], [0.2077], [0.4157], [0.8379], [0.9675]], [[0.4452], [0.489], [0.4035], [0.7561], [0.159]], [[0.0409], [0.6071], [0.7776], [0.3989], [0.8261]]]]], 3, Con11095), 
LMul53507 = multiply_layer([[[[[[0.5696, 0.2241]], [[0.7058, 0.4942]]]]], [[[[[0.0951, 0.7398]], [[0.4046, 0.0687]]]]]], Mul53507), 
LRes4464 = reshape_layer(Mul53507, [1, 2, 2], Res4464), 
LZer49717 = zero_padding2D_layer(Res4464, 1, 0, 1, 0, Zer49717), 
LMax12606 = maximum_layer([[[[[0.6028]], [[0.9795]]]], [[[[0.6048]], [[0.0328]]]]], Max12606), 
LZer66695 = zero_padding2D_layer(Max12606, 0, 0, 2, 0, Zer66695), 
LCon91686 = concatenate_layer([Zer66695,[[[[0.8501], [0.1849], [0.1317]], [[0.2289], [0.4576], [0.7087]]]]], 3, Con91686), 
LSub13363 = subtract_layer(Zer49717,Con91686, Sub13363), 
LZer94815 = zero_padding2D_layer(Sub13363, 18, 0, 2, 0, Zer94815), 
LMax79860 = maximum_layer([Con11095,Zer94815], Max79860), 
exec_layers([LAdd83371,LRes3419,LRes35819,LZer32989,LMas65846,LRes69840,LZer75746,LCon21819,LMin26135,LFla7909,LRes90937,LRes36289,LZer67089,LCon11095,LMul53507,LRes4464,LZer49717,LMax12606,LZer66695,LCon91686,LSub13363,LZer94815,LMax79860],["Add83371","Res3419","Res35819","Zer32989","Mas65846","Res69840","Zer75746","Con21819","Min26135","Fla7909","Res90937","Res36289","Zer67089","Con11095","Mul53507","Res4464","Zer49717","Max12606","Zer66695","Con91686","Sub13363","Zer94815","Max79860"],Max79860,"Max79860")

Actual (Unparsed): [[[[0.0000000, 0.2370000], [0.0000000, 0.5218000], [0.0000000, 0.6748000], [0.0000000, 0.9514000], [0.0000000, 0.4373000]], [[0.0000000, 0.4447000], [0.0000000, 0.0855000], [0.0000000, 0.7201000], [0.0000000, 0.4935000], [0.0000000, 0.1033000]], [[0.0000000, 0.4320000], [0.0000000, 0.1699000], [0.0000000, 0.1030000], [0.0000000, 0.5876000], [0.0000000, 0.7978000]], [[0.0000000, 0.5484000], [0.0000000, 0.6775000], [0.0000000, 0.6125000], [0.0000000, 0.6950000], [0.0000000, 0.5837000]], [[0.0000000, 0.7880000], [0.0000000, 0.1209000], [0.0000000, 0.7096000], [0.0000000, 0.8774000], [0.0000000, 0.6643000]], [[0.0000000, 0.7674000], [0.0000000, 0.3440000], [0.0000000, 0.4665000], [0.0000000, 0.9852000], [0.0000000, 0.9710000]], [[0.0000000, 0.7867000], [0.0000000, 0.2242000], [0.0000000, 0.9352000], [0.0000000, 0.7620000], [0.0000000, 0.7184000]], [[0.0000000, 0.5706000], [0.0000000, 0.7820000], [0.0000000, 0.9579000], [0.0000000, 0.6810000], [0.0000000, 0.0417000]], [[0.0000000, 0.0296000], [0.0000000, 0.3009000], [0.0000000, 0.9816000], [0.0000000, 0.6247000], [0.0000000, 0.5442000]], [[0.0000000, 0.0625000], [0.0000000, 0.5814000], [0.0000000, 0.4111000], [0.0000000, 0.9141000], [0.0000000, 0.2809000]], [[0.0000000, 0.9272000], [0.0000000, 0.0413000], [0.0000000, 0.7057000], [0.0000000, 0.2331000], [0.0000000, 0.2259000]], [[0.0000000, 0.6167000], [0.0000000, 0.2099000], [0.0000000, 0.9649000], [0.0000000, 0.2293000], [0.0000000, 0.2436000]], [[0.0000000, 0.7309000], [0.0000000, 0.7018000], [0.0000000, 0.2044000], [0.0000000, 0.1384000], [0.0000000, 0.4689000]], [[0.0000000, 0.7469000], [0.0000000, 0.3925000], [0.0000000, 0.2703000], [0.0000000, 0.5654000], [0.0000000, 0.0349000]], [[0.0000000, 0.9310000], [0.0000000, 0.8487000], [0.0000000, 0.9414000], [0.0000000, 0.8558000], [0.0000000, 0.9037000]], [[0.0000000, 0.5721000], [0.0000000, 0.1427000], [0.0000000, 0.3894000], [0.0000000, 0.9148000], [0.0000000, 0.4466000]], [[0.0000000, 0.5250000], [0.0000000, 0.5954000], [0.0000000, 0.3415000], [0.0000000, 0.1556000], [0.0000000, 0.7618000]], [[0.0000000, 0.6981000], [0.0000000, 0.2077000], [0.0000000, 0.4157000], [0.0000000, 0.8379000], [0.0000000, 0.9675000]], [[0.0000000, 0.4452000], [0.0000000, 0.4890000], [0.0000000, 0.4035000], [0.0000000, 0.7561000], [0.0000000, 0.1590000]], [[0.0000000, 0.0409000], [0.0000000, 0.6071000], [0.0000000, 0.7776000], [0.0541690, 0.3989000], [0.5278000, 0.8261000]]]]

Expected (Unparsed): [[[[0,0.237],[0,0.5218],[0,0.6748],[0,0.9514],[0,0.4373]],[[0,0.4447],[0,0.0855],[0,0.7201],[0,0.4935],[0,0.1033]],[[0,0.432],[0,0.1699],[0,0.103],[0,0.5876],[0,0.7978]],[[0,0.5484],[0,0.6775],[0,0.6125],[0,0.695],[0,0.5837]],[[0,0.788],[0,0.1209],[0,0.7096],[0,0.8774],[0,0.6643]],[[0,0.7674],[0,0.344],[0,0.4665],[0,0.9852],[0,0.971]],[[0,0.7867],[0,0.2242],[0,0.9352],[0,0.762],[0,0.7184]],[[0,0.5706],[0,0.782],[0,0.9579],[0,0.681],[0,0.0417]],[[0,0.0296],[0,0.3009],[0,0.9816],[0,0.6247],[0,0.5442]],[[0,0.0625],[0,0.5814],[0,0.4111],[0,0.9141],[0,0.2809]],[[0,0.9272],[0,0.0413],[0,0.7057],[0,0.2331],[0,0.2259]],[[0,0.6167],[0,0.2099],[0,0.9649],[0,0.2293],[0,0.2436]],[[0,0.7309],[0,0.7018],[0,0.2044],[0,0.1384],[0,0.4689]],[[0,0.7469],[0,0.3925],[0,0.2703],[0,0.5654],[0,0.0349]],[[0,0.931],[0,0.8487],[0,0.9414],[0,0.8558],[0,0.9037]],[[0,0.5721],[0,0.1427],[0,0.3894],[0,0.9148],[0,0.4466]],[[0,0.525],[0,0.5954],[0,0.3415],[0,0.1556],[0,0.7618]],[[0,0.6981],[0,0.2077],[0,0.4157],[0,0.8379],[0,0.9675]],[[0,0.4452],[0,0.489],[0,0.4035],[0,0.7561],[0,0.159]],[[0,0.0409],[0,0.6071],[0,0.7776],[0.05416896,0.3989],[0.5277999999999999,0.8261]]]]

Actual:   [[[[0, 0.237], [0, 0.5218], [0, 0.6748], [0, 0.9514], [0, 0.4373]], [[0, 0.4447], [0, 0.0855], [0, 0.7201], [0, 0.4935], [0, 0.1033]], [[0, 0.432], [0, 0.1699], [0, 0.103], [0, 0.5876], [0, 0.7978]], [[0, 0.5484], [0, 0.6775], [0, 0.6125], [0, 0.695], [0, 0.5837]], [[0, 0.788], [0, 0.1209], [0, 0.7096], [0, 0.8774], [0, 0.6643]], [[0, 0.7674], [0, 0.344], [0, 0.4665], [0, 0.9852], [0, 0.971]], [[0, 0.7867], [0, 0.2242], [0, 0.9352], [0, 0.762], [0, 0.7184]], [[0, 0.5706], [0, 0.782], [0, 0.9579], [0, 0.681], [0, 0.0417]], [[0, 0.0296], [0, 0.3009], [0, 0.9816], [0, 0.6247], [0, 0.5442]], [[0, 0.0625], [0, 0.5814], [0, 0.4111], [0, 0.9141], [0, 0.2809]], [[0, 0.9272], [0, 0.0413], [0, 0.7057], [0, 0.2331], [0, 0.2259]], [[0, 0.6167], [0, 0.2099], [0, 0.9649], [0, 0.2293], [0, 0.2436]], [[0, 0.7309], [0, 0.7018], [0, 0.2044], [0, 0.1384], [0, 0.4689]], [[0, 0.7469], [0, 0.3925], [0, 0.2703], [0, 0.5654], [0, 0.0349]], [[0, 0.931], [0, 0.8487], [0, 0.9414], [0, 0.8558], [0, 0.9037]], [[0, 0.5721], [0, 0.1427], [0, 0.3894], [0, 0.9148], [0, 0.4466]], [[0, 0.525], [0, 0.5954], [0, 0.3415], [0, 0.1556], [0, 0.7618]], [[0, 0.6981], [0, 0.2077], [0, 0.4157], [0, 0.8379], [0, 0.9675]], [[0, 0.4452], [0, 0.489], [0, 0.4035], [0, 0.7561], [0, 0.159]], [[0, 0.0409], [0, 0.6071], [0, 0.7776], [0.0542, 0.3989], [0.5278, 0.8261]]]]

Expected: [[[[0, 0.237], [0, 0.5218], [0, 0.6748], [0, 0.9514], [0, 0.4373]], [[0, 0.4447], [0, 0.0855], [0, 0.7201], [0, 0.4935], [0, 0.1033]], [[0, 0.432], [0, 0.1699], [0, 0.103], [0, 0.5876], [0, 0.7978]], [[0, 0.5484], [0, 0.6775], [0, 0.6125], [0, 0.695], [0, 0.5837]], [[0, 0.788], [0, 0.1209], [0, 0.7096], [0, 0.8774], [0, 0.6643]], [[0, 0.7674], [0, 0.344], [0, 0.4665], [0, 0.9852], [0, 0.971]], [[0, 0.7867], [0, 0.2242], [0, 0.9352], [0, 0.762], [0, 0.7184]], [[0, 0.5706], [0, 0.782], [0, 0.9579], [0, 0.681], [0, 0.0417]], [[0, 0.0296], [0, 0.3009], [0, 0.9816], [0, 0.6247], [0, 0.5442]], [[0, 0.0625], [0, 0.5814], [0, 0.4111], [0, 0.9141], [0, 0.2809]], [[0, 0.9272], [0, 0.0413], [0, 0.7057], [0, 0.2331], [0, 0.2259]], [[0, 0.6167], [0, 0.2099], [0, 0.9649], [0, 0.2293], [0, 0.2436]], [[0, 0.7309], [0, 0.7018], [0, 0.2044], [0, 0.1384], [0, 0.4689]], [[0, 0.7469], [0, 0.3925], [0, 0.2703], [0, 0.5654], [0, 0.0349]], [[0, 0.931], [0, 0.8487], [0, 0.9414], [0, 0.8558], [0, 0.9037]], [[0, 0.5721], [0, 0.1427], [0, 0.3894], [0, 0.9148], [0, 0.4466]], [[0, 0.525], [0, 0.5954], [0, 0.3415], [0, 0.1556], [0, 0.7618]], [[0, 0.6981], [0, 0.2077], [0, 0.4157], [0, 0.8379], [0, 0.9675]], [[0, 0.4452], [0, 0.489], [0, 0.4035], [0, 0.7561], [0, 0.159]], [[0, 0.0409], [0, 0.6071], [0, 0.7776], [0.0542, 0.3989], [0.5278, 0.8261]]]]