import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Lea17349 = tf.keras.layers.Input(shape=([2, 2]))
in0Glo57993 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0Con19914 = tf.keras.layers.Input(shape=([2]))
in0Con11665 = tf.keras.layers.Input(shape=([5, 2]))
in0Max49311 = tf.keras.layers.Input(shape=([1, 2]))
in1Max49311 = tf.keras.layers.Input(shape=([1, 2]))

Lea17349 = keras.layers.LeakyReLU(alpha=6.380999135941616, name = 'Lea17349', input_shape=(2, 2))(in0Lea17349)
Fla25312 = keras.layers.Flatten(name = 'Fla25312', )(Lea17349)
Glo57993 = keras.layers.GlobalMaxPool3D(name = 'Glo57993', )(in0Glo57993)
Con19914 = keras.layers.Concatenate(axis=1, name = 'Con19914', )([Glo57993,in0Con19914])
Max83690 = keras.layers.Maximum(name = 'Max83690', )([Fla25312,Con19914])
Res78570 = keras.layers.Reshape((4, 1), name = 'Res78570', )(Max83690)
Zer85478 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer85478', )(Res78570)
Con11665 = keras.layers.Concatenate(axis=2, name = 'Con11665', )([Zer85478,in0Con11665])
Max49311 = keras.layers.Maximum(name = 'Max49311', )([in0Max49311,in1Max49311])
Glo13209 = keras.layers.GlobalMaxPool1D(name = 'Glo13209', )(Max49311)
Res55395 = keras.layers.Reshape((2, 1), name = 'Res55395', )(Glo13209)
LST57900 = keras.layers.LSTM(1,recurrent_activation='sigmoid', name = 'LST57900', )(Res55395)
Res47069 = keras.layers.Reshape((1, 1), name = 'Res47069', )(LST57900)
Res44097 = keras.layers.Reshape((1, 1, 1), name = 'Res44097', )(Res47069)
Zer169 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer169', )(Res44097)
Res44270 = keras.layers.Reshape((3, 3), name = 'Res44270', )(Zer169)
Dot72467 = keras.layers.Dot(axes=(2, 2), name = 'Dot72467', )([Con11665,Res44270])
model = tf.keras.models.Model(inputs=[in0Lea17349,in0Glo57993,in0Con19914,in0Con11665,in0Max49311,in1Max49311], outputs=Dot72467)
w = model.get_layer('LST57900').get_weights() 
w[0] = np.array([[2, 9, 1, 5]])
w[1] = np.array([[5, 6, 3, 1]])
w[2] = np.array([3, 10, 1, 5])
model.get_layer('LST57900').set_weights(w) 
in0Lea17349 = tf.constant([[[0.9834, 0.0849], [0.3785, 0.4631]]])
in0Glo57993 = tf.constant([[[[[1.5031, 1.6273]], [[1.9514, 1.0839]]], [[[1.5411, 1.9594]], [[1.8769, 1.7834]]]]])
in0Con19914 = tf.constant([[0.679, 0.771]])
in0Con11665 = tf.constant([[[0.4359, 0.6513], [0.6359, 0.0646], [0.6854, 0.2305], [0.0387, 0.1453], [0.1885, 0.9104]]])
in0Max49311 = tf.constant([[[0.9993, 0.8552]]])
in1Max49311 = tf.constant([[[0.0467, 0.3049]]])
print (np.array2string(model.predict([in0Lea17349,in0Glo57993,in0Con19914,in0Con11665,in0Max49311,in1Max49311],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot72467.png')

LLea17349 = leaky_relu_layer([[[0.9834, 0.0849], [0.3785, 0.4631]]], 6.380999135941616, Lea17349), 
LFla25312 = flatten_layer(Lea17349, Fla25312), 
LGlo57993 = global_max_pool3D_layer([[[[[1.5031, 1.6273]], [[1.9514, 1.0839]]], [[[1.5411, 1.9594]], [[1.8769, 1.7834]]]]], Glo57993), 
LCon19914 = concatenate_layer([Glo57993,[[0.679, 0.771]]], 1, Con19914), 
LMax83690 = maximum_layer([Fla25312,Con19914], Max83690), 
LRes78570 = reshape_layer(Max83690, [4, 1], Res78570), 
LZer85478 = zero_padding1D_layer(Res78570, 1, 0, Zer85478), 
LCon11665 = concatenate_layer([Zer85478,[[[0.4359, 0.6513], [0.6359, 0.0646], [0.6854, 0.2305], [0.0387, 0.1453], [0.1885, 0.9104]]]], 2, Con11665), 
LMax49311 = maximum_layer([[[[0.9993, 0.8552]]], [[[0.0467, 0.3049]]]], Max49311), 
LGlo13209 = global_max_pool1D_layer(Max49311, Glo13209), 
LRes55395 = reshape_layer(Glo13209, [2, 1], Res55395), 
LLST57900 = lstm_layer(Res55395,[[2, 9, 1, 5]],[[5, 6, 3, 1]],[3, 10, 1, 5], LST57900), 
LRes47069 = reshape_layer(LST57900, [1, 1], Res47069), 
LRes44097 = reshape_layer(Res47069, [1, 1, 1], Res44097), 
LZer169 = zero_padding2D_layer(Res44097, 1, 1, 1, 1, Zer169), 
LRes44270 = reshape_layer(Zer169, [3, 3], Res44270), 
LDot72467 = dot_layer(Con11665,Res44270, 2, 2, Dot72467), 
exec_layers([LLea17349,LFla25312,LGlo57993,LCon19914,LMax83690,LRes78570,LZer85478,LCon11665,LMax49311,LGlo13209,LRes55395,LLST57900,LRes47069,LRes44097,LZer169,LRes44270,LDot72467],["Lea17349","Fla25312","Glo57993","Con19914","Max83690","Res78570","Zer85478","Con11665","Max49311","Glo13209","Res55395","LST57900","Res47069","Res44097","Zer169","Res44270","Dot72467"],Dot72467,"Dot72467")

Actual (Unparsed): [[[0.0000000, 0.4188114, 0.0000000], [0.0000000, 0.6109708, 0.0000000], [0.0000000, 0.6585302, 0.0000000], [0.0000000, 0.0371828, 0.0000000], [0.0000000, 0.1811102, 0.0000000]]]

Expected (Unparsed): [[[0.0,0.41881136533849406,0.0],[0.0,0.6109707437915769,0.0],[0.0,0.6585301899587149,0.0],[0.0,0.037182839730671526,0.0],[0.0,0.18111021419203058,0.0]]]

Actual:   [[[0, 0.4189, 0], [0, 0.611, 0], [0, 0.6586, 0], [0, 0.0372, 0], [0, 0.1812, 0]]]

Expected: [[[0, 0.4189, 0], [0, 0.611, 0], [0, 0.6586, 0], [0, 0.0372, 0], [0, 0.1812, 0]]]