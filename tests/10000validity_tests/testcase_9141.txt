import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ReL17863 = tf.keras.layers.Input(shape=([2, 1]))
in0Max4022 = tf.keras.layers.Input(shape=([2, 1, 2]))
in1Max4022 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0PRe39896 = tf.keras.layers.Input(shape=([1, 2]))
in0Con90393 = tf.keras.layers.Input(shape=([2, 2]))

ReL17863 = keras.layers.ReLU(max_value=0.10754336079648377, negative_slope=5.521097216241592, threshold=7.336787651203385, name = 'ReL17863', input_shape=(2, 1))(in0ReL17863)
Lea91284 = keras.layers.LeakyReLU(alpha=3.871443129090166, name = 'Lea91284', )(ReL17863)
Ave694 = keras.layers.AveragePooling1D(pool_size=(1), strides=(1), padding='same', name = 'Ave694', )(Lea91284)
Sep88203 = keras.layers.SeparableConv1D(3, (1),strides=(1), padding='same', name = 'Sep88203', )(Ave694)
Max4022 = keras.layers.Maximum(name = 'Max4022', )([in0Max4022,in1Max4022])
Res22349 = keras.layers.Reshape((2, 2), name = 'Res22349', )(Max4022)
PRe39896 = keras.layers.PReLU(name = 'PRe39896', input_shape=(1, 2))(in0PRe39896)
Dot48642 = keras.layers.Dot(axes=(1, 2), name = 'Dot48642', )([Res22349,PRe39896])
Con90393 = keras.layers.Concatenate(axis=2, name = 'Con90393', )([Dot48642,in0Con90393])
Ave20422 = keras.layers.Average(name = 'Ave20422', )([Sep88203,Con90393])
model = tf.keras.models.Model(inputs=[in0ReL17863,in0Max4022,in1Max4022,in0PRe39896,in0Con90393], outputs=Ave20422)
w = model.get_layer('Sep88203').get_weights() 
w[0] = np.array([[[0.7322]]])
w[1] = np.array([[[0.9739, 0.9041, 0.5961]]])
w[2] = np.array([0, 0, 0])
model.get_layer('Sep88203').set_weights(w) 
w = model.get_layer('PRe39896').get_weights() 
w[0] = np.array([[0.7897, 0.1215]])
model.get_layer('PRe39896').set_weights(w) 
in0ReL17863 = tf.constant([[[0.0406], [0.3716]]])
in0Max4022 = tf.constant([[[[0.8542, 0.5784]], [[0.1166, 0.4379]]]])
in1Max4022 = tf.constant([[[[0.1799, 0.387]], [[0.6762, 0.0185]]]])
in0PRe39896 = tf.constant([[[0.824, 0.796]]])
in0Con90393 = tf.constant([[[0.1309, 0.9327], [0.9186, 0.8343]]])
print (np.array2string(model.predict([in0ReL17863,in0Max4022,in1Max4022,in0PRe39896,in0Con90393],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave20422.png')

LReL17863 = relu_layer([[[0.0406], [0.3716]]], 0.10754336079648377, 5.521097216241592, 7.336787651203385, ReL17863), 
LLea91284 = leaky_relu_layer(ReL17863, 3.871443129090166, Lea91284), 
LAve694 = average_pooling1D_layer(Lea91284, 1, 1, true, Ave694), 
LSep88203 = separable_conv1D_layer(Ave694, 1,[[[[0.7322]]],[[[0.9739, 0.9041, 0.5961]]]],[0, 0, 0], 1, true, Sep88203), 
LMax4022 = maximum_layer([[[[[0.8542, 0.5784]], [[0.1166, 0.4379]]]], [[[[0.1799, 0.387]], [[0.6762, 0.0185]]]]], Max4022), 
LRes22349 = reshape_layer(Max4022, [2, 2], Res22349), 
LPRe39896 = prelu_layer([[[0.824, 0.796]]], [[0.7897, 0.1215]], PRe39896), 
LDot48642 = dot_layer(Res22349,PRe39896, 1, 2, Dot48642), 
LCon90393 = concatenate_layer([Dot48642,[[[0.1309, 0.9327], [0.9186, 0.8343]]]], 2, Con90393), 
LAve20422 = average_layer([Sep88203,Con90393], Ave20422), 
exec_layers([LReL17863,LLea91284,LAve694,LSep88203,LMax4022,LRes22349,LPRe39896,LDot48642,LCon90393,LAve20422],["ReL17863","Lea91284","Ave694","Sep88203","Max4022","Res22349","PRe39896","Dot48642","Con90393","Ave20422"],Ave20422,"Ave20422")

Actual (Unparsed): [[[-54.9832394, -51.5536539, -33.5676593], [-52.6691590, -48.8180434, -32.0728671]]]

Expected (Unparsed): [[[-54.983240755122274,-51.55365514889213,-33.567660152919586],[-52.669160365899906,-48.818044681497184,-32.072867879261665]]]

Actual:   [[[-54.9832, -51.5536, -33.5676], [-52.6691, -48.818, -32.0728]]]

Expected: [[[-54.9832, -51.5536, -33.5676], [-52.6691, -48.818, -32.0728]]]