import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ReL34299 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Lea31138 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con54244 = tf.keras.layers.Input(shape=([1]))
in0Dep7279 = tf.keras.layers.Input(shape=([2, 1, 2]))

ReL34299 = keras.layers.ReLU(max_value=7.0821795717689415, negative_slope=2.396640897926651, threshold=8.06003409924005, name = 'ReL34299', input_shape=(1, 2, 1))(in0ReL34299)
Res83237 = keras.layers.Reshape((1, 2), name = 'Res83237', )(ReL34299)
Lea31138 = keras.layers.LeakyReLU(alpha=6.562972431012332, name = 'Lea31138', input_shape=(2, 1, 2))(in0Lea31138)
Res96785 = keras.layers.Reshape((2, 2), name = 'Res96785', )(Lea31138)
Glo37753 = keras.layers.GlobalAveragePooling1D(name = 'Glo37753', )(Res96785)
Res21637 = keras.layers.Reshape((1, 2), name = 'Res21637', )(Glo37753)
Mul51292 = keras.layers.Multiply(name = 'Mul51292', )([Res83237,Res21637])
Fla97357 = keras.layers.Flatten(name = 'Fla97357', )(Mul51292)
Con54244 = keras.layers.Concatenate(axis=1, name = 'Con54244', )([Fla97357,in0Con54244])
Dep7279 = keras.layers.DepthwiseConv2D((2, 1),strides=(1, 1), padding='valid', name = 'Dep7279', )(in0Dep7279)
Res31987 = keras.layers.Reshape((1, 2), name = 'Res31987', )(Dep7279)
Glo20391 = keras.layers.GlobalMaxPool1D(name = 'Glo20391', )(Res31987)
Res95938 = keras.layers.Reshape((2, 1), name = 'Res95938', )(Glo20391)
Sim74592 = keras.layers.SimpleRNN(3,name = 'Sim74592', )(Res95938)
Dot66084 = keras.layers.Dot(axes=(1, 1), name = 'Dot66084', )([Con54244,Sim74592])
model = tf.keras.models.Model(inputs=[in0ReL34299,in0Lea31138,in0Con54244,in0Dep7279], outputs=Dot66084)
w = model.get_layer('Dep7279').get_weights() 
w[0] = np.array([[[[0.0715], [0.0749]]], [[[0.6211], [0.4908]]]])
w[1] = np.array([0, 0])
model.get_layer('Dep7279').set_weights(w) 
w = model.get_layer('Sim74592').get_weights() 
w[0] = np.array([[1, 10, 1]])
w[1] = np.array([[2, 3, 8], [9, 2, 6], [4, 2, 6]])
w[2] = np.array([5, 6, 1])
model.get_layer('Sim74592').set_weights(w) 
in0ReL34299 = tf.constant([[[[0.7529], [0.5411]]]])
in0Lea31138 = tf.constant([[[[0.8396, 0.928]], [[0.0941, 0.8277]]]])
in0Con54244 = tf.constant([[0.9235]])
in0Dep7279 = tf.constant([[[[0.9997, 0.1648]], [[0.4925, 0.1809]]]])
print (np.array2string(model.predict([in0ReL34299,in0Lea31138,in0Con54244,in0Dep7279],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot66084.png')

LReL34299 = relu_layer([[[[0.7529], [0.5411]]]], 7.0821795717689415, 2.396640897926651, 8.06003409924005, ReL34299), 
LRes83237 = reshape_layer(ReL34299, [1, 2], Res83237), 
LLea31138 = leaky_relu_layer([[[[0.8396, 0.928]], [[0.0941, 0.8277]]]], 6.562972431012332, Lea31138), 
LRes96785 = reshape_layer(Lea31138, [2, 2], Res96785), 
LGlo37753 = global_average_pooling1D_layer(Res96785, Glo37753), 
LRes21637 = reshape_layer(Glo37753, [1, 2], Res21637), 
LMul51292 = multiply_layer([Res83237,Res21637], Mul51292), 
LFla97357 = flatten_layer(Mul51292, Fla97357), 
LCon54244 = concatenate_layer([Fla97357,[[0.9235]]], 1, Con54244), 
LDep7279 = depthwise_conv2D_layer([[[[0.9997, 0.1648]], [[0.4925, 0.1809]]]], 2, 1,[[[[0.0715], [0.0749]]], [[[0.6211], [0.4908]]]],[0, 0], 1, 1, false, Dep7279), 
LRes31987 = reshape_layer(Dep7279, [1, 2], Res31987), 
LGlo20391 = global_max_pool1D_layer(Res31987, Glo20391), 
LRes95938 = reshape_layer(Glo20391, [2, 1], Res95938), 
LSim74592 = simple_rnn_layer(Res95938,[[1, 10, 1]],[[2, 3, 8], [9, 2, 6], [4, 2, 6]],[5, 6, 1], Sim74592), 
LDot66084 = dot_layer(Con54244,Sim74592, 1, 1, Dot66084), 
exec_layers([LReL34299,LRes83237,LLea31138,LRes96785,LGlo37753,LRes21637,LMul51292,LFla97357,LCon54244,LDep7279,LRes31987,LGlo20391,LRes95938,LSim74592,LDot66084],["ReL34299","Res83237","Lea31138","Res96785","Glo37753","Res21637","Mul51292","Fla97357","Con54244","Dep7279","Res31987","Glo20391","Res95938","Sim74592","Dot66084"],Dot66084,"Dot66084")

Actual (Unparsed): [[-23.0712658]]

Expected (Unparsed): [[-23.071265682624638]]

Actual:   [[-23.0712]]

Expected: [[-23.0712]]