import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo41081 = tf.keras.layers.Input(shape=([2, 1]))
in0Con37775 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Sub63774 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Sub63774 = tf.keras.layers.Input(shape=([2, 2, 2]))

Glo41081 = keras.layers.GlobalAveragePooling1D(name = 'Glo41081', )(in0Glo41081)
Res57326 = keras.layers.Reshape((1, 1), name = 'Res57326', )(Glo41081)
Res26103 = keras.layers.Reshape((1, 1, 1), name = 'Res26103', )(Res57326)
Zer78066 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer78066', )(Res26103)
Con37775 = keras.layers.Concatenate(axis=3, name = 'Con37775', )([Zer78066,in0Con37775])
Sub63774 = keras.layers.Subtract(name = 'Sub63774', )([in0Sub63774,in1Sub63774])
Max4721 = keras.layers.Maximum(name = 'Max4721', )([Con37775,Sub63774])
Res24165 = keras.layers.Reshape((2, 4), name = 'Res24165', )(Max4721)
Sim52217 = keras.layers.SimpleRNN(1,name = 'Sim52217', )(Res24165)
Lay60361 = keras.layers.LayerNormalization(axis=1, epsilon=1.0497898395436198, name = 'Lay60361', )(Sim52217)
Res94403 = keras.layers.Reshape((1, 1), name = 'Res94403', )(Lay60361)
Sim88449 = keras.layers.SimpleRNN(2,name = 'Sim88449', )(Res94403)
model = tf.keras.models.Model(inputs=[in0Glo41081,in0Con37775,in0Sub63774,in1Sub63774], outputs=Sim88449)
w = model.get_layer('Sim52217').get_weights() 
w[0] = np.array([[3], [8], [3], [5]])
w[1] = np.array([[7]])
w[2] = np.array([4])
model.get_layer('Sim52217').set_weights(w) 
w = model.get_layer('Sim88449').get_weights() 
w[0] = np.array([[6, 5]])
w[1] = np.array([[2, 9], [5, 7]])
w[2] = np.array([10, 9])
model.get_layer('Sim88449').set_weights(w) 
in0Glo41081 = tf.constant([[[1.4007], [1.229]]])
in0Con37775 = tf.constant([[[[0.7995], [0.9363]], [[0.3732], [0.667]]]])
in0Sub63774 = tf.constant([[[[0.2731, 0.8019], [0.24, 0.8438]], [[0.4743, 0.6551], [0.1825, 0.8381]]]])
in1Sub63774 = tf.constant([[[[0.4696, 0.9478], [0.3429, 0.8528]], [[0.2853, 0.8786], [0.1223, 0.1961]]]])
print (np.array2string(model.predict([in0Glo41081,in0Con37775,in0Sub63774,in1Sub63774],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sim88449.png')

LGlo41081 = global_average_pooling1D_layer([[[1.4007], [1.229]]], Glo41081), 
LRes57326 = reshape_layer(Glo41081, [1, 1], Res57326), 
LRes26103 = reshape_layer(Res57326, [1, 1, 1], Res26103), 
LZer78066 = zero_padding2D_layer(Res26103, 1, 0, 1, 0, Zer78066), 
LCon37775 = concatenate_layer([Zer78066,[[[[0.7995], [0.9363]], [[0.3732], [0.667]]]]], 3, Con37775), 
LSub63774 = subtract_layer([[[[0.2731, 0.8019], [0.24, 0.8438]], [[0.4743, 0.6551], [0.1825, 0.8381]]]], [[[[0.4696, 0.9478], [0.3429, 0.8528]], [[0.2853, 0.8786], [0.1223, 0.1961]]]], Sub63774), 
LMax4721 = maximum_layer([Con37775,Sub63774], Max4721), 
LRes24165 = reshape_layer(Max4721, [2, 4], Res24165), 
LSim52217 = simple_rnn_layer(Res24165,[[3], [8], [3], [5]],[[7]],[4], Sim52217), 
LLay60361 = layer_normalization_layer(Sim52217, 1, 1.0497898395436198, Lay60361), 
LRes94403 = reshape_layer(Lay60361, [1, 1], Res94403), 
LSim88449 = simple_rnn_layer(Res94403,[[6, 5]],[[2, 9], [5, 7]],[10, 9], Sim88449), 
exec_layers([LGlo41081,LRes57326,LRes26103,LZer78066,LCon37775,LSub63774,LMax4721,LRes24165,LSim52217,LLay60361,LRes94403,LSim88449],["Glo41081","Res57326","Res26103","Zer78066","Con37775","Sub63774","Max4721","Res24165","Sim52217","Lay60361","Res94403","Sim88449"],Sim88449,"Sim88449")

Actual (Unparsed): [[1.0000000, 1.0000000]]

Expected (Unparsed): [[0.9999999958776927,0.999999969540041]]

Actual:   [[1, 1]]

Expected: [[1, 1]]