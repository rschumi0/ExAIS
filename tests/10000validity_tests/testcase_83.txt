import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0LST25107 = tf.keras.layers.Input(shape=([3, 1]))
in0Glo64735 = tf.keras.layers.Input(shape=([1, 1]))
in0Con88201 = tf.keras.layers.Input(shape=([1]))
in0Con71823 = tf.keras.layers.Input(shape=([5, 4, 1]))
in0Zer47956 = tf.keras.layers.Input(shape=([3, 2, 1]))

LST25107 = keras.layers.LSTM(2,recurrent_activation='sigmoid', name = 'LST25107', )(in0LST25107)
Glo64735 = keras.layers.GlobalAveragePooling1D(name = 'Glo64735', )(in0Glo64735)
Con88201 = keras.layers.Concatenate(axis=1, name = 'Con88201', )([Glo64735,in0Con88201])
Min70566 = keras.layers.Minimum(name = 'Min70566', )([LST25107,Con88201])
Res54370 = keras.layers.Reshape((2, 1), name = 'Res54370', )(Min70566)
Res36858 = keras.layers.Reshape((2, 1, 1), name = 'Res36858', )(Res54370)
Zer55913 = keras.layers.ZeroPadding2D(padding=((3, 0), (3, 0)), name = 'Zer55913', )(Res36858)
Con71823 = keras.layers.Concatenate(axis=3, name = 'Con71823', )([Zer55913,in0Con71823])
Zer47956 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer47956', )(in0Zer47956)
Den98830 = keras.layers.Dense(2,name = 'Den98830', )(Zer47956)
Mul82466 = keras.layers.Multiply(name = 'Mul82466', )([Con71823,Den98830])
model = tf.keras.models.Model(inputs=[in0LST25107,in0Glo64735,in0Con88201,in0Con71823,in0Zer47956], outputs=Mul82466)
w = model.get_layer('LST25107').get_weights() 
w[0] = np.array([[1, 3, 7, 5, 7, 6, 6, 2]])
w[1] = np.array([[1, 7, 9, 10, 6, 8, 9, 8], [1, 3, 7, 1, 2, 7, 6, 10]])
w[2] = np.array([4, 8, 10, 10, 3, 5, 9, 8])
model.get_layer('LST25107').set_weights(w) 
w = model.get_layer('Den98830').get_weights() 
w[0] = np.array([[0.6039, 0.6747]])
w[1] = np.array([0.7768, 0.8948])
model.get_layer('Den98830').set_weights(w) 
in0LST25107 = tf.constant([[[8], [10], [7]]])
in0Glo64735 = tf.constant([[[1.5818]]])
in0Con88201 = tf.constant([[0.4585]])
in0Con71823 = tf.constant([[[[0.4964], [0.1132], [0.9328], [0.811]], [[0.9663], [0.128], [0.1082], [0.8133]], [[0.4286], [0.3556], [0.2739], [0.9944]], [[0.1989], [0.8667], [0.5926], [0.4751]], [[0.2844], [0.3519], [0.7629], [0.4542]]]])
in0Zer47956 = tf.constant([[[[1.1423], [1.7358]], [[1.1142], [1.3123]], [[1.5561], [1.2828]]]])
print (np.array2string(model.predict([in0LST25107,in0Glo64735,in0Con88201,in0Con71823,in0Zer47956],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul82466.png')

LLST25107 = lstm_layer([[[8], [10], [7]]],[[1, 3, 7, 5, 7, 6, 6, 2]],[[1, 7, 9, 10, 6, 8, 9, 8], [1, 3, 7, 1, 2, 7, 6, 10]],[4, 8, 10, 10, 3, 5, 9, 8], LST25107), 
LGlo64735 = global_average_pooling1D_layer([[[1.5818]]], Glo64735), 
LCon88201 = concatenate_layer([Glo64735,[[0.4585]]], 1, Con88201), 
LMin70566 = minimum_layer([LST25107,Con88201], Min70566), 
LRes54370 = reshape_layer(Min70566, [2, 1], Res54370), 
LRes36858 = reshape_layer(Res54370, [2, 1, 1], Res36858), 
LZer55913 = zero_padding2D_layer(Res36858, 3, 0, 3, 0, Zer55913), 
LCon71823 = concatenate_layer([Zer55913,[[[[0.4964], [0.1132], [0.9328], [0.811]], [[0.9663], [0.128], [0.1082], [0.8133]], [[0.4286], [0.3556], [0.2739], [0.9944]], [[0.1989], [0.8667], [0.5926], [0.4751]], [[0.2844], [0.3519], [0.7629], [0.4542]]]]], 3, Con71823), 
LZer47956 = zero_padding2D_layer([[[[1.1423], [1.7358]], [[1.1142], [1.3123]], [[1.5561], [1.2828]]]], 1, 1, 1, 1, Zer47956), 
LDen98830 = dense_layer(Zer47956, [[0.6039, 0.6747]],[0.7768, 0.8948], Den98830), 
LMul82466 = multiply_layer([Con71823,Den98830], Mul82466), 
exec_layers([LLST25107,LGlo64735,LCon88201,LMin70566,LRes54370,LRes36858,LZer55913,LCon71823,LZer47956,LDen98830,LMul82466],["LST25107","Glo64735","Con88201","Min70566","Res54370","Res36858","Zer55913","Con71823","Zer47956","Den98830","Mul82466"],Mul82466,"Mul82466")

Actual (Unparsed): [[[[0.0000000, 0.4441787], [0.0000000, 0.1012914], [0.0000000, 0.8346694], [0.0000000, 0.7256828]], [[0.0000000, 0.8646452], [0.0000000, 0.2131853], [0.0000000, 0.2235352], [0.0000000, 0.7277409]], [[0.0000000, 0.3835113], [0.0000000, 0.5855134], [0.0000000, 0.4875992], [0.0000000, 0.8897891]], [[0.0000000, 0.1779757], [0.0000000, 1.6854721], [0.0000000, 1.0431568], [0.7729585, 0.4251195]], [[0.0000000, 0.2544811], [0.0000000, 0.3148801], [0.0000000, 0.6826429], [0.3561628, 0.4064182]]]]

Expected (Unparsed): [[[[0.0,0.44417872],[0.0,0.10129136],[0.0,0.83466944],[0.0,0.7256828000000001]],[[0.0,0.8646452400000001],[0.0,0.21318525568000002],[0.0,0.22353516893200004],[0.0,0.72774084]],[[0.0,0.38351128],[0.0,0.585513443144],[0.0,0.48759919305899996],[0.0,0.88978912]],[[0.0,0.17797572],[0.0,1.685472070689],[0.0,1.0431568378159999],[0.7729584655701102,0.42511948000000005]],[[0.0,0.25448112],[0.0,0.31488012],[0.0,0.68264292],[0.35616280000000006,0.40641816000000003]]]]

Actual:   [[[[0, 0.4442], [0, 0.1013], [0, 0.8347], [0, 0.7257]], [[0, 0.8647], [0, 0.2132], [0, 0.2236], [0, 0.7278]], [[0, 0.3836], [0, 0.5856], [0, 0.4876], [0, 0.8898]], [[0, 0.178], [0, 1.6855], [0, 1.0432], [0.773, 0.4252]], [[0, 0.2545], [0, 0.3149], [0, 0.6827], [0.3562, 0.4065]]]]

Expected: [[[[0, 0.4442], [0, 0.1013], [0, 0.8347], [0, 0.7257]], [[0, 0.8647], [0, 0.2132], [0, 0.2236], [0, 0.7278]], [[0, 0.3836], [0, 0.5856], [0, 0.4876], [0, 0.8898]], [[0, 0.178], [0, 1.6855], [0, 1.0432], [0.773, 0.4252]], [[0, 0.2545], [0, 0.3149], [0, 0.6827], [0.3562, 0.4065]]]]