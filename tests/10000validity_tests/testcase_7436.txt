import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave1169 = tf.keras.layers.Input(shape=([2, 2]))
in1Ave1169 = tf.keras.layers.Input(shape=([2, 2]))
in0Glo28494 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con60085 = tf.keras.layers.Input(shape=([2]))
in0Up_34578 = tf.keras.layers.Input(shape=([2, 1]))

Ave1169 = keras.layers.Average(name = 'Ave1169', )([in0Ave1169,in1Ave1169])
Fla11066 = keras.layers.Flatten(name = 'Fla11066', )(Ave1169)
Glo28494 = keras.layers.GlobalAveragePooling2D(name = 'Glo28494', )(in0Glo28494)
Con60085 = keras.layers.Concatenate(axis=1, name = 'Con60085', )([Glo28494,in0Con60085])
Sub31993 = keras.layers.Subtract(name = 'Sub31993', )([Fla11066,Con60085])
Res76811 = keras.layers.Reshape((4, 1), name = 'Res76811', )(Sub31993)
Zer93076 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer93076', )(Res76811)
ELU57944 = keras.layers.ELU(alpha=2.0762325447815417, name = 'ELU57944', )(Zer93076)
Up_34578 = keras.layers.UpSampling1D(size=(2), name = 'Up_34578', )(in0Up_34578)
Zer2274 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer2274', )(Up_34578)
Add32432 = keras.layers.Add(name = 'Add32432', )([ELU57944,Zer2274])
model = tf.keras.models.Model(inputs=[in0Ave1169,in1Ave1169,in0Glo28494,in0Con60085,in0Up_34578], outputs=Add32432)
in0Ave1169 = tf.constant([[[0.2906, 0.4081], [0.8548, 0.9551]]])
in1Ave1169 = tf.constant([[[0.5802, 0.5915], [0.4873, 0.4742]]])
in0Glo28494 = tf.constant([[[[1.4532, 1.709]], [[1.128, 1.4792]]]])
in0Con60085 = tf.constant([[0.618, 0.813]])
in0Up_34578 = tf.constant([[[1.2546], [1.7687]]])
print (np.array2string(model.predict([in0Ave1169,in1Ave1169,in0Glo28494,in0Con60085,in0Up_34578],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add32432.png')

LAve1169 = average_layer([[[[0.2906, 0.4081], [0.8548, 0.9551]]], [[[0.5802, 0.5915], [0.4873, 0.4742]]]], Ave1169), 
LFla11066 = flatten_layer(Ave1169, Fla11066), 
LGlo28494 = global_average_pooling2D_layer([[[[1.4532, 1.709]], [[1.128, 1.4792]]]], Glo28494), 
LCon60085 = concatenate_layer([Glo28494,[[0.618, 0.813]]], 1, Con60085), 
LSub31993 = subtract_layer(Fla11066,Con60085, Sub31993), 
LRes76811 = reshape_layer(Sub31993, [4, 1], Res76811), 
LZer93076 = zero_padding1D_layer(Res76811, 1, 1, Zer93076), 
LELU57944 = elu_layer(Zer93076, 2.0762325447815417, ELU57944), 
LUp_34578 = up_sampling1D_layer([[[1.2546], [1.7687]]], 2, Up_34578), 
LZer2274 = zero_padding1D_layer(Up_34578, 2, 0, Zer2274), 
LAdd32432 = add_layer([ELU57944,Zer2274], Add32432), 
exec_layers([LAve1169,LFla11066,LGlo28494,LCon60085,LSub31993,LRes76811,LZer93076,LELU57944,LUp_34578,LZer2274,LAdd32432],["Ave1169","Fla11066","Glo28494","Con60085","Sub31993","Res76811","Zer93076","ELU57944","Up_34578","Zer2274","Add32432"],Add32432,"Add32432")

Actual (Unparsed): [[[0.0000000], [-1.1934223], [-0.1265641], [1.3076501], [1.5742227], [1.7687000]]]

Expected (Unparsed): [[[0],[-1.193422322409833],[-0.12656414769048308],[1.30765],[1.5742226862810291],[1.7687]]]

Actual:   [[[0], [-1.1934], [-0.1265], [1.3077], [1.5743], [1.7687]]]

Expected: [[[0], [-1.1934], [-0.1265], [1.3077], [1.5743], [1.7687]]]