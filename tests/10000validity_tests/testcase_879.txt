import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con85294 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Sub99771 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Sub99771 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Con50857 = tf.keras.layers.Input(shape=([1, 2, 1]))

Con85294 = keras.layers.Conv2DTranspose(4, (1, 1),strides=(1, 1), padding='valid', name = 'Con85294', )(in0Con85294)
Zer65794 = keras.layers.ZeroPadding2D(padding=((0, 0), (1, 0)), name = 'Zer65794', )(Con85294)
Sub99771 = keras.layers.Subtract(name = 'Sub99771', )([in0Sub99771,in1Sub99771])
Res6043 = keras.layers.Reshape((2, 2, 4), name = 'Res6043', )(Sub99771)
Con33181 = keras.layers.Conv2D(3, (1, 2),strides=(2, 1), padding='same', dilation_rate=(1, 1), name = 'Con33181', )(Res6043)
Con50857 = keras.layers.Concatenate(axis=3, name = 'Con50857', )([Con33181,in0Con50857])
Add64748 = keras.layers.Add(name = 'Add64748', )([Zer65794,Con50857])
model = tf.keras.models.Model(inputs=[in0Con85294,in0Sub99771,in1Sub99771,in0Con50857], outputs=Add64748)
w = model.get_layer('Con85294').get_weights() 
w[0] = np.array([[[[0.9357], [0.0699], [0.4237], [0.7405]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con85294').set_weights(w) 
w = model.get_layer('Con33181').get_weights() 
w[0] = np.array([[[[0.0268, 0.0936, 0.6407], [0.7725, 0.1615, 0.7952], [0.5394, 0.8647, 0.0412], [0.6275, 0.4525, 0.7165]], [[0.8409, 0.3627, 0.1252], [0.7415, 0.5228, 0.0503], [0.0437, 0.8473, 0.0716], [0.9555, 0.0555, 0.6948]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con33181').set_weights(w) 
in0Con85294 = tf.constant([[[[0.9042]]]])
in0Sub99771 = tf.constant([[[[[0.2799, 0.7587], [0.3786, 0.0547]], [[0.0294, 0.5318], [0.317, 0.9868]]], [[[0.3599, 0.6011], [0.0316, 0.1851]], [[0.1758, 0.2786], [0.6637, 0.6792]]]]])
in1Sub99771 = tf.constant([[[[[0.0315, 0.1297], [0.2484, 0.6597]], [[0.3179, 0.0496], [0.5636, 0.5458]]], [[[0.1698, 0.8265], [0.6433, 0.1704]], [[0.5759, 0.2532], [0.3675, 0.2649]]]]])
in0Con50857 = tf.constant([[[[0.6742], [0.3495]]]])
print (np.array2string(model.predict([in0Con85294,in0Sub99771,in1Sub99771,in0Con50857],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add64748.png')

LCon85294 = conv2D_transpose_layer([[[[0.9042]]]], 1, 1,[[[[0.9357], [0.0699], [0.4237], [0.7405]]]],[0, 0, 0, 0], 1, 1, false, Con85294), 
LZer65794 = zero_padding2D_layer(Con85294, 0, 0, 1, 0, Zer65794), 
LSub99771 = subtract_layer([[[[[0.2799, 0.7587], [0.3786, 0.0547]], [[0.0294, 0.5318], [0.317, 0.9868]]], [[[0.3599, 0.6011], [0.0316, 0.1851]], [[0.1758, 0.2786], [0.6637, 0.6792]]]]], [[[[[0.0315, 0.1297], [0.2484, 0.6597]], [[0.3179, 0.0496], [0.5636, 0.5458]]], [[[0.1698, 0.8265], [0.6433, 0.1704]], [[0.5759, 0.2532], [0.3675, 0.2649]]]]], Sub99771), 
LRes6043 = reshape_layer(Sub99771, [2, 2, 4], Res6043), 
LCon33181 = conv2D_layer(Res6043, 1, 2,[[[[0.0268, 0.0936, 0.6407], [0.7725, 0.1615, 0.7952], [0.5394, 0.8647, 0.0412], [0.6275, 0.4525, 0.7165]], [[0.8409, 0.3627, 0.1252], [0.7415, 0.5228, 0.0503], [0.0437, 0.8473, 0.0716], [0.9555, 0.0555, 0.6948]]]],[0, 0, 0], 2, 1, true, 1, 1, Con33181), 
LCon50857 = concatenate_layer([Con33181,[[[[0.6742], [0.3495]]]]], 3, Con50857), 
LAdd64748 = add_layer([Zer65794,Con50857], Add64748), 
exec_layers([LCon85294,LZer65794,LSub99771,LRes6043,LCon33181,LCon50857,LAdd64748],["Con85294","Zer65794","Sub99771","Res6043","Con33181","Con50857","Add64748"],Add64748,"Add64748")

Actual (Unparsed): [[[[0.7087028, -0.0733583, 0.5080972, 0.6742000], [1.3545391, 0.1003928, 0.8875296, 1.0190601]]]]

Expected (Unparsed): [[[[0.7087027300000002,-0.07335828999999999,0.50809712,0.6742],[1.3545391,0.10039276000000005,0.8875296100000001,1.0190601]]]]

Actual:   [[[[0.7088, -0.0733, 0.5081, 0.6742], [1.3546, 0.1004, 0.8876, 1.0191]]]]

Expected: [[[[0.7088, -0.0733, 0.5081, 0.6742], [1.3546, 0.1004, 0.8876, 1.0191]]]]