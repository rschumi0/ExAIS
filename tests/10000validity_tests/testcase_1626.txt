import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul4539 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in1Mul4539 = tf.keras.layers.Input(shape=([2, 1, 2, 1]))
in0Glo85875 = tf.keras.layers.Input(shape=([1, 1]))
in0Con38835 = tf.keras.layers.Input(shape=([15]))

Mul4539 = keras.layers.Multiply(name = 'Mul4539', )([in0Mul4539,in1Mul4539])
Den5670 = keras.layers.Dense(4,name = 'Den5670', )(Mul4539)
Res24540 = keras.layers.Reshape((2, 1, 8), name = 'Res24540', )(Den5670)
Res2446 = keras.layers.Reshape((2, 8), name = 'Res2446', )(Res24540)
Fla74268 = keras.layers.Flatten(name = 'Fla74268', )(Res2446)
Glo85875 = keras.layers.GlobalAveragePooling1D(name = 'Glo85875', )(in0Glo85875)
Res7126 = keras.layers.Reshape((1, 1), name = 'Res7126', )(Glo85875)
Glo46996 = keras.layers.GlobalMaxPool1D(name = 'Glo46996', )(Res7126)
Con38835 = keras.layers.Concatenate(axis=1, name = 'Con38835', )([Glo46996,in0Con38835])
Sub71178 = keras.layers.Subtract(name = 'Sub71178', )([Fla74268,Con38835])
model = tf.keras.models.Model(inputs=[in0Mul4539,in1Mul4539,in0Glo85875,in0Con38835], outputs=Sub71178)
w = model.get_layer('Den5670').get_weights() 
w[0] = np.array([[0.0838, 0.9972, 0.0933, 0.8621]])
w[1] = np.array([0.4535, 0.4349, 0.4874, 0.6635])
model.get_layer('Den5670').set_weights(w) 
in0Mul4539 = tf.constant([[[[[0.7462], [0.5459]]], [[[0.8576], [0.9915]]]]])
in1Mul4539 = tf.constant([[[[[0.3295], [0.7403]]], [[[0.6318], [0.0857]]]]])
in0Glo85875 = tf.constant([[[1.2834]]])
in0Con38835 = tf.constant([[0.382, 0.6463, 0.3628, 0.3227, 0.2333, 0.3571, 0.6043, 0.6105, 0.1091, 0.5372, 0.7634, 0.886, 0.1055, 0.5811, 0.0361]])
print (np.array2string(model.predict([in0Mul4539,in1Mul4539,in0Glo85875,in0Con38835],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub71178.png')

LMul4539 = multiply_layer([[[[[[0.7462], [0.5459]]], [[[0.8576], [0.9915]]]]], [[[[[0.3295], [0.7403]]], [[[0.6318], [0.0857]]]]]], Mul4539), 
LDen5670 = dense_layer(Mul4539, [[0.0838, 0.9972, 0.0933, 0.8621]],[0.4535, 0.4349, 0.4874, 0.6635], Den5670), 
LRes24540 = reshape_layer(Den5670, [2, 1, 8], Res24540), 
LRes2446 = reshape_layer(Res24540, [2, 8], Res2446), 
LFla74268 = flatten_layer(Res2446, Fla74268), 
LGlo85875 = global_average_pooling1D_layer([[[1.2834]]], Glo85875), 
LRes7126 = reshape_layer(Glo85875, [1, 1], Res7126), 
LGlo46996 = global_max_pool1D_layer(Res7126, Glo46996), 
LCon38835 = concatenate_layer([Glo46996,[[0.382, 0.6463, 0.3628, 0.3227, 0.2333, 0.3571, 0.6043, 0.6105, 0.1091, 0.5372, 0.7634, 0.886, 0.1055, 0.5811, 0.0361]]], 1, Con38835), 
LSub71178 = subtract_layer(Fla74268,Con38835, Sub71178), 
exec_layers([LMul4539,LDen5670,LRes24540,LRes2446,LFla74268,LGlo85875,LRes7126,LGlo46996,LCon38835,LSub71178],["Mul4539","Den5670","Res24540","Res2446","Fla74268","Glo85875","Res7126","Glo46996","Con38835","Sub71178"],Sub71178,"Sub71178")

Actual (Unparsed): [[-0.8092959, 0.2980845, -0.1359601, 0.5126670, 0.1646661, 0.6045982, 0.1680053, 0.4076002, -0.1115945, 0.8661145, 0.0007529, 0.3672131, -0.4253794, 0.4141336, -0.0857721, 0.7006540]]

Expected (Unparsed): [[-0.8092958509800001,0.29808445588,-0.13596005843000003,0.51266702709,0.16466607472600003,0.6045982066439999,0.16800530754100007,0.4076002747170001,-0.111594505216,0.866114551296,0.0007528957439999484,0.36721309132799995,-0.42537938411,0.41413362966000006,-0.08577215438499997,0.700653973255]]

Actual:   [[-0.8092, 0.2981, -0.1359, 0.5127, 0.1647, 0.6046, 0.1681, 0.4077, -0.1115, 0.8662, 0.0008, 0.3673, -0.4253, 0.4142, -0.0857, 0.7007]]

Expected: [[-0.8092, 0.2981, -0.1359, 0.5127, 0.1647, 0.6046, 0.1681, 0.4077, -0.1115, 0.8662, 0.0008, 0.3673, -0.4253, 0.4142, -0.0857, 0.7007]]