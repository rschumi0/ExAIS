import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub19073 = tf.keras.layers.Input(shape=([2, 2, 3]))
in1Sub19073 = tf.keras.layers.Input(shape=([2, 2, 3]))
in0Con35699 = tf.keras.layers.Input(shape=([60]))
in0Up_48727 = tf.keras.layers.Input(shape=([4, 3, 2]))
in0Zer4693 = tf.keras.layers.Input(shape=([4, 1]))
in0Con7716 = tf.keras.layers.Input(shape=([6, 11]))
in0Dot4521 = tf.keras.layers.Input(shape=([2]))
in1Dot4521 = tf.keras.layers.Input(shape=([2]))
in0Con74200 = tf.keras.layers.Input(shape=([71]))

Sub19073 = keras.layers.Subtract(name = 'Sub19073', )([in0Sub19073,in1Sub19073])
Res47864 = keras.layers.Reshape((2, 6), name = 'Res47864', )(Sub19073)
Fla5822 = keras.layers.Flatten(name = 'Fla5822', )(Res47864)
Con35699 = keras.layers.Concatenate(axis=1, name = 'Con35699', )([Fla5822,in0Con35699])
Up_48727 = keras.layers.UpSampling2D(size=(1, 2), name = 'Up_48727', )(in0Up_48727)
Res74988 = keras.layers.Reshape((4, 12), name = 'Res74988', )(Up_48727)
Zer99059 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer99059', )(Res74988)
Zer4693 = keras.layers.ZeroPadding1D(padding=((1, 1)), name = 'Zer4693', )(in0Zer4693)
Con7716 = keras.layers.Concatenate(axis=2, name = 'Con7716', )([Zer4693,in0Con7716])
Add82165 = keras.layers.Add(name = 'Add82165', )([Zer99059,Con7716])
Fla59540 = keras.layers.Flatten(name = 'Fla59540', )(Add82165)
Dot4521 = keras.layers.Dot(axes=(1, 1), name = 'Dot4521', )([in0Dot4521,in1Dot4521])
Con74200 = keras.layers.Concatenate(axis=1, name = 'Con74200', )([Dot4521,in0Con74200])
Min682 = keras.layers.Minimum(name = 'Min682', )([Fla59540,Con74200])
Max13634 = keras.layers.Maximum(name = 'Max13634', )([Con35699,Min682])
model = tf.keras.models.Model(inputs=[in0Sub19073,in1Sub19073,in0Con35699,in0Up_48727,in0Zer4693,in0Con7716,in0Dot4521,in1Dot4521,in0Con74200], outputs=Max13634)
in0Sub19073 = tf.constant([[[[0.2473, 0.322, 0.05], [0.0602, 0.1585, 0.6701]], [[0.8774, 0.6314, 0.66], [0.5626, 0.2283, 0.5881]]]])
in1Sub19073 = tf.constant([[[[0.9892, 0.0199, 0.3447], [0.5678, 0.0228, 0.1749]], [[0.5498, 0.7184, 0.2503], [0.3435, 0.1421, 0.4352]]]])
in0Con35699 = tf.constant([[0.3094, 0.9296, 0.2844, 0.4163, 0.566, 0.7929, 0.5756, 0.9505, 0.5155, 0.88, 0.5422, 0.9434, 0.0466, 0.4794, 0.4067, 0.4599, 0.4745, 0.2573, 0.7152, 0.8825, 0.1463, 0.5934, 0.334, 0.9699, 0.7717, 0.1995, 0.0898, 0.8777, 0.0841, 0.4229, 0.3824, 0.7256, 0.3264, 0.7551, 0.0046, 0.0504, 0.2318, 0.7157, 0.0909, 0.2783, 0.6214, 0.4621, 0.5896, 0.1677, 0.4775, 0.1884, 0.9018, 0.0275, 0.3664, 0.617, 0.3614, 0.4014, 0.3846, 0.6657, 0.0494, 0.8214, 0.3795, 0.6746, 0.0227, 0.1795]])
in0Up_48727 = tf.constant([[[[1.1327, 1.0874], [1.4888, 1.0227], [1.5232, 1.9101]], [[1.3156, 1.8551], [1.4753, 1.9165], [1.9802, 1.065]], [[1.9463, 1.2333], [1.3389, 1.5256], [1.6141, 1.2428]], [[1.6683, 1.9054], [1.2698, 1.7101], [1.9857, 1.877]]]])
in0Zer4693 = tf.constant([[[1.0219], [1.7005], [1.0297], [1.1353]]])
in0Con7716 = tf.constant([[[0.7316, 0.967, 0.4526, 0.5307, 0.862, 0.2892, 0.7399, 0.6849, 0.3063, 0.0218, 0.0081], [0.9241, 0.7375, 0.074, 0.4212, 0.1377, 0.2647, 0.5767, 0.2577, 0.2053, 0.2351, 0.3566], [0.385, 0.5407, 0.5421, 0.76, 0.4538, 0.6557, 0.9377, 0.4065, 0.0543, 0.5574, 0.094], [0.4858, 0.9595, 0.0874, 0.93, 0.0268, 0.4994, 0.893, 0.0286, 0.1576, 0.0518, 0.5806], [0.8024, 0.7567, 0.6166, 0.7407, 0.4375, 0.0492, 0.4468, 0.9608, 0.5432, 0.642, 0.7506], [0.6421, 0.8652, 0.2101, 0.5507, 0.426, 0.3839, 0.5495, 0.888, 0.2972, 0.6098, 0.9923]]])
in0Dot4521 = tf.constant([[0.8547, 0.7777]])
in1Dot4521 = tf.constant([[0.1083, 0.7453]])
in0Con74200 = tf.constant([[0.8525, 0.4479, 0.178, 0.4358, 0.1013, 0.9626, 0.2732, 0.6806, 0.6703, 0.3314, 0.531, 0.0776, 0.0805, 0.6618, 0.2334, 0.4391, 0.3078, 0.3126, 0.4923, 0.0039, 0.2782, 0.0413, 0.2073, 0.0889, 0.2663, 0.4371, 0.7671, 0.4076, 0.0433, 0.2772, 0.2407, 0.9198, 0.6123, 0.4098, 0.3019, 0.1844, 0.6303, 0.2578, 0.4161, 0.3169, 0.1667, 0.0621, 0.8796, 0.82, 0.2765, 0.5401, 0.1478, 0.7511, 0.9773, 0.72, 0.5138, 0.9206, 0.6098, 0.3321, 0.6065, 0.0684, 0.2349, 0.2857, 0.3658, 0.2636, 0.6752, 0.4418, 0.122, 0.0845, 0.0428, 0.1028, 0.1574, 0.4987, 0.113, 0.386, 0.6611]])
print (np.array2string(model.predict([in0Sub19073,in1Sub19073,in0Con35699,in0Up_48727,in0Zer4693,in0Con7716,in0Dot4521,in1Dot4521,in0Con74200],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max13634.png')

LSub19073 = subtract_layer([[[[0.2473, 0.322, 0.05], [0.0602, 0.1585, 0.6701]], [[0.8774, 0.6314, 0.66], [0.5626, 0.2283, 0.5881]]]], [[[[0.9892, 0.0199, 0.3447], [0.5678, 0.0228, 0.1749]], [[0.5498, 0.7184, 0.2503], [0.3435, 0.1421, 0.4352]]]], Sub19073), 
LRes47864 = reshape_layer(Sub19073, [2, 6], Res47864), 
LFla5822 = flatten_layer(Res47864, Fla5822), 
LCon35699 = concatenate_layer([Fla5822,[[0.3094, 0.9296, 0.2844, 0.4163, 0.566, 0.7929, 0.5756, 0.9505, 0.5155, 0.88, 0.5422, 0.9434, 0.0466, 0.4794, 0.4067, 0.4599, 0.4745, 0.2573, 0.7152, 0.8825, 0.1463, 0.5934, 0.334, 0.9699, 0.7717, 0.1995, 0.0898, 0.8777, 0.0841, 0.4229, 0.3824, 0.7256, 0.3264, 0.7551, 0.0046, 0.0504, 0.2318, 0.7157, 0.0909, 0.2783, 0.6214, 0.4621, 0.5896, 0.1677, 0.4775, 0.1884, 0.9018, 0.0275, 0.3664, 0.617, 0.3614, 0.4014, 0.3846, 0.6657, 0.0494, 0.8214, 0.3795, 0.6746, 0.0227, 0.1795]]], 1, Con35699), 
LUp_48727 = up_sampling2D_layer([[[[1.1327, 1.0874], [1.4888, 1.0227], [1.5232, 1.9101]], [[1.3156, 1.8551], [1.4753, 1.9165], [1.9802, 1.065]], [[1.9463, 1.2333], [1.3389, 1.5256], [1.6141, 1.2428]], [[1.6683, 1.9054], [1.2698, 1.7101], [1.9857, 1.877]]]], 1, 2, Up_48727), 
LRes74988 = reshape_layer(Up_48727, [4, 12], Res74988), 
LZer99059 = zero_padding1D_layer(Res74988, 2, 0, Zer99059), 
LZer4693 = zero_padding1D_layer([[[1.0219], [1.7005], [1.0297], [1.1353]]], 1, 1, Zer4693), 
LCon7716 = concatenate_layer([Zer4693,[[[0.7316, 0.967, 0.4526, 0.5307, 0.862, 0.2892, 0.7399, 0.6849, 0.3063, 0.0218, 0.0081], [0.9241, 0.7375, 0.074, 0.4212, 0.1377, 0.2647, 0.5767, 0.2577, 0.2053, 0.2351, 0.3566], [0.385, 0.5407, 0.5421, 0.76, 0.4538, 0.6557, 0.9377, 0.4065, 0.0543, 0.5574, 0.094], [0.4858, 0.9595, 0.0874, 0.93, 0.0268, 0.4994, 0.893, 0.0286, 0.1576, 0.0518, 0.5806], [0.8024, 0.7567, 0.6166, 0.7407, 0.4375, 0.0492, 0.4468, 0.9608, 0.5432, 0.642, 0.7506], [0.6421, 0.8652, 0.2101, 0.5507, 0.426, 0.3839, 0.5495, 0.888, 0.2972, 0.6098, 0.9923]]]], 2, Con7716), 
LAdd82165 = add_layer([Zer99059,Con7716], Add82165), 
LFla59540 = flatten_layer(Add82165, Fla59540), 
LDot4521 = dot_layer([[0.8547, 0.7777]], [[0.1083, 0.7453]], 1, 1, Dot4521), 
LCon74200 = concatenate_layer([Dot4521,[[0.8525, 0.4479, 0.178, 0.4358, 0.1013, 0.9626, 0.2732, 0.6806, 0.6703, 0.3314, 0.531, 0.0776, 0.0805, 0.6618, 0.2334, 0.4391, 0.3078, 0.3126, 0.4923, 0.0039, 0.2782, 0.0413, 0.2073, 0.0889, 0.2663, 0.4371, 0.7671, 0.4076, 0.0433, 0.2772, 0.2407, 0.9198, 0.6123, 0.4098, 0.3019, 0.1844, 0.6303, 0.2578, 0.4161, 0.3169, 0.1667, 0.0621, 0.8796, 0.82, 0.2765, 0.5401, 0.1478, 0.7511, 0.9773, 0.72, 0.5138, 0.9206, 0.6098, 0.3321, 0.6065, 0.0684, 0.2349, 0.2857, 0.3658, 0.2636, 0.6752, 0.4418, 0.122, 0.0845, 0.0428, 0.1028, 0.1574, 0.4987, 0.113, 0.386, 0.6611]]], 1, Con74200), 
LMin682 = minimum_layer([Fla59540,Con74200], Min682), 
LMax13634 = maximum_layer([Con35699,Min682], Max13634), 
exec_layers([LSub19073,LRes47864,LFla5822,LCon35699,LUp_48727,LRes74988,LZer99059,LZer4693,LCon7716,LAdd82165,LFla59540,LDot4521,LCon74200,LMin682,LMax13634],["Sub19073","Res47864","Fla5822","Con35699","Up_48727","Res74988","Zer99059","Zer4693","Con7716","Add82165","Fla59540","Dot4521","Con74200","Min682","Max13634"],Max13634,"Max13634")

Actual (Unparsed): [[0.0000000, 0.7316000, 0.4479000, 0.1780000, 0.4358000, 0.4952000, 0.3276000, 0.2732000, 0.6806000, 0.3063000, 0.0862000, 0.1529000, 0.3094000, 0.9296000, 0.6618000, 0.4163000, 0.5660000, 0.7929000, 0.5756000, 0.9505000, 0.5155000, 0.8800000, 0.5422000, 0.9434000, 0.0889000, 0.4794000, 0.4371000, 0.7671000, 0.4745000, 0.2573000, 0.7152000, 0.8825000, 0.9198000, 0.6123000, 0.4098000, 0.9699000, 0.7717000, 0.6303000, 0.2578000, 0.8777000, 0.3169000, 0.4229000, 0.3824000, 0.8796000, 0.8200000, 0.7551000, 0.5401000, 0.1478000, 0.7511000, 0.9773000, 0.7200000, 0.5138000, 0.9206000, 0.6098000, 0.5896000, 0.6065000, 0.4775000, 0.2349000, 0.9018000, 0.3658000, 0.3664000, 0.6752000, 0.4418000, 0.4014000, 0.3846000, 0.6657000, 0.1028000, 0.8214000, 0.4987000, 0.6746000, 0.3860000, 0.6611000]]

Expected (Unparsed): [[0,0.7316,0.4479,0.178,0.4358,0.49520000000000003,0.3276,0.2732,0.6806,0.3063,0.0862,0.15289999999999998,0.3094,0.9296,0.6618,0.4163,0.566,0.7929,0.5756,0.9505,0.5155,0.88,0.5422,0.9434,0.0889,0.4794,0.4371,0.7671,0.4745,0.2573,0.7152,0.8825,0.9198,0.6123,0.4098,0.9699,0.7717,0.6303,0.2578,0.8777,0.3169,0.4229,0.3824,0.8796,0.82,0.7551,0.5401,0.1478,0.7511,0.9773,0.72,0.5138,0.9206,0.6098,0.5896,0.6065,0.4775,0.2349,0.9018,0.3658,0.3664,0.6752,0.4418,0.4014,0.3846,0.6657,0.1028,0.8214,0.4987,0.6746,0.386,0.6611]]

Actual:   [[0, 0.7316, 0.4479, 0.178, 0.4358, 0.4952, 0.3276, 0.2732, 0.6806, 0.3063, 0.0862, 0.1529, 0.3094, 0.9296, 0.6618, 0.4163, 0.566, 0.7929, 0.5756, 0.9505, 0.5155, 0.88, 0.5422, 0.9434, 0.0889, 0.4794, 0.4371, 0.7671, 0.4745, 0.2573, 0.7152, 0.8825, 0.9198, 0.6123, 0.4098, 0.9699, 0.7717, 0.6303, 0.2578, 0.8777, 0.3169, 0.4229, 0.3824, 0.8796, 0.82, 0.7551, 0.5401, 0.1478, 0.7511, 0.9773, 0.72, 0.5138, 0.9206, 0.6098, 0.5896, 0.6065, 0.4775, 0.2349, 0.9018, 0.3658, 0.3664, 0.6752, 0.4418, 0.4014, 0.3846, 0.6657, 0.1028, 0.8214, 0.4987, 0.6746, 0.386, 0.6611]]

Expected: [[0, 0.7316, 0.4479, 0.178, 0.4358, 0.4953, 0.3276, 0.2732, 0.6806, 0.3063, 0.0862, 0.1529, 0.3094, 0.9296, 0.6618, 0.4163, 0.566, 0.7929, 0.5756, 0.9505, 0.5155, 0.88, 0.5422, 0.9434, 0.0889, 0.4794, 0.4371, 0.7671, 0.4745, 0.2573, 0.7152, 0.8825, 0.9198, 0.6123, 0.4098, 0.9699, 0.7717, 0.6303, 0.2578, 0.8777, 0.3169, 0.4229, 0.3824, 0.8796, 0.82, 0.7551, 0.5401, 0.1478, 0.7511, 0.9773, 0.72, 0.5138, 0.9206, 0.6098, 0.5896, 0.6065, 0.4775, 0.2349, 0.9018, 0.3658, 0.3664, 0.6752, 0.4418, 0.4014, 0.3846, 0.6657, 0.1028, 0.8214, 0.4987, 0.6746, 0.386, 0.6611]]