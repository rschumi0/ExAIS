import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mas25596 = tf.keras.layers.Input(shape=([2, 4, 2]))
in0Con92074 = tf.keras.layers.Input(shape=([3, 7, 2]))
in0Con7340 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Ave1774 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con28946 = tf.keras.layers.Input(shape=([3, 7, 3]))

Mas25596 = keras.layers.Masking(mask_value=1, name = 'Mas25596', )(in0Mas25596)
Zer59635 = keras.layers.ZeroPadding2D(padding=((1, 0), (3, 0)), name = 'Zer59635', )(Mas25596)
Con92074 = keras.layers.Concatenate(axis=3, name = 'Con92074', )([Zer59635,in0Con92074])
Con7340 = keras.layers.Conv2DTranspose(4, (2, 1),strides=(1, 1), padding='valid', name = 'Con7340', )(in0Con7340)
Lea51177 = keras.layers.LeakyReLU(alpha=3.3884467583303572, name = 'Lea51177', )(Con7340)
Zer53508 = keras.layers.ZeroPadding2D(padding=((0, 0), (6, 0)), name = 'Zer53508', )(Lea51177)
Min43068 = keras.layers.Minimum(name = 'Min43068', )([Con92074,Zer53508])
Ave1774 = keras.layers.AveragePooling2D(pool_size=(2, 1), strides=(1, 4), padding='valid', name = 'Ave1774', )(in0Ave1774)
Zer62118 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer62118', )(Ave1774)
Zer70816 = keras.layers.ZeroPadding2D(padding=((0, 0), (4, 0)), name = 'Zer70816', )(Zer62118)
Con28946 = keras.layers.Concatenate(axis=3, name = 'Con28946', )([Zer70816,in0Con28946])
Max67707 = keras.layers.Maximum(name = 'Max67707', )([Min43068,Con28946])
model = tf.keras.models.Model(inputs=[in0Mas25596,in0Con92074,in0Con7340,in0Ave1774,in0Con28946], outputs=Max67707)
w = model.get_layer('Con7340').get_weights() 
w[0] = np.array([[[[0.083], [0.6135], [0.0854], [0.541]]], [[[0.43], [0.4438], [0.9072], [0.6458]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con7340').set_weights(w) 
in0Mas25596 = tf.constant([[[[1.2702, 1.9656], [1.391, 1.9154], [1.9814, 1.4605], [1.6533, 1.0327]], [[1.763, 1.2285], [1.3815, 1.9156], [1.9227, 1.9708], [1.6496, 1.1527]]]])
in0Con92074 = tf.constant([[[[0.1502, 0.5424], [0.4496, 0.049], [0.1857, 0.0152], [0.3056, 0.9603], [0.9858, 0.3124], [0.1131, 0.4614], [0.5186, 0.0896]], [[0.271, 0.6189], [0.4797, 0.9336], [0.6497, 0.8998], [0.2986, 0.0167], [0.545, 0.469], [0.8509, 0.093], [0.3524, 0.282]], [[0.9089, 0.5978], [0.4705, 0.0716], [0.8215, 0.6101], [0.5422, 0.0975], [0.9089, 0.2224], [0.7784, 0.5723], [0.5821, 0.4233]]]])
in0Con7340 = tf.constant([[[[0.9096]], [[0.7128]]]])
in0Ave1774 = tf.constant([[[[1.0653]], [[1.13]]]])
in0Con28946 = tf.constant([[[[0.3033, 0.4177, 0.4179], [0.7138, 0.0508, 0.6194], [0.8058, 0.1588, 0.824], [0.7862, 0.3853, 0.6347], [0.4303, 0.5274, 0.8389], [0.2159, 0.5226, 0.1545], [0.7978, 0.6252, 0.7303]], [[0.8017, 0.2892, 0.0878], [0.1258, 0.9284, 0.4958], [0.0024, 0.4523, 0.943], [0.6374, 0.2553, 0.246], [0.1193, 0.4977, 0.0768], [0.9654, 0.9385, 0.6235], [0.4387, 0.5133, 0.4824]], [[0.5061, 0.1283, 0.0797], [0.5282, 0.1159, 0.7989], [0.067, 0.552, 0.0082], [0.49, 0.9652, 0.9322], [0.843, 0.3437, 0.4417], [0.2656, 0.5688, 0.496], [0.5765, 0.8559, 0.7096]]]])
print (np.array2string(model.predict([in0Mas25596,in0Con92074,in0Con7340,in0Ave1774,in0Con28946],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max67707.png')

LMas25596 = masking_layer([[[[1.2702, 1.9656], [1.391, 1.9154], [1.9814, 1.4605], [1.6533, 1.0327]], [[1.763, 1.2285], [1.3815, 1.9156], [1.9227, 1.9708], [1.6496, 1.1527]]]], 1, Mas25596), 
LZer59635 = zero_padding2D_layer(Mas25596, 1, 0, 3, 0, Zer59635), 
LCon92074 = concatenate_layer([Zer59635,[[[[0.1502, 0.5424], [0.4496, 0.049], [0.1857, 0.0152], [0.3056, 0.9603], [0.9858, 0.3124], [0.1131, 0.4614], [0.5186, 0.0896]], [[0.271, 0.6189], [0.4797, 0.9336], [0.6497, 0.8998], [0.2986, 0.0167], [0.545, 0.469], [0.8509, 0.093], [0.3524, 0.282]], [[0.9089, 0.5978], [0.4705, 0.0716], [0.8215, 0.6101], [0.5422, 0.0975], [0.9089, 0.2224], [0.7784, 0.5723], [0.5821, 0.4233]]]]], 3, Con92074), 
LCon7340 = conv2D_transpose_layer([[[[0.9096]], [[0.7128]]]], 2, 1,[[[[0.083], [0.6135], [0.0854], [0.541]]], [[[0.43], [0.4438], [0.9072], [0.6458]]]],[0, 0, 0, 0], 1, 1, false, Con7340), 
LLea51177 = leaky_relu_layer(Con7340, 3.3884467583303572, Lea51177), 
LZer53508 = zero_padding2D_layer(Lea51177, 0, 0, 6, 0, Zer53508), 
LMin43068 = minimum_layer([Con92074,Zer53508], Min43068), 
LAve1774 = average_pooling2D_layer([[[[1.0653]], [[1.13]]]], 2, 1, 1, 4, false, Ave1774), 
LZer62118 = zero_padding2D_layer(Ave1774, 1, 1, 1, 1, Zer62118), 
LZer70816 = zero_padding2D_layer(Zer62118, 0, 0, 4, 0, Zer70816), 
LCon28946 = concatenate_layer([Zer70816,[[[[0.3033, 0.4177, 0.4179], [0.7138, 0.0508, 0.6194], [0.8058, 0.1588, 0.824], [0.7862, 0.3853, 0.6347], [0.4303, 0.5274, 0.8389], [0.2159, 0.5226, 0.1545], [0.7978, 0.6252, 0.7303]], [[0.8017, 0.2892, 0.0878], [0.1258, 0.9284, 0.4958], [0.0024, 0.4523, 0.943], [0.6374, 0.2553, 0.246], [0.1193, 0.4977, 0.0768], [0.9654, 0.9385, 0.6235], [0.4387, 0.5133, 0.4824]], [[0.5061, 0.1283, 0.0797], [0.5282, 0.1159, 0.7989], [0.067, 0.552, 0.0082], [0.49, 0.9652, 0.9322], [0.843, 0.3437, 0.4417], [0.2656, 0.5688, 0.496], [0.5765, 0.8559, 0.7096]]]]], 3, Con28946), 
LMax67707 = maximum_layer([Min43068,Con28946], Max67707), 
exec_layers([LMas25596,LZer59635,LCon92074,LCon7340,LLea51177,LZer53508,LMin43068,LAve1774,LZer62118,LZer70816,LCon28946,LMax67707],["Mas25596","Zer59635","Con92074","Con7340","Lea51177","Zer53508","Min43068","Ave1774","Zer62118","Zer70816","Con28946","Max67707"],Max67707,"Max67707")

Actual (Unparsed): [[[[0.0000000, 0.3033000, 0.4177000, 0.4179000], [0.0000000, 0.7138000, 0.0508000, 0.6194000], [0.0000000, 0.8058000, 0.1588000, 0.8240000], [0.0000000, 0.7862000, 0.3853000, 0.6347000], [0.0000000, 0.4303000, 0.5274000, 0.8389000], [0.0000000, 0.2159000, 0.5226000, 0.1545000], [0.0000000, 0.7978000, 0.6252000, 0.7303000]], [[0.0000000, 0.8017000, 0.2892000, 0.0878000], [0.0000000, 0.1258000, 0.9284000, 0.4958000], [0.0000000, 0.0024000, 0.4523000, 0.9430000], [0.0000000, 0.6374000, 0.2553000, 0.2460000], [0.0000000, 0.1193000, 0.4977000, 0.0768000], [1.0976500, 0.9654000, 0.9385000, 0.6235000], [0.4502904, 0.8409833, 0.5133000, 0.4824000]], [[0.0000000, 0.5061000, 0.1283000, 0.0797000], [0.0000000, 0.5282000, 0.1159000, 0.7989000], [0.0000000, 0.0670000, 0.5520000, 0.0082000], [0.0000000, 0.4900000, 0.9652000, 0.9322000], [0.0000000, 0.8430000, 0.3437000, 0.4417000], [0.0000000, 0.2656000, 0.5688000, 0.4960000], [0.3065040, 0.5765000, 0.8559000, 0.7096000]]]]

Expected (Unparsed): [[[[0,0.3033,0.4177,0.4179],[0,0.7138,0.0508,0.6194],[0,0.8058,0.1588,0.824],[0,0.7862,0.3853,0.6347],[0,0.4303,0.5274,0.8389],[0,0.2159,0.5226,0.1545],[0,0.7978,0.6252,0.7303]],[[0,0.8017,0.2892,0.0878],[0,0.1258,0.9284,0.4958],[0,0.0024,0.4523,0.943],[0,0.6374,0.2553,0.246],[0,0.1193,0.4977,0.0768],[1.0976499999999998,0.9654,0.9385,0.6235],[0.4502904,0.84098328,0.5133,0.4824]],[[0,0.5061,0.1283,0.0797],[0,0.5282,0.1159,0.7989],[0,0.067,0.552,0.0082],[0,0.49,0.9652,0.9322],[0,0.843,0.3437,0.4417],[0,0.2656,0.5688,0.496],[0.306504,0.5765,0.8559,0.7096]]]]

Actual:   [[[[0, 0.3033, 0.4177, 0.4179], [0, 0.7138, 0.0508, 0.6194], [0, 0.8058, 0.1588, 0.824], [0, 0.7862, 0.3853, 0.6347], [0, 0.4303, 0.5274, 0.8389], [0, 0.2159, 0.5226, 0.1545], [0, 0.7978, 0.6252, 0.7303]], [[0, 0.8017, 0.2892, 0.0878], [0, 0.1258, 0.9284, 0.4958], [0, 0.0024, 0.4523, 0.943], [0, 0.6374, 0.2553, 0.246], [0, 0.1193, 0.4977, 0.0768], [1.0977, 0.9654, 0.9385, 0.6235], [0.4503, 0.841, 0.5133, 0.4824]], [[0, 0.5061, 0.1283, 0.0797], [0, 0.5282, 0.1159, 0.7989], [0, 0.067, 0.552, 0.0082], [0, 0.49, 0.9652, 0.9322], [0, 0.843, 0.3437, 0.4417], [0, 0.2656, 0.5688, 0.496], [0.3066, 0.5765, 0.8559, 0.7096]]]]

Expected: [[[[0, 0.3033, 0.4177, 0.4179], [0, 0.7138, 0.0508, 0.6194], [0, 0.8058, 0.1588, 0.824], [0, 0.7862, 0.3853, 0.6347], [0, 0.4303, 0.5274, 0.8389], [0, 0.2159, 0.5226, 0.1545], [0, 0.7978, 0.6252, 0.7303]], [[0, 0.8017, 0.2892, 0.0878], [0, 0.1258, 0.9284, 0.4958], [0, 0.0024, 0.4523, 0.943], [0, 0.6374, 0.2553, 0.246], [0, 0.1193, 0.4977, 0.0768], [1.0977, 0.9654, 0.9385, 0.6235], [0.4503, 0.841, 0.5133, 0.4824]], [[0, 0.5061, 0.1283, 0.0797], [0, 0.5282, 0.1159, 0.7989], [0, 0.067, 0.552, 0.0082], [0, 0.49, 0.9652, 0.9322], [0, 0.843, 0.3437, 0.4417], [0, 0.2656, 0.5688, 0.496], [0.3066, 0.5765, 0.8559, 0.7096]]]]