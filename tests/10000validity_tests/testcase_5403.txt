import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave43124 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in1Ave43124 = tf.keras.layers.Input(shape=([2, 1, 2, 2]))
in0Con78674 = tf.keras.layers.Input(shape=([4, 1]))
in0Max28507 = tf.keras.layers.Input(shape=([2, 2]))
in1Max28507 = tf.keras.layers.Input(shape=([2, 2]))

Ave43124 = keras.layers.Average(name = 'Ave43124', )([in0Ave43124,in1Ave43124])
Res75275 = keras.layers.Reshape((2, 1, 4), name = 'Res75275', )(Ave43124)
Res42617 = keras.layers.Reshape((2, 4), name = 'Res42617', )(Res75275)
Glo34462 = keras.layers.GlobalAveragePooling1D(name = 'Glo34462', )(Res42617)
Res3162 = keras.layers.Reshape((4, 1), name = 'Res3162', )(Glo34462)
Con78674 = keras.layers.Concatenate(axis=2, name = 'Con78674', )([Res3162,in0Con78674])
Max28507 = keras.layers.Maximum(name = 'Max28507', )([in0Max28507,in1Max28507])
Zer68182 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer68182', )(Max28507)
Sub69037 = keras.layers.Subtract(name = 'Sub69037', )([Con78674,Zer68182])
model = tf.keras.models.Model(inputs=[in0Ave43124,in1Ave43124,in0Con78674,in0Max28507,in1Max28507], outputs=Sub69037)
in0Ave43124 = tf.constant([[[[[0.7398, 0.5375], [0.6171, 0.6763]]], [[[0.2901, 0.131], [0.0145, 0.4832]]]]])
in1Ave43124 = tf.constant([[[[[0.9887, 0.2959], [0.1211, 0.2979]]], [[[0.1712, 0.4193], [0.6779, 0.3932]]]]])
in0Con78674 = tf.constant([[[0.5922], [0.4133], [0.6081], [0.193]]])
in0Max28507 = tf.constant([[[0.5729, 0.3455], [0.5741, 0.6088]]])
in1Max28507 = tf.constant([[[0.2686, 0.4817], [0.5404, 0.4189]]])
print (np.array2string(model.predict([in0Ave43124,in1Ave43124,in0Con78674,in0Max28507,in1Max28507],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub69037.png')

LAve43124 = average_layer([[[[[[0.7398, 0.5375], [0.6171, 0.6763]]], [[[0.2901, 0.131], [0.0145, 0.4832]]]]], [[[[[0.9887, 0.2959], [0.1211, 0.2979]]], [[[0.1712, 0.4193], [0.6779, 0.3932]]]]]], Ave43124), 
LRes75275 = reshape_layer(Ave43124, [2, 1, 4], Res75275), 
LRes42617 = reshape_layer(Res75275, [2, 4], Res42617), 
LGlo34462 = global_average_pooling1D_layer(Res42617, Glo34462), 
LRes3162 = reshape_layer(Glo34462, [4, 1], Res3162), 
LCon78674 = concatenate_layer([Res3162,[[[0.5922], [0.4133], [0.6081], [0.193]]]], 2, Con78674), 
LMax28507 = maximum_layer([[[[0.5729, 0.3455], [0.5741, 0.6088]]], [[[0.2686, 0.4817], [0.5404, 0.4189]]]], Max28507), 
LZer68182 = zero_padding1D_layer(Max28507, 2, 0, Zer68182), 
LSub69037 = subtract_layer(Con78674,Zer68182, Sub69037), 
exec_layers([LAve43124,LRes75275,LRes42617,LGlo34462,LRes3162,LCon78674,LMax28507,LZer68182,LSub69037],["Ave43124","Res75275","Res42617","Glo34462","Res3162","Con78674","Max28507","Zer68182","Sub69037"],Sub69037,"Sub69037")

Actual (Unparsed): [[[0.5474500, 0.5922000], [0.3459250, 0.4133000], [-0.2152500, 0.1264000], [-0.1114500, -0.4158000]]]

Expected (Unparsed): [[[0.54745,0.5922],[0.345925,0.4133],[-0.21525,0.12639999999999996],[-0.11145000000000005,-0.4158]]]

Actual:   [[[0.5475, 0.5922], [0.346, 0.4133], [-0.2152, 0.1264], [-0.1114, -0.4158]]]

Expected: [[[0.5475, 0.5922], [0.346, 0.4133], [-0.2152, 0.1264], [-0.1114, -0.4158]]]