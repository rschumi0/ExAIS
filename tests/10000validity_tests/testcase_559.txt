import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave86015 = tf.keras.layers.Input(shape=([2, 1, 1, 1]))
in1Ave86015 = tf.keras.layers.Input(shape=([2, 1, 1, 1]))
in0Add84700 = tf.keras.layers.Input(shape=([1, 2]))
in1Add84700 = tf.keras.layers.Input(shape=([1, 2]))
in0Con66715 = tf.keras.layers.Input(shape=([6]))

Ave86015 = keras.layers.Average(name = 'Ave86015', )([in0Ave86015,in1Ave86015])
Res90820 = keras.layers.Reshape((2, 1, 1), name = 'Res90820', )(Ave86015)
Res30886 = keras.layers.Reshape((2, 1), name = 'Res30886', )(Res90820)
Con32464 = keras.layers.Conv1D(4, (2),strides=(1), padding='same', dilation_rate=(1), name = 'Con32464', )(Res30886)
Fla3438 = keras.layers.Flatten(name = 'Fla3438', )(Con32464)
Add84700 = keras.layers.Add(name = 'Add84700', )([in0Add84700,in1Add84700])
Glo54434 = keras.layers.GlobalAveragePooling1D(name = 'Glo54434', )(Add84700)
Con66715 = keras.layers.Concatenate(axis=1, name = 'Con66715', )([Glo54434,in0Con66715])
Mul62731 = keras.layers.Multiply(name = 'Mul62731', )([Fla3438,Con66715])
model = tf.keras.models.Model(inputs=[in0Ave86015,in1Ave86015,in0Add84700,in1Add84700,in0Con66715], outputs=Mul62731)
w = model.get_layer('Con32464').get_weights() 
w[0] = np.array([[[0.4691, 0.6665, 0.9701, 0.2488]], [[0.1905, 0.9661, 0.9001, 0.5738]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con32464').set_weights(w) 
in0Ave86015 = tf.constant([[[[[0.9875]]], [[[0.4975]]]]])
in1Ave86015 = tf.constant([[[[[0.1076]]], [[[0.1645]]]]])
in0Add84700 = tf.constant([[[0.1793, 0.186]]])
in1Add84700 = tf.constant([[[0.8569, 0.5691]]])
in0Con66715 = tf.constant([[0.1534, 0.9724, 0.063, 0.0457, 0.3505, 0.5521]])
print (np.array2string(model.predict([in0Ave86015,in1Ave86015,in0Add84700,in1Add84700,in0Con66715],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul62731.png')

LAve86015 = average_layer([[[[[[0.9875]]], [[[0.4975]]]]], [[[[[0.1076]]], [[[0.1645]]]]]], Ave86015), 
LRes90820 = reshape_layer(Ave86015, [2, 1, 1], Res90820), 
LRes30886 = reshape_layer(Res90820, [2, 1], Res30886), 
LCon32464 = conv1D_layer(Res30886, 2,[[[0.4691, 0.6665, 0.9701, 0.2488]], [[0.1905, 0.9661, 0.9001, 0.5738]]],[0, 0, 0, 0], 1, true, 1, Con32464), 
LFla3438 = flatten_layer(Con32464, Fla3438), 
LAdd84700 = add_layer([[[[0.1793, 0.186]]], [[[0.8569, 0.5691]]]], Add84700), 
LGlo54434 = global_average_pooling1D_layer(Add84700, Glo54434), 
LCon66715 = concatenate_layer([Glo54434,[[0.1534, 0.9724, 0.063, 0.0457, 0.3505, 0.5521]]], 1, Con66715), 
LMul62731 = multiply_layer([Fla3438,Con66715], Mul62731), 
exec_layers([LAve86015,LRes90820,LRes30886,LCon32464,LFla3438,LAdd84700,LGlo54434,LCon66715,LMul62731],["Ave86015","Res90820","Res30886","Con32464","Fla3438","Add84700","Glo54434","Con66715","Mul62731"],Mul62731,"Mul62731")

Actual (Unparsed): [[0.3314920, 0.5170330, 0.1271857, 0.3171563, 0.0097821, 0.0100819, 0.1125466, 0.0454670]]

Expected (Unparsed): [[0.331491990621,0.5170329592425,0.127185681857,0.317156272576,0.009782142300000001,0.01008194555,0.11254663655000001,0.04546698088000001]]

Actual:   [[0.3315, 0.5171, 0.1272, 0.3172, 0.0098, 0.0101, 0.1126, 0.0455]]

Expected: [[0.3315, 0.5171, 0.1272, 0.3172, 0.0098, 0.0101, 0.1126, 0.0455]]