import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add53342 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in1Add53342 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0Cro80127 = tf.keras.layers.Input(shape=([3, 1, 1, 1]))
in0Con6277 = tf.keras.layers.Input(shape=([5]))

Add53342 = keras.layers.Add(name = 'Add53342', )([in0Add53342,in1Add53342])
Con35421 = keras.layers.Conv3D(3, (1, 1, 1),strides=(1, 1, 1), padding='valid', dilation_rate=(1, 1, 1), name = 'Con35421', )(Add53342)
Res33812 = keras.layers.Reshape((2, 2, 3), name = 'Res33812', )(Con35421)
Res93223 = keras.layers.Reshape((2, 6), name = 'Res93223', )(Res33812)
Glo34215 = keras.layers.GlobalMaxPool1D(name = 'Glo34215', )(Res93223)
Cro80127 = keras.layers.Cropping3D(cropping=((1, 1), (0, 0), (0, 0)), name = 'Cro80127', )(in0Cro80127)
Fla81607 = keras.layers.Flatten(name = 'Fla81607', )(Cro80127)
Lea30979 = keras.layers.LeakyReLU(alpha=2.851750064960391, name = 'Lea30979', )(Fla81607)
Con6277 = keras.layers.Concatenate(axis=1, name = 'Con6277', )([Lea30979,in0Con6277])
Max70145 = keras.layers.Maximum(name = 'Max70145', )([Glo34215,Con6277])
model = tf.keras.models.Model(inputs=[in0Add53342,in1Add53342,in0Cro80127,in0Con6277], outputs=Max70145)
w = model.get_layer('Con35421').get_weights() 
w[0] = np.array([[[[[0.1587, 0.9995, 0.6336], [0.8562, 0.4792, 0.4018]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con35421').set_weights(w) 
in0Add53342 = tf.constant([[[[[0.3067, 0.588]], [[0.5814, 0.7209]]], [[[0.4141, 0.5683]], [[0.5431, 0.5276]]]]])
in1Add53342 = tf.constant([[[[[0.4906, 0.6209]], [[0.3265, 0.9776]]], [[[0.9015, 0.3735]], [[0.2584, 0.9288]]]]])
in0Cro80127 = tf.constant([[[[[1.3128]]], [[[1.6713]]], [[[1.173]]]]])
in0Con6277 = tf.constant([[0.3408, 0.6104, 0.9758, 0.9084, 0.7918]])
print (np.array2string(model.predict([in0Add53342,in1Add53342,in0Cro80127,in0Con6277],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max70145.png')

LAdd53342 = add_layer([[[[[[0.3067, 0.588]], [[0.5814, 0.7209]]], [[[0.4141, 0.5683]], [[0.5431, 0.5276]]]]], [[[[[0.4906, 0.6209]], [[0.3265, 0.9776]]], [[[0.9015, 0.3735]], [[0.2584, 0.9288]]]]]], Add53342), 
LCon35421 = conv3D_layer(Add53342, 1, 1, 1,[[[[[0.1587, 0.9995, 0.6336], [0.8562, 0.4792, 0.4018]]]]],[0, 0, 0], 1, 1, 1, false, 1, 1, 1, Con35421), 
LRes33812 = reshape_layer(Con35421, [2, 2, 3], Res33812), 
LRes93223 = reshape_layer(Res33812, [2, 6], Res93223), 
LGlo34215 = global_max_pool1D_layer(Res93223, Glo34215), 
LCro80127 = cropping3D_layer([[[[[1.3128]]], [[[1.6713]]], [[[1.173]]]]], 1, 1, 0, 0, 0, 0, Cro80127), 
LFla81607 = flatten_layer(Cro80127, Fla81607), 
LLea30979 = leaky_relu_layer(Fla81607, 2.851750064960391, Lea30979), 
LCon6277 = concatenate_layer([Lea30979,[[0.3408, 0.6104, 0.9758, 0.9084, 0.7918]]], 1, Con6277), 
LMax70145 = maximum_layer([Glo34215,Con6277], Max70145), 
exec_layers([LAdd53342,LCon35421,LRes33812,LRes93223,LGlo34215,LCro80127,LFla81607,LLea30979,LCon6277,LMax70145],["Add53342","Con35421","Res33812","Res93223","Glo34215","Cro80127","Fla81607","Lea30979","Con6277","Max70145"],Max70145,"Max70145")

Actual (Unparsed): [[1.6713001, 1.7662527, 1.2119794, 1.5983394, 1.7213672, 1.2577027]]

Expected (Unparsed): [[1.6713,1.76625276,1.2119794,1.59833943,1.7213672500000001,1.25770274]]

Actual:   [[1.6714, 1.7663, 1.212, 1.5984, 1.7214, 1.2578]]

Expected: [[1.6713, 1.7663, 1.212, 1.5984, 1.7214, 1.2578]]