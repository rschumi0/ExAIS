import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min86626 = tf.keras.layers.Input(shape=([2, 2]))
in1Min86626 = tf.keras.layers.Input(shape=([2, 2]))
in0Con18801 = tf.keras.layers.Input(shape=([3, 3, 3, 2]))
in0Sub74438 = tf.keras.layers.Input(shape=([3, 3, 3, 3]))
in1Sub74438 = tf.keras.layers.Input(shape=([3, 3, 3, 3]))
in0Ave54693 = tf.keras.layers.Input(shape=([1, 2, 2]))
in1Ave54693 = tf.keras.layers.Input(shape=([1, 2, 2]))
in0Con59403 = tf.keras.layers.Input(shape=([77]))

Min86626 = keras.layers.Minimum(name = 'Min86626', )([in0Min86626,in1Min86626])
Res70488 = keras.layers.Reshape((2, 2, 1), name = 'Res70488', )(Min86626)
Res99904 = keras.layers.Reshape((2, 2, 1, 1), name = 'Res99904', )(Res70488)
Zer79098 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (2, 0)), name = 'Zer79098', )(Res99904)
Con18801 = keras.layers.Concatenate(axis=4, name = 'Con18801', )([Zer79098,in0Con18801])
Sub74438 = keras.layers.Subtract(name = 'Sub74438', )([in0Sub74438,in1Sub74438])
Add6368 = keras.layers.Add(name = 'Add6368', )([Con18801,Sub74438])
Bat35725 = keras.layers.BatchNormalization(axis=1, epsilon=0.2468549749647222,  name = 'Bat35725', )(Add6368)
Res50098 = keras.layers.Reshape((3, 3, 9), name = 'Res50098', )(Bat35725)
Res20454 = keras.layers.Reshape((3, 27), name = 'Res20454', )(Res50098)
Fla13990 = keras.layers.Flatten(name = 'Fla13990', )(Res20454)
Ave54693 = keras.layers.Average(name = 'Ave54693', )([in0Ave54693,in1Ave54693])
Fla39768 = keras.layers.Flatten(name = 'Fla39768', )(Ave54693)
Con59403 = keras.layers.Concatenate(axis=1, name = 'Con59403', )([Fla39768,in0Con59403])
Add77725 = keras.layers.Add(name = 'Add77725', )([Fla13990,Con59403])
model = tf.keras.models.Model(inputs=[in0Min86626,in1Min86626,in0Con18801,in0Sub74438,in1Sub74438,in0Ave54693,in1Ave54693,in0Con59403], outputs=Add77725)
w = model.get_layer('Bat35725').get_weights() 
w[0] = np.array([0.8297, 0.4061, 0.3272])
w[1] = np.array([0.2878, 0.7945, 0.5946])
w[2] = np.array([0.1976, 0.3253, 0.4931])
w[3] = np.array([0.3971, 0.011, 0.1483])
model.get_layer('Bat35725').set_weights(w) 
in0Min86626 = tf.constant([[[0.9455, 0.7868], [0.964, 0.6594]]])
in1Min86626 = tf.constant([[[0.7758, 0.2523], [0.2716, 0.3912]]])
in0Con18801 = tf.constant([[[[[0.0851, 0.0963], [0.0857, 0.235], [0.9943, 0.546]], [[0.5869, 0.0735], [0.8559, 0.2598], [0.6365, 0.1326]], [[0.5993, 0.0053], [0.2657, 0.5206], [0.2817, 0.6985]]], [[[0.5418, 0.2827], [0.6485, 0.4568], [0.1329, 0.6719]], [[0.3874, 0.2776], [0.1636, 0.1415], [0.0875, 0.908]], [[0.0118, 0.7815], [0.2631, 0.1665], [0.3074, 0.5076]]], [[[0.9231, 0.706], [0.2851, 0.4279], [0.0805, 0.9655]], [[0.8155, 0.4662], [0.278, 0.8476], [0.8949, 0.4963]], [[0.6806, 0.4817], [0.1072, 0.9576], [0.5354, 0.2834]]]]])
in0Sub74438 = tf.constant([[[[[0.4052, 0.5328, 0.1214], [0.5756, 0.1869, 0.9483], [0.1424, 0.4548, 0.6547]], [[0.5159, 0.8312, 0.5978], [0.8584, 0.3186, 0.248], [0.9641, 0.2168, 0.622]], [[0.3082, 0.5208, 0.383], [0.2852, 0.9891, 0.0047], [0.8739, 0.2711, 0.8603]]], [[[0.6414, 0.3732, 0.4833], [0.829, 0.5017, 0.6894], [0.7313, 0.8926, 0.706]], [[0.319, 0.3562, 0.989], [0.8709, 0.4495, 0.9384], [0.7445, 0.0347, 0.0183]], [[0.5501, 0.0336, 0.7928], [0.1409, 0.2195, 0.7846], [0.5298, 0.8161, 0.6261]]], [[[0.3937, 0.4439, 0.3243], [0.5619, 0.4392, 0.5241], [0.1425, 0.3607, 0.1324]], [[0.7645, 0.521, 0.324], [0.0813, 0.677, 0.087], [0.1526, 0.5006, 0.5976]], [[0.9722, 0.5314, 0.9542], [0.3759, 0.9973, 0.3074], [0.0855, 0.7788, 0.387]]]]])
in1Sub74438 = tf.constant([[[[[0.154, 0.5571, 0.3486], [0.3415, 0.2176, 0.6017], [0.5107, 0.5405, 0.0074]], [[0.1668, 0.4448, 0.3213], [0.7088, 0.6258, 0.6036], [0.8368, 0.1733, 0.4233]], [[0.7936, 0.9747, 0.0718], [0.8258, 0.4137, 0.1987], [0.085, 0.1532, 0.7932]]], [[[0.757, 0.5484, 0.4859], [0.5614, 0.899, 0.6698], [0.8577, 0.6411, 0.8369]], [[0.2931, 0.3761, 0.7623], [0.1948, 0.1959, 0.5405], [0.3611, 0.5987, 0.0772]], [[0.2706, 0.3516, 0.8801], [0.715, 0.8025, 0.5335], [0.0853, 0.2578, 0.6616]]], [[[0.3357, 0.1181, 0.2488], [0.3771, 0.1872, 0.3736], [0.7788, 0.4731, 0.0505]], [[0.1683, 0.1104, 0.5336], [0.5595, 0.1182, 0.2251], [0.8233, 0.7617, 0.8697]], [[0.0078, 0.0238, 0.6804], [0.7535, 0.1985, 0.1364], [0.7857, 0.9951, 0.8227]]]]])
in0Ave54693 = tf.constant([[[[0.4976, 0.9896], [0.0908, 0.5353]]]])
in1Ave54693 = tf.constant([[[[0.1557, 0.9666], [0.8391, 0.2092]]]])
in0Con59403 = tf.constant([[0.471, 0.2107, 0.7101, 0.2298, 0.6691, 0.4642, 0.7802, 0.5689, 0.2373, 0.9378, 0.4845, 0.9445, 0.397, 0.5663, 0.3272, 0.5322, 0.3349, 0.7714, 0.4277, 0.4078, 0.5675, 0.6319, 0.3052, 0.045, 0.9172, 0.1889, 0.7381, 0.923, 0.4035, 0.6711, 0.9909, 0.7152, 0.6224, 0.1452, 0.1845, 0.5791, 0.1298, 0.7309, 0.222, 0.5275, 0.928, 0.0515, 0.477, 0.7241, 0.4079, 0.0376, 0.4011, 0.8186, 0.9983, 0.5474, 0.3146, 0.1114, 0.3357, 0.5218, 0.9052, 0.4215, 0.9823, 0.5567, 0.3809, 0.0225, 0.5943, 0.8381, 0.7964, 0.903, 0.9676, 0.3628, 0.8055, 0.9143, 0.5751, 0.2445, 0.9775, 0.0717, 0.0502, 0.6941, 0.8622, 0.3935, 0.567]])
print (np.array2string(model.predict([in0Min86626,in1Min86626,in0Con18801,in0Sub74438,in1Sub74438,in0Ave54693,in1Ave54693,in0Con59403],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add77725.png')

LMin86626 = minimum_layer([[[[0.9455, 0.7868], [0.964, 0.6594]]], [[[0.7758, 0.2523], [0.2716, 0.3912]]]], Min86626), 
LRes70488 = reshape_layer(Min86626, [2, 2, 1], Res70488), 
LRes99904 = reshape_layer(Res70488, [2, 2, 1, 1], Res99904), 
LZer79098 = zero_padding3D_layer(Res99904, 1, 0, 1, 0, 2, 0, Zer79098), 
LCon18801 = concatenate_layer([Zer79098,[[[[[0.0851, 0.0963], [0.0857, 0.235], [0.9943, 0.546]], [[0.5869, 0.0735], [0.8559, 0.2598], [0.6365, 0.1326]], [[0.5993, 0.0053], [0.2657, 0.5206], [0.2817, 0.6985]]], [[[0.5418, 0.2827], [0.6485, 0.4568], [0.1329, 0.6719]], [[0.3874, 0.2776], [0.1636, 0.1415], [0.0875, 0.908]], [[0.0118, 0.7815], [0.2631, 0.1665], [0.3074, 0.5076]]], [[[0.9231, 0.706], [0.2851, 0.4279], [0.0805, 0.9655]], [[0.8155, 0.4662], [0.278, 0.8476], [0.8949, 0.4963]], [[0.6806, 0.4817], [0.1072, 0.9576], [0.5354, 0.2834]]]]]], 4, Con18801), 
LSub74438 = subtract_layer([[[[[0.4052, 0.5328, 0.1214], [0.5756, 0.1869, 0.9483], [0.1424, 0.4548, 0.6547]], [[0.5159, 0.8312, 0.5978], [0.8584, 0.3186, 0.248], [0.9641, 0.2168, 0.622]], [[0.3082, 0.5208, 0.383], [0.2852, 0.9891, 0.0047], [0.8739, 0.2711, 0.8603]]], [[[0.6414, 0.3732, 0.4833], [0.829, 0.5017, 0.6894], [0.7313, 0.8926, 0.706]], [[0.319, 0.3562, 0.989], [0.8709, 0.4495, 0.9384], [0.7445, 0.0347, 0.0183]], [[0.5501, 0.0336, 0.7928], [0.1409, 0.2195, 0.7846], [0.5298, 0.8161, 0.6261]]], [[[0.3937, 0.4439, 0.3243], [0.5619, 0.4392, 0.5241], [0.1425, 0.3607, 0.1324]], [[0.7645, 0.521, 0.324], [0.0813, 0.677, 0.087], [0.1526, 0.5006, 0.5976]], [[0.9722, 0.5314, 0.9542], [0.3759, 0.9973, 0.3074], [0.0855, 0.7788, 0.387]]]]], [[[[[0.154, 0.5571, 0.3486], [0.3415, 0.2176, 0.6017], [0.5107, 0.5405, 0.0074]], [[0.1668, 0.4448, 0.3213], [0.7088, 0.6258, 0.6036], [0.8368, 0.1733, 0.4233]], [[0.7936, 0.9747, 0.0718], [0.8258, 0.4137, 0.1987], [0.085, 0.1532, 0.7932]]], [[[0.757, 0.5484, 0.4859], [0.5614, 0.899, 0.6698], [0.8577, 0.6411, 0.8369]], [[0.2931, 0.3761, 0.7623], [0.1948, 0.1959, 0.5405], [0.3611, 0.5987, 0.0772]], [[0.2706, 0.3516, 0.8801], [0.715, 0.8025, 0.5335], [0.0853, 0.2578, 0.6616]]], [[[0.3357, 0.1181, 0.2488], [0.3771, 0.1872, 0.3736], [0.7788, 0.4731, 0.0505]], [[0.1683, 0.1104, 0.5336], [0.5595, 0.1182, 0.2251], [0.8233, 0.7617, 0.8697]], [[0.0078, 0.0238, 0.6804], [0.7535, 0.1985, 0.1364], [0.7857, 0.9951, 0.8227]]]]], Sub74438), 
LAdd6368 = add_layer([Con18801,Sub74438], Add6368), 
LBat35725 = batch_normalization_layer(Add6368, 1, 0.2468549749647222, [0.8297, 0.4061, 0.3272], [0.2878, 0.7945, 0.5946], [0.1976, 0.3253, 0.4931], [0.3971, 0.011, 0.1483], Bat35725), 
LRes50098 = reshape_layer(Bat35725, [3, 3, 9], Res50098), 
LRes20454 = reshape_layer(Res50098, [3, 27], Res20454), 
LFla13990 = flatten_layer(Res20454, Fla13990), 
LAve54693 = average_layer([[[[[0.4976, 0.9896], [0.0908, 0.5353]]]], [[[[0.1557, 0.9666], [0.8391, 0.2092]]]]], Ave54693), 
LFla39768 = flatten_layer(Ave54693, Fla39768), 
LCon59403 = concatenate_layer([Fla39768,[[0.471, 0.2107, 0.7101, 0.2298, 0.6691, 0.4642, 0.7802, 0.5689, 0.2373, 0.9378, 0.4845, 0.9445, 0.397, 0.5663, 0.3272, 0.5322, 0.3349, 0.7714, 0.4277, 0.4078, 0.5675, 0.6319, 0.3052, 0.045, 0.9172, 0.1889, 0.7381, 0.923, 0.4035, 0.6711, 0.9909, 0.7152, 0.6224, 0.1452, 0.1845, 0.5791, 0.1298, 0.7309, 0.222, 0.5275, 0.928, 0.0515, 0.477, 0.7241, 0.4079, 0.0376, 0.4011, 0.8186, 0.9983, 0.5474, 0.3146, 0.1114, 0.3357, 0.5218, 0.9052, 0.4215, 0.9823, 0.5567, 0.3809, 0.0225, 0.5943, 0.8381, 0.7964, 0.903, 0.9676, 0.3628, 0.8055, 0.9143, 0.5751, 0.2445, 0.9775, 0.0717, 0.0502, 0.6941, 0.8622, 0.3935, 0.567]]], 1, Con59403), 
LAdd77725 = add_layer([Fla13990,Con59403], Add77725), 
exec_layers([LMin86626,LRes70488,LRes99904,LZer79098,LCon18801,LSub74438,LAdd6368,LBat35725,LRes50098,LRes20454,LFla13990,LAve54693,LFla39768,LCon59403,LAdd77725],["Min86626","Res70488","Res99904","Zer79098","Con18801","Sub74438","Add6368","Bat35725","Res50098","Res20454","Fla13990","Ave54693","Fla39768","Con59403","Add77725"],Add77725,"Add77725")

Actual (Unparsed): [[0.6698689, 1.1244577, 0.4131023, 0.6977887, 0.6113608, 0.8955311, 0.4127961, 1.2527280, 1.9863893, 0.9086412, 1.8700236, 1.0142717, 0.4754711, 1.5886146, 0.4689433, 1.1596144, 1.1835704, 0.9923371, -0.0911778, 0.7660286, 0.7456349, 0.2959490, 1.3808373, 0.8289777, 1.4666659, 1.1285549, 1.1802752, 0.4868975, 1.7447290, 0.9472520, 1.4864554, 1.6582397, 1.3188397, 1.1043605, 1.8326642, 1.6822025, 1.1774598, 0.9734488, 1.1221523, 1.6541465, 0.9977955, 1.6966229, 1.6833977, 0.6807737, 2.1414003, 0.8093722, 0.7664684, 1.8136216, 0.4831198, 0.3161120, 1.2694154, 1.9102010, 2.2249759, 1.4593009, 0.6827258, 1.0994019, 1.0804152, 0.9559266, 1.5227025, 1.0604995, 0.9890353, 0.8780319, 1.2640190, 0.6707647, 1.5704343, 1.3095993, 0.8854281, 1.6764995, 1.6748385, 0.4930005, 1.4733358, 1.3689347, 1.4150166, 1.2009069, 1.7086820, 0.2130914, 0.8597188, 1.6194845, 1.0392985, 0.8975311, 0.8256624]]

Expected (Unparsed): [[0.6698689289809704,1.1244576588694635,0.4131022729431195,0.6977886363396533,0.6113608344648063,0.8955311329979972,0.4127960464490453,1.2527279571916041,1.9863893206409007,0.9086411891906161,1.870023567360798,1.0142717309085802,0.4754711083752504,1.5886146635301999,0.4689433999437177,1.1596143524745854,1.183570360828734,0.9923371418797714,-0.09117777041050024,0.7660285803580849,0.7456349002954736,0.2959490042210377,1.3808373283442998,0.8289776462415146,1.4666659087023848,1.1285549189208215,1.1802752175595375,0.486897545742904,1.7447289892511182,0.9472520505048294,1.4864553830559437,1.6582397553630057,1.3188397161221301,1.1043604250670667,1.8326642436983316,1.6822024934979716,1.17745982126429,0.9734487493074381,1.122152277868043,1.654146475285528,0.9977954990842076,1.696622920064514,1.6833976788500622,0.6807737631586764,2.141400352778106,0.8093722104672828,0.766468360482295,1.8136216497515143,0.48311978371777703,0.3161120129583164,1.269415392442572,1.9102009565808826,2.224975927150226,1.4593008625197137,0.682725843257764,1.0994019022426615,1.080415253515194,0.9559265857880226,1.5227024658622348,1.060499553137469,0.9890353421634535,0.8780319414165159,1.2640190188053815,0.6707646415999184,1.5704342608413218,1.3095992459904877,0.8854280660911654,1.676499489019321,1.6748384911951733,0.4930004535844104,1.4733358397003737,1.3689347029464782,1.415016640019802,1.200906909564533,1.7086819782329643,0.21309143122163887,0.8597188216935631,1.6194844785329603,1.039298457543214,0.8975311577266167,0.8256624666480369]]

Actual:   [[0.6699, 1.1245, 0.4132, 0.6978, 0.6114, 0.8956, 0.4128, 1.2528, 1.9864, 0.9087, 1.8701, 1.0143, 0.4755, 1.5887, 0.469, 1.1597, 1.1836, 0.9924, -0.0911, 0.7661, 0.7457, 0.296, 1.3809, 0.829, 1.4667, 1.1286, 1.1803, 0.4869, 1.7448, 0.9473, 1.4865, 1.6583, 1.3189, 1.1044, 1.8327, 1.6823, 1.1775, 0.9735, 1.1222, 1.6542, 0.9978, 1.6967, 1.6834, 0.6808, 2.1415, 0.8094, 0.7665, 1.8137, 0.4832, 0.3162, 1.2695, 1.9103, 2.225, 1.4594, 0.6828, 1.0995, 1.0805, 0.956, 1.5228, 1.0605, 0.9891, 0.8781, 1.2641, 0.6708, 1.5705, 1.3096, 0.8855, 1.6765, 1.6749, 0.4931, 1.4734, 1.369, 1.4151, 1.201, 1.7087, 0.2131, 0.8598, 1.6195, 1.0393, 0.8976, 0.8257]]

Expected: [[0.6699, 1.1245, 0.4132, 0.6978, 0.6114, 0.8956, 0.4128, 1.2528, 1.9864, 0.9087, 1.8701, 1.0143, 0.4755, 1.5887, 0.469, 1.1597, 1.1836, 0.9924, -0.0911, 0.7661, 0.7457, 0.296, 1.3809, 0.829, 1.4667, 1.1286, 1.1803, 0.4869, 1.7448, 0.9473, 1.4865, 1.6583, 1.3189, 1.1044, 1.8327, 1.6823, 1.1775, 0.9735, 1.1222, 1.6542, 0.9978, 1.6967, 1.6834, 0.6808, 2.1415, 0.8094, 0.7665, 1.8137, 0.4832, 0.3162, 1.2695, 1.9103, 2.225, 1.4594, 0.6828, 1.0995, 1.0805, 0.956, 1.5228, 1.0605, 0.9891, 0.8781, 1.2641, 0.6708, 1.5705, 1.3096, 0.8855, 1.6765, 1.6749, 0.4931, 1.4734, 1.369, 1.4151, 1.201, 1.7087, 0.2131, 0.8598, 1.6195, 1.0393, 0.8976, 0.8257]]