import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max35779 = tf.keras.layers.Input(shape=([1, 1, 2]))
in1Max35779 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con8770 = tf.keras.layers.Input(shape=([2, 1, 3, 1]))
in0Mul70295 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))
in1Mul70295 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))

Max35779 = keras.layers.Maximum(name = 'Max35779', )([in0Max35779,in1Max35779])
Res6220 = keras.layers.Reshape((1, 1, 2, 1), name = 'Res6220', )(Max35779)
Zer71774 = keras.layers.ZeroPadding3D(padding=((1, 0), (0, 0), (1, 0)), name = 'Zer71774', )(Res6220)
Con8770 = keras.layers.Concatenate(axis=4, name = 'Con8770', )([Zer71774,in0Con8770])
Mul70295 = keras.layers.Multiply(name = 'Mul70295', )([in0Mul70295,in1Mul70295])
Zer32707 = keras.layers.ZeroPadding3D(padding=((0, 0), (0, 0), (2, 0)), name = 'Zer32707', )(Mul70295)
Max27659 = keras.layers.Maximum(name = 'Max27659', )([Con8770,Zer32707])
Den65940 = keras.layers.Dense(4,name = 'Den65940', )(Max27659)
model = tf.keras.models.Model(inputs=[in0Max35779,in1Max35779,in0Con8770,in0Mul70295,in1Mul70295], outputs=Den65940)
w = model.get_layer('Den65940').get_weights() 
w[0] = np.array([[0.4306, 0.6566, 0.4131, 0.0574], [0.5556, 0.2384, 0.9414, 0.3289]])
w[1] = np.array([0.0601, 0.0949, 0.737, 0.8955])
model.get_layer('Den65940').set_weights(w) 
in0Max35779 = tf.constant([[[[0.8776, 0.6425]]]])
in1Max35779 = tf.constant([[[[0.6614, 0.1007]]]])
in0Con8770 = tf.constant([[[[[0.3086], [0.765], [0.5585]]], [[[0.0018], [0.8822], [0.5391]]]]])
in0Mul70295 = tf.constant([[[[[0.564, 0.4736]]], [[[0.1642, 0.2712]]]]])
in1Mul70295 = tf.constant([[[[[0.9617, 0.1279]]], [[[0.8029, 0.32]]]]])
print (np.array2string(model.predict([in0Max35779,in1Max35779,in0Con8770,in0Mul70295,in1Mul70295],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Den65940.png')

LMax35779 = maximum_layer([[[[[0.8776, 0.6425]]]], [[[[0.6614, 0.1007]]]]], Max35779), 
LRes6220 = reshape_layer(Max35779, [1, 1, 2, 1], Res6220), 
LZer71774 = zero_padding3D_layer(Res6220, 1, 0, 0, 0, 1, 0, Zer71774), 
LCon8770 = concatenate_layer([Zer71774,[[[[[0.3086], [0.765], [0.5585]]], [[[0.0018], [0.8822], [0.5391]]]]]], 4, Con8770), 
LMul70295 = multiply_layer([[[[[[0.564, 0.4736]]], [[[0.1642, 0.2712]]]]], [[[[[0.9617, 0.1279]]], [[[0.8029, 0.32]]]]]], Mul70295), 
LZer32707 = zero_padding3D_layer(Mul70295, 0, 0, 0, 0, 2, 0, Zer32707), 
LMax27659 = maximum_layer([Con8770,Zer32707], Max27659), 
LDen65940 = dense_layer(Max27659, [[0.4306, 0.6566, 0.4131, 0.0574], [0.5556, 0.2384, 0.9414, 0.3289]],[0.0601, 0.0949, 0.737, 0.8955], Den65940), 
exec_layers([LMax35779,LRes6220,LZer71774,LCon8770,LMul70295,LZer32707,LMax27659,LDen65940],["Max35779","Res6220","Zer71774","Con8770","Mul70295","Zer32707","Max27659","Den65940"],Den65940,"Den65940")

Actual (Unparsed): [[[[[0.2315582, 0.1684702, 1.0275160, 0.9969985], [0.4851340, 0.2772760, 1.4571710, 1.1471085], [0.6039595, 0.5841855, 1.4868368, 1.1103243]]], [[[0.0611001, 0.0953291, 0.7386945, 0.8960920], [0.9281449, 0.8814486, 1.9300396, 1.2360298], [0.6362844, 0.6452869, 1.5099255, 1.1096895]]]]]

Expected (Unparsed): [[[[[0.23155816,0.16847024,1.02751604,0.99699854],[0.48513399999999995,0.277276,1.457171,1.1471084999999999],[0.6039595232799999,0.58418545208,1.48683684428,1.11032434112]]],[[[0.06110008,0.09532912,0.73869452,0.89609202],[0.92814488,0.88144864,1.93003964,1.23602982],[0.6362844599999999,0.64528694,1.50992549,1.10968949]]]]]

Actual:   [[[[[0.2316, 0.1685, 1.0276, 0.997], [0.4852, 0.2773, 1.4572, 1.1472], [0.604, 0.5842, 1.4869, 1.1104]]], [[[0.0612, 0.0954, 0.7387, 0.8961], [0.9282, 0.8815, 1.9301, 1.2361], [0.6363, 0.6453, 1.51, 1.1097]]]]]

Expected: [[[[[0.2316, 0.1685, 1.0276, 0.997], [0.4852, 0.2773, 1.4572, 1.1472], [0.604, 0.5842, 1.4869, 1.1104]]], [[[0.0612, 0.0954, 0.7387, 0.8961], [0.9282, 0.8815, 1.9301, 1.2361], [0.6363, 0.6453, 1.51, 1.1097]]]]]