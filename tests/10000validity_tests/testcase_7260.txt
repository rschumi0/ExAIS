import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub17373 = tf.keras.layers.Input(shape=([2, 2, 3, 3]))
in1Sub17373 = tf.keras.layers.Input(shape=([2, 2, 3, 3]))
in0Add18293 = tf.keras.layers.Input(shape=([2, 2]))
in1Add18293 = tf.keras.layers.Input(shape=([2, 2]))
in0Con36327 = tf.keras.layers.Input(shape=([2, 17]))
in0Mul72981 = tf.keras.layers.Input(shape=([1, 1]))
in1Mul72981 = tf.keras.layers.Input(shape=([1, 1]))

Sub17373 = keras.layers.Subtract(name = 'Sub17373', )([in0Sub17373,in1Sub17373])
Res27338 = keras.layers.Reshape((2, 2, 9), name = 'Res27338', )(Sub17373)
Res28479 = keras.layers.Reshape((2, 18), name = 'Res28479', )(Res27338)
Add18293 = keras.layers.Add(name = 'Add18293', )([in0Add18293,in1Add18293])
Den40426 = keras.layers.Dense(1,name = 'Den40426', )(Add18293)
Con36327 = keras.layers.Concatenate(axis=2, name = 'Con36327', )([Den40426,in0Con36327])
Add25534 = keras.layers.Add(name = 'Add25534', )([Res28479,Con36327])
Fla53077 = keras.layers.Flatten(name = 'Fla53077', )(Add25534)
Mas47334 = keras.layers.Masking(mask_value=1, name = 'Mas47334', )(Fla53077)
Res75846 = keras.layers.Reshape((36, 1), name = 'Res75846', )(Mas47334)
Zer7932 = keras.layers.ZeroPadding1D(padding=((35, 0)), name = 'Zer7932', )(Res75846)
Mul72981 = keras.layers.Multiply(name = 'Mul72981', )([in0Mul72981,in1Mul72981])
Dot77204 = keras.layers.Dot(axes=(2, 1), name = 'Dot77204', )([Zer7932,Mul72981])
model = tf.keras.models.Model(inputs=[in0Sub17373,in1Sub17373,in0Add18293,in1Add18293,in0Con36327,in0Mul72981,in1Mul72981], outputs=Dot77204)
w = model.get_layer('Den40426').get_weights() 
w[0] = np.array([[0.507], [0.457]])
w[1] = np.array([0.2415])
model.get_layer('Den40426').set_weights(w) 
in0Sub17373 = tf.constant([[[[[0.5134, 0.0069, 0.841], [0.4691, 0.3468, 0.1571], [0.411, 0.7252, 0.6397]], [[0.7942, 0.9808, 0.4066], [0.3121, 0.6451, 0.6263], [0.7223, 0.982, 0.3789]]], [[[0.0119, 0.3897, 0.1498], [0.9712, 0.194, 0.8355], [0.1904, 0.0517, 0.3972]], [[0.0872, 0.76, 0.8187], [0.5356, 0.6717, 0.5962], [0.6713, 0.3297, 0.2324]]]]])
in1Sub17373 = tf.constant([[[[[0.7177, 0.1834, 0.0959], [0.3786, 0.7162, 0.4244], [0.6789, 0.4888, 0.172]], [[0.9171, 0.5357, 0.8042], [0.2235, 0.7142, 0.6844], [0.1674, 0.9726, 0.1768]]], [[[0.0861, 0.1911, 0.7192], [0.0402, 0.0387, 0.4717], [0.9814, 0.2641, 0.3348]], [[0.704, 0.8846, 0.9832], [0.256, 0.1968, 0.7742], [0.5956, 0.9625, 0.3434]]]]])
in0Add18293 = tf.constant([[[0.8482, 0.658], [0.4696, 0.0567]]])
in1Add18293 = tf.constant([[[0.1919, 0.7918], [0.2009, 0.0439]]])
in0Con36327 = tf.constant([[[0.2903, 0.1178, 0.6693, 0.65, 0.5891, 0.0862, 0.6389, 0.4317, 0.762, 0.5436, 0.8155, 0.0397, 0.4694, 0.6004, 0.1431, 0.5902, 0.5255], [0.8484, 0.8252, 0.4071, 0.5796, 0.6126, 0.7527, 0.4349, 0.2006, 0.633, 0.9265, 0.3255, 0.0228, 0.5478, 0.7522, 0.6398, 0.9006, 0.0982]]])
in0Mul72981 = tf.constant([[[0.2476]]])
in1Mul72981 = tf.constant([[[0.0546]]])
print (np.array2string(model.predict([in0Sub17373,in1Sub17373,in0Add18293,in1Add18293,in0Con36327,in0Mul72981,in1Mul72981],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot77204.png')

LSub17373 = subtract_layer([[[[[0.5134, 0.0069, 0.841], [0.4691, 0.3468, 0.1571], [0.411, 0.7252, 0.6397]], [[0.7942, 0.9808, 0.4066], [0.3121, 0.6451, 0.6263], [0.7223, 0.982, 0.3789]]], [[[0.0119, 0.3897, 0.1498], [0.9712, 0.194, 0.8355], [0.1904, 0.0517, 0.3972]], [[0.0872, 0.76, 0.8187], [0.5356, 0.6717, 0.5962], [0.6713, 0.3297, 0.2324]]]]], [[[[[0.7177, 0.1834, 0.0959], [0.3786, 0.7162, 0.4244], [0.6789, 0.4888, 0.172]], [[0.9171, 0.5357, 0.8042], [0.2235, 0.7142, 0.6844], [0.1674, 0.9726, 0.1768]]], [[[0.0861, 0.1911, 0.7192], [0.0402, 0.0387, 0.4717], [0.9814, 0.2641, 0.3348]], [[0.704, 0.8846, 0.9832], [0.256, 0.1968, 0.7742], [0.5956, 0.9625, 0.3434]]]]], Sub17373), 
LRes27338 = reshape_layer(Sub17373, [2, 2, 9], Res27338), 
LRes28479 = reshape_layer(Res27338, [2, 18], Res28479), 
LAdd18293 = add_layer([[[[0.8482, 0.658], [0.4696, 0.0567]]], [[[0.1919, 0.7918], [0.2009, 0.0439]]]], Add18293), 
LDen40426 = dense_layer(Add18293, [[0.507], [0.457]],[0.2415], Den40426), 
LCon36327 = concatenate_layer([Den40426,[[[0.2903, 0.1178, 0.6693, 0.65, 0.5891, 0.0862, 0.6389, 0.4317, 0.762, 0.5436, 0.8155, 0.0397, 0.4694, 0.6004, 0.1431, 0.5902, 0.5255], [0.8484, 0.8252, 0.4071, 0.5796, 0.6126, 0.7527, 0.4349, 0.2006, 0.633, 0.9265, 0.3255, 0.0228, 0.5478, 0.7522, 0.6398, 0.9006, 0.0982]]]], 2, Con36327), 
LAdd25534 = add_layer([Res28479,Con36327], Add25534), 
LFla53077 = flatten_layer(Add25534, Fla53077), 
LMas47334 = masking_layer(Fla53077, 1, Mas47334), 
LRes75846 = reshape_layer(Mas47334, [36, 1], Res75846), 
LZer7932 = zero_padding1D_layer(Res75846, 35, 0, Zer7932), 
LMul72981 = multiply_layer([[[[0.2476]]], [[[0.0546]]]], Mul72981), 
LDot77204 = dot_layer(Zer7932,Mul72981, 2, 1, Dot77204), 
exec_layers([LSub17373,LRes27338,LRes28479,LAdd18293,LDen40426,LCon36327,LAdd25534,LFla53077,LMas47334,LRes75846,LZer7932,LMul72981,LDot77204],["Sub17373","Res27338","Res28479","Add18293","Den40426","Con36327","Add25534","Fla53077","Mas47334","Res75846","Zer7932","Mul72981","Dot77204"],Dot77204,"Dot77204")

Actual (Unparsed): [[[0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0000000], [0.0165890], [0.0015385], [0.0116655], [0.0102717], [0.0037934], [0.0043504], [-0.0024564], [0.0118331], [0.0121590], [0.0086400], [0.0133662], [0.0056496], [0.0017345], [0.0054116], [0.0073313], [0.0094362], [0.0081060], [0.0098364], [0.0074789], [0.0141544], [0.0034582], [0.0180897], [0.0099351], [0.0131999], [-0.0005178], [0.0030080], [0.0035555], [0.0002190], [0.0108409], [0.0021766], [0.0040881], [0.0138258], [0.0077626], [0.0096728], [0.0036204], [-0.0001730]]]

Expected (Unparsed): [[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.016588971163128005],[0.0015384576479999998],[0.011665510584],[0.010271705808000001],[0.003793420176000001],[0.004350401328],[-0.0024563950319999995],[0.011833145687999999],[0.012158952624],[0.008639967336],[0.013366195752],[0.005649573384],[0.0017344825679999995],[0.005411639688000001],[0.007331332008],[0.009436234080000001],[0.008105968415999998],[0.009836395296],[0.007478927957592],[0.014154351120000002],[0.003458149968000002],[0.018089720376],[0.009935083704],[0.013199912544],[-0.000517776168],[0.0030079686],[0.0035554864800000003],[0.0002190071519999999],[0.010840854023999999],[0.0021765525600000004],[0.004088133504],[0.013825840391999999],[0.007762586831999999],[0.00967281588],[0.003620377487999999],[-0.0001730426879999999]]]

Actual:   [[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0.0166], [0.0016], [0.0117], [0.0103], [0.0038], [0.0044], [-0.0024], [0.0119], [0.0122], [0.0087], [0.0134], [0.0057], [0.0018], [0.0055], [0.0074], [0.0095], [0.0082], [0.0099], [0.0075], [0.0142], [0.0035], [0.0181], [0.01], [0.0132], [-0.0005], [0.0031], [0.0036], [0.0003], [0.0109], [0.0022], [0.0041], [0.0139], [0.0078], [0.0097], [0.0037], [-0.0001]]]

Expected: [[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0.0166], [0.0016], [0.0117], [0.0103], [0.0038], [0.0044], [-0.0024], [0.0119], [0.0122], [0.0087], [0.0134], [0.0057], [0.0018], [0.0055], [0.0074], [0.0095], [0.0082], [0.0099], [0.0075], [0.0142], [0.0035], [0.0181], [0.01], [0.0132], [-0.0005], [0.0031], [0.0036], [0.0003], [0.0109], [0.0022], [0.0041], [0.0139], [0.0078], [0.0097], [0.0037], [-0.0001]]]