import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Up_85759 = tf.keras.layers.Input(shape=([4, 2, 3]))
in0Mul35299 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Mul35299 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con56654 = tf.keras.layers.Input(shape=([8, 5]))

Up_85759 = keras.layers.UpSampling2D(size=(2, 2), name = 'Up_85759', )(in0Up_85759)
Cro94815 = keras.layers.Cropping2D(cropping=((0, 0), (1, 0)), name = 'Cro94815', )(Up_85759)
Res19417 = keras.layers.Reshape((8, 9), name = 'Res19417', )(Cro94815)
Mul35299 = keras.layers.Multiply(name = 'Mul35299', )([in0Mul35299,in1Mul35299])
Res47537 = keras.layers.Reshape((2, 4), name = 'Res47537', )(Mul35299)
Cro61522 = keras.layers.Cropping1D(cropping=((0, 1)), name = 'Cro61522', )(Res47537)
Zer4195 = keras.layers.ZeroPadding1D(padding=((7, 0)), name = 'Zer4195', )(Cro61522)
Con56654 = keras.layers.Concatenate(axis=2, name = 'Con56654', )([Zer4195,in0Con56654])
Sub93100 = keras.layers.Subtract(name = 'Sub93100', )([Res19417,Con56654])
model = tf.keras.models.Model(inputs=[in0Up_85759,in0Mul35299,in1Mul35299,in0Con56654], outputs=Sub93100)
in0Up_85759 = tf.constant([[[[1.5627, 1.0323, 1.4831], [1.0022, 1.4774, 1.7522]], [[1.5427, 1.0107, 1.2115], [1.4296, 1.0727, 1.7734]], [[1.6989, 1.3502, 1.7524], [1.4373, 1.7406, 1.7385]], [[1.9924, 1.4993, 1.5047], [1.2993, 1.8202, 1.7297]]]])
in0Mul35299 = tf.constant([[[[0.654, 0.9206], [0.5692, 0.9827]], [[0.2571, 0.9301], [0.4205, 0.1052]]]])
in1Mul35299 = tf.constant([[[[0.5571, 0.8749], [0.1531, 0.7442]], [[0.6166, 0.6555], [0.2918, 0.2337]]]])
in0Con56654 = tf.constant([[[0.8247, 0.438, 0.229, 0.6418, 0.7461], [0.0438, 0.7935, 0.2234, 0.8286, 0.2382], [0.5117, 0.3411, 0.3553, 0.3628, 0.0447], [0.2088, 0.0478, 0.3711, 0.3737, 0.8621], [0.812, 0.4588, 0.6269, 0.6217, 0.1975], [0.3744, 0.2058, 0.8469, 0.6639, 0.0794], [0.8399, 0.1452, 0.2633, 0.1741, 0.7285], [0.585, 0.1458, 0.7785, 0.2454, 0.8756]]])
print (np.array2string(model.predict([in0Up_85759,in0Mul35299,in1Mul35299,in0Con56654],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub93100.png')

LUp_85759 = up_sampling2D_layer([[[[1.5627, 1.0323, 1.4831], [1.0022, 1.4774, 1.7522]], [[1.5427, 1.0107, 1.2115], [1.4296, 1.0727, 1.7734]], [[1.6989, 1.3502, 1.7524], [1.4373, 1.7406, 1.7385]], [[1.9924, 1.4993, 1.5047], [1.2993, 1.8202, 1.7297]]]], 2, 2, Up_85759), 
LCro94815 = cropping2D_layer(Up_85759, 0, 0, 1, 0, Cro94815), 
LRes19417 = reshape_layer(Cro94815, [8, 9], Res19417), 
LMul35299 = multiply_layer([[[[[0.654, 0.9206], [0.5692, 0.9827]], [[0.2571, 0.9301], [0.4205, 0.1052]]]], [[[[0.5571, 0.8749], [0.1531, 0.7442]], [[0.6166, 0.6555], [0.2918, 0.2337]]]]], Mul35299), 
LRes47537 = reshape_layer(Mul35299, [2, 4], Res47537), 
LCro61522 = cropping1D_layer(Res47537, 0, 1, Cro61522), 
LZer4195 = zero_padding1D_layer(Cro61522, 7, 0, Zer4195), 
LCon56654 = concatenate_layer([Zer4195,[[[0.8247, 0.438, 0.229, 0.6418, 0.7461], [0.0438, 0.7935, 0.2234, 0.8286, 0.2382], [0.5117, 0.3411, 0.3553, 0.3628, 0.0447], [0.2088, 0.0478, 0.3711, 0.3737, 0.8621], [0.812, 0.4588, 0.6269, 0.6217, 0.1975], [0.3744, 0.2058, 0.8469, 0.6639, 0.0794], [0.8399, 0.1452, 0.2633, 0.1741, 0.7285], [0.585, 0.1458, 0.7785, 0.2454, 0.8756]]]], 2, Con56654), 
LSub93100 = subtract_layer(Res19417,Con56654, Sub93100), 
exec_layers([LUp_85759,LCro94815,LRes19417,LMul35299,LRes47537,LCro61522,LZer4195,LCon56654,LSub93100],["Up_85759","Cro94815","Res19417","Mul35299","Res47537","Cro61522","Zer4195","Con56654","Sub93100"],Sub93100,"Sub93100")

Actual (Unparsed): [[[1.5627000, 1.0323000, 1.4831001, 1.0022000, 0.6526999, 1.3142000, 0.7732000, 0.8356000, 1.0061000], [1.5627000, 1.0323000, 1.4831001, 1.0022000, 1.4335999, 0.9587000, 0.7788000, 0.6488000, 1.5140000], [1.5427001, 1.0107000, 1.2115000, 1.4296000, 0.5610000, 1.4322999, 1.0743000, 0.7099000, 1.7286999], [1.5427001, 1.0107000, 1.2115000, 1.4296000, 0.8639000, 1.7255999, 1.0585000, 0.6990000, 0.9112999], [1.6989000, 1.3502001, 1.7524000, 1.4373000, 0.9286000, 1.2797000, 0.8103999, 1.1189000, 1.5410000], [1.6989000, 1.3502001, 1.7524000, 1.4373000, 1.3662000, 1.5327000, 0.5904000, 1.0767000, 1.6591000], [1.9924001, 1.4993000, 1.5046999, 1.2993000, 0.9802999, 1.5845000, 1.0360000, 1.6461000, 1.0012000], [1.6280567, 0.6938671, 1.4175554, 0.5679746, 1.2352000, 1.5839000, 0.5207999, 1.5748000, 0.8541000]]]

Expected (Unparsed): [[[1.5627,1.0323,1.4831,1.0022,0.6527000000000001,1.3142,0.7732,0.8356,1.0061],[1.5627,1.0323,1.4831,1.0022,1.4336,0.9587,0.7787999999999999,0.6488,1.514],[1.5427,1.0107,1.2115,1.4296,0.5609999999999999,1.4323000000000001,1.0743,0.7099,1.7287000000000001],[1.5427,1.0107,1.2115,1.4296,0.8639,1.7256,1.0585,0.6990000000000001,0.9113000000000001],[1.6989,1.3502,1.7524,1.4373,0.9285999999999999,1.2797,0.8104,1.1189,1.541],[1.6989,1.3502,1.7524,1.4373,1.3661999999999999,1.5327,0.5904,1.0766999999999998,1.6591],[1.9924,1.4993,1.5047,1.2993,0.9803000000000001,1.5845,1.036,1.6461000000000001,1.0011999999999999],[1.6280565999999999,0.6938670600000001,1.4175554799999999,0.56797466,1.2352,1.5839,0.5207999999999999,1.5748,0.8541]]]

Actual:   [[[1.5627, 1.0323, 1.4832, 1.0022, 0.6527, 1.3142, 0.7732, 0.8356, 1.0061], [1.5627, 1.0323, 1.4832, 1.0022, 1.4336, 0.9587, 0.7788, 0.6488, 1.514], [1.5428, 1.0107, 1.2115, 1.4296, 0.561, 1.4323, 1.0743, 0.7099, 1.7287], [1.5428, 1.0107, 1.2115, 1.4296, 0.8639, 1.7256, 1.0585, 0.699, 0.9113], [1.6989, 1.3503, 1.7524, 1.4373, 0.9286, 1.2797, 0.8104, 1.1189, 1.541], [1.6989, 1.3503, 1.7524, 1.4373, 1.3662, 1.5327, 0.5904, 1.0767, 1.6591], [1.9925, 1.4993, 1.5047, 1.2993, 0.9803, 1.5845, 1.036, 1.6461, 1.0012], [1.6281, 0.6939, 1.4176, 0.568, 1.2352, 1.5839, 0.5208, 1.5748, 0.8541]]]

Expected: [[[1.5627, 1.0323, 1.4831, 1.0022, 0.6528, 1.3142, 0.7732, 0.8356, 1.0061], [1.5627, 1.0323, 1.4831, 1.0022, 1.4336, 0.9587, 0.7788, 0.6488, 1.514], [1.5427, 1.0107, 1.2115, 1.4296, 0.561, 1.4324, 1.0743, 0.7099, 1.7288], [1.5427, 1.0107, 1.2115, 1.4296, 0.8639, 1.7256, 1.0585, 0.6991, 0.9114], [1.6989, 1.3502, 1.7524, 1.4373, 0.9286, 1.2797, 0.8104, 1.1189, 1.541], [1.6989, 1.3502, 1.7524, 1.4373, 1.3662, 1.5327, 0.5904, 1.0767, 1.6591], [1.9924, 1.4993, 1.5047, 1.2993, 0.9804, 1.5845, 1.036, 1.6462, 1.0012], [1.6281, 0.6939, 1.4176, 0.568, 1.2352, 1.5839, 0.5208, 1.5748, 0.8541]]]