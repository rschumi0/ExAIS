import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub32887 = tf.keras.layers.Input(shape=([3, 2, 3, 3]))
in1Sub32887 = tf.keras.layers.Input(shape=([3, 2, 3, 3]))
in0Up_71365 = tf.keras.layers.Input(shape=([1, 3, 1, 3]))
in0Add80702 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in1Add80702 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in0Con23341 = tf.keras.layers.Input(shape=([2, 3, 3, 1]))
in0Min64445 = tf.keras.layers.Input(shape=([2, 1, 2]))
in1Min64445 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con52966 = tf.keras.layers.Input(shape=([4, 34]))

Sub32887 = keras.layers.Subtract(name = 'Sub32887', )([in0Sub32887,in1Sub32887])
Zer91386 = keras.layers.ZeroPadding3D(padding=((0, 0), (2, 0), (0, 0)), name = 'Zer91386', )(Sub32887)
Up_71365 = keras.layers.UpSampling3D(size=(2, 1, 1), name = 'Up_71365', )(in0Up_71365)
Zer58176 = keras.layers.ZeroPadding3D(padding=((0, 0), (0, 0), (2, 0)), name = 'Zer58176', )(Up_71365)
Add80702 = keras.layers.Add(name = 'Add80702', )([in0Add80702,in1Add80702])
Zer46236 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (1, 0)), name = 'Zer46236', )(Add80702)
Con23341 = keras.layers.Concatenate(axis=4, name = 'Con23341', )([Zer46236,in0Con23341])
Min79067 = keras.layers.Minimum(name = 'Min79067', )([Zer58176,Con23341])
Zer71431 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (0, 0)), name = 'Zer71431', )(Min79067)
Sub65121 = keras.layers.Subtract(name = 'Sub65121', )([Zer91386,Zer71431])
Res8418 = keras.layers.Reshape((3, 4, 9), name = 'Res8418', )(Sub65121)
Res81328 = keras.layers.Reshape((3, 36), name = 'Res81328', )(Res8418)
Zer45209 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer45209', )(Res81328)
Min64445 = keras.layers.Minimum(name = 'Min64445', )([in0Min64445,in1Min64445])
Res69786 = keras.layers.Reshape((2, 2), name = 'Res69786', )(Min64445)
Up_94352 = keras.layers.UpSampling1D(size=(2), name = 'Up_94352', )(Res69786)
Con52966 = keras.layers.Concatenate(axis=2, name = 'Con52966', )([Up_94352,in0Con52966])
Max98764 = keras.layers.Maximum(name = 'Max98764', )([Zer45209,Con52966])
model = tf.keras.models.Model(inputs=[in0Sub32887,in1Sub32887,in0Up_71365,in0Add80702,in1Add80702,in0Con23341,in0Min64445,in1Min64445,in0Con52966], outputs=Max98764)
in0Sub32887 = tf.constant([[[[[0.0768, 0.8163, 0.9874], [0.7916, 0.5907, 0.1858], [0.1571, 0.2749, 0.8413]], [[0.803, 0.4926, 0.1205], [0.7495, 0.8429, 0.5507], [0.9522, 0.2491, 0.2023]]], [[[0.4343, 0.889, 0.8889], [0.3109, 0.6943, 0.8138], [0.7999, 0.1382, 0.6444]], [[0.7719, 0.0282, 0.2652], [0.0437, 0.5404, 0.7427], [0.3953, 0.4362, 0.8718]]], [[[0.2373, 0.3524, 0.1734], [0.0404, 0.964, 0.4378], [0.2925, 0.0954, 0.0569]], [[0.9989, 0.9767, 0.6618], [0.9381, 0.2004, 0.2769], [0.2205, 0.6317, 0.2836]]]]])
in1Sub32887 = tf.constant([[[[[0.1451, 0.5428, 0.3532], [0.0476, 0.5939, 0.3641], [0.7945, 0.8951, 0.9778]], [[0.4345, 0.2744, 0.5459], [0.9732, 0.8053, 0.5884], [0.4417, 0.8224, 0.5775]]], [[[0.9601, 0.9414, 0.805], [0.3723, 0.9663, 0.6342], [0.6982, 0.4628, 0.6921]], [[0.4907, 0.2005, 0.8496], [0.6556, 0.1114, 0.9013], [0.5615, 0.2344, 0.0356]]], [[[0.4052, 0.1118, 0.4269], [0.9273, 0.6437, 0.3538], [0.7833, 0.4702, 0.2388]], [[0.9433, 0.2545, 0.9702], [0.0267, 0.2391, 0.5231], [0.9915, 0.4893, 0.748]]]]])
in0Up_71365 = tf.constant([[[[[1.1065, 1.8317, 1.8993]], [[1.1605, 1.1483, 1.2802]], [[1.4364, 1.608, 1.3543]]]]])
in0Add80702 = tf.constant([[[[[0.8978, 0.4026], [0.0247, 0.9689]], [[0.0058, 0.9292], [0.3979, 0.0382]]]]])
in1Add80702 = tf.constant([[[[[0.6788, 0.2502], [0.2497, 0.4593]], [[0.2993, 0.6952], [0.9116, 0.4782]]]]])
in0Con23341 = tf.constant([[[[[0.5807], [0.0035], [0.2339]], [[0.6602], [0.1463], [0.0993]], [[0.8994], [0.4934], [0.7414]]], [[[0.3078], [0.7763], [0.5697]], [[0.1263], [0.3413], [0.4984]], [[0.4085], [0.6779], [0.5805]]]]])
in0Min64445 = tf.constant([[[[0.6491, 0.0472]], [[0.0221, 0.365]]]])
in1Min64445 = tf.constant([[[[0.09, 0.8057]], [[0.2083, 0.9682]]]])
in0Con52966 = tf.constant([[[0.6847, 0.5899, 0.067, 0.742, 0.1285, 0.738, 0.1553, 0.5931, 0.6581, 0.8363, 0.2243, 0.4073, 0.962, 0.4634, 0.9789, 0.5011, 0.3292, 0.1232, 0.6348, 0.2067, 0.0055, 0.8, 0.4668, 0.7292, 0.2392, 0.0584, 0.4535, 0.427, 0.1468, 0.1127, 0.255, 0.9044, 0.2434, 0.5404], [0.6065, 0.3227, 0.7248, 0.346, 0.101, 0.633, 0.3617, 0.8985, 0.245, 0.0149, 0.1737, 0.8553, 0.6187, 0.6629, 0.8878, 0.5659, 0.9508, 0.2066, 0.5514, 0.6033, 0.9242, 0.4727, 0.5734, 0.0104, 0.5725, 0.9989, 0.8948, 0.5682, 0.1946, 0.6995, 0.9526, 0.8945, 0.8206, 0.3445], [0.594, 0.4613, 0.394, 0.0646, 0.1247, 0.6876, 0.0008, 0.9234, 0.2249, 0.1019, 0.6721, 0.707, 0.5611, 0.2032, 0.5154, 0.4748, 0.5335, 0.0474, 0.1868, 0.086, 0.752, 0.7836, 0.009, 0.8724, 0.5126, 0.3259, 0.357, 0.8621, 0.76, 0.1047, 0.2914, 0.476, 0.7616, 0.3686], [0.7982, 0.4164, 0.9975, 0.8236, 0.4121, 0.5464, 0.5721, 0.4912, 0.445, 0.9193, 0.7929, 0.5421, 0.5193, 0.7579, 0.4296, 0.5197, 0.6153, 0.1081, 0.5636, 0.8074, 0.3799, 0.0933, 0.8738, 0.41, 0.0184, 0.1834, 0.6606, 0.125, 0.6898, 0.6573, 0.9076, 0.9584, 0.9628, 0.4858]]])
print (np.array2string(model.predict([in0Sub32887,in1Sub32887,in0Up_71365,in0Add80702,in1Add80702,in0Con23341,in0Min64445,in1Min64445,in0Con52966],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max98764.png')

LSub32887 = subtract_layer([[[[[0.0768, 0.8163, 0.9874], [0.7916, 0.5907, 0.1858], [0.1571, 0.2749, 0.8413]], [[0.803, 0.4926, 0.1205], [0.7495, 0.8429, 0.5507], [0.9522, 0.2491, 0.2023]]], [[[0.4343, 0.889, 0.8889], [0.3109, 0.6943, 0.8138], [0.7999, 0.1382, 0.6444]], [[0.7719, 0.0282, 0.2652], [0.0437, 0.5404, 0.7427], [0.3953, 0.4362, 0.8718]]], [[[0.2373, 0.3524, 0.1734], [0.0404, 0.964, 0.4378], [0.2925, 0.0954, 0.0569]], [[0.9989, 0.9767, 0.6618], [0.9381, 0.2004, 0.2769], [0.2205, 0.6317, 0.2836]]]]], [[[[[0.1451, 0.5428, 0.3532], [0.0476, 0.5939, 0.3641], [0.7945, 0.8951, 0.9778]], [[0.4345, 0.2744, 0.5459], [0.9732, 0.8053, 0.5884], [0.4417, 0.8224, 0.5775]]], [[[0.9601, 0.9414, 0.805], [0.3723, 0.9663, 0.6342], [0.6982, 0.4628, 0.6921]], [[0.4907, 0.2005, 0.8496], [0.6556, 0.1114, 0.9013], [0.5615, 0.2344, 0.0356]]], [[[0.4052, 0.1118, 0.4269], [0.9273, 0.6437, 0.3538], [0.7833, 0.4702, 0.2388]], [[0.9433, 0.2545, 0.9702], [0.0267, 0.2391, 0.5231], [0.9915, 0.4893, 0.748]]]]], Sub32887), 
LZer91386 = zero_padding3D_layer(Sub32887, 0, 0, 2, 0, 0, 0, Zer91386), 
LUp_71365 = up_sampling3D_layer([[[[[1.1065, 1.8317, 1.8993]], [[1.1605, 1.1483, 1.2802]], [[1.4364, 1.608, 1.3543]]]]], 2, 1, 1, Up_71365), 
LZer58176 = zero_padding3D_layer(Up_71365, 0, 0, 0, 0, 2, 0, Zer58176), 
LAdd80702 = add_layer([[[[[[0.8978, 0.4026], [0.0247, 0.9689]], [[0.0058, 0.9292], [0.3979, 0.0382]]]]], [[[[[0.6788, 0.2502], [0.2497, 0.4593]], [[0.2993, 0.6952], [0.9116, 0.4782]]]]]], Add80702), 
LZer46236 = zero_padding3D_layer(Add80702, 1, 0, 1, 0, 1, 0, Zer46236), 
LCon23341 = concatenate_layer([Zer46236,[[[[[0.5807], [0.0035], [0.2339]], [[0.6602], [0.1463], [0.0993]], [[0.8994], [0.4934], [0.7414]]], [[[0.3078], [0.7763], [0.5697]], [[0.1263], [0.3413], [0.4984]], [[0.4085], [0.6779], [0.5805]]]]]], 4, Con23341), 
LMin79067 = minimum_layer([Zer58176,Con23341], Min79067), 
LZer71431 = zero_padding3D_layer(Min79067, 1, 0, 1, 0, 0, 0, Zer71431), 
LSub65121 = subtract_layer(Zer91386,Zer71431, Sub65121), 
LRes8418 = reshape_layer(Sub65121, [3, 4, 9], Res8418), 
LRes81328 = reshape_layer(Res8418, [3, 36], Res81328), 
LZer45209 = zero_padding1D_layer(Res81328, 1, 0, Zer45209), 
LMin64445 = minimum_layer([[[[[0.6491, 0.0472]], [[0.0221, 0.365]]]], [[[[0.09, 0.8057]], [[0.2083, 0.9682]]]]], Min64445), 
LRes69786 = reshape_layer(Min64445, [2, 2], Res69786), 
LUp_94352 = up_sampling1D_layer(Res69786, 2, Up_94352), 
LCon52966 = concatenate_layer([Up_94352,[[[0.6847, 0.5899, 0.067, 0.742, 0.1285, 0.738, 0.1553, 0.5931, 0.6581, 0.8363, 0.2243, 0.4073, 0.962, 0.4634, 0.9789, 0.5011, 0.3292, 0.1232, 0.6348, 0.2067, 0.0055, 0.8, 0.4668, 0.7292, 0.2392, 0.0584, 0.4535, 0.427, 0.1468, 0.1127, 0.255, 0.9044, 0.2434, 0.5404], [0.6065, 0.3227, 0.7248, 0.346, 0.101, 0.633, 0.3617, 0.8985, 0.245, 0.0149, 0.1737, 0.8553, 0.6187, 0.6629, 0.8878, 0.5659, 0.9508, 0.2066, 0.5514, 0.6033, 0.9242, 0.4727, 0.5734, 0.0104, 0.5725, 0.9989, 0.8948, 0.5682, 0.1946, 0.6995, 0.9526, 0.8945, 0.8206, 0.3445], [0.594, 0.4613, 0.394, 0.0646, 0.1247, 0.6876, 0.0008, 0.9234, 0.2249, 0.1019, 0.6721, 0.707, 0.5611, 0.2032, 0.5154, 0.4748, 0.5335, 0.0474, 0.1868, 0.086, 0.752, 0.7836, 0.009, 0.8724, 0.5126, 0.3259, 0.357, 0.8621, 0.76, 0.1047, 0.2914, 0.476, 0.7616, 0.3686], [0.7982, 0.4164, 0.9975, 0.8236, 0.4121, 0.5464, 0.5721, 0.4912, 0.445, 0.9193, 0.7929, 0.5421, 0.5193, 0.7579, 0.4296, 0.5197, 0.6153, 0.1081, 0.5636, 0.8074, 0.3799, 0.0933, 0.8738, 0.41, 0.0184, 0.1834, 0.6606, 0.125, 0.6898, 0.6573, 0.9076, 0.9584, 0.9628, 0.4858]]]], 2, Con52966), 
LMax98764 = maximum_layer([Zer45209,Con52966], Max98764), 
exec_layers([LSub32887,LZer91386,LUp_71365,LZer58176,LAdd80702,LZer46236,LCon23341,LMin79067,LZer71431,LSub65121,LRes8418,LRes81328,LZer45209,LMin64445,LRes69786,LUp_94352,LCon52966,LMax98764],["Sub32887","Zer91386","Up_71365","Zer58176","Add80702","Zer46236","Con23341","Min79067","Zer71431","Sub65121","Res8418","Res81328","Zer45209","Min64445","Res69786","Up_94352","Con52966","Max98764"],Max98764,"Max98764")

Actual (Unparsed): [[[0.0900000, 0.0472000, 0.6847000, 0.5899000, 0.0670000, 0.7420000, 0.1285000, 0.7380000, 0.1553000, 0.5931000, 0.6581000, 0.8363000, 0.2243000, 0.4073000, 0.9620000, 0.4634000, 0.9789000, 0.5011000, 0.3292000, 0.1232000, 0.6348000, 0.2067000, 0.0055000, 0.8000000, 0.4668000, 0.7292000, 0.2392000, 0.0584000, 0.4535000, 0.4270000, 0.1468000, 0.1127000, 0.2550000, 0.9044000, 0.2434000, 0.5404000], [0.0900000, 0.0472000, 0.6065000, 0.3227000, 0.7248000, 0.3460000, 0.1010000, 0.6330000, 0.3617000, 0.8985000, 0.2450000, 0.0149000, 0.1737000, 0.8553000, 0.6187000, 0.6629000, 0.8878000, 0.5659000, 0.9508000, 0.2735000, 0.6342000, 0.7440000, 0.9242000, 0.4727000, 0.5734000, 0.0104000, 0.5725000, 0.9989000, 0.8948000, 0.5682000, 0.1946000, 0.6995000, 0.9526000, 0.8945000, 0.8206000, 0.3445000], [0.0221000, 0.3650000, 0.5940000, 0.4613000, 0.3940000, 0.0646000, 0.1247000, 0.6876000, 0.0008000, 0.9234000, 0.2249000, 0.1019000, 0.6721000, 0.7070000, 0.5611000, 0.2032000, 0.5154000, 0.4748000, 0.5335000, 0.0474000, 0.1868000, 0.0860000, 0.7520000, 0.7836000, 0.1017000, 0.8724000, 0.5126000, 0.3259000, 0.3570000, 0.8621000, 0.7600000, 0.4290000, 0.2914000, 0.4760000, 0.7616000, 0.3686000], [0.0221000, 0.3650000, 0.7982000, 0.4164000, 0.9975000, 0.8236000, 0.4121000, 0.5464000, 0.5721000, 0.4912000, 0.4450000, 0.9193000, 0.7929000, 0.5421000, 0.5193000, 0.7579000, 0.4296000, 0.5197000, 0.6153000, 0.2406000, 0.5636000, 0.8074000, 0.3799000, 0.0933000, 0.8738000, 0.4100000, 0.0184000, 0.1834000, 0.7222000, 0.1250000, 0.9114000, 0.6573000, 0.9076000, 0.9584000, 0.9628000, 0.4858000]]]

Expected (Unparsed): [[[0.09,0.0472,0.6847,0.5899,0.067,0.742,0.1285,0.738,0.1553,0.5931,0.6581,0.8363,0.2243,0.4073,0.962,0.4634,0.9789,0.5011,0.3292,0.1232,0.6348,0.2067,0.0055,0.8,0.4668,0.7292,0.2392,0.0584,0.4535,0.427,0.1468,0.1127,0.255,0.9044,0.2434,0.5404],[0.09,0.0472,0.6065,0.3227,0.7248,0.346,0.101,0.633,0.3617,0.8985,0.245,0.0149,0.1737,0.8553,0.6187,0.6629,0.8878,0.5659,0.9508,0.2735000000000001,0.6342000000000001,0.744,0.9242,0.4727,0.5734,0.0104,0.5725,0.9989,0.8948,0.5682,0.1946,0.6995,0.9526,0.8945,0.8206,0.3445],[0.0221,0.365,0.594,0.4613,0.394,0.0646,0.1247,0.6876,0.0008,0.9234,0.2249,0.1019,0.6721,0.707,0.5611,0.2032,0.5154,0.4748,0.5335,0.0474,0.1868,0.086,0.752,0.7836,0.10170000000000001,0.8724,0.5126,0.3259,0.357,0.8621,0.76,0.429,0.2914,0.476,0.7616,0.3686],[0.0221,0.365,0.7982,0.4164,0.9975,0.8236,0.4121,0.5464,0.5721,0.4912,0.445,0.9193,0.7929,0.5421,0.5193,0.7579,0.4296,0.5197,0.6153,0.24059999999999998,0.5636,0.8074,0.3799,0.0933,0.8738,0.41,0.0184,0.1834,0.7222,0.125,0.9114,0.6573,0.9076,0.9584,0.9628,0.4858]]]

Actual:   [[[0.09, 0.0472, 0.6847, 0.5899, 0.067, 0.742, 0.1285, 0.738, 0.1553, 0.5931, 0.6581, 0.8363, 0.2243, 0.4073, 0.962, 0.4634, 0.9789, 0.5011, 0.3292, 0.1232, 0.6348, 0.2067, 0.0055, 0.8, 0.4668, 0.7292, 0.2392, 0.0584, 0.4535, 0.427, 0.1468, 0.1127, 0.255, 0.9044, 0.2434, 0.5404], [0.09, 0.0472, 0.6065, 0.3227, 0.7248, 0.346, 0.101, 0.633, 0.3617, 0.8985, 0.245, 0.0149, 0.1737, 0.8553, 0.6187, 0.6629, 0.8878, 0.5659, 0.9508, 0.2735, 0.6342, 0.744, 0.9242, 0.4727, 0.5734, 0.0104, 0.5725, 0.9989, 0.8948, 0.5682, 0.1946, 0.6995, 0.9526, 0.8945, 0.8206, 0.3445], [0.0221, 0.365, 0.594, 0.4613, 0.394, 0.0646, 0.1247, 0.6876, 0.0008, 0.9234, 0.2249, 0.1019, 0.6721, 0.707, 0.5611, 0.2032, 0.5154, 0.4748, 0.5335, 0.0474, 0.1868, 0.086, 0.752, 0.7836, 0.1017, 0.8724, 0.5126, 0.3259, 0.357, 0.8621, 0.76, 0.429, 0.2914, 0.476, 0.7616, 0.3686], [0.0221, 0.365, 0.7982, 0.4164, 0.9975, 0.8236, 0.4121, 0.5464, 0.5721, 0.4912, 0.445, 0.9193, 0.7929, 0.5421, 0.5193, 0.7579, 0.4296, 0.5197, 0.6153, 0.2406, 0.5636, 0.8074, 0.3799, 0.0933, 0.8738, 0.41, 0.0184, 0.1834, 0.7222, 0.125, 0.9114, 0.6573, 0.9076, 0.9584, 0.9628, 0.4858]]]

Expected: [[[0.09, 0.0472, 0.6847, 0.5899, 0.067, 0.742, 0.1285, 0.738, 0.1553, 0.5931, 0.6581, 0.8363, 0.2243, 0.4073, 0.962, 0.4634, 0.9789, 0.5011, 0.3292, 0.1232, 0.6348, 0.2067, 0.0055, 0.8, 0.4668, 0.7292, 0.2392, 0.0584, 0.4535, 0.427, 0.1468, 0.1127, 0.255, 0.9044, 0.2434, 0.5404], [0.09, 0.0472, 0.6065, 0.3227, 0.7248, 0.346, 0.101, 0.633, 0.3617, 0.8985, 0.245, 0.0149, 0.1737, 0.8553, 0.6187, 0.6629, 0.8878, 0.5659, 0.9508, 0.2736, 0.6343, 0.744, 0.9242, 0.4727, 0.5734, 0.0104, 0.5725, 0.9989, 0.8948, 0.5682, 0.1946, 0.6995, 0.9526, 0.8945, 0.8206, 0.3445], [0.0221, 0.365, 0.594, 0.4613, 0.394, 0.0646, 0.1247, 0.6876, 0.0008, 0.9234, 0.2249, 0.1019, 0.6721, 0.707, 0.5611, 0.2032, 0.5154, 0.4748, 0.5335, 0.0474, 0.1868, 0.086, 0.752, 0.7836, 0.1018, 0.8724, 0.5126, 0.3259, 0.357, 0.8621, 0.76, 0.429, 0.2914, 0.476, 0.7616, 0.3686], [0.0221, 0.365, 0.7982, 0.4164, 0.9975, 0.8236, 0.4121, 0.5464, 0.5721, 0.4912, 0.445, 0.9193, 0.7929, 0.5421, 0.5193, 0.7579, 0.4296, 0.5197, 0.6153, 0.2406, 0.5636, 0.8074, 0.3799, 0.0933, 0.8738, 0.41, 0.0184, 0.1834, 0.7222, 0.125, 0.9114, 0.6573, 0.9076, 0.9584, 0.9628, 0.4858]]]