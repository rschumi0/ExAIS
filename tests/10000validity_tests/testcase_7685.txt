import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con42003 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Max52161 = tf.keras.layers.Input(shape=([1, 2, 2]))
in1Max52161 = tf.keras.layers.Input(shape=([1, 2, 2]))
in0Con64218 = tf.keras.layers.Input(shape=([4, 4, 2]))
in0Loc89168 = tf.keras.layers.Input(shape=([1, 2]))
in0Min21907 = tf.keras.layers.Input(shape=([1, 1, 1]))
in1Min21907 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con9146 = tf.keras.layers.Input(shape=([1]))
in0Con32146 = tf.keras.layers.Input(shape=([46]))

Con42003 = keras.layers.Conv2DTranspose(4, (1, 2),strides=(2, 2), padding='same', name = 'Con42003', )(in0Con42003)
Max52161 = keras.layers.Maximum(name = 'Max52161', )([in0Max52161,in1Max52161])
Zer61237 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer61237', )(Max52161)
Zer92129 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer92129', )(Zer61237)
Con64218 = keras.layers.Concatenate(axis=3, name = 'Con64218', )([Zer92129,in0Con64218])
Sub42429 = keras.layers.Subtract(name = 'Sub42429', )([Con42003,Con64218])
Den27317 = keras.layers.Dense(3,name = 'Den27317', )(Sub42429)
Res6512 = keras.layers.Reshape((4, 12), name = 'Res6512', )(Den27317)
Fla31875 = keras.layers.Flatten(name = 'Fla31875', )(Res6512)
Loc89168 = keras.layers.LocallyConnected1D(2, (1),strides=(1), name = 'Loc89168', )(in0Loc89168)
Fla82524 = keras.layers.Flatten(name = 'Fla82524', )(Loc89168)
Min21907 = keras.layers.Minimum(name = 'Min21907', )([in0Min21907,in1Min21907])
Res56943 = keras.layers.Reshape((1, 1), name = 'Res56943', )(Min21907)
LST54359 = keras.layers.LSTM(1,recurrent_activation='sigmoid', name = 'LST54359', )(Res56943)
Con9146 = keras.layers.Concatenate(axis=1, name = 'Con9146', )([LST54359,in0Con9146])
Max7442 = keras.layers.Maximum(name = 'Max7442', )([Fla82524,Con9146])
Sof64723 = keras.layers.Softmax(axis=1, name = 'Sof64723', )(Max7442)
Con32146 = keras.layers.Concatenate(axis=1, name = 'Con32146', )([Sof64723,in0Con32146])
Min23163 = keras.layers.Minimum(name = 'Min23163', )([Fla31875,Con32146])
model = tf.keras.models.Model(inputs=[in0Con42003,in0Max52161,in1Max52161,in0Con64218,in0Loc89168,in0Min21907,in1Min21907,in0Con9146,in0Con32146], outputs=Min23163)
w = model.get_layer('Con42003').get_weights() 
w[0] = np.array([[[[0.0606], [0.9231], [0.3763], [0.7777]], [[0.5914], [0.6003], [0.2422], [0.7951]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con42003').set_weights(w) 
w = model.get_layer('Den27317').get_weights() 
w[0] = np.array([[0.4452, 0.8854, 0.3335], [0.8693, 0.8646, 0.0109], [0.6906, 0.041, 0.1401], [0.827, 0.511, 0.506]])
w[1] = np.array([0.5447, 0.4587, 0.56])
model.get_layer('Den27317').set_weights(w) 
w = model.get_layer('Loc89168').get_weights() 
w[0] = np.array([[[0.539, 0.1643], [0.308, 0.5056]]])
w[1] = np.array([[0, 0]])
model.get_layer('Loc89168').set_weights(w) 
w = model.get_layer('LST54359').get_weights() 
w[0] = np.array([[6, 8, 9, 2]])
w[1] = np.array([[3, 3, 7, 8]])
w[2] = np.array([7, 1, 7, 9])
model.get_layer('LST54359').set_weights(w) 
in0Con42003 = tf.constant([[[[0.1381], [0.902]], [[0.0158], [0.4648]]]])
in0Max52161 = tf.constant([[[[0.7358, 0.4348], [0.2979, 0.1869]]]])
in1Max52161 = tf.constant([[[[0.4043, 0.1406], [0.9528, 0.7974]]]])
in0Con64218 = tf.constant([[[[0.472, 0.5328], [0.0548, 0.8861], [0.7707, 0.1632], [0.9069, 0.0515]], [[0.8592, 0.1009], [0.3941, 0.1548], [0.3529, 0.5318], [0.6312, 0.1894]], [[0.2235, 0.9599], [0.3827, 0.1335], [0.8909, 0.4241], [0.7685, 0.8491]], [[0.63, 0.5641], [0.2991, 0.9107], [0.1774, 0.1693], [0.4673, 0.9794]]]])
in0Loc89168 = tf.constant([[[0.7796, 0.8264]]])
in0Min21907 = tf.constant([[[[0.1187]]]])
in1Min21907 = tf.constant([[[[0.0862]]]])
in0Con9146 = tf.constant([[0.0575]])
in0Con32146 = tf.constant([[0.008, 0.3075, 0.82, 0.8691, 0.494, 0.4675, 0.9299, 0.0059, 0.5674, 0.6014, 0.5433, 0.2164, 0.4714, 0.4168, 0.6005, 0.2904, 0.2322, 0.5466, 0.6487, 0.5554, 0.3018, 0.2484, 0.4737, 0.2184, 0.1039, 0.0958, 0.4601, 0.0731, 0.0303, 0.7907, 0.5733, 0.3003, 0.0435, 0.4044, 0.9177, 0.8492, 0.7998, 0.9351, 0.5388, 0.5423, 0.1311, 0.0628, 0.5113, 0.6194, 0.7931, 0.3741]])
print (np.array2string(model.predict([in0Con42003,in0Max52161,in1Max52161,in0Con64218,in0Loc89168,in0Min21907,in1Min21907,in0Con9146,in0Con32146],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min23163.png')

LCon42003 = conv2D_transpose_layer([[[[0.1381], [0.902]], [[0.0158], [0.4648]]]], 1, 2,[[[[0.0606], [0.9231], [0.3763], [0.7777]], [[0.5914], [0.6003], [0.2422], [0.7951]]]],[0, 0, 0, 0], 2, 2, true, Con42003), 
LMax52161 = maximum_layer([[[[[0.7358, 0.4348], [0.2979, 0.1869]]]], [[[[0.4043, 0.1406], [0.9528, 0.7974]]]]], Max52161), 
LZer61237 = zero_padding2D_layer(Max52161, 1, 1, 1, 1, Zer61237), 
LZer92129 = zero_padding2D_layer(Zer61237, 1, 0, 0, 0, Zer92129), 
LCon64218 = concatenate_layer([Zer92129,[[[[0.472, 0.5328], [0.0548, 0.8861], [0.7707, 0.1632], [0.9069, 0.0515]], [[0.8592, 0.1009], [0.3941, 0.1548], [0.3529, 0.5318], [0.6312, 0.1894]], [[0.2235, 0.9599], [0.3827, 0.1335], [0.8909, 0.4241], [0.7685, 0.8491]], [[0.63, 0.5641], [0.2991, 0.9107], [0.1774, 0.1693], [0.4673, 0.9794]]]]], 3, Con64218), 
LSub42429 = subtract_layer(Con42003,Con64218, Sub42429), 
LDen27317 = dense_layer(Sub42429, [[0.4452, 0.8854, 0.3335], [0.8693, 0.8646, 0.0109], [0.6906, 0.041, 0.1401], [0.827, 0.511, 0.506]],[0.5447, 0.4587, 0.56], Den27317), 
LRes6512 = reshape_layer(Den27317, [4, 12], Res6512), 
LFla31875 = flatten_layer(Res6512, Fla31875), 
LLoc89168 = locally_connected1D_layer([[[0.7796, 0.8264]]], 1,[[[0.539, 0.1643], [0.308, 0.5056]]],[[0, 0]], 1, Loc89168), 
LFla82524 = flatten_layer(Loc89168, Fla82524), 
LMin21907 = minimum_layer([[[[[0.1187]]]], [[[[0.0862]]]]], Min21907), 
LRes56943 = reshape_layer(Min21907, [1, 1], Res56943), 
LLST54359 = lstm_layer(Res56943,[[6, 8, 9, 2]],[[3, 3, 7, 8]],[7, 1, 7, 9], LST54359), 
LCon9146 = concatenate_layer([LST54359,[[0.0575]]], 1, Con9146), 
LMax7442 = maximum_layer([Fla82524,Con9146], Max7442), 
LSof64723 = softmax_layer(Max7442, 1, Sof64723), 
LCon32146 = concatenate_layer([Sof64723,[[0.008, 0.3075, 0.82, 0.8691, 0.494, 0.4675, 0.9299, 0.0059, 0.5674, 0.6014, 0.5433, 0.2164, 0.4714, 0.4168, 0.6005, 0.2904, 0.2322, 0.5466, 0.6487, 0.5554, 0.3018, 0.2484, 0.4737, 0.2184, 0.1039, 0.0958, 0.4601, 0.0731, 0.0303, 0.7907, 0.5733, 0.3003, 0.0435, 0.4044, 0.9177, 0.8492, 0.7998, 0.9351, 0.5388, 0.5423, 0.1311, 0.0628, 0.5113, 0.6194, 0.7931, 0.3741]]], 1, Con32146), 
LMin23163 = minimum_layer([Fla31875,Con32146], Min23163), 
exec_layers([LCon42003,LMax52161,LZer61237,LZer92129,LCon64218,LSub42429,LDen27317,LRes6512,LFla31875,LLoc89168,LFla82524,LMin21907,LRes56943,LLST54359,LCon9146,LMax7442,LSof64723,LCon32146,LMin23163],["Con42003","Max52161","Zer61237","Zer92129","Con64218","Sub42429","Den27317","Res6512","Fla31875","Loc89168","Fla82524","Min21907","Res56943","LST54359","Con9146","Max7442","Sof64723","Con32146","Min23163"],Min23163,"Min23163")

Actual (Unparsed): [[0.0173640, 0.3417285, 0.0080000, -0.0036164, 0.2051262, 0.1923438, 0.4940000, 0.4675000, 0.7992557, 0.0059000, 0.5674000, 0.6014000, -0.1321078, 0.2164000, 0.3885707, 0.1445149, 0.3634391, 0.2904000, -0.1388113, 0.1724813, 0.2414679, -0.0478405, 0.3018000, 0.2484000, -0.3761135, -0.0209917, 0.0505071, -0.5101098, -0.6295645, 0.0731000, -0.7334049, -0.7397968, 0.1156206, 0.0600698, 0.0435000, 0.3201736, -0.3568887, 0.1446149, 0.1863024, -0.4150074, -0.0189308, 0.0572819, 0.1311000, 0.0628000, 0.4494805, -0.5879812, -0.0609327, -0.0010451]]

Expected (Unparsed): [[0.017364013002999945,0.34172852905000006,0.008,-0.0036164392710000826,0.20512621824399996,0.192343785419,0.494,0.4675,0.79925569344,0.0059,0.5674,0.6014,-0.13210781999999996,0.2164,0.38857068000000006,0.14451493999999995,0.3634391,0.2904,-0.13881134000000006,0.17248129999999995,0.24146791000000006,-0.04784052,0.3018,0.2484,-0.3761135220459999,-0.020991712100000004,0.05050707197600007,-0.510109819178,-0.629564434408,0.0731,-0.7334049191759999,-0.7397968475999999,0.11562063825600002,0.060069748232000064,0.0435,0.3201735597520002,-0.35688870000000006,0.14461489999999994,0.18630240000000003,-0.41500735999999994,-0.01893079999999997,0.05728189,0.1311,0.0628,0.4494804600000001,-0.5879811800000001,-0.06093270000000006,-0.0010451299999999497]]

Actual:   [[0.0174, 0.3418, 0.008, -0.0036, 0.2052, 0.1924, 0.494, 0.4675, 0.7993, 0.0059, 0.5674, 0.6014, -0.1321, 0.2164, 0.3886, 0.1446, 0.3635, 0.2904, -0.1388, 0.1725, 0.2415, -0.0478, 0.3018, 0.2484, -0.3761, -0.0209, 0.0506, -0.5101, -0.6295, 0.0731, -0.7334, -0.7397, 0.1157, 0.0601, 0.0435, 0.3202, -0.3568, 0.1447, 0.1864, -0.415, -0.0189, 0.0573, 0.1311, 0.0628, 0.4495, -0.5879, -0.0609, -0.001]]

Expected: [[0.0174, 0.3418, 0.008, -0.0036, 0.2052, 0.1924, 0.494, 0.4675, 0.7993, 0.0059, 0.5674, 0.6014, -0.1321, 0.2164, 0.3886, 0.1446, 0.3635, 0.2904, -0.1388, 0.1725, 0.2415, -0.0478, 0.3018, 0.2484, -0.3761, -0.0209, 0.0506, -0.5101, -0.6295, 0.0731, -0.7334, -0.7397, 0.1157, 0.0601, 0.0435, 0.3202, -0.3568, 0.1447, 0.1864, -0.415, -0.0189, 0.0573, 0.1311, 0.0628, 0.4495, -0.5879, -0.0609, -0.001]]