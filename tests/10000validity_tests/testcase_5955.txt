import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max36345 = tf.keras.layers.Input(shape=([1, 1, 2]))
in1Max36345 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con35532 = tf.keras.layers.Input(shape=([4, 2, 3]))
in0Bat93758 = tf.keras.layers.Input(shape=([4, 2, 4]))

Max36345 = keras.layers.Maximum(name = 'Max36345', )([in0Max36345,in1Max36345])
Res69449 = keras.layers.Reshape((1, 1, 2, 1), name = 'Res69449', )(Max36345)
Cro28341 = keras.layers.Cropping3D(cropping=((0, 0), (0, 0), (1, 0)), name = 'Cro28341', )(Res69449)
Res1134 = keras.layers.Reshape((1, 1, 1), name = 'Res1134', )(Cro28341)
Zer85724 = keras.layers.ZeroPadding2D(padding=((3, 0), (1, 0)), name = 'Zer85724', )(Res1134)
Con35532 = keras.layers.Concatenate(axis=3, name = 'Con35532', )([Zer85724,in0Con35532])
Bat93758 = keras.layers.BatchNormalization(axis=3, epsilon=0.7697322319698643,  name = 'Bat93758', )(in0Bat93758)
Sub8752 = keras.layers.Subtract(name = 'Sub8752', )([Con35532,Bat93758])
ELU16326 = keras.layers.ELU(alpha=7.937972565899688, name = 'ELU16326', )(Sub8752)
model = tf.keras.models.Model(inputs=[in0Max36345,in1Max36345,in0Con35532,in0Bat93758], outputs=ELU16326)
w = model.get_layer('Bat93758').get_weights() 
w[0] = np.array([0.7462, 0.0828, 0.2824, 0.2672])
w[1] = np.array([0.9762, 0.4834, 0.3265, 0.2128])
w[2] = np.array([0.2486, 0.8569, 0.6762, 0.5229])
w[3] = np.array([0.3537, 0.3697, 0.7739, 0.0632])
model.get_layer('Bat93758').set_weights(w) 
in0Max36345 = tf.constant([[[[0.426, 0.8597]]]])
in1Max36345 = tf.constant([[[[0.0719, 0.6501]]]])
in0Con35532 = tf.constant([[[[0.6226, 0.6701, 0.3301], [0.9691, 0.7988, 0.4022]], [[0.5313, 0.3457, 0.3205], [0.4829, 0.393, 0.3316]], [[0.4877, 0.7417, 0.9869], [0.0142, 0.5235, 0.2577]], [[0.1922, 0.0775, 0.8732], [0.9806, 0.6457, 0.0733]]]])
in0Bat93758 = tf.constant([[[[1.8892, 1.9297, 1.4766, 1.4326], [1.775, 1.0853, 1.0168, 1.0389]], [[1.9768, 1.0166, 1.244, 1.8838], [1.6142, 1.4326, 1.6355, 1.5804]], [[1.1463, 1.0909, 1.2561, 1.4193], [1.4802, 1.7089, 1.6281, 1.496]], [[1.9252, 1.4427, 1.7288, 1.858], [1.9886, 1.8112, 1.3241, 1.9986]]]])
print (np.array2string(model.predict([in0Max36345,in1Max36345,in0Con35532,in0Bat93758],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='ELU16326.png')

LMax36345 = maximum_layer([[[[[0.426, 0.8597]]]], [[[[0.0719, 0.6501]]]]], Max36345), 
LRes69449 = reshape_layer(Max36345, [1, 1, 2, 1], Res69449), 
LCro28341 = cropping3D_layer(Res69449, 0, 0, 0, 0, 1, 0, Cro28341), 
LRes1134 = reshape_layer(Cro28341, [1, 1, 1], Res1134), 
LZer85724 = zero_padding2D_layer(Res1134, 3, 0, 1, 0, Zer85724), 
LCon35532 = concatenate_layer([Zer85724,[[[[0.6226, 0.6701, 0.3301], [0.9691, 0.7988, 0.4022]], [[0.5313, 0.3457, 0.3205], [0.4829, 0.393, 0.3316]], [[0.4877, 0.7417, 0.9869], [0.0142, 0.5235, 0.2577]], [[0.1922, 0.0775, 0.8732], [0.9806, 0.6457, 0.0733]]]]], 3, Con35532), 
LBat93758 = batch_normalization_layer([[[[1.8892, 1.9297, 1.4766, 1.4326], [1.775, 1.0853, 1.0168, 1.0389]], [[1.9768, 1.0166, 1.244, 1.8838], [1.6142, 1.4326, 1.6355, 1.5804]], [[1.1463, 1.0909, 1.2561, 1.4193], [1.4802, 1.7089, 1.6281, 1.496]], [[1.9252, 1.4427, 1.7288, 1.858], [1.9886, 1.8112, 1.3241, 1.9986]]]], 3, 0.7697322319698643, [0.7462, 0.0828, 0.2824, 0.2672], [0.9762, 0.4834, 0.3265, 0.2128], [0.2486, 0.8569, 0.6762, 0.5229], [0.3537, 0.3697, 0.7739, 0.0632], Bat93758), 
LSub8752 = subtract_layer(Con35532,Bat93758, Sub8752), 
LELU16326 = elu_layer(Sub8752, 7.937972565899688, ELU16326), 
exec_layers([LMax36345,LRes69449,LCro28341,LRes1134,LZer85724,LCon35532,LBat93758,LSub8752,LELU16326],["Max36345","Res69449","Cro28341","Res1134","Zer85724","Con35532","Bat93758","Sub8752","ELU16326"],ELU16326,"ELU16326")

Actual (Unparsed): [[[[-6.9957830, 0.0559844, 0.1616718, -1.0991066], [-6.9169040, 0.4679833, 0.3948828, 0.0383289]], [[-7.0521340, 0.0355123, -0.8258627, -2.0026430], [-6.7945166, -0.3504765, -1.1162476, -1.3788946]], [[-6.3484021, -0.1091914, 0.2833907, 0.5116579], [-6.6813932, -3.2902867, -0.1522286, -1.6937286]], [[-7.0193623, -2.2689416, -3.0664546, 0.2695182], [-5.8625348, 0.4231763, 0.1719346, -3.4557807]]]]

Expected (Unparsed): [[[[-6.995783035088442,0.05598438035944797,0.16167187097900604,-1.099106526086431],[-6.916904024207739,0.46798332631813744,0.394882807665479,0.03832892441439617]],[[-7.052133975551825,0.03551229077498491,-0.8258627557449915,-2.0026428849455185],[-6.794516568887296,-0.3504764720518514,-1.1162476958977243,-1.378894689993534]],[[-6.348402168251097,-0.10919136454834187,0.28339075209985704,0.5116579221803579],[-6.681393201130873,-3.290286707753269,-0.1522287337280025,-1.6937284339711034]],[[-7.019362324215463,-2.268941595339334,-3.066454586036052,0.2695182305923648],[-5.862534801658493,0.4231762622828311,0.1719345892145152,-3.4557806732152203]]]]

Actual:   [[[[-6.9957, 0.056, 0.1617, -1.0991], [-6.9169, 0.468, 0.3949, 0.0384]], [[-7.0521, 0.0356, -0.8258, -2.0026], [-6.7945, -0.3504, -1.1162, -1.3788]], [[-6.3484, -0.1091, 0.2834, 0.5117], [-6.6813, -3.2902, -0.1522, -1.6937]], [[-7.0193, -2.2689, -3.0664, 0.2696], [-5.8625, 0.4232, 0.172, -3.4557]]]]

Expected: [[[[-6.9957, 0.056, 0.1617, -1.0991], [-6.9169, 0.468, 0.3949, 0.0384]], [[-7.0521, 0.0356, -0.8258, -2.0026], [-6.7945, -0.3504, -1.1162, -1.3788]], [[-6.3484, -0.1091, 0.2834, 0.5117], [-6.6813, -3.2902, -0.1522, -1.6937]], [[-7.0193, -2.2689, -3.0664, 0.2696], [-5.8625, 0.4232, 0.172, -3.4557]]]]