import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add42319 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in1Add42319 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Dot40962 = tf.keras.layers.Input(shape=([2, 3]))
in1Dot40962 = tf.keras.layers.Input(shape=([2, 3]))
in0Con13951 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))
in0Min92702 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in1Min92702 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))

Add42319 = keras.layers.Add(name = 'Add42319', )([in0Add42319,in1Add42319])
Res38272 = keras.layers.Reshape((1, 1, 4), name = 'Res38272', )(Add42319)
Res6181 = keras.layers.Reshape((1, 4), name = 'Res6181', )(Res38272)
Dot40962 = keras.layers.Dot(axes=(2, 2), name = 'Dot40962', )([in0Dot40962,in1Dot40962])
Res34557 = keras.layers.Reshape((2, 2, 1), name = 'Res34557', )(Dot40962)
Res46238 = keras.layers.Reshape((2, 2, 1, 1), name = 'Res46238', )(Res34557)
Con13951 = keras.layers.Concatenate(axis=4, name = 'Con13951', )([Res46238,in0Con13951])
Min92702 = keras.layers.Minimum(name = 'Min92702', )([in0Min92702,in1Min92702])
Add73170 = keras.layers.Add(name = 'Add73170', )([Con13951,Min92702])
Res54678 = keras.layers.Reshape((2, 2, 2), name = 'Res54678', )(Add73170)
Res5445 = keras.layers.Reshape((2, 4), name = 'Res5445', )(Res54678)
Zer36386 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer36386', )(Res5445)
Dot7562 = keras.layers.Dot(axes=(2, 2), name = 'Dot7562', )([Res6181,Zer36386])
Thr61525 = keras.layers.ThresholdedReLU(theta=6.674698177206905, name = 'Thr61525', )(Dot7562)
Glo18026 = keras.layers.GlobalAveragePooling1D(name = 'Glo18026', )(Thr61525)
model = tf.keras.models.Model(inputs=[in0Add42319,in1Add42319,in0Dot40962,in1Dot40962,in0Con13951,in0Min92702,in1Min92702], outputs=Glo18026)
in0Add42319 = tf.constant([[[[[0.489, 0.954], [0.7935, 0.9136]]]]])
in1Add42319 = tf.constant([[[[[0.1648, 0.5933], [0.0819, 0.8143]]]]])
in0Dot40962 = tf.constant([[[0.6559, 0.8344, 0.1006], [0.3385, 0.8046, 0.1255]]])
in1Dot40962 = tf.constant([[[0.5742, 0.4021, 0.2923], [0.426, 0.3309, 0.5209]]])
in0Con13951 = tf.constant([[[[[0.9015]], [[0.5762]]], [[[0.2654]], [[0.8641]]]]])
in0Min92702 = tf.constant([[[[[0.6362, 0.0894]], [[0.9186, 0.4678]]], [[[0.8257, 0.3232]], [[0.1853, 0.7546]]]]])
in1Min92702 = tf.constant([[[[[0.2902, 0.4845]], [[0.9987, 0.1503]]], [[[0.9592, 0.0438]], [[0.1755, 0.9786]]]]])
print (np.array2string(model.predict([in0Add42319,in1Add42319,in0Dot40962,in1Dot40962,in0Con13951,in0Min92702,in1Min92702],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Glo18026.png')

LAdd42319 = add_layer([[[[[[0.489, 0.954], [0.7935, 0.9136]]]]], [[[[[0.1648, 0.5933], [0.0819, 0.8143]]]]]], Add42319), 
LRes38272 = reshape_layer(Add42319, [1, 1, 4], Res38272), 
LRes6181 = reshape_layer(Res38272, [1, 4], Res6181), 
LDot40962 = dot_layer([[[0.6559, 0.8344, 0.1006], [0.3385, 0.8046, 0.1255]]], [[[0.5742, 0.4021, 0.2923], [0.426, 0.3309, 0.5209]]], 2, 2, Dot40962), 
LRes34557 = reshape_layer(Dot40962, [2, 2, 1], Res34557), 
LRes46238 = reshape_layer(Res34557, [2, 2, 1, 1], Res46238), 
LCon13951 = concatenate_layer([Res46238,[[[[[0.9015]], [[0.5762]]], [[[0.2654]], [[0.8641]]]]]], 4, Con13951), 
LMin92702 = minimum_layer([[[[[[0.6362, 0.0894]], [[0.9186, 0.4678]]], [[[0.8257, 0.3232]], [[0.1853, 0.7546]]]]], [[[[[0.2902, 0.4845]], [[0.9987, 0.1503]]], [[[0.9592, 0.0438]], [[0.1755, 0.9786]]]]]], Min92702), 
LAdd73170 = add_layer([Con13951,Min92702], Add73170), 
LRes54678 = reshape_layer(Add73170, [2, 2, 2], Res54678), 
LRes5445 = reshape_layer(Res54678, [2, 4], Res5445), 
LZer36386 = zero_padding1D_layer(Res5445, 1, 0, Zer36386), 
LDot7562 = dot_layer(Res6181,Zer36386, 2, 2, Dot7562), 
LThr61525 = thresholded_relu_layer(Dot7562, 6.674698177206905, Thr61525), 
LGlo18026 = global_average_pooling1D_layer(Thr61525, Glo18026), 
exec_layers([LAdd42319,LRes38272,LRes6181,LDot40962,LRes34557,LRes46238,LCon13951,LMin92702,LAdd73170,LRes54678,LRes5445,LZer36386,LDot7562,LThr61525,LGlo18026],["Add42319","Res38272","Res6181","Dot40962","Res34557","Res46238","Con13951","Min92702","Add73170","Res54678","Res5445","Zer36386","Dot7562","Thr61525","Glo18026"],Glo18026,"Glo18026")

Actual (Unparsed): [[0.0000000, 0.0000000, 0.0000000]]

Expected (Unparsed): [[0,0,0]]

Actual:   [[0, 0, 0]]

Expected: [[0, 0, 0]]