import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add62936 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in1Add62936 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in0Add18122 = tf.keras.layers.Input(shape=([2, 1, 2]))
in1Add18122 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con78979 = tf.keras.layers.Input(shape=([4]))

Add62936 = keras.layers.Add(name = 'Add62936', )([in0Add62936,in1Add62936])
Res32525 = keras.layers.Reshape((2, 2, 2), name = 'Res32525', )(Add62936)
Res25470 = keras.layers.Reshape((2, 4), name = 'Res25470', )(Res32525)
Fla33980 = keras.layers.Flatten(name = 'Fla33980', )(Res25470)
Add18122 = keras.layers.Add(name = 'Add18122', )([in0Add18122,in1Add18122])
Fla87880 = keras.layers.Flatten(name = 'Fla87880', )(Add18122)
Con78979 = keras.layers.Concatenate(axis=1, name = 'Con78979', )([Fla87880,in0Con78979])
Min29462 = keras.layers.Minimum(name = 'Min29462', )([Fla33980,Con78979])
Res14034 = keras.layers.Reshape((8, 1), name = 'Res14034', )(Min29462)
Res71097 = keras.layers.Reshape((8, 1, 1), name = 'Res71097', )(Res14034)
Con99126 = keras.layers.Conv2DTranspose(4, (2, 1),strides=(1, 1), padding='same', name = 'Con99126', )(Res71097)
model = tf.keras.models.Model(inputs=[in0Add62936,in1Add62936,in0Add18122,in1Add18122,in0Con78979], outputs=Con99126)
w = model.get_layer('Con99126').get_weights() 
w[0] = np.array([[[[0.8914], [0.6248], [0.7016], [0.7985]]], [[[0.2376], [0.9642], [0.9583], [0.5654]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con99126').set_weights(w) 
in0Add62936 = tf.constant([[[[[0.6755], [0.6569]], [[0.7737], [0.798]]], [[[0.1551], [0.888]], [[0.2944], [0.1617]]]]])
in1Add62936 = tf.constant([[[[[0.6265], [0.4796]], [[0.4648], [0.2674]]], [[[0.9457], [0.184]], [[0.4146], [0.6413]]]]])
in0Add18122 = tf.constant([[[[0.1245, 0.6734]], [[0.5746, 0.0612]]]])
in1Add18122 = tf.constant([[[[0.0686, 0.1001]], [[0.2344, 0.4506]]]])
in0Con78979 = tf.constant([[0.5834, 0.293, 0.7453, 0.58]])
print (np.array2string(model.predict([in0Add62936,in1Add62936,in0Add18122,in1Add18122,in0Con78979],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Con99126.png')

LAdd62936 = add_layer([[[[[[0.6755], [0.6569]], [[0.7737], [0.798]]], [[[0.1551], [0.888]], [[0.2944], [0.1617]]]]], [[[[[0.6265], [0.4796]], [[0.4648], [0.2674]]], [[[0.9457], [0.184]], [[0.4146], [0.6413]]]]]], Add62936), 
LRes32525 = reshape_layer(Add62936, [2, 2, 2], Res32525), 
LRes25470 = reshape_layer(Res32525, [2, 4], Res25470), 
LFla33980 = flatten_layer(Res25470, Fla33980), 
LAdd18122 = add_layer([[[[[0.1245, 0.6734]], [[0.5746, 0.0612]]]], [[[[0.0686, 0.1001]], [[0.2344, 0.4506]]]]], Add18122), 
LFla87880 = flatten_layer(Add18122, Fla87880), 
LCon78979 = concatenate_layer([Fla87880,[[0.5834, 0.293, 0.7453, 0.58]]], 1, Con78979), 
LMin29462 = minimum_layer([Fla33980,Con78979], Min29462), 
LRes14034 = reshape_layer(Min29462, [8, 1], Res14034), 
LRes71097 = reshape_layer(Res14034, [8, 1, 1], Res71097), 
LCon99126 = conv2D_transpose_layer(Res71097, 2, 1,[[[[0.8914], [0.6248], [0.7016], [0.7985]]], [[[0.2376], [0.9642], [0.9583], [0.5654]]]],[0, 0, 0, 0], 1, 1, true, Con99126), 
exec_layers([LAdd62936,LRes32525,LRes25470,LFla33980,LAdd18122,LFla87880,LCon78979,LMin29462,LRes14034,LRes71097,LCon99126],["Add62936","Res32525","Res25470","Fla33980","Add18122","Fla87880","Con78979","Min29462","Res14034","Res71097","Con99126"],Con99126,"Con99126")

Actual (Unparsed): [[[[0.1721293, 0.1206489, 0.1354790, 0.1541903]], [[0.7353784, 0.6694698, 0.7277353, 0.7268185]], [[0.9049262, 1.2512719, 1.3088394, 1.0833234]], [[0.6484369, 1.0998104, 1.1343436, 0.8660809]], [[0.6416464, 0.8579859, 0.8997714, 0.7552166]], [[0.3997961, 0.7455807, 0.7646410, 0.5638149]], [[0.7016194, 0.7254938, 0.7782163, 0.7317987]], [[0.6854704, 1.0460018, 1.0863627, 0.8639986]]]]

Expected (Unparsed): [[[[0.17212934,0.12064888,0.13547896,0.15419035]],[[0.73537846,0.66946982,0.7277353299999999,0.7268184899999999]],[[0.9049262,1.2512718999999999,1.3088394499999998,1.0833233999999998]],[[0.64843692,1.09981044,1.1343435800000001,0.8660809]],[[0.64164644,0.85798588,0.89977138,0.75521662]],[[0.39979604,0.74558068,0.76464102,0.56381486]],[[0.7016194000000001,0.7254938,0.7782163,0.7317987]],[[0.6854703999999999,1.0460018,1.0863627,0.8639986000000001]]]]

Actual:   [[[[0.1722, 0.1207, 0.1355, 0.1542]], [[0.7354, 0.6695, 0.7278, 0.7269]], [[0.905, 1.2513, 1.3089, 1.0834]], [[0.6485, 1.0999, 1.1344, 0.8661]], [[0.6417, 0.858, 0.8998, 0.7553]], [[0.3998, 0.7456, 0.7647, 0.5639]], [[0.7017, 0.7255, 0.7783, 0.7318]], [[0.6855, 1.0461, 1.0864, 0.864]]]]

Expected: [[[[0.1722, 0.1207, 0.1355, 0.1542]], [[0.7354, 0.6695, 0.7278, 0.7269]], [[0.905, 1.2513, 1.3089, 1.0834]], [[0.6485, 1.0999, 1.1344, 0.8661]], [[0.6417, 0.858, 0.8998, 0.7553]], [[0.3998, 0.7456, 0.7647, 0.5639]], [[0.7017, 0.7255, 0.7783, 0.7318]], [[0.6855, 1.0461, 1.0864, 0.864]]]]