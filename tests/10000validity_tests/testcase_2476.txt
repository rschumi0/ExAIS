import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot31940 = tf.keras.layers.Input(shape=([2, 2]))
in1Dot31940 = tf.keras.layers.Input(shape=([2, 2]))
in0Con24299 = tf.keras.layers.Input(shape=([5, 5, 2]))
in0Sub15198 = tf.keras.layers.Input(shape=([3, 3]))
in1Sub15198 = tf.keras.layers.Input(shape=([3, 3]))

Dot31940 = keras.layers.Dot(axes=(2, 1), name = 'Dot31940', )([in0Dot31940,in1Dot31940])
LST45210 = keras.layers.LSTM(1,recurrent_activation='sigmoid', name = 'LST45210', )(Dot31940)
Res53543 = keras.layers.Reshape((1, 1), name = 'Res53543', )(LST45210)
Res40638 = keras.layers.Reshape((1, 1, 1), name = 'Res40638', )(Res53543)
Zer3574 = keras.layers.ZeroPadding2D(padding=((4, 0), (4, 0)), name = 'Zer3574', )(Res40638)
Con24299 = keras.layers.Concatenate(axis=3, name = 'Con24299', )([Zer3574,in0Con24299])
Sub15198 = keras.layers.Subtract(name = 'Sub15198', )([in0Sub15198,in1Sub15198])
Res49682 = keras.layers.Reshape((3, 3, 1), name = 'Res49682', )(Sub15198)
Res21859 = keras.layers.Reshape((3, 3, 1, 1), name = 'Res21859', )(Res49682)
Zer40651 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer40651', )(Res21859)
Res27793 = keras.layers.Reshape((5, 5, 3), name = 'Res27793', )(Zer40651)
PRe27597 = keras.layers.PReLU(name = 'PRe27597', )(Res27793)
Add44940 = keras.layers.Add(name = 'Add44940', )([Con24299,PRe27597])
model = tf.keras.models.Model(inputs=[in0Dot31940,in1Dot31940,in0Con24299,in0Sub15198,in1Sub15198], outputs=Add44940)
w = model.get_layer('LST45210').get_weights() 
w[0] = np.array([[7, 6, 1, 9], [10, 4, 4, 3]])
w[1] = np.array([[5, 3, 10, 4]])
w[2] = np.array([3, 8, 4, 4])
model.get_layer('LST45210').set_weights(w) 
w = model.get_layer('PRe27597').get_weights() 
w[0] = np.array([[[0.0039, 0.8065, 0.6347], [0.9122, 0.8268, 0.4245], [0.1348, 0.775, 0.9661], [0.8748, 0.8625, 0.1262], [0.5472, 0.9916, 0.9515]], [[0.4351, 0.2391, 0.7753], [0.3773, 0.0858, 0.3222], [0.9831, 0.8847, 0.4933], [0.7583, 0.3317, 0.646], [0.8058, 0.528, 0.211]], [[0.6465, 0.889, 0.0002], [0.5008, 0.9916, 0.8063], [0.2509, 0.683, 0.6894], [0.9403, 0.0573, 0.9426], [0.9733, 0.2279, 0.7612]], [[0.3669, 0.8981, 0.7266], [0.314, 0.6649, 0.7701], [0.87, 0.5986, 0.0559], [0.9507, 0.3258, 0.5543], [0.1049, 0.7124, 0.3264]], [[0.7235, 0.3191, 0.1196], [0.7053, 0.5851, 0.2603], [0.3565, 0.6452, 0.4439], [0.7795, 0.531, 0.319], [0.7044, 0.7337, 0.7466]]])
model.get_layer('PRe27597').set_weights(w) 
in0Dot31940 = tf.constant([[[0.8521, 0.4577], [0.7187, 0.5859]]])
in1Dot31940 = tf.constant([[[0.3647, 0.4783], [0.0843, 0.9134]]])
in0Con24299 = tf.constant([[[[0.7004, 0.1252], [0.7181, 0.0066], [0.4121, 0.2173], [0.646, 0.6797], [0.6574, 0.4254]], [[0.3593, 0.7507], [0.0662, 0.9471], [0.3119, 0.8903], [0.9116, 0.0116], [0.4444, 0.5166]], [[0.2287, 0.4402], [0.1794, 0.8574], [0.6678, 0.4904], [0.3507, 0.0896], [0.5555, 0.4123]], [[0.0485, 0.8155], [0.1923, 0.4077], [0.6254, 0.2181], [0.6364, 0.8398], [0.5273, 0.7281]], [[0.0919, 0.611], [0.1874, 0.9289], [0.5494, 0.5971], [0.954, 0.7309], [0.51, 0.9095]]]])
in0Sub15198 = tf.constant([[[0.4841, 0.7309, 0.7535], [0.7714, 0.4, 0.6623], [0.8192, 0.1486, 0.9978]]])
in1Sub15198 = tf.constant([[[0.5931, 0.1083, 0.881], [0.186, 0.0219, 0.8877], [0.0934, 0.1335, 0.0011]]])
print (np.array2string(model.predict([in0Dot31940,in1Dot31940,in0Con24299,in0Sub15198,in1Sub15198],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add44940.png')

LDot31940 = dot_layer([[[0.8521, 0.4577], [0.7187, 0.5859]]], [[[0.3647, 0.4783], [0.0843, 0.9134]]], 2, 1, Dot31940), 
LLST45210 = lstm_layer(Dot31940,[[7, 6, 1, 9], [10, 4, 4, 3]],[[5, 3, 10, 4]],[3, 8, 4, 4], LST45210), 
LRes53543 = reshape_layer(LST45210, [1, 1], Res53543), 
LRes40638 = reshape_layer(Res53543, [1, 1, 1], Res40638), 
LZer3574 = zero_padding2D_layer(Res40638, 4, 0, 4, 0, Zer3574), 
LCon24299 = concatenate_layer([Zer3574,[[[[0.7004, 0.1252], [0.7181, 0.0066], [0.4121, 0.2173], [0.646, 0.6797], [0.6574, 0.4254]], [[0.3593, 0.7507], [0.0662, 0.9471], [0.3119, 0.8903], [0.9116, 0.0116], [0.4444, 0.5166]], [[0.2287, 0.4402], [0.1794, 0.8574], [0.6678, 0.4904], [0.3507, 0.0896], [0.5555, 0.4123]], [[0.0485, 0.8155], [0.1923, 0.4077], [0.6254, 0.2181], [0.6364, 0.8398], [0.5273, 0.7281]], [[0.0919, 0.611], [0.1874, 0.9289], [0.5494, 0.5971], [0.954, 0.7309], [0.51, 0.9095]]]]], 3, Con24299), 
LSub15198 = subtract_layer([[[0.4841, 0.7309, 0.7535], [0.7714, 0.4, 0.6623], [0.8192, 0.1486, 0.9978]]], [[[0.5931, 0.1083, 0.881], [0.186, 0.0219, 0.8877], [0.0934, 0.1335, 0.0011]]], Sub15198), 
LRes49682 = reshape_layer(Sub15198, [3, 3, 1], Res49682), 
LRes21859 = reshape_layer(Res49682, [3, 3, 1, 1], Res21859), 
LZer40651 = zero_padding3D_layer(Res21859, 1, 1, 1, 1, 1, 1, Zer40651), 
LRes27793 = reshape_layer(Zer40651, [5, 5, 3], Res27793), 
LPRe27597 = prelu_layer(Res27793, [[[0.0039, 0.8065, 0.6347], [0.9122, 0.8268, 0.4245], [0.1348, 0.775, 0.9661], [0.8748, 0.8625, 0.1262], [0.5472, 0.9916, 0.9515]], [[0.4351, 0.2391, 0.7753], [0.3773, 0.0858, 0.3222], [0.9831, 0.8847, 0.4933], [0.7583, 0.3317, 0.646], [0.8058, 0.528, 0.211]], [[0.6465, 0.889, 0.0002], [0.5008, 0.9916, 0.8063], [0.2509, 0.683, 0.6894], [0.9403, 0.0573, 0.9426], [0.9733, 0.2279, 0.7612]], [[0.3669, 0.8981, 0.7266], [0.314, 0.6649, 0.7701], [0.87, 0.5986, 0.0559], [0.9507, 0.3258, 0.5543], [0.1049, 0.7124, 0.3264]], [[0.7235, 0.3191, 0.1196], [0.7053, 0.5851, 0.2603], [0.3565, 0.6452, 0.4439], [0.7795, 0.531, 0.319], [0.7044, 0.7337, 0.7466]]], PRe27597), 
LAdd44940 = add_layer([Con24299,PRe27597], Add44940), 
exec_layers([LDot31940,LLST45210,LRes53543,LRes40638,LZer3574,LCon24299,LSub15198,LRes49682,LRes21859,LZer40651,LRes27793,LPRe27597,LAdd44940],["Dot31940","LST45210","Res53543","Res40638","Zer3574","Con24299","Sub15198","Res49682","Res21859","Zer40651","Res27793","PRe27597","Add44940"],Add44940,"Add44940")

Actual (Unparsed): [[[[0.0000000, 0.7004000, 0.1252000], [0.0000000, 0.7181000, 0.0066000], [0.0000000, 0.4121000, 0.2173000], [0.0000000, 0.6460000, 0.6797000], [0.0000000, 0.6574000, 0.4254000]], [[0.0000000, 0.3593000, 0.7507000], [0.0000000, 0.0568478, 0.9471000], [0.0000000, 0.9345000, 0.8903000], [0.0000000, 0.8693082, 0.0116000], [0.0000000, 0.4444000, 0.5166000]], [[0.0000000, 0.2287000, 0.4402000], [0.0000000, 0.7648000, 0.8574000], [0.0000000, 1.0459000, 0.4904000], [0.0000000, 0.3377846, 0.0896000], [0.0000000, 0.5555000, 0.4123000]], [[0.0000000, 0.0485000, 0.8155000], [0.0000000, 0.9181000, 0.4077000], [0.0000000, 0.6405000, 0.2181000], [0.0000000, 1.6331000, 0.8398000], [0.0000000, 0.5273000, 0.7281000]], [[0.0000000, 0.0919000, 0.6110000], [0.0000000, 0.1874000, 0.9289000], [0.0000000, 0.5494000, 0.5971000], [0.0000000, 0.9540000, 0.7309000], [0.9640238, 0.5100000, 0.9095000]]]]

Expected (Unparsed): [[[[0,0.7004,0.1252],[0,0.7181,0.0066],[0,0.4121,0.2173],[0,0.646,0.6797],[0,0.6574,0.4254]],[[0,0.3593,0.7507],[0,0.0568478,0.9471],[0,0.9345000000000001,0.8903],[0,0.86930825,0.0116],[0,0.4444,0.5166]],[[0,0.2287,0.4402],[0,0.7647999999999999,0.8574],[0,1.0459,0.4904],[0,0.33778458,0.0896],[0,0.5555,0.4123]],[[0,0.0485,0.8155],[0,0.9181,0.4077],[0,0.6405,0.2181],[0,1.6331,0.8398],[0,0.5273,0.7281]],[[0,0.0919,0.611],[0,0.1874,0.9289],[0,0.5494,0.5971],[0,0.954,0.7309],[0.9640238149192859,0.51,0.9095]]]]

Actual:   [[[[0, 0.7004, 0.1252], [0, 0.7181, 0.0066], [0, 0.4121, 0.2173], [0, 0.646, 0.6797], [0, 0.6574, 0.4254]], [[0, 0.3593, 0.7507], [0, 0.0569, 0.9471], [0, 0.9345, 0.8903], [0, 0.8694, 0.0116], [0, 0.4444, 0.5166]], [[0, 0.2287, 0.4402], [0, 0.7648, 0.8574], [0, 1.0459, 0.4904], [0, 0.3378, 0.0896], [0, 0.5555, 0.4123]], [[0, 0.0485, 0.8155], [0, 0.9181, 0.4077], [0, 0.6405, 0.2181], [0, 1.6331, 0.8398], [0, 0.5273, 0.7281]], [[0, 0.0919, 0.611], [0, 0.1874, 0.9289], [0, 0.5494, 0.5971], [0, 0.954, 0.7309], [0.9641, 0.51, 0.9095]]]]

Expected: [[[[0, 0.7004, 0.1252], [0, 0.7181, 0.0066], [0, 0.4121, 0.2173], [0, 0.646, 0.6797], [0, 0.6574, 0.4254]], [[0, 0.3593, 0.7507], [0, 0.0569, 0.9471], [0, 0.9346, 0.8903], [0, 0.8694, 0.0116], [0, 0.4444, 0.5166]], [[0, 0.2287, 0.4402], [0, 0.7648, 0.8574], [0, 1.0459, 0.4904], [0, 0.3378, 0.0896], [0, 0.5555, 0.4123]], [[0, 0.0485, 0.8155], [0, 0.9181, 0.4077], [0, 0.6405, 0.2181], [0, 1.6331, 0.8398], [0, 0.5273, 0.7281]], [[0, 0.0919, 0.611], [0, 0.1874, 0.9289], [0, 0.5494, 0.5971], [0, 0.954, 0.7309], [0.9641, 0.51, 0.9095]]]]