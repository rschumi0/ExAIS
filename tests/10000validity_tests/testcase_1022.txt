import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sep49090 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con76681 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Sub79538 = tf.keras.layers.Input(shape=([2]))
in1Sub79538 = tf.keras.layers.Input(shape=([2]))
in0Con13277 = tf.keras.layers.Input(shape=([30]))

Sep49090 = keras.layers.SeparableConv2D(2, (1, 1),strides=(1, 1), padding='same', name = 'Sep49090', )(in0Sep49090)
Res70809 = keras.layers.Reshape((1, 4), name = 'Res70809', )(Sep49090)
Zer84919 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer84919', )(Res70809)
Con76681 = keras.layers.Conv2D(4, (1, 1),strides=(1, 1), padding='valid', dilation_rate=(1, 1), name = 'Con76681', )(in0Con76681)
Res45742 = keras.layers.Reshape((2, 8), name = 'Res45742', )(Con76681)
Dot94778 = keras.layers.Dot(axes=(1, 1), name = 'Dot94778', )([Zer84919,Res45742])
Fla58339 = keras.layers.Flatten(name = 'Fla58339', )(Dot94778)
Sub79538 = keras.layers.Subtract(name = 'Sub79538', )([in0Sub79538,in1Sub79538])
Con13277 = keras.layers.Concatenate(axis=1, name = 'Con13277', )([Sub79538,in0Con13277])
Max61121 = keras.layers.Maximum(name = 'Max61121', )([Fla58339,Con13277])
model = tf.keras.models.Model(inputs=[in0Sep49090,in0Con76681,in0Sub79538,in1Sub79538,in0Con13277], outputs=Max61121)
w = model.get_layer('Sep49090').get_weights() 
w[0] = np.array([[[[0.3742]]]])
w[1] = np.array([[[[0.7166, 0.1421]]]])
w[2] = np.array([0, 0])
model.get_layer('Sep49090').set_weights(w) 
w = model.get_layer('Con76681').get_weights() 
w[0] = np.array([[[[0.8122, 0.4831, 0.3413, 0.5153]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con76681').set_weights(w) 
in0Sep49090 = tf.constant([[[[0.9126], [0.3678]]]])
in0Con76681 = tf.constant([[[[0.8587], [0.1756]], [[0.2607], [0.6939]]]])
in0Sub79538 = tf.constant([[0.9372, 0.7202]])
in1Sub79538 = tf.constant([[0.2919, 0.5134]])
in0Con13277 = tf.constant([[0.2764, 0.5645, 0.9792, 0.0887, 0.3182, 0.0647, 0.2696, 0.2703, 0.4676, 0.724, 0.4748, 0.4223, 0.6762, 0.8877, 0.5453, 0.2194, 0.6811, 0.7519, 0.5307, 0.9651, 0.7682, 0.9907, 0.5748, 0.9988, 0.3954, 0.3741, 0.4525, 0.8941, 0.3905, 0.94]])
print (np.array2string(model.predict([in0Sep49090,in0Con76681,in0Sub79538,in1Sub79538,in0Con13277],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max61121.png')

LSep49090 = separable_conv2D_layer([[[[0.9126], [0.3678]]]], 1, 1,[[[[[0.3742]]]],[[[[0.7166, 0.1421]]]]],[0, 0], 1, 1, true, Sep49090), 
LRes70809 = reshape_layer(Sep49090, [1, 4], Res70809), 
LZer84919 = zero_padding1D_layer(Res70809, 1, 0, Zer84919), 
LCon76681 = conv2D_layer([[[[0.8587], [0.1756]], [[0.2607], [0.6939]]]], 1, 1,[[[[0.8122, 0.4831, 0.3413, 0.5153]]]],[0, 0, 0, 0], 1, 1, false, 1, 1, Con76681), 
LRes45742 = reshape_layer(Con76681, [2, 8], Res45742), 
LDot94778 = dot_layer(Zer84919,Res45742, 1, 1, Dot94778), 
LFla58339 = flatten_layer(Dot94778, Fla58339), 
LSub79538 = subtract_layer([[0.9372, 0.7202]], [[0.2919, 0.5134]], Sub79538), 
LCon13277 = concatenate_layer([Sub79538,[[0.2764, 0.5645, 0.9792, 0.0887, 0.3182, 0.0647, 0.2696, 0.2703, 0.4676, 0.724, 0.4748, 0.4223, 0.6762, 0.8877, 0.5453, 0.2194, 0.6811, 0.7519, 0.5307, 0.9651, 0.7682, 0.9907, 0.5748, 0.9988, 0.3954, 0.3741, 0.4525, 0.8941, 0.3905, 0.94]]], 1, Con13277), 
LMax61121 = maximum_layer([Fla58339,Con13277], Max61121), 
exec_layers([LSep49090,LRes70809,LZer84919,LCon76681,LRes45742,LDot94778,LFla58339,LSub79538,LCon13277,LMax61121],["Sep49090","Res70809","Zer84919","Con76681","Res45742","Dot94778","Fla58339","Sub79538","Con13277","Max61121"],Max61121,"Max61121")

Actual (Unparsed): [[0.6453000, 0.2068000, 0.2764000, 0.5645000, 0.9792000, 0.0887000, 0.3182000, 0.0875020, 0.2696000, 0.2703000, 0.4676000, 0.7240000, 0.4748000, 0.4223000, 0.6762000, 0.8877000, 0.5453000, 0.2194000, 0.6811000, 0.7519000, 0.5307000, 0.9651000, 0.7682000, 0.9907000, 0.5748000, 0.9988000, 0.3954000, 0.3741000, 0.4525000, 0.8941000, 0.3905000, 0.9400000]]

Expected (Unparsed): [[0.6453,0.20679999999999998,0.2764,0.5645,0.9792,0.0887,0.3182,0.08750202049910233,0.2696,0.2703,0.4676,0.724,0.4748,0.4223,0.6762,0.8877,0.5453,0.2194,0.6811,0.7519,0.5307,0.9651,0.7682,0.9907,0.5748,0.9988,0.3954,0.3741,0.4525,0.8941,0.3905,0.94]]

Actual:   [[0.6453, 0.2068, 0.2764, 0.5645, 0.9792, 0.0887, 0.3182, 0.0876, 0.2696, 0.2703, 0.4676, 0.724, 0.4748, 0.4223, 0.6762, 0.8877, 0.5453, 0.2194, 0.6811, 0.7519, 0.5307, 0.9651, 0.7682, 0.9907, 0.5748, 0.9988, 0.3954, 0.3741, 0.4525, 0.8941, 0.3905, 0.94]]

Expected: [[0.6453, 0.2068, 0.2764, 0.5645, 0.9792, 0.0887, 0.3182, 0.0876, 0.2696, 0.2703, 0.4676, 0.724, 0.4748, 0.4223, 0.6762, 0.8877, 0.5453, 0.2194, 0.6811, 0.7519, 0.5307, 0.9651, 0.7682, 0.9907, 0.5748, 0.9988, 0.3954, 0.3741, 0.4525, 0.8941, 0.3905, 0.94]]