import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub80367 = tf.keras.layers.Input(shape=([2, 3, 3, 2]))
in1Sub80367 = tf.keras.layers.Input(shape=([2, 3, 3, 2]))
in0Ave50041 = tf.keras.layers.Input(shape=([1, 2]))
in1Ave50041 = tf.keras.layers.Input(shape=([1, 2]))
in0Max65541 = tf.keras.layers.Input(shape=([2, 1]))
in1Max65541 = tf.keras.layers.Input(shape=([2, 1]))
in0Con67057 = tf.keras.layers.Input(shape=([2, 17]))

Sub80367 = keras.layers.Subtract(name = 'Sub80367', )([in0Sub80367,in1Sub80367])
Res89892 = keras.layers.Reshape((2, 3, 6), name = 'Res89892', )(Sub80367)
Res12249 = keras.layers.Reshape((2, 18), name = 'Res12249', )(Res89892)
Ave50041 = keras.layers.Average(name = 'Ave50041', )([in0Ave50041,in1Ave50041])
Zer89309 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer89309', )(Ave50041)
Max65541 = keras.layers.Maximum(name = 'Max65541', )([in0Max65541,in1Max65541])
Dot33234 = keras.layers.Dot(axes=(1, 1), name = 'Dot33234', )([Zer89309,Max65541])
Per66875 = keras.layers.Permute((1,2), name = 'Per66875',)(Dot33234)
Con67057 = keras.layers.Concatenate(axis=2, name = 'Con67057', )([Per66875,in0Con67057])
Ave29086 = keras.layers.Average(name = 'Ave29086', )([Res12249,Con67057])
model = tf.keras.models.Model(inputs=[in0Sub80367,in1Sub80367,in0Ave50041,in1Ave50041,in0Max65541,in1Max65541,in0Con67057], outputs=Ave29086)
in0Sub80367 = tf.constant([[[[[0.584, 0.4713], [0.7963, 0.887], [0.9141, 0.112]], [[0.8044, 0.4128], [0.0621, 0.4807], [0.6268, 0.0038]], [[0.9342, 0.0541], [0.3105, 0.1449], [0.5992, 0.3537]]], [[[0.2401, 0.7674], [0.6173, 0.3912], [0.5388, 0.5678]], [[0.1565, 0.3765], [0.5968, 0.6873], [0.5291, 0.8177]], [[0.9922, 0.628], [0.0582, 0.4555], [0.4871, 0.3589]]]]])
in1Sub80367 = tf.constant([[[[[0.9864, 0.5694], [0.229, 0.9289], [0.4779, 0.0697]], [[0.7605, 0.5431], [0.6344, 0.4448], [0.9551, 0.9812]], [[0.8415, 0.0738], [0.5312, 0.4422], [0.6946, 0.6328]]], [[[0.3732, 0.386], [0.2173, 0.3245], [0.4855, 0.7047]], [[0.0737, 0.4437], [0.0439, 0.6098], [0.0055, 0.3531]], [[0.6712, 0.947], [0.7766, 0.291], [0.7608, 0.261]]]]])
in0Ave50041 = tf.constant([[[0.4967, 0.556]]])
in1Ave50041 = tf.constant([[[0.3989, 0.8259]]])
in0Max65541 = tf.constant([[[0.3139], [0.5221]]])
in1Max65541 = tf.constant([[[0.1965], [0.0286]]])
in0Con67057 = tf.constant([[[0.5484, 0.517, 0.8183, 0.4895, 0.5278, 0.9701, 0.0308, 0.5488, 0.1611, 0.4968, 0.156, 0.7449, 0.9482, 0.595, 0.4038, 0.8415, 0.8445], [0.6587, 0.872, 0.142, 0.1638, 0.1169, 0.2326, 0.3606, 0.7256, 0.8466, 0.4001, 0.9073, 0.5859, 0.229, 0.4711, 0.5137, 0.5935, 0.1542]]])
print (np.array2string(model.predict([in0Sub80367,in1Sub80367,in0Ave50041,in1Ave50041,in0Max65541,in1Max65541,in0Con67057],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave29086.png')

LSub80367 = subtract_layer([[[[[0.584, 0.4713], [0.7963, 0.887], [0.9141, 0.112]], [[0.8044, 0.4128], [0.0621, 0.4807], [0.6268, 0.0038]], [[0.9342, 0.0541], [0.3105, 0.1449], [0.5992, 0.3537]]], [[[0.2401, 0.7674], [0.6173, 0.3912], [0.5388, 0.5678]], [[0.1565, 0.3765], [0.5968, 0.6873], [0.5291, 0.8177]], [[0.9922, 0.628], [0.0582, 0.4555], [0.4871, 0.3589]]]]], [[[[[0.9864, 0.5694], [0.229, 0.9289], [0.4779, 0.0697]], [[0.7605, 0.5431], [0.6344, 0.4448], [0.9551, 0.9812]], [[0.8415, 0.0738], [0.5312, 0.4422], [0.6946, 0.6328]]], [[[0.3732, 0.386], [0.2173, 0.3245], [0.4855, 0.7047]], [[0.0737, 0.4437], [0.0439, 0.6098], [0.0055, 0.3531]], [[0.6712, 0.947], [0.7766, 0.291], [0.7608, 0.261]]]]], Sub80367), 
LRes89892 = reshape_layer(Sub80367, [2, 3, 6], Res89892), 
LRes12249 = reshape_layer(Res89892, [2, 18], Res12249), 
LAve50041 = average_layer([[[[0.4967, 0.556]]], [[[0.3989, 0.8259]]]], Ave50041), 
LZer89309 = zero_padding1D_layer(Ave50041, 1, 0, Zer89309), 
LMax65541 = maximum_layer([[[[0.3139], [0.5221]]], [[[0.1965], [0.0286]]]], Max65541), 
LDot33234 = dot_layer(Zer89309,Max65541, 1, 1, Dot33234), 
LPer66875 = permute_layer(Dot33234, 1,2, Per66875), 
LCon67057 = concatenate_layer([Per66875,[[[0.5484, 0.517, 0.8183, 0.4895, 0.5278, 0.9701, 0.0308, 0.5488, 0.1611, 0.4968, 0.156, 0.7449, 0.9482, 0.595, 0.4038, 0.8415, 0.8445], [0.6587, 0.872, 0.142, 0.1638, 0.1169, 0.2326, 0.3606, 0.7256, 0.8466, 0.4001, 0.9073, 0.5859, 0.229, 0.4711, 0.5137, 0.5935, 0.1542]]]], 2, Con67057), 
LAve29086 = average_layer([Res12249,Con67057], Ave29086), 
exec_layers([LSub80367,LRes89892,LRes12249,LAve50041,LZer89309,LMax65541,LDot33234,LPer66875,LCon67057,LAve29086],["Sub80367","Res89892","Res12249","Ave50041","Zer89309","Max65541","Dot33234","Per66875","Con67057","Ave29086"],Ave29086,"Ave29086")

Actual (Unparsed): [[[-0.0843018, 0.2251500, 0.5421500, 0.3882000, 0.4628500, 0.2850500, 0.5070000, -0.0497500, -0.0117500, 0.0985000, 0.0842500, -0.4107000, 0.4188000, 0.4642500, 0.1871500, 0.0532500, 0.3730500, 0.2827000], [0.1138225, 0.5200500, 0.6360000, 0.1043500, 0.1085500, -0.0100000, 0.1577000, 0.1467000, 0.6392500, 0.4620500, 0.4618500, 0.6859500, 0.4534500, -0.0450000, -0.1236500, 0.3391000, 0.1599000, 0.1260500]]]

Expected (Unparsed): [[[-0.08430181000000005,0.22515,0.54215,0.38820000000000005,0.46285,0.28505,0.507,-0.049750000000000016,-0.011749999999999983,0.09850000000000002,0.08425000000000005,-0.41069999999999995,0.4188,0.46425,0.18714999999999998,0.05324999999999999,0.37305,0.2827],[0.1138224975,0.5200499999999999,0.636,0.10434999999999998,0.10854999999999998,-0.010000000000000009,0.1577,0.1467,0.63925,0.46205,0.46185000000000004,0.68595,0.45344999999999996,-0.04499999999999997,-0.12364999999999995,0.33910000000000007,0.1599,0.12605]]]

Actual:   [[[-0.0843, 0.2252, 0.5422, 0.3882, 0.4629, 0.2851, 0.507, -0.0497, -0.0117, 0.0985, 0.0843, -0.4107, 0.4188, 0.4643, 0.1872, 0.0533, 0.3731, 0.2827], [0.1139, 0.5201, 0.636, 0.1044, 0.1086, -0.01, 0.1577, 0.1467, 0.6393, 0.4621, 0.4619, 0.686, 0.4535, -0.045, -0.1236, 0.3391, 0.1599, 0.1261]]]

Expected: [[[-0.0843, 0.2252, 0.5422, 0.3883, 0.4629, 0.2851, 0.507, -0.0497, -0.0117, 0.0986, 0.0843, -0.4106, 0.4188, 0.4643, 0.1872, 0.0533, 0.3731, 0.2827], [0.1139, 0.5201, 0.636, 0.1044, 0.1086, -0.01, 0.1577, 0.1467, 0.6393, 0.4621, 0.4619, 0.686, 0.4535, -0.0449, -0.1236, 0.3392, 0.1599, 0.1261]]]