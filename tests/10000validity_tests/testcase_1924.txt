import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Zer18749 = tf.keras.layers.Input(shape=([4, 4, 2]))
in0Dot35217 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot35217 = tf.keras.layers.Input(shape=([3, 3]))
in0Con75533 = tf.keras.layers.Input(shape=([6, 9]))

Zer18749 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer18749', )(in0Zer18749)
Res6819 = keras.layers.Reshape((6, 12), name = 'Res6819', )(Zer18749)
Dot35217 = keras.layers.Dot(axes=(1, 1), name = 'Dot35217', )([in0Dot35217,in1Dot35217])
Zer1950 = keras.layers.ZeroPadding1D(padding=((3, 0)), name = 'Zer1950', )(Dot35217)
Con75533 = keras.layers.Concatenate(axis=2, name = 'Con75533', )([Zer1950,in0Con75533])
Max32938 = keras.layers.Maximum(name = 'Max32938', )([Res6819,Con75533])
Per49847 = keras.layers.Permute((2,1), name = 'Per49847',)(Max32938)
model = tf.keras.models.Model(inputs=[in0Zer18749,in0Dot35217,in1Dot35217,in0Con75533], outputs=Per49847)
in0Zer18749 = tf.constant([[[[1.2656, 1.5933], [1.1807, 1.6902], [1.5083, 1.6637], [1.2947, 1.8958]], [[1.4733, 1.2515], [1.2601, 1.6529], [1.5726, 1.6048], [1.4023, 1.8387]], [[1.6839, 1.4015], [1.1729, 1.4054], [1.2153, 1.2095], [1.6921, 1.6506]], [[1.3228, 1.688], [1.4323, 1.2485], [1.0997, 1.4179], [1.7598, 1.3645]]]])
in0Dot35217 = tf.constant([[[0.0806, 0.4039, 0.648], [0.5295, 0.326, 0.1011], [0.3863, 0.4642, 0.6883]]])
in1Dot35217 = tf.constant([[[0.2807, 0.5141, 0.713], [0.5997, 0.1785, 0.5296], [0.7712, 0.8659, 0.1399]]])
in0Con75533 = tf.constant([[[0.7898, 0.4435, 0.2695, 0.0783, 0.1871, 0.9974, 0.8773, 0.587, 0.9695], [0.4977, 0.461, 0.8633, 0.587, 0.1441, 0.6375, 0.2326, 0.4671, 0.2512], [0.5872, 0.8065, 0.4833, 0.0861, 0.9186, 0.6814, 0.1968, 0.0558, 0.5627], [0.1316, 0.5142, 0.1209, 0.8353, 0.8641, 0.6819, 0.0366, 0.2864, 0.4467], [0.4731, 0.6531, 0.5918, 0.4851, 0.0137, 0.0411, 0.539, 0.9856, 0.9411], [0.652, 0.1065, 0.6102, 0.4913, 0.0717, 0.7448, 0.2112, 0.673, 0.1794]]])
print (np.array2string(model.predict([in0Zer18749,in0Dot35217,in1Dot35217,in0Con75533],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Per49847.png')

LZer18749 = zero_padding2D_layer([[[[1.2656, 1.5933], [1.1807, 1.6902], [1.5083, 1.6637], [1.2947, 1.8958]], [[1.4733, 1.2515], [1.2601, 1.6529], [1.5726, 1.6048], [1.4023, 1.8387]], [[1.6839, 1.4015], [1.1729, 1.4054], [1.2153, 1.2095], [1.6921, 1.6506]], [[1.3228, 1.688], [1.4323, 1.2485], [1.0997, 1.4179], [1.7598, 1.3645]]]], 1, 1, 1, 1, Zer18749), 
LRes6819 = reshape_layer(Zer18749, [6, 12], Res6819), 
LDot35217 = dot_layer([[[0.0806, 0.4039, 0.648], [0.5295, 0.326, 0.1011], [0.3863, 0.4642, 0.6883]]], [[[0.2807, 0.5141, 0.713], [0.5997, 0.1785, 0.5296], [0.7712, 0.8659, 0.1399]]], 1, 1, Dot35217), 
LZer1950 = zero_padding1D_layer(Dot35217, 3, 0, Zer1950), 
LCon75533 = concatenate_layer([Zer1950,[[[0.7898, 0.4435, 0.2695, 0.0783, 0.1871, 0.9974, 0.8773, 0.587, 0.9695], [0.4977, 0.461, 0.8633, 0.587, 0.1441, 0.6375, 0.2326, 0.4671, 0.2512], [0.5872, 0.8065, 0.4833, 0.0861, 0.9186, 0.6814, 0.1968, 0.0558, 0.5627], [0.1316, 0.5142, 0.1209, 0.8353, 0.8641, 0.6819, 0.0366, 0.2864, 0.4467], [0.4731, 0.6531, 0.5918, 0.4851, 0.0137, 0.0411, 0.539, 0.9856, 0.9411], [0.652, 0.1065, 0.6102, 0.4913, 0.0717, 0.7448, 0.2112, 0.673, 0.1794]]]], 2, Con75533), 
LMax32938 = maximum_layer([Res6819,Con75533], Max32938), 
LPer49847 = permute_layer(Max32938, 2,1, Per49847), 
exec_layers([LZer18749,LRes6819,LDot35217,LZer1950,LCon75533,LMax32938,LPer49847],["Zer18749","Res6819","Dot35217","Zer1950","Con75533","Max32938","Per49847"],Per49847,"Per49847")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.0000000, 0.6380801, 0.6668680, 0.7733402], [0.0000000, 0.0000000, 0.0000000, 0.4704494, 0.6677868, 0.9471821], [0.0000000, 1.2656000, 1.4733000, 1.6839000, 1.3228000, 0.6118597], [0.7898000, 1.5933000, 1.2515000, 1.4015000, 1.6880000, 0.6520000], [0.4435000, 1.1806999, 1.2601000, 1.1729000, 1.4323000, 0.1065000], [0.2695000, 1.6902000, 1.6529000, 1.4054000, 1.2485000, 0.6102000], [0.0783000, 1.5082999, 1.5726000, 1.2153000, 1.0997000, 0.4913000], [0.1871000, 1.6637000, 1.6048000, 1.2095000, 1.4179000, 0.0717000], [0.9974000, 1.2947000, 1.4023000, 1.6921000, 1.7598000, 0.7448000], [0.8773000, 1.8958000, 1.8387001, 1.6506000, 1.3645000, 0.2112000], [0.5870000, 0.4671000, 0.0558000, 0.2864000, 0.9856000, 0.6730000], [0.9695000, 0.2512000, 0.5627000, 0.4467000, 0.9411000, 0.1794000]]]

Expected (Unparsed): [[[0,0,0,0.63808013,0.66686797,0.7733402300000001],[0,0,0,0.4704493799999999,0.66778677,0.94718212],[0,1.2656,1.4733,1.6839,1.3228,0.61185973],[0.7898,1.5933,1.2515,1.4015,1.688,0.652],[0.4435,1.1807,1.2601,1.1729,1.4323,0.1065],[0.2695,1.6902,1.6529,1.4054,1.2485,0.6102],[0.0783,1.5083,1.5726,1.2153,1.0997,0.4913],[0.1871,1.6637,1.6048,1.2095,1.4179,0.0717],[0.9974,1.2947,1.4023,1.6921,1.7598,0.7448],[0.8773,1.8958,1.8387,1.6506,1.3645,0.2112],[0.587,0.4671,0.0558,0.2864,0.9856,0.673],[0.9695,0.2512,0.5627,0.4467,0.9411,0.1794]]]

Actual:   [[[0, 0, 0, 0.6381, 0.6669, 0.7734], [0, 0, 0, 0.4705, 0.6678, 0.9472], [0, 1.2656, 1.4733, 1.6839, 1.3228, 0.6119], [0.7898, 1.5933, 1.2515, 1.4015, 1.688, 0.652], [0.4435, 1.1807, 1.2601, 1.1729, 1.4323, 0.1065], [0.2695, 1.6902, 1.6529, 1.4054, 1.2485, 0.6102], [0.0783, 1.5083, 1.5726, 1.2153, 1.0997, 0.4913], [0.1871, 1.6637, 1.6048, 1.2095, 1.4179, 0.0717], [0.9974, 1.2947, 1.4023, 1.6921, 1.7598, 0.7448], [0.8773, 1.8958, 1.8388, 1.6506, 1.3645, 0.2112], [0.587, 0.4671, 0.0558, 0.2864, 0.9856, 0.673], [0.9695, 0.2512, 0.5627, 0.4467, 0.9411, 0.1794]]]

Expected: [[[0, 0, 0, 0.6381, 0.6669, 0.7734], [0, 0, 0, 0.4705, 0.6678, 0.9472], [0, 1.2656, 1.4733, 1.6839, 1.3228, 0.6119], [0.7898, 1.5933, 1.2515, 1.4015, 1.688, 0.652], [0.4435, 1.1807, 1.2601, 1.1729, 1.4323, 0.1065], [0.2695, 1.6902, 1.6529, 1.4054, 1.2485, 0.6102], [0.0783, 1.5083, 1.5726, 1.2153, 1.0997, 0.4913], [0.1871, 1.6637, 1.6048, 1.2095, 1.4179, 0.0717], [0.9974, 1.2947, 1.4023, 1.6921, 1.7598, 0.7448], [0.8773, 1.8958, 1.8387, 1.6506, 1.3645, 0.2112], [0.587, 0.4671, 0.0558, 0.2864, 0.9856, 0.673], [0.9695, 0.2512, 0.5627, 0.4467, 0.9411, 0.1794]]]