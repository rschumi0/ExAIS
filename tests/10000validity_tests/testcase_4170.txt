import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub20054 = tf.keras.layers.Input(shape=([3, 2, 2, 2]))
in1Sub20054 = tf.keras.layers.Input(shape=([3, 2, 2, 2]))
in0Glo99026 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Con81733 = tf.keras.layers.Input(shape=([22]))

Sub20054 = keras.layers.Subtract(name = 'Sub20054', )([in0Sub20054,in1Sub20054])
Con97660 = keras.layers.Conv3DTranspose(2, (1, 1, 1),strides=(1, 1, 1), padding='valid', name = 'Con97660', )(Sub20054)
Res89980 = keras.layers.Reshape((3, 2, 4), name = 'Res89980', )(Con97660)
Res14271 = keras.layers.Reshape((3, 8), name = 'Res14271', )(Res89980)
Fla73000 = keras.layers.Flatten(name = 'Fla73000', )(Res14271)
Glo99026 = keras.layers.GlobalMaxPool3D(name = 'Glo99026', )(in0Glo99026)
Con81733 = keras.layers.Concatenate(axis=1, name = 'Con81733', )([Glo99026,in0Con81733])
Add96308 = keras.layers.Add(name = 'Add96308', )([Fla73000,Con81733])
model = tf.keras.models.Model(inputs=[in0Sub20054,in1Sub20054,in0Glo99026,in0Con81733], outputs=Add96308)
w = model.get_layer('Con97660').get_weights() 
w[0] = np.array([[[[[0.8628, 0.044], [0.267, 0.6968]]]]])
w[1] = np.array([0, 0])
model.get_layer('Con97660').set_weights(w) 
in0Sub20054 = tf.constant([[[[[0.6387, 0.3786], [0.4618, 0.3859]], [[0.5152, 0.9246], [0.4185, 0.1149]]], [[[0.7046, 0.3843], [0.7106, 0.244]], [[0.7821, 0.7498], [0.4506, 0.8549]]], [[[0.6727, 0.6981], [0.3409, 0.982]], [[0.0539, 0.4694], [0.6693, 0.5352]]]]])
in1Sub20054 = tf.constant([[[[[0.9491, 0.939], [0.7815, 0.0714]], [[0.0444, 0.9479], [0.3341, 0.9955]]], [[[0.0676, 0.058], [0.0854, 0.1311]], [[0.9056, 0.7668], [0.4519, 0.2421]]], [[[0.0046, 0.8796], [0.5724, 0.0107]], [[0.9948, 0.1722], [0.1579, 0.18]]]]])
in0Glo99026 = tf.constant([[[[[1.4157, 1.6982], [1.9796, 1.0553]], [[1.8769, 1.0956], [1.4484, 1.3255]]], [[[1.983, 1.0293], [1.3726, 1.2123]], [[1.8781, 1.4709], [1.647, 1.285]]]]])
in0Con81733 = tf.constant([[0.7181, 0.8773, 0.5107, 0.7669, 0.9006, 0.1281, 0.483, 0.5331, 0.2928, 0.4439, 0.0864, 0.2392, 0.3117, 0.366, 0.3774, 0.6441, 0.1605, 0.8238, 0.255, 0.7506, 0.5676, 0.7]])
print (np.array2string(model.predict([in0Sub20054,in1Sub20054,in0Glo99026,in0Con81733],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add96308.png')

LSub20054 = subtract_layer([[[[[0.6387, 0.3786], [0.4618, 0.3859]], [[0.5152, 0.9246], [0.4185, 0.1149]]], [[[0.7046, 0.3843], [0.7106, 0.244]], [[0.7821, 0.7498], [0.4506, 0.8549]]], [[[0.6727, 0.6981], [0.3409, 0.982]], [[0.0539, 0.4694], [0.6693, 0.5352]]]]], [[[[[0.9491, 0.939], [0.7815, 0.0714]], [[0.0444, 0.9479], [0.3341, 0.9955]]], [[[0.0676, 0.058], [0.0854, 0.1311]], [[0.9056, 0.7668], [0.4519, 0.2421]]], [[[0.0046, 0.8796], [0.5724, 0.0107]], [[0.9948, 0.1722], [0.1579, 0.18]]]]], Sub20054), 
LCon97660 = conv3D_transpose_layer(Sub20054, 1, 1, 1,[[[[[0.8628, 0.044], [0.267, 0.6968]]]]],[0, 0], 1, 1, 1, false, Con97660), 
LRes89980 = reshape_layer(Con97660, [3, 2, 4], Res89980), 
LRes14271 = reshape_layer(Res89980, [3, 8], Res14271), 
LFla73000 = flatten_layer(Res14271, Fla73000), 
LGlo99026 = global_max_pool3D_layer([[[[[1.4157, 1.6982], [1.9796, 1.0553]], [[1.8769, 1.0956], [1.4484, 1.3255]]], [[[1.983, 1.0293], [1.3726, 1.2123]], [[1.8781, 1.4709], [1.647, 1.285]]]]], Glo99026), 
LCon81733 = concatenate_layer([Glo99026,[[0.7181, 0.8773, 0.5107, 0.7669, 0.9006, 0.1281, 0.483, 0.5331, 0.2928, 0.4439, 0.0864, 0.2392, 0.3117, 0.366, 0.3774, 0.6441, 0.1605, 0.8238, 0.255, 0.7506, 0.5676, 0.7]]], 1, Con81733), 
LAdd96308 = add_layer([Fla73000,Con81733], Add96308), 
exec_layers([LSub20054,LCon97660,LRes89980,LRes14271,LFla73000,LGlo99026,LCon81733,LAdd96308],["Sub20054","Con97660","Res89980","Res14271","Fla73000","Glo99026","Con81733","Add96308"],Add96308,"Add96308")

Actual (Unparsed): [[1.6905293, 1.2248365, 0.4561009, 1.0110837, 0.9158810, 0.8763682, 0.9346739, -0.4629673, 1.0469608, 0.9305448, 0.8371902, 0.6894971, -0.0209038, 0.1943799, 0.3375415, 0.7926519, 0.9458507, 0.6960135, 0.0034990, 1.4387914, -0.5437317, 0.7064686, 1.0244647, 1.0840471]]

Expected (Unparsed): [[1.69052928,1.22483648,0.45610084,1.0110837,0.91588104,0.8763681600000001,0.9346739199999999,-0.4629672800000001,1.0469608,0.93054484,0.83719016,0.68949712,-0.020903799999999945,0.1943799,0.33754155999999996,0.79265194,0.9458506799999999,0.6960135,0.0034989999999999744,1.4387913399999999,-0.54373172,0.7064686600000001,1.02446472,1.08404716]]

Actual:   [[1.6906, 1.2249, 0.4562, 1.0111, 0.9159, 0.8764, 0.9347, -0.4629, 1.047, 0.9306, 0.8372, 0.6895, -0.0209, 0.1944, 0.3376, 0.7927, 0.9459, 0.6961, 0.0035, 1.4388, -0.5437, 0.7065, 1.0245, 1.0841]]

Expected: [[1.6906, 1.2249, 0.4562, 1.0111, 0.9159, 0.8764, 0.9347, -0.4629, 1.047, 0.9306, 0.8372, 0.6895, -0.0209, 0.1944, 0.3376, 0.7927, 0.9459, 0.6961, 0.0035, 1.4388, -0.5437, 0.7065, 1.0245, 1.0841]]