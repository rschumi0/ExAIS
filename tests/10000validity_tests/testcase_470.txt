import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot27066 = tf.keras.layers.Input(shape=([3]))
in1Dot27066 = tf.keras.layers.Input(shape=([3]))
in0Con51271 = tf.keras.layers.Input(shape=([5, 5, 3]))
in0Zer43337 = tf.keras.layers.Input(shape=([3, 3, 4]))

Dot27066 = keras.layers.Dot(axes=(1, 1), name = 'Dot27066', )([in0Dot27066,in1Dot27066])
Res47317 = keras.layers.Reshape((1, 1), name = 'Res47317', )(Dot27066)
Res8683 = keras.layers.Reshape((1, 1, 1), name = 'Res8683', )(Res47317)
Max73730 = keras.layers.MaxPool2D(pool_size=(1, 1), strides=(1, 1), padding='same', name = 'Max73730', )(Res8683)
ELU7713 = keras.layers.ELU(alpha=6.391496126593111, name = 'ELU7713', )(Max73730)
Zer49325 = keras.layers.ZeroPadding2D(padding=((4, 0), (4, 0)), name = 'Zer49325', )(ELU7713)
Con51271 = keras.layers.Concatenate(axis=3, name = 'Con51271', )([Zer49325,in0Con51271])
Zer43337 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer43337', )(in0Zer43337)
Add35580 = keras.layers.Add(name = 'Add35580', )([Con51271,Zer43337])
Fla95368 = keras.layers.Flatten(name = 'Fla95368', )(Add35580)
model = tf.keras.models.Model(inputs=[in0Dot27066,in1Dot27066,in0Con51271,in0Zer43337], outputs=Fla95368)
in0Dot27066 = tf.constant([[0.7939, 0.3615, 0.2371]])
in1Dot27066 = tf.constant([[0.2334, 0.9921, 0.7415]])
in0Con51271 = tf.constant([[[[0.9221, 0.9297, 0.4187], [0.276, 0.1841, 0.4276], [0.788, 0.1668, 0.1575], [0.5553, 0.6913, 0.8349], [0.7062, 0.9736, 0.1919]], [[0.4939, 0.6799, 0.2514], [0.9835, 0.6496, 0.5468], [0.3289, 0.1879, 0.3603], [0.5662, 0.1162, 0.8187], [0.2805, 0.4519, 0.3889]], [[0.8582, 0.1303, 0.2252], [0.6703, 0.2762, 0.0276], [0.2258, 0.1074, 0.7356], [0.2007, 0.0596, 0.4384], [0.1758, 0.9592, 0.5938]], [[0.0297, 0.9424, 0.4424], [0.9834, 0.6137, 0.6402], [0.587, 0.1081, 0.8003], [0.4278, 0.9614, 0.7329], [0.6526, 0.0404, 0.5973]], [[0.1638, 0.6194, 0.4344], [0.7164, 0.1667, 0.8987], [0.5768, 0.3003, 0.4409], [0.8706, 0.5705, 0.7759], [0.9921, 0.5819, 0.001]]]])
in0Zer43337 = tf.constant([[[[1.3077, 1.5411, 1.7393, 1.5751], [1.6131, 1.8498, 1.3674, 1.8536], [1.6272, 1.7359, 1.0072, 1.665]], [[1.5927, 1.3332, 1.2668, 1.5017], [1.6535, 1.7374, 1.544, 1.1299], [1.5384, 1.1398, 1.0312, 1.7808]], [[1.0407, 1.8265, 1.1284, 1.53], [1.3915, 1.6076, 1.2875, 1.7296], [1.6396, 1.0746, 1.2767, 1.2738]]]])
print (np.array2string(model.predict([in0Dot27066,in1Dot27066,in0Con51271,in0Zer43337],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Fla95368.png')

LDot27066 = dot_layer([[0.7939, 0.3615, 0.2371]], [[0.2334, 0.9921, 0.7415]], 1, 1, Dot27066), 
LRes47317 = reshape_layer(Dot27066, [1, 1], Res47317), 
LRes8683 = reshape_layer(Res47317, [1, 1, 1], Res8683), 
LMax73730 = max_pool2D_layer(Res8683, 1, 1, 1, 1, true, Max73730), 
LELU7713 = elu_layer(Max73730, 6.391496126593111, ELU7713), 
LZer49325 = zero_padding2D_layer(ELU7713, 4, 0, 4, 0, Zer49325), 
LCon51271 = concatenate_layer([Zer49325,[[[[0.9221, 0.9297, 0.4187], [0.276, 0.1841, 0.4276], [0.788, 0.1668, 0.1575], [0.5553, 0.6913, 0.8349], [0.7062, 0.9736, 0.1919]], [[0.4939, 0.6799, 0.2514], [0.9835, 0.6496, 0.5468], [0.3289, 0.1879, 0.3603], [0.5662, 0.1162, 0.8187], [0.2805, 0.4519, 0.3889]], [[0.8582, 0.1303, 0.2252], [0.6703, 0.2762, 0.0276], [0.2258, 0.1074, 0.7356], [0.2007, 0.0596, 0.4384], [0.1758, 0.9592, 0.5938]], [[0.0297, 0.9424, 0.4424], [0.9834, 0.6137, 0.6402], [0.587, 0.1081, 0.8003], [0.4278, 0.9614, 0.7329], [0.6526, 0.0404, 0.5973]], [[0.1638, 0.6194, 0.4344], [0.7164, 0.1667, 0.8987], [0.5768, 0.3003, 0.4409], [0.8706, 0.5705, 0.7759], [0.9921, 0.5819, 0.001]]]]], 3, Con51271), 
LZer43337 = zero_padding2D_layer([[[[1.3077, 1.5411, 1.7393, 1.5751], [1.6131, 1.8498, 1.3674, 1.8536], [1.6272, 1.7359, 1.0072, 1.665]], [[1.5927, 1.3332, 1.2668, 1.5017], [1.6535, 1.7374, 1.544, 1.1299], [1.5384, 1.1398, 1.0312, 1.7808]], [[1.0407, 1.8265, 1.1284, 1.53], [1.3915, 1.6076, 1.2875, 1.7296], [1.6396, 1.0746, 1.2767, 1.2738]]]], 1, 1, 1, 1, Zer43337), 
LAdd35580 = add_layer([Con51271,Zer43337], Add35580), 
LFla95368 = flatten_layer(Add35580, Fla95368), 
exec_layers([LDot27066,LRes47317,LRes8683,LMax73730,LELU7713,LZer49325,LCon51271,LZer43337,LAdd35580,LFla95368],["Dot27066","Res47317","Res8683","Max73730","ELU7713","Zer49325","Con51271","Zer43337","Add35580","Fla95368"],Fla95368,"Fla95368")

Actual (Unparsed): [[0.0000000, 0.9221000, 0.9297000, 0.4187000, 0.0000000, 0.2760000, 0.1841000, 0.4276000, 0.0000000, 0.7880000, 0.1668000, 0.1575000, 0.0000000, 0.5553000, 0.6913000, 0.8349000, 0.0000000, 0.7062000, 0.9736000, 0.1919000, 0.0000000, 0.4939000, 0.6799000, 0.2514000, 1.3077000, 2.5246000, 2.3889000, 2.1219000, 1.6131001, 2.1787000, 1.5553001, 2.2139000, 1.6272000, 2.3021001, 1.1234000, 2.4837000, 0.0000000, 0.2805000, 0.4519000, 0.3889000, 0.0000000, 0.8582000, 0.1303000, 0.2252000, 1.5927000, 2.0035000, 1.5430000, 1.5293000, 1.6535000, 1.9632000, 1.6514000, 1.8655000, 1.5384001, 1.3405000, 1.0908001, 2.2192000, 0.0000000, 0.1758000, 0.9592000, 0.5938000, 0.0000000, 0.0297000, 0.9424000, 0.4424000, 1.0407000, 2.8099000, 1.7420999, 2.1702000, 1.3915000, 2.1946000, 1.3956000, 2.5299000, 1.6396000, 1.5024000, 2.2381000, 2.0067000, 0.0000000, 0.6526000, 0.0404000, 0.5973000, 0.0000000, 0.1638000, 0.6194000, 0.4344000, 0.0000000, 0.7164000, 0.1667000, 0.8987000, 0.0000000, 0.5768000, 0.3003000, 0.4409000, 0.0000000, 0.8706000, 0.5705000, 0.7759000, 0.7197501, 0.9921000, 0.5819000, 0.0010000]]

Expected (Unparsed): [[0,0.9221,0.9297,0.4187,0,0.276,0.1841,0.4276,0,0.788,0.1668,0.1575,0,0.5553,0.6913,0.8349,0,0.7062,0.9736,0.1919,0,0.4939,0.6799,0.2514,1.3077,2.5246,2.3889,2.1219,1.6131,2.1787,1.5553,2.2138999999999998,1.6272,2.3021000000000003,1.1234000000000002,2.4837,0,0.2805,0.4519,0.3889,0,0.8582,0.1303,0.2252,1.5927,2.0035,1.543,1.5293,1.6535,1.9632,1.6514,1.8655,1.5384,1.3405,1.0908,2.2192,0,0.1758,0.9592,0.5938,0,0.0297,0.9424,0.4424,1.0407,2.8099,1.7421000000000002,2.1702,1.3915,2.1946,1.3956000000000002,2.5299,1.6396,1.5024,2.2381,2.0067,0,0.6526,0.0404,0.5973,0,0.1638,0.6194,0.4344,0,0.7164,0.1667,0.8987,0,0.5768,0.3003,0.4409,0,0.8706,0.5705,0.7759,0.7197500600000001,0.9921,0.5819,0.001]]

Actual:   [[0, 0.9221, 0.9297, 0.4187, 0, 0.276, 0.1841, 0.4276, 0, 0.788, 0.1668, 0.1575, 0, 0.5553, 0.6913, 0.8349, 0, 0.7062, 0.9736, 0.1919, 0, 0.4939, 0.6799, 0.2514, 1.3077, 2.5246, 2.3889, 2.1219, 1.6132, 2.1787, 1.5554, 2.2139, 1.6272, 2.3022, 1.1234, 2.4837, 0, 0.2805, 0.4519, 0.3889, 0, 0.8582, 0.1303, 0.2252, 1.5927, 2.0035, 1.543, 1.5293, 1.6535, 1.9632, 1.6514, 1.8655, 1.5385, 1.3405, 1.0909, 2.2192, 0, 0.1758, 0.9592, 0.5938, 0, 0.0297, 0.9424, 0.4424, 1.0407, 2.8099, 1.7421, 2.1702, 1.3915, 2.1946, 1.3956, 2.5299, 1.6396, 1.5024, 2.2381, 2.0067, 0, 0.6526, 0.0404, 0.5973, 0, 0.1638, 0.6194, 0.4344, 0, 0.7164, 0.1667, 0.8987, 0, 0.5768, 0.3003, 0.4409, 0, 0.8706, 0.5705, 0.7759, 0.7198, 0.9921, 0.5819, 0.001]]

Expected: [[0, 0.9221, 0.9297, 0.4187, 0, 0.276, 0.1841, 0.4276, 0, 0.788, 0.1668, 0.1575, 0, 0.5553, 0.6913, 0.8349, 0, 0.7062, 0.9736, 0.1919, 0, 0.4939, 0.6799, 0.2514, 1.3077, 2.5246, 2.3889, 2.1219, 1.6131, 2.1787, 1.5553, 2.2139, 1.6272, 2.3022, 1.1235, 2.4837, 0, 0.2805, 0.4519, 0.3889, 0, 0.8582, 0.1303, 0.2252, 1.5927, 2.0035, 1.543, 1.5293, 1.6535, 1.9632, 1.6514, 1.8655, 1.5384, 1.3405, 1.0908, 2.2192, 0, 0.1758, 0.9592, 0.5938, 0, 0.0297, 0.9424, 0.4424, 1.0407, 2.8099, 1.7422, 2.1702, 1.3915, 2.1946, 1.3957, 2.5299, 1.6396, 1.5024, 2.2381, 2.0067, 0, 0.6526, 0.0404, 0.5973, 0, 0.1638, 0.6194, 0.4344, 0, 0.7164, 0.1667, 0.8987, 0, 0.5768, 0.3003, 0.4409, 0, 0.8706, 0.5705, 0.7759, 0.7198, 0.9921, 0.5819, 0.001]]