import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul284 = tf.keras.layers.Input(shape=([2, 1]))
in1Mul284 = tf.keras.layers.Input(shape=([2, 1]))
in0Con52882 = tf.keras.layers.Input(shape=([6]))
in0Fla8513 = tf.keras.layers.Input(shape=([2, 1, 4]))
in0Con61096 = tf.keras.layers.Input(shape=([3, 3]))
in0Mul15173 = tf.keras.layers.Input(shape=([1, 1, 2]))
in1Mul15173 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con83205 = tf.keras.layers.Input(shape=([3, 2]))
in0Dot22495 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot22495 = tf.keras.layers.Input(shape=([3, 3]))

Mul284 = keras.layers.Multiply(name = 'Mul284', )([in0Mul284,in1Mul284])
Fla45462 = keras.layers.Flatten(name = 'Fla45462', )(Mul284)
Con52882 = keras.layers.Concatenate(axis=1, name = 'Con52882', )([Fla45462,in0Con52882])
Fla8513 = keras.layers.Flatten(name = 'Fla8513', )(in0Fla8513)
Dot18586 = keras.layers.Dot(axes=(1, 1), name = 'Dot18586', )([Con52882,Fla8513])
Res40529 = keras.layers.Reshape((1, 1), name = 'Res40529', )(Dot18586)
GRU200 = keras.layers.GRU(3,reset_after=True, recurrent_activation='sigmoid', name = 'GRU200', )(Res40529)
Res35143 = keras.layers.Reshape((3, 1), name = 'Res35143', )(GRU200)
Con61096 = keras.layers.Concatenate(axis=2, name = 'Con61096', )([Res35143,in0Con61096])
Mul15173 = keras.layers.Multiply(name = 'Mul15173', )([in0Mul15173,in1Mul15173])
Res43929 = keras.layers.Reshape((1, 2), name = 'Res43929', )(Mul15173)
Zer87688 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer87688', )(Res43929)
Con83205 = keras.layers.Concatenate(axis=2, name = 'Con83205', )([Zer87688,in0Con83205])
Dot22495 = keras.layers.Dot(axes=(2, 2), name = 'Dot22495', )([in0Dot22495,in1Dot22495])
Den92502 = keras.layers.Dense(4,name = 'Den92502', )(Dot22495)
Add14777 = keras.layers.Add(name = 'Add14777', )([Con83205,Den92502])
Min2899 = keras.layers.Minimum(name = 'Min2899', )([Con61096,Add14777])
model = tf.keras.models.Model(inputs=[in0Mul284,in1Mul284,in0Con52882,in0Fla8513,in0Con61096,in0Mul15173,in1Mul15173,in0Con83205,in0Dot22495,in1Dot22495], outputs=Min2899)
w = model.get_layer('GRU200').get_weights() 
w[0] = np.array([[5, 6, 10, 6, 1, 5, 10, 3, 10]])
w[1] = np.array([[7, 9, 1, 6, 1, 5, 2, 5, 8], [6, 4, 8, 4, 3, 2, 6, 3, 7], [7, 8, 8, 9, 3, 10, 3, 5, 5]])
w[2] = np.array([[6, 8, 1, 6, 5, 7, 10, 1, 5], [2, 5, 9, 5, 1, 2, 3, 9, 1]])
model.get_layer('GRU200').set_weights(w) 
w = model.get_layer('Den92502').get_weights() 
w[0] = np.array([[0.72, 0.8057, 0.3263, 0.6726], [0.2529, 0.3163, 0.2014, 0.6535], [0.2799, 0.3959, 0.1667, 0.5521]])
w[1] = np.array([0.934, 0.6083, 0.8447, 0.3302])
model.get_layer('Den92502').set_weights(w) 
in0Mul284 = tf.constant([[[0.1868], [0.1952]]])
in1Mul284 = tf.constant([[[0.3479], [0.3429]]])
in0Con52882 = tf.constant([[0.217, 0.6653, 0.0132, 0.0673, 0.4238, 0.4737]])
in0Fla8513 = tf.constant([[[[1.2712, 1.9346, 1.2483, 1.2931]], [[1.5362, 1.0575, 1.4792, 1.3275]]]])
in0Con61096 = tf.constant([[[0.653, 0.7704, 0.9059], [0.8288, 0.3561, 0.097], [0.737, 0.7798, 0.0304]]])
in0Mul15173 = tf.constant([[[[0.3982, 0.315]]]])
in1Mul15173 = tf.constant([[[[0.7802, 0.7322]]]])
in0Con83205 = tf.constant([[[0.0214, 0.5293], [0.8365, 0.4444], [0.1035, 0.7152]]])
in0Dot22495 = tf.constant([[[0.4157, 0.4188, 0.1682], [0.9425, 0.2561, 0.3118], [0.029, 0.8646, 0.7474]]])
in1Dot22495 = tf.constant([[[0.5942, 0.3618, 0.0169], [0.5243, 0.4579, 0.3756], [0.7429, 0.1056, 0.5399]]])
print (np.array2string(model.predict([in0Mul284,in1Mul284,in0Con52882,in0Fla8513,in0Con61096,in0Mul15173,in1Mul15173,in0Con83205,in0Dot22495,in1Dot22495],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min2899.png')

LMul284 = multiply_layer([[[[0.1868], [0.1952]]], [[[0.3479], [0.3429]]]], Mul284), 
LFla45462 = flatten_layer(Mul284, Fla45462), 
LCon52882 = concatenate_layer([Fla45462,[[0.217, 0.6653, 0.0132, 0.0673, 0.4238, 0.4737]]], 1, Con52882), 
LFla8513 = flatten_layer([[[[1.2712, 1.9346, 1.2483, 1.2931]], [[1.5362, 1.0575, 1.4792, 1.3275]]]], Fla8513), 
LDot18586 = dot_layer(Con52882,Fla8513, 1, 1, Dot18586), 
LRes40529 = reshape_layer(Dot18586, [1, 1], Res40529), 
LGRU200 = gru_layer(Res40529,[[5, 6, 10, 6, 1, 5, 10, 3, 10]],[[7, 9, 1, 6, 1, 5, 2, 5, 8], [6, 4, 8, 4, 3, 2, 6, 3, 7], [7, 8, 8, 9, 3, 10, 3, 5, 5]],[[6, 8, 1, 6, 5, 7, 10, 1, 5], [2, 5, 9, 5, 1, 2, 3, 9, 1]], true, GRU200), 
LRes35143 = reshape_layer(GRU200, [3, 1], Res35143), 
LCon61096 = concatenate_layer([Res35143,[[[0.653, 0.7704, 0.9059], [0.8288, 0.3561, 0.097], [0.737, 0.7798, 0.0304]]]], 2, Con61096), 
LMul15173 = multiply_layer([[[[[0.3982, 0.315]]]], [[[[0.7802, 0.7322]]]]], Mul15173), 
LRes43929 = reshape_layer(Mul15173, [1, 2], Res43929), 
LZer87688 = zero_padding1D_layer(Res43929, 2, 0, Zer87688), 
LCon83205 = concatenate_layer([Zer87688,[[[0.0214, 0.5293], [0.8365, 0.4444], [0.1035, 0.7152]]]], 2, Con83205), 
LDot22495 = dot_layer([[[0.4157, 0.4188, 0.1682], [0.9425, 0.2561, 0.3118], [0.029, 0.8646, 0.7474]]], [[[0.5942, 0.3618, 0.0169], [0.5243, 0.4579, 0.3756], [0.7429, 0.1056, 0.5399]]], 2, 2, Dot22495), 
LDen92502 = dense_layer(Dot22495, [[0.72, 0.8057, 0.3263, 0.6726], [0.2529, 0.3163, 0.2014, 0.6535], [0.2799, 0.3959, 0.1667, 0.5521]],[0.934, 0.6083, 0.8447, 0.3302], Den92502), 
LAdd14777 = add_layer([Con83205,Den92502], Add14777), 
LMin2899 = minimum_layer([Con61096,Add14777], Min2899), 
exec_layers([LMul284,LFla45462,LCon52882,LFla8513,LDot18586,LRes40529,LGRU200,LRes35143,LCon61096,LMul15173,LRes43929,LZer87688,LCon83205,LDot22495,LDen92502,LAdd14777,LMin2899],["Mul284","Fla45462","Con52882","Fla8513","Dot18586","Res40529","GRU200","Res35143","Con61096","Mul15173","Res43929","Zer87688","Con83205","Dot22495","Den92502","Add14777","Min2899"],Min2899,"Min2899")

Actual (Unparsed): [[[0.0000000, 0.6530000, 0.7704000, 0.9059000], [0.0000000, 0.8288000, 0.3561000, 0.0970000], [0.0000000, 0.7370000, 0.7798000, 0.0304000]]]

Expected (Unparsed): [[[4.823919041996305e-10,0.653,0.7704,0.9059],[2.20490292690556e-13,0.8288,0.3561,0.097],[0.0,0.737,0.7798,0.0304]]]

Actual:   [[[0, 0.653, 0.7704, 0.9059], [0, 0.8288, 0.3561, 0.097], [0, 0.737, 0.7798, 0.0304]]]

Expected: [[[0, 0.653, 0.7704, 0.9059], [0, 0.8288, 0.3561, 0.097], [0, 0.737, 0.7798, 0.0304]]]