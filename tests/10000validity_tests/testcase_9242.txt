import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min87287 = tf.keras.layers.Input(shape=([2, 1, 2]))
in1Min87287 = tf.keras.layers.Input(shape=([2, 1, 2]))
in0Con35341 = tf.keras.layers.Input(shape=([28]))
in0Up_73082 = tf.keras.layers.Input(shape=([1, 4, 2, 2]))
in0Add35970 = tf.keras.layers.Input(shape=([1, 2, 1]))
in1Add35970 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con65649 = tf.keras.layers.Input(shape=([31]))

Min87287 = keras.layers.Minimum(name = 'Min87287', )([in0Min87287,in1Min87287])
Res18763 = keras.layers.Reshape((2, 2), name = 'Res18763', )(Min87287)
Fla67889 = keras.layers.Flatten(name = 'Fla67889', )(Res18763)
Con35341 = keras.layers.Concatenate(axis=1, name = 'Con35341', )([Fla67889,in0Con35341])
Up_73082 = keras.layers.UpSampling3D(size=(2, 1, 1), name = 'Up_73082', )(in0Up_73082)
Res73280 = keras.layers.Reshape((2, 4, 4), name = 'Res73280', )(Up_73082)
Res61713 = keras.layers.Reshape((2, 16), name = 'Res61713', )(Res73280)
Fla24921 = keras.layers.Flatten(name = 'Fla24921', )(Res61713)
Add35970 = keras.layers.Add(name = 'Add35970', )([in0Add35970,in1Add35970])
Res67565 = keras.layers.Reshape((1, 2, 1, 1), name = 'Res67565', )(Add35970)
Glo63339 = keras.layers.GlobalMaxPool3D(name = 'Glo63339', )(Res67565)
Con65649 = keras.layers.Concatenate(axis=1, name = 'Con65649', )([Glo63339,in0Con65649])
Mul99407 = keras.layers.Multiply(name = 'Mul99407', )([Fla24921,Con65649])
Add84963 = keras.layers.Add(name = 'Add84963', )([Con35341,Mul99407])
model = tf.keras.models.Model(inputs=[in0Min87287,in1Min87287,in0Con35341,in0Up_73082,in0Add35970,in1Add35970,in0Con65649], outputs=Add84963)
in0Min87287 = tf.constant([[[[0.5098, 0.9332]], [[0.1178, 0.7235]]]])
in1Min87287 = tf.constant([[[[0.0088, 0.8321]], [[0.1162, 0.0664]]]])
in0Con35341 = tf.constant([[0.8091, 0.4244, 0.9318, 0.1309, 0.1237, 0.4169, 0.0921, 0.2117, 0.9924, 0.0106, 0.173, 0.2331, 0.8529, 0.9317, 0.2907, 0.1521, 0.6089, 0.0106, 0.593, 0.7569, 0.1968, 0.577, 0.9407, 0.7008, 0.0021, 0.009, 0.2629, 0.9917]])
in0Up_73082 = tf.constant([[[[[1.6866, 1.5728], [1.6367, 1.3168]], [[1.5354, 1.0057], [1.4907, 1.1775]], [[1.3084, 1.7298], [1.7433, 1.5096]], [[1.3544, 1.0376], [1.195, 1.7984]]]]])
in0Add35970 = tf.constant([[[[0.2119], [0.3811]]]])
in1Add35970 = tf.constant([[[[0.1193], [0.6936]]]])
in0Con65649 = tf.constant([[0.9708, 0.2662, 0.1536, 0.5419, 0.843, 0.1814, 0.4846, 0.1234, 0.803, 0.6853, 0.7763, 0.2249, 0.3438, 0.3691, 0.5561, 0.2052, 0.1764, 0.5449, 0.5095, 0.0862, 0.064, 0.318, 0.1218, 0.2746, 0.2752, 0.5996, 0.8562, 0.7957, 0.0764, 0.3762, 0.7748]])
print (np.array2string(model.predict([in0Min87287,in1Min87287,in0Con35341,in0Up_73082,in0Add35970,in1Add35970,in0Con65649],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add84963.png')

LMin87287 = minimum_layer([[[[[0.5098, 0.9332]], [[0.1178, 0.7235]]]], [[[[0.0088, 0.8321]], [[0.1162, 0.0664]]]]], Min87287), 
LRes18763 = reshape_layer(Min87287, [2, 2], Res18763), 
LFla67889 = flatten_layer(Res18763, Fla67889), 
LCon35341 = concatenate_layer([Fla67889,[[0.8091, 0.4244, 0.9318, 0.1309, 0.1237, 0.4169, 0.0921, 0.2117, 0.9924, 0.0106, 0.173, 0.2331, 0.8529, 0.9317, 0.2907, 0.1521, 0.6089, 0.0106, 0.593, 0.7569, 0.1968, 0.577, 0.9407, 0.7008, 0.0021, 0.009, 0.2629, 0.9917]]], 1, Con35341), 
LUp_73082 = up_sampling3D_layer([[[[[1.6866, 1.5728], [1.6367, 1.3168]], [[1.5354, 1.0057], [1.4907, 1.1775]], [[1.3084, 1.7298], [1.7433, 1.5096]], [[1.3544, 1.0376], [1.195, 1.7984]]]]], 2, 1, 1, Up_73082), 
LRes73280 = reshape_layer(Up_73082, [2, 4, 4], Res73280), 
LRes61713 = reshape_layer(Res73280, [2, 16], Res61713), 
LFla24921 = flatten_layer(Res61713, Fla24921), 
LAdd35970 = add_layer([[[[[0.2119], [0.3811]]]], [[[[0.1193], [0.6936]]]]], Add35970), 
LRes67565 = reshape_layer(Add35970, [1, 2, 1, 1], Res67565), 
LGlo63339 = global_max_pool3D_layer(Res67565, Glo63339), 
LCon65649 = concatenate_layer([Glo63339,[[0.9708, 0.2662, 0.1536, 0.5419, 0.843, 0.1814, 0.4846, 0.1234, 0.803, 0.6853, 0.7763, 0.2249, 0.3438, 0.3691, 0.5561, 0.2052, 0.1764, 0.5449, 0.5095, 0.0862, 0.064, 0.318, 0.1218, 0.2746, 0.2752, 0.5996, 0.8562, 0.7957, 0.0764, 0.3762, 0.7748]]], 1, Con65649), 
LMul99407 = multiply_layer([Fla24921,Con65649], Mul99407), 
LAdd84963 = add_layer([Con35341,Mul99407], Add84963), 
exec_layers([LMin87287,LRes18763,LFla67889,LCon35341,LUp_73082,LRes73280,LRes61713,LFla24921,LAdd35970,LRes67565,LGlo63339,LCon65649,LMul99407,LAdd84963],["Min87287","Res18763","Fla67889","Con35341","Up_73082","Res73280","Res61713","Fla24921","Add35970","Res67565","Glo63339","Con65649","Mul99407","Add84963"],Add84963,"Add84963")

Actual (Unparsed): [[1.8213890, 2.3589742, 0.5518896, 0.2686605, 1.6411332, 1.2722051, 1.2022130, 0.7015165, 0.2851566, 1.8059294, 1.2867835, 1.3836025, 1.2970046, 0.3673269, 0.6140745, 1.2331903, 1.1989903, 1.2091419, 1.1825378, 0.8230096, 0.7412515, 0.0749648, 1.0670426, 0.9003195, 0.5560866, 1.0530410, 1.9859827, 1.9933195, 1.0797961, 0.0882726, 0.7124590, 2.3851004]]

Expected (Unparsed): [[1.82138902,2.3589742399999998,0.55188954,0.26866048,1.6411332600000001,1.2722050999999999,1.2022129799999999,0.7015165,0.28515656,1.8059294000000001,1.2867834900000001,1.38360248,1.29700456,0.36732688,0.6140745,1.23319024,1.19899032,1.20914192,1.18253783,0.8230095999999999,0.74125148,0.0749648,1.0670426,0.9003195,0.55608664,1.05304096,1.9859826800000002,1.99331952,1.07979608,0.08827264,0.712459,2.3851003200000003]]

Actual:   [[1.8214, 2.359, 0.5519, 0.2687, 1.6412, 1.2723, 1.2023, 0.7016, 0.2852, 1.806, 1.2868, 1.3837, 1.2971, 0.3674, 0.6141, 1.2332, 1.199, 1.2092, 1.1826, 0.8231, 0.7413, 0.075, 1.0671, 0.9004, 0.5561, 1.0531, 1.986, 1.9934, 1.0798, 0.0883, 0.7125, 2.3852]]

Expected: [[1.8214, 2.359, 0.5519, 0.2687, 1.6412, 1.2723, 1.2023, 0.7016, 0.2852, 1.806, 1.2868, 1.3837, 1.2971, 0.3674, 0.6141, 1.2332, 1.199, 1.2092, 1.1826, 0.8231, 0.7413, 0.075, 1.0671, 0.9004, 0.5561, 1.0531, 1.986, 1.9934, 1.0798, 0.0883, 0.7125, 2.3852]]