import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat19907 = tf.keras.layers.Input(shape=([4]))
in0Con88503 = tf.keras.layers.Input(shape=([4, 2]))
in0Sub47644 = tf.keras.layers.Input(shape=([3, 3]))
in1Sub47644 = tf.keras.layers.Input(shape=([3, 3]))
in0Con14290 = tf.keras.layers.Input(shape=([4, 3, 3, 1]))
in0Con73949 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))

Bat19907 = keras.layers.BatchNormalization(axis=1, epsilon=0.7929285392817568,  name = 'Bat19907', )(in0Bat19907)
Res52446 = keras.layers.Reshape((4, 1), name = 'Res52446', )(Bat19907)
Con88503 = keras.layers.Concatenate(axis=2, name = 'Con88503', )([Res52446,in0Con88503])
Sub47644 = keras.layers.Subtract(name = 'Sub47644', )([in0Sub47644,in1Sub47644])
Zer29026 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer29026', )(Sub47644)
Mul69287 = keras.layers.Multiply(name = 'Mul69287', )([Con88503,Zer29026])
Res33598 = keras.layers.Reshape((4, 3, 1), name = 'Res33598', )(Mul69287)
Res70228 = keras.layers.Reshape((4, 3, 1, 1), name = 'Res70228', )(Res33598)
Zer79245 = keras.layers.ZeroPadding3D(padding=((0, 0), (0, 0), (2, 0)), name = 'Zer79245', )(Res70228)
Con14290 = keras.layers.Concatenate(axis=4, name = 'Con14290', )([Zer79245,in0Con14290])
Con73949 = keras.layers.Conv3D(2, (2, 2, 1),strides=(1, 1, 1), padding='valid', dilation_rate=(1, 1, 1), name = 'Con73949', )(in0Con73949)
Zer64249 = keras.layers.ZeroPadding3D(padding=((3, 0), (2, 0), (1, 0)), name = 'Zer64249', )(Con73949)
Ave68027 = keras.layers.Average(name = 'Ave68027', )([Con14290,Zer64249])
model = tf.keras.models.Model(inputs=[in0Bat19907,in0Con88503,in0Sub47644,in1Sub47644,in0Con14290,in0Con73949], outputs=Ave68027)
w = model.get_layer('Bat19907').get_weights() 
w[0] = np.array([0.1701, 0.1046, 0.4871, 0.5627])
w[1] = np.array([0.507, 0.2257, 0.2819, 0.6284])
w[2] = np.array([0.3093, 0.1991, 0.2365, 0.7673])
w[3] = np.array([0.969, 0.9867, 0.5972, 0.8142])
model.get_layer('Bat19907').set_weights(w) 
w = model.get_layer('Con73949').get_weights() 
w[0] = np.array([[[[[0.2614, 0.6413], [0.8386, 0.3189]]], [[[0.0088, 0.2198], [0.8345, 0.6543]]]], [[[[0.2177, 0.9106], [0.3065, 0.0834]]], [[[0.1157, 0.4078], [0.9764, 0.0168]]]]])
w[1] = np.array([0, 0])
model.get_layer('Con73949').set_weights(w) 
in0Bat19907 = tf.constant([[1.4742, 1.3481, 1.7764, 1.6264]])
in0Con88503 = tf.constant([[[0.277, 0.6764], [0.7487, 0.4585], [0.0797, 0.2431], [0.9443, 0.7055]]])
in0Sub47644 = tf.constant([[[0.3887, 0.2786, 0.7436], [0.4588, 0.0262, 0.9894], [0.848, 0.3495, 0.0369]]])
in1Sub47644 = tf.constant([[[0.5908, 0.4867, 0.5106], [0.1913, 0.546, 0.8921], [0.9381, 0.4609, 0.0148]]])
in0Con14290 = tf.constant([[[[[0.0111], [0.5817], [0.7419]], [[0.5298], [0.5003], [0.8557]], [[0.0217], [0.6724], [0.8838]]], [[[0.3398], [0.3237], [0.2962]], [[0.7981], [0.7038], [0.0868]], [[0.6275], [0.1948], [0.3536]]], [[[0.6625], [0.4021], [0.6017]], [[0.5522], [0.2325], [0.6427]], [[0.5193], [0.1956], [0.7405]]], [[[0.8075], [0.251], [0.3281]], [[0.0166], [0.7785], [0.6357]], [[0.7216], [0.8926], [0.9708]]]]])
in0Con73949 = tf.constant([[[[[0.298, 0.1689], [0.8174, 0.6861]], [[0.9946, 0.8734], [0.0492, 0.5341]]], [[[0.5071, 0.251], [0.1173, 0.9127]], [[0.6849, 0.6317], [0.7047, 0.5422]]]]])
print (np.array2string(model.predict([in0Bat19907,in0Con88503,in0Sub47644,in1Sub47644,in0Con14290,in0Con73949],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave68027.png')

LBat19907 = batch_normalization_layer([[1.4742, 1.3481, 1.7764, 1.6264]], 1, 0.7929285392817568, [0.1701, 0.1046, 0.4871, 0.5627], [0.507, 0.2257, 0.2819, 0.6284], [0.3093, 0.1991, 0.2365, 0.7673], [0.969, 0.9867, 0.5972, 0.8142], Bat19907), 
LRes52446 = reshape_layer(Bat19907, [4, 1], Res52446), 
LCon88503 = concatenate_layer([Res52446,[[[0.277, 0.6764], [0.7487, 0.4585], [0.0797, 0.2431], [0.9443, 0.7055]]]], 2, Con88503), 
LSub47644 = subtract_layer([[[0.3887, 0.2786, 0.7436], [0.4588, 0.0262, 0.9894], [0.848, 0.3495, 0.0369]]], [[[0.5908, 0.4867, 0.5106], [0.1913, 0.546, 0.8921], [0.9381, 0.4609, 0.0148]]], Sub47644), 
LZer29026 = zero_padding1D_layer(Sub47644, 1, 0, Zer29026), 
LMul69287 = multiply_layer([Con88503,Zer29026], Mul69287), 
LRes33598 = reshape_layer(Mul69287, [4, 3, 1], Res33598), 
LRes70228 = reshape_layer(Res33598, [4, 3, 1, 1], Res70228), 
LZer79245 = zero_padding3D_layer(Res70228, 0, 0, 0, 0, 2, 0, Zer79245), 
LCon14290 = concatenate_layer([Zer79245,[[[[[0.0111], [0.5817], [0.7419]], [[0.5298], [0.5003], [0.8557]], [[0.0217], [0.6724], [0.8838]]], [[[0.3398], [0.3237], [0.2962]], [[0.7981], [0.7038], [0.0868]], [[0.6275], [0.1948], [0.3536]]], [[[0.6625], [0.4021], [0.6017]], [[0.5522], [0.2325], [0.6427]], [[0.5193], [0.1956], [0.7405]]], [[[0.8075], [0.251], [0.3281]], [[0.0166], [0.7785], [0.6357]], [[0.7216], [0.8926], [0.9708]]]]]], 4, Con14290), 
LCon73949 = conv3D_layer([[[[[0.298, 0.1689], [0.8174, 0.6861]], [[0.9946, 0.8734], [0.0492, 0.5341]]], [[[0.5071, 0.251], [0.1173, 0.9127]], [[0.6849, 0.6317], [0.7047, 0.5422]]]]], 2, 2, 1,[[[[[0.2614, 0.6413], [0.8386, 0.3189]]], [[[0.0088, 0.2198], [0.8345, 0.6543]]]], [[[[0.2177, 0.9106], [0.3065, 0.0834]]], [[[0.1157, 0.4078], [0.9764, 0.0168]]]]],[0, 0], 1, 1, 1, false, 1, 1, 1, Con73949), 
LZer64249 = zero_padding3D_layer(Con73949, 3, 0, 2, 0, 1, 0, Zer64249), 
LAve68027 = average_layer([Con14290,Zer64249], Ave68027), 
exec_layers([LBat19907,LRes52446,LCon88503,LSub47644,LZer29026,LMul69287,LRes33598,LRes70228,LZer79245,LCon14290,LCon73949,LZer64249,LAve68027],["Bat19907","Res52446","Con88503","Sub47644","Zer29026","Mul69287","Res33598","Res70228","Zer79245","Con14290","Con73949","Zer64249","Ave68027"],Ave68027,"Ave68027")

Actual (Unparsed): [[[[[0.0000000, 0.0055500], [0.0000000, 0.2908500], [0.0000000, 0.3709500]], [[0.0000000, 0.2649000], [0.0000000, 0.2501500], [0.0000000, 0.4278500]], [[0.0000000, 0.0108500], [0.0000000, 0.3362000], [0.0000000, 0.4419000]]], [[[0.0000000, 0.1699000], [0.0000000, 0.1618500], [-0.0319108, 0.1481000]], [[0.0000000, 0.3990500], [0.0000000, 0.3519000], [-0.0779022, 0.0434000]], [[0.0000000, 0.3137500], [0.0000000, 0.0974000], [0.0534153, 0.1768000]]], [[[0.0000000, 0.3312500], [0.0000000, 0.2010500], [0.1227938, 0.3008500]], [[0.0000000, 0.2761000], [0.0000000, 0.1162500], [-0.0207140, 0.3213500]], [[0.0000000, 0.2596500], [0.0000000, 0.0978000], [0.0118268, 0.3702500]]], [[[0.0000000, 0.4037500], [0.0000000, 0.1255000], [-0.0454881, 0.1640500]], [[0.0000000, 0.0083000], [0.0000000, 0.3892500], [-0.0525975, 0.3178500]], [[0.0000000, 0.3608000], [0.9202517, 1.3501309], [1.0834897, 1.2767449]]]]]

Expected (Unparsed): [[[[[0,0.00555],[0,0.29085],[0.0,0.37095]],[[0,0.2649],[0,0.25015],[0.0,0.42785]],[[0,0.01085],[0,0.3362],[0.0,0.4419]]],[[[0,0.1699],[0,0.16185],[-0.03191079845745797,0.1481]],[[0,0.39905],[0,0.3519],[-0.077902235,0.0434]],[[0,0.31375],[0,0.0974],[0.05341525,0.1768]]],[[[0,0.33125],[0,0.20105],[0.12279381854142647,0.30085]],[[0,0.2761],[0,0.11625],[-0.02071403,0.32135]],[[0,0.25965],[0,0.0978],[0.011826814999999994,0.37025]]],[[[0,0.40375],[0,0.1255],[-0.045488113172004865,0.16405]],[[0,0.0083],[0,0.38925],[-0.05259751,0.31785]],[[0,0.3608],[0.92025175,1.350130875],[1.083489705,1.27674494]]]]]

Actual:   [[[[[0, 0.0056], [0, 0.2909], [0, 0.371]], [[0, 0.2649], [0, 0.2502], [0, 0.4279]], [[0, 0.0109], [0, 0.3362], [0, 0.4419]]], [[[0, 0.1699], [0, 0.1619], [-0.0319, 0.1481]], [[0, 0.3991], [0, 0.3519], [-0.0779, 0.0434]], [[0, 0.3138], [0, 0.0974], [0.0535, 0.1768]]], [[[0, 0.3313], [0, 0.2011], [0.1228, 0.3009]], [[0, 0.2761], [0, 0.1163], [-0.0207, 0.3214]], [[0, 0.2597], [0, 0.0978], [0.0119, 0.3703]]], [[[0, 0.4038], [0, 0.1255], [-0.0454, 0.1641]], [[0, 0.0083], [0, 0.3893], [-0.0525, 0.3179]], [[0, 0.3608], [0.9203, 1.3502], [1.0835, 1.2768]]]]]

Expected: [[[[[0, 0.0056], [0, 0.2909], [0, 0.371]], [[0, 0.2649], [0, 0.2502], [0, 0.4279]], [[0, 0.0109], [0, 0.3362], [0, 0.4419]]], [[[0, 0.1699], [0, 0.1619], [-0.0319, 0.1481]], [[0, 0.3991], [0, 0.3519], [-0.0779, 0.0434]], [[0, 0.3138], [0, 0.0974], [0.0535, 0.1768]]], [[[0, 0.3313], [0, 0.2011], [0.1228, 0.3009]], [[0, 0.2761], [0, 0.1163], [-0.0207, 0.3214]], [[0, 0.2597], [0, 0.0978], [0.0119, 0.3703]]], [[[0, 0.4038], [0, 0.1255], [-0.0454, 0.1641]], [[0, 0.0083], [0, 0.3893], [-0.0525, 0.3179]], [[0, 0.3608], [0.9203, 1.3502], [1.0835, 1.2768]]]]]