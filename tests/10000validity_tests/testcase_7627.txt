import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Loc57716 = tf.keras.layers.Input(shape=([1, 1]))
in0Con41135 = tf.keras.layers.Input(shape=([1, 1]))
in0Con37118 = tf.keras.layers.Input(shape=([1, 4, 1, 2]))
in0Con52181 = tf.keras.layers.Input(shape=([2, 1, 1, 1]))
in0Con27183 = tf.keras.layers.Input(shape=([1, 6, 1, 1]))

Loc57716 = keras.layers.LocallyConnected1D(4, (1),strides=(1), name = 'Loc57716', )(in0Loc57716)
Res21468 = keras.layers.Reshape((1, 4, 1), name = 'Res21468', )(Loc57716)
Res38611 = keras.layers.Reshape((1, 4, 1, 1), name = 'Res38611', )(Res21468)
Con73060 = keras.layers.Conv3DTranspose(4, (1, 3, 1),strides=(1, 1, 1), padding='valid', name = 'Con73060', )(Res38611)
Con41135 = keras.layers.Conv1D(4, (1),strides=(1), padding='same', dilation_rate=(1), name = 'Con41135', )(in0Con41135)
Res31595 = keras.layers.Reshape((1, 4, 1), name = 'Res31595', )(Con41135)
Res21461 = keras.layers.Reshape((1, 4, 1, 1), name = 'Res21461', )(Res31595)
Con37118 = keras.layers.Concatenate(axis=4, name = 'Con37118', )([Res21461,in0Con37118])
Con52181 = keras.layers.Conv3D(3, (2, 1, 1),strides=(1, 1, 1), padding='valid', dilation_rate=(1, 1, 1), name = 'Con52181', )(in0Con52181)
Zer32260 = keras.layers.ZeroPadding3D(padding=((0, 0), (3, 0), (0, 0)), name = 'Zer32260', )(Con52181)
Mul22797 = keras.layers.Multiply(name = 'Mul22797', )([Con37118,Zer32260])
Zer36952 = keras.layers.ZeroPadding3D(padding=((0, 0), (2, 0), (0, 0)), name = 'Zer36952', )(Mul22797)
Con27183 = keras.layers.Concatenate(axis=4, name = 'Con27183', )([Zer36952,in0Con27183])
Max84233 = keras.layers.Maximum(name = 'Max84233', )([Con73060,Con27183])
Res49563 = keras.layers.Reshape((1, 6, 4), name = 'Res49563', )(Max84233)
Res67805 = keras.layers.Reshape((1, 24), name = 'Res67805', )(Res49563)
Bat81692 = keras.layers.BatchNormalization(axis=2, epsilon=0.5748194482802441,  name = 'Bat81692', )(Res67805)
Res29840 = keras.layers.Reshape((1, 24, 1), name = 'Res29840', )(Bat81692)
Up_73738 = keras.layers.UpSampling2D(size=(2, 1), name = 'Up_73738', )(Res29840)
model = tf.keras.models.Model(inputs=[in0Loc57716,in0Con41135,in0Con37118,in0Con52181,in0Con27183], outputs=Up_73738)
w = model.get_layer('Loc57716').get_weights() 
w[0] = np.array([[[0.9361, 0.86, 0.3958, 0.5611]]])
w[1] = np.array([[0, 0, 0, 0]])
model.get_layer('Loc57716').set_weights(w) 
w = model.get_layer('Con73060').get_weights() 
w[0] = np.array([[[[[0.5463], [0.0809], [0.5772], [0.6196]]], [[[0.8667], [0.934], [0.7021], [0.6141]]], [[[0.7534], [0.7972], [0.1057], [0.9904]]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con73060').set_weights(w) 
w = model.get_layer('Con41135').get_weights() 
w[0] = np.array([[[0.2632, 0.6671, 0.358, 0.2151]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con41135').set_weights(w) 
w = model.get_layer('Con52181').get_weights() 
w[0] = np.array([[[[[0.9051, 0.4212, 0.5437]]]], [[[[0.0946, 0.448, 0.7988]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con52181').set_weights(w) 
w = model.get_layer('Bat81692').get_weights() 
w[0] = np.array([0.2944, 0.1131, 0.1847, 0.8088, 0.1858, 0.8017, 0.7559, 0.3572, 0.9874, 0.669, 0.5106, 0.1704, 0.4649, 0.3776, 0.6513, 0.4832, 0.5222, 0.5559, 0.6824, 0.8025, 0.3121, 0.7076, 0.0467, 0.3748])
w[1] = np.array([0.7653, 0.2437, 0.7754, 0.8549, 0.5873, 0.0753, 0.846, 0.3845, 0.7249, 0.4755, 0.844, 0.638, 0.409, 0.5929, 0.0858, 0.6505, 0.143, 0.0871, 0.574, 0.3994, 0.4262, 0.8415, 0.0305, 0.1827])
w[2] = np.array([0.576, 0.6062, 0.779, 0.8092, 0.7438, 0.7253, 0.4345, 0.4939, 0.1081, 0.8107, 0.1984, 0.1418, 0.2718, 0.3391, 0.053, 0.3916, 0.0911, 0.6689, 0.3048, 0.3927, 0.5182, 0.9009, 0.7343, 0.7918])
w[3] = np.array([0.5569, 0.3393, 0.0758, 0.8176, 0.0936, 0.0496, 0.674, 0.6689, 0.1957, 0.1544, 0.9396, 0.6344, 0.4491, 0.0599, 0.6652, 0.5055, 0.0444, 0.766, 0.3493, 0.8738, 0.6151, 0.7734, 0.425, 0.8543])
model.get_layer('Bat81692').set_weights(w) 
in0Loc57716 = tf.constant([[[0.3752]]])
in0Con41135 = tf.constant([[[0.7834]]])
in0Con37118 = tf.constant([[[[[0.821, 0.1751]], [[0.5352, 0.4439]], [[0.0698, 0.0876]], [[0.6414, 0.1273]]]]])
in0Con52181 = tf.constant([[[[[0.852]]], [[[0.5688]]]]])
in0Con27183 = tf.constant([[[[[0.8446]], [[0.5294]], [[0.7861]], [[0.7557]], [[0.8602]], [[0.6063]]]]])
print (np.array2string(model.predict([in0Loc57716,in0Con41135,in0Con37118,in0Con52181,in0Con27183],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Up_73738.png')

LLoc57716 = locally_connected1D_layer([[[0.3752]]], 1,[[[0.9361, 0.86, 0.3958, 0.5611]]],[[0, 0, 0, 0]], 1, Loc57716), 
LRes21468 = reshape_layer(Loc57716, [1, 4, 1], Res21468), 
LRes38611 = reshape_layer(Res21468, [1, 4, 1, 1], Res38611), 
LCon73060 = conv3D_transpose_layer(Res38611, 1, 3, 1,[[[[[0.5463], [0.0809], [0.5772], [0.6196]]], [[[0.8667], [0.934], [0.7021], [0.6141]]], [[[0.7534], [0.7972], [0.1057], [0.9904]]]]],[0, 0, 0, 0], 1, 1, 1, false, Con73060), 
LCon41135 = conv1D_layer([[[0.7834]]], 1,[[[0.2632, 0.6671, 0.358, 0.2151]]],[0, 0, 0, 0], 1, true, 1, Con41135), 
LRes31595 = reshape_layer(Con41135, [1, 4, 1], Res31595), 
LRes21461 = reshape_layer(Res31595, [1, 4, 1, 1], Res21461), 
LCon37118 = concatenate_layer([Res21461,[[[[[0.821, 0.1751]], [[0.5352, 0.4439]], [[0.0698, 0.0876]], [[0.6414, 0.1273]]]]]], 4, Con37118), 
LCon52181 = conv3D_layer([[[[[0.852]]], [[[0.5688]]]]], 2, 1, 1,[[[[[0.9051, 0.4212, 0.5437]]]], [[[[0.0946, 0.448, 0.7988]]]]],[0, 0, 0], 1, 1, 1, false, 1, 1, 1, Con52181), 
LZer32260 = zero_padding3D_layer(Con52181, 0, 0, 3, 0, 0, 0, Zer32260), 
LMul22797 = multiply_layer([Con37118,Zer32260], Mul22797), 
LZer36952 = zero_padding3D_layer(Mul22797, 0, 0, 2, 0, 0, 0, Zer36952), 
LCon27183 = concatenate_layer([Zer36952,[[[[[0.8446]], [[0.5294]], [[0.7861]], [[0.7557]], [[0.8602]], [[0.6063]]]]]], 4, Con27183), 
LMax84233 = maximum_layer([Con73060,Con27183], Max84233), 
LRes49563 = reshape_layer(Max84233, [1, 6, 4], Res49563), 
LRes67805 = reshape_layer(Res49563, [1, 24], Res67805), 
LBat81692 = batch_normalization_layer(Res67805, 2, 0.5748194482802441, [0.2944, 0.1131, 0.1847, 0.8088, 0.1858, 0.8017, 0.7559, 0.3572, 0.9874, 0.669, 0.5106, 0.1704, 0.4649, 0.3776, 0.6513, 0.4832, 0.5222, 0.5559, 0.6824, 0.8025, 0.3121, 0.7076, 0.0467, 0.3748], [0.7653, 0.2437, 0.7754, 0.8549, 0.5873, 0.0753, 0.846, 0.3845, 0.7249, 0.4755, 0.844, 0.638, 0.409, 0.5929, 0.0858, 0.6505, 0.143, 0.0871, 0.574, 0.3994, 0.4262, 0.8415, 0.0305, 0.1827], [0.576, 0.6062, 0.779, 0.8092, 0.7438, 0.7253, 0.4345, 0.4939, 0.1081, 0.8107, 0.1984, 0.1418, 0.2718, 0.3391, 0.053, 0.3916, 0.0911, 0.6689, 0.3048, 0.3927, 0.5182, 0.9009, 0.7343, 0.7918], [0.5569, 0.3393, 0.0758, 0.8176, 0.0936, 0.0496, 0.674, 0.6689, 0.1957, 0.1544, 0.9396, 0.6344, 0.4491, 0.0599, 0.6652, 0.5055, 0.0444, 0.766, 0.3493, 0.8738, 0.6151, 0.7734, 0.425, 0.8543], Bat81692), 
LRes29840 = reshape_layer(Bat81692, [1, 24, 1], Res29840), 
LUp_73738 = up_sampling2D_layer(Res29840, 2, 1, Up_73738), 
exec_layers([LLoc57716,LRes21468,LRes38611,LCon73060,LCon41135,LRes31595,LRes21461,LCon37118,LCon52181,LZer32260,LMul22797,LZer36952,LCon27183,LMax84233,LRes49563,LRes67805,LBat81692,LRes29840,LUp_73738],["Loc57716","Res21468","Res38611","Con73060","Con41135","Res31595","Res21461","Con37118","Con52181","Zer32260","Mul22797","Zer36952","Con27183","Max84233","Res49563","Res67805","Bat81692","Res29840","Up_73738"],Up_73738,"Up_73738")

Actual (Unparsed): [[[[0.6589979], [0.1753516], [0.6434432], [0.8791638], [0.5275041], [-0.3012524], [0.8448779], [0.3958705], [1.3067943], [0.3052509], [0.9066474], [0.7378401], [0.5077880], [0.6279106], [0.2068035], [0.8197667], [0.2778758], [-0.0827910], [0.4737007], [0.7111091], [0.3233171], [0.5323584], [0.0016606], [0.1245420]], [[0.6589979], [0.1753516], [0.6434432], [0.8791638], [0.5275041], [-0.3012524], [0.8448779], [0.3958705], [1.3067943], [0.3052509], [0.9066474], [0.7378401], [0.5077880], [0.6279106], [0.2068035], [0.8197667], [0.2778758], [-0.0827910], [0.4737007], [0.7111091], [0.3233171], [0.5323584], [0.0016606], [0.1245420]]]]

Expected (Unparsed): [[[[0.6589978503418448],[0.17535164208834053],[0.6434432179551013],[0.8791638305486468],[0.5275040960376104],[-0.30125239637574164],[0.8448779285642586],[0.39587047455098634],[1.3067942849940375],[0.30525093344460097],[0.9066474239864648],[0.7378401351079039],[0.507787975041595],[0.6279106432966995],[0.20680354076972918],[0.8197666921912243],[0.27787580060861317],[-0.08279104266399985],[0.4737007294551664],[0.7111091138822102],[0.32331704977415765],[0.5323583858446782],[0.001660575394332356],[0.12454203102122917]],[[0.6589978503418448],[0.17535164208834053],[0.6434432179551013],[0.8791638305486468],[0.5275040960376104],[-0.30125239637574164],[0.8448779285642586],[0.39587047455098634],[1.3067942849940375],[0.30525093344460097],[0.9066474239864648],[0.7378401351079039],[0.507787975041595],[0.6279106432966995],[0.20680354076972918],[0.8197666921912243],[0.27787580060861317],[-0.08279104266399985],[0.4737007294551664],[0.7111091138822102],[0.32331704977415765],[0.5323583858446782],[0.001660575394332356],[0.12454203102122917]]]]

Actual:   [[[[0.659], [0.1754], [0.6435], [0.8792], [0.5276], [-0.3012], [0.8449], [0.3959], [1.3068], [0.3053], [0.9067], [0.7379], [0.5078], [0.628], [0.2069], [0.8198], [0.2779], [-0.0827], [0.4738], [0.7112], [0.3234], [0.5324], [0.0017], [0.1246]], [[0.659], [0.1754], [0.6435], [0.8792], [0.5276], [-0.3012], [0.8449], [0.3959], [1.3068], [0.3053], [0.9067], [0.7379], [0.5078], [0.628], [0.2069], [0.8198], [0.2779], [-0.0827], [0.4738], [0.7112], [0.3234], [0.5324], [0.0017], [0.1246]]]]

Expected: [[[[0.659], [0.1754], [0.6435], [0.8792], [0.5276], [-0.3012], [0.8449], [0.3959], [1.3068], [0.3053], [0.9067], [0.7379], [0.5078], [0.628], [0.2069], [0.8198], [0.2779], [-0.0827], [0.4738], [0.7112], [0.3234], [0.5324], [0.0017], [0.1246]], [[0.659], [0.1754], [0.6435], [0.8792], [0.5276], [-0.3012], [0.8449], [0.3959], [1.3068], [0.3053], [0.9067], [0.7379], [0.5078], [0.628], [0.2069], [0.8198], [0.2779], [-0.0827], [0.4738], [0.7112], [0.3234], [0.5324], [0.0017], [0.1246]]]]