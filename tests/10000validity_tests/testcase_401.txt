import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub39798 = tf.keras.layers.Input(shape=([2, 2]))
in1Sub39798 = tf.keras.layers.Input(shape=([2, 2]))
in0Sub10295 = tf.keras.layers.Input(shape=([2, 2]))
in1Sub10295 = tf.keras.layers.Input(shape=([2, 2]))
in0Mul95594 = tf.keras.layers.Input(shape=([1, 2]))
in1Mul95594 = tf.keras.layers.Input(shape=([1, 2]))

Sub39798 = keras.layers.Subtract(name = 'Sub39798', )([in0Sub39798,in1Sub39798])
Sub10295 = keras.layers.Subtract(name = 'Sub10295', )([in0Sub10295,in1Sub10295])
Mul95594 = keras.layers.Multiply(name = 'Mul95594', )([in0Mul95594,in1Mul95594])
Bat81918 = keras.layers.BatchNormalization(axis=2, epsilon=0.9547928941227642,  name = 'Bat81918', )(Mul95594)
Zer41875 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer41875', )(Bat81918)
Max69005 = keras.layers.Maximum(name = 'Max69005', )([Sub10295,Zer41875])
Dot32145 = keras.layers.Dot(axes=(1, 1), name = 'Dot32145', )([Sub39798,Max69005])
model = tf.keras.models.Model(inputs=[in0Sub39798,in1Sub39798,in0Sub10295,in1Sub10295,in0Mul95594,in1Mul95594], outputs=Dot32145)
w = model.get_layer('Bat81918').get_weights() 
w[0] = np.array([0.0501, 0.6644])
w[1] = np.array([0.2138, 0.3068])
w[2] = np.array([0.1408, 0.5544])
w[3] = np.array([0.9587, 0.965])
model.get_layer('Bat81918').set_weights(w) 
in0Sub39798 = tf.constant([[[0.7515, 0.8589], [0.8773, 0.1236]]])
in1Sub39798 = tf.constant([[[0.4429, 0.2432], [0.3694, 0.5247]]])
in0Sub10295 = tf.constant([[[0.4938, 0.7162], [0.597, 0.9242]]])
in1Sub10295 = tf.constant([[[0.818, 0.2453], [0.5748, 0.2151]]])
in0Mul95594 = tf.constant([[[0.4331, 0.2575]]])
in1Mul95594 = tf.constant([[[0.1839, 0.8584]]])
print (np.array2string(model.predict([in0Sub39798,in1Sub39798,in0Sub10295,in1Sub10295,in0Mul95594,in1Mul95594],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot32145.png')

LSub39798 = subtract_layer([[[0.7515, 0.8589], [0.8773, 0.1236]]], [[[0.4429, 0.2432], [0.3694, 0.5247]]], Sub39798), 
LSub10295 = subtract_layer([[[0.4938, 0.7162], [0.597, 0.9242]]], [[[0.818, 0.2453], [0.5748, 0.2151]]], Sub10295), 
LMul95594 = multiply_layer([[[[0.4331, 0.2575]]], [[[0.1839, 0.8584]]]], Mul95594), 
LBat81918 = batch_normalization_layer(Mul95594, 2, 0.9547928941227642, [0.0501, 0.6644], [0.2138, 0.3068], [0.1408, 0.5544], [0.9587, 0.965], Bat81918), 
LZer41875 = zero_padding1D_layer(Bat81918, 1, 0, Zer41875), 
LMax69005 = maximum_layer([Sub10295,Zer41875], Max69005), 
LDot32145 = dot_layer(Sub39798,Max69005, 1, 1, Dot32145), 
exec_layers([LSub39798,LSub10295,LMul95594,LBat81918,LZer41875,LMax69005,LDot32145],["Sub39798","Sub10295","Mul95594","Bat81918","Zer41875","Max69005","Dot32145"],Dot32145,"Dot32145")

Actual (Unparsed): [[[0.1074641, 0.5054717], [-0.0848668, 0.0055131]]]

Expected (Unparsed): [[[0.10746410517613539,0.50547163],[-0.08486680958091733,0.005513119999999927]]]

Actual:   [[[0.1075, 0.5055], [-0.0848, 0.0056]]]

Expected: [[[0.1075, 0.5055], [-0.0848, 0.0056]]]