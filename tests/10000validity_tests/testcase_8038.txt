import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add51152 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in1Add51152 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in0Ave6524 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Ave6524 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Dot64301 = tf.keras.layers.Input(shape=([2, 3]))
in1Dot64301 = tf.keras.layers.Input(shape=([2, 3]))
in0Con5793 = tf.keras.layers.Input(shape=([5]))

Add51152 = keras.layers.Add(name = 'Add51152', )([in0Add51152,in1Add51152])
Res7768 = keras.layers.Reshape((1, 2, 2), name = 'Res7768', )(Add51152)
Zer15569 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer15569', )(Res7768)
Ave6524 = keras.layers.Average(name = 'Ave6524', )([in0Ave6524,in1Ave6524])
Mas34121 = keras.layers.Masking(mask_value=2, name = 'Mas34121', )(Ave6524)
Sub57056 = keras.layers.Subtract(name = 'Sub57056', )([Zer15569,Mas34121])
Res17220 = keras.layers.Reshape((2, 4), name = 'Res17220', )(Sub57056)
Fla99122 = keras.layers.Flatten(name = 'Fla99122', )(Res17220)
Dot64301 = keras.layers.Dot(axes=(1, 1), name = 'Dot64301', )([in0Dot64301,in1Dot64301])
Glo21463 = keras.layers.GlobalAveragePooling1D(name = 'Glo21463', )(Dot64301)
Con5793 = keras.layers.Concatenate(axis=1, name = 'Con5793', )([Glo21463,in0Con5793])
Max47992 = keras.layers.Maximum(name = 'Max47992', )([Fla99122,Con5793])
model = tf.keras.models.Model(inputs=[in0Add51152,in1Add51152,in0Ave6524,in1Ave6524,in0Dot64301,in1Dot64301,in0Con5793], outputs=Max47992)
in0Add51152 = tf.constant([[[[[0.8772], [0.1066]], [[0.1118], [0.1139]]]]])
in1Add51152 = tf.constant([[[[[0.9028], [0.6447]], [[0.3429], [0.992]]]]])
in0Ave6524 = tf.constant([[[[0.0236, 0.5561], [0.9959, 0.5899]], [[0.8363, 0.6336], [0.4226, 0.1639]]]])
in1Ave6524 = tf.constant([[[[0.0083, 0.5472], [0.5124, 0.7831]], [[0.0283, 0.5867], [0.9999, 0.2743]]]])
in0Dot64301 = tf.constant([[[0.3775, 0.433, 0.1126], [0.0624, 0.2993, 0.424]]])
in1Dot64301 = tf.constant([[[0.0267, 0.2313, 0.9663], [0.5991, 0.9263, 0.7741]]])
in0Con5793 = tf.constant([[0.7014, 0.916, 0.8473, 0.3682, 0.4581]])
print (np.array2string(model.predict([in0Add51152,in1Add51152,in0Ave6524,in1Ave6524,in0Dot64301,in1Dot64301,in0Con5793],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Max47992.png')

LAdd51152 = add_layer([[[[[[0.8772], [0.1066]], [[0.1118], [0.1139]]]]], [[[[[0.9028], [0.6447]], [[0.3429], [0.992]]]]]], Add51152), 
LRes7768 = reshape_layer(Add51152, [1, 2, 2], Res7768), 
LZer15569 = zero_padding2D_layer(Res7768, 1, 0, 0, 0, Zer15569), 
LAve6524 = average_layer([[[[[0.0236, 0.5561], [0.9959, 0.5899]], [[0.8363, 0.6336], [0.4226, 0.1639]]]], [[[[0.0083, 0.5472], [0.5124, 0.7831]], [[0.0283, 0.5867], [0.9999, 0.2743]]]]], Ave6524), 
LMas34121 = masking_layer(Ave6524, 2, Mas34121), 
LSub57056 = subtract_layer(Zer15569,Mas34121, Sub57056), 
LRes17220 = reshape_layer(Sub57056, [2, 4], Res17220), 
LFla99122 = flatten_layer(Res17220, Fla99122), 
LDot64301 = dot_layer([[[0.3775, 0.433, 0.1126], [0.0624, 0.2993, 0.424]]], [[[0.0267, 0.2313, 0.9663], [0.5991, 0.9263, 0.7741]]], 1, 1, Dot64301), 
LGlo21463 = global_average_pooling1D_layer(Dot64301, Glo21463), 
LCon5793 = concatenate_layer([Glo21463,[[0.7014, 0.916, 0.8473, 0.3682, 0.4581]]], 1, Con5793), 
LMax47992 = maximum_layer([Fla99122,Con5793], Max47992), 
exec_layers([LAdd51152,LRes7768,LZer15569,LAve6524,LMas34121,LSub57056,LRes17220,LFla99122,LDot64301,LGlo21463,LCon5793,LMax47992],["Add51152","Res7768","Zer15569","Ave6524","Mas34121","Sub57056","Res17220","Fla99122","Dot64301","Glo21463","Con5793","Max47992"],Max47992,"Max47992")

Actual (Unparsed): [[0.1651199, 0.3137690, 0.5000673, 0.7014000, 1.3477000, 0.8473000, 0.3682000, 0.8868000]]

Expected (Unparsed): [[0.16511988,0.31376898,0.5000673000000001,0.7014,1.3477000000000001,0.8473,0.3682,0.8868000000000001]]

Actual:   [[0.1652, 0.3138, 0.5001, 0.7014, 1.3477, 0.8473, 0.3682, 0.8868]]

Expected: [[0.1652, 0.3138, 0.5001, 0.7014, 1.3478, 0.8473, 0.3682, 0.8869]]