import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave78275 = tf.keras.layers.Input(shape=([2, 2, 1]))
in1Ave78275 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Up_21378 = tf.keras.layers.Input(shape=([3, 3, 3, 1]))
in0Up_8103 = tf.keras.layers.Input(shape=([4, 3, 1]))
in0Loc26278 = tf.keras.layers.Input(shape=([1, 2]))
in0Con80587 = tf.keras.layers.Input(shape=([20]))
in0Con25896 = tf.keras.layers.Input(shape=([192]))

Ave78275 = keras.layers.Average(name = 'Ave78275', )([in0Ave78275,in1Ave78275])
Res20719 = keras.layers.Reshape((2, 2), name = 'Res20719', )(Ave78275)
Per25638 = keras.layers.Permute((1,2), name = 'Per25638',)(Res20719)
Res85510 = keras.layers.Reshape((2, 2, 1), name = 'Res85510', )(Per25638)
Res51261 = keras.layers.Reshape((2, 2, 1, 1), name = 'Res51261', )(Res85510)
Zer74449 = keras.layers.ZeroPadding3D(padding=((4, 0), (4, 0), (5, 0)), name = 'Zer74449', )(Res51261)
Up_21378 = keras.layers.UpSampling3D(size=(2, 2, 2), name = 'Up_21378', )(in0Up_21378)
Add67842 = keras.layers.Add(name = 'Add67842', )([Zer74449,Up_21378])
Res26531 = keras.layers.Reshape((6, 6, 6), name = 'Res26531', )(Add67842)
Res54840 = keras.layers.Reshape((6, 36), name = 'Res54840', )(Res26531)
Fla94415 = keras.layers.Flatten(name = 'Fla94415', )(Res54840)
Up_8103 = keras.layers.UpSampling2D(size=(2, 1), name = 'Up_8103', )(in0Up_8103)
Res68532 = keras.layers.Reshape((8, 3), name = 'Res68532', )(Up_8103)
Fla67975 = keras.layers.Flatten(name = 'Fla67975', )(Res68532)
Loc26278 = keras.layers.LocallyConnected1D(4, (1),strides=(1), name = 'Loc26278', )(in0Loc26278)
Glo24711 = keras.layers.GlobalAveragePooling1D(name = 'Glo24711', )(Loc26278)
Con80587 = keras.layers.Concatenate(axis=1, name = 'Con80587', )([Glo24711,in0Con80587])
Mul75491 = keras.layers.Multiply(name = 'Mul75491', )([Fla67975,Con80587])
Con25896 = keras.layers.Concatenate(axis=1, name = 'Con25896', )([Mul75491,in0Con25896])
Min20862 = keras.layers.Minimum(name = 'Min20862', )([Fla94415,Con25896])
model = tf.keras.models.Model(inputs=[in0Ave78275,in1Ave78275,in0Up_21378,in0Up_8103,in0Loc26278,in0Con80587,in0Con25896], outputs=Min20862)
w = model.get_layer('Loc26278').get_weights() 
w[0] = np.array([[[0.1662, 0.2851, 0.1552, 0.753], [0.2592, 0.1956, 0.4646, 0.505]]])
w[1] = np.array([[0, 0, 0, 0]])
model.get_layer('Loc26278').set_weights(w) 
in0Ave78275 = tf.constant([[[[0.1898], [0.6483]], [[0.5898], [0.0845]]]])
in1Ave78275 = tf.constant([[[[0.5281], [0.5723]], [[0.9652], [0.0818]]]])
in0Up_21378 = tf.constant([[[[[1.1305], [1.9808], [1.5252]], [[1.3256], [1.3], [1.6139]], [[1.8305], [1.7508], [1.957]]], [[[1.9138], [1.7228], [1.8633]], [[1.5725], [1.0638], [1.6654]], [[1.7047], [1.1482], [1.5231]]], [[[1.142], [1.8435], [1.6628]], [[1.7979], [1.3407], [1.5405]], [[1.3704], [1.9176], [1.6536]]]]])
in0Up_8103 = tf.constant([[[[1.4199], [1.2249], [1.9749]], [[1.2277], [1.8205], [1.4837]], [[1.1319], [1.9196], [1.4953]], [[1.2403], [1.6942], [1.5257]]]])
in0Loc26278 = tf.constant([[[0.4846, 0.2331]]])
in0Con80587 = tf.constant([[0.3499, 0.8606, 0.1652, 0.9243, 0.8916, 0.8727, 0.7134, 0.6676, 0.9835, 0.9166, 0.1616, 0.011, 0.2879, 0.1038, 0.6978, 0.214, 0.3499, 0.6041, 0.6656, 0.4299]])
in0Con25896 = tf.constant([[0.2711, 0.4461, 0.5383, 0.2989, 0.453, 0.827, 0.0343, 0.7791, 0.1938, 0.4393, 0.8519, 0.4528, 0.9922, 0.0162, 0.9182, 0.9645, 0.3518, 0.6669, 0.319, 0.1654, 0.1001, 0.0772, 0.8856, 0.8761, 0.4234, 0.1044, 0.5455, 0.1933, 0.4076, 0.1217, 0.9143, 0.3882, 0.6651, 0.3297, 0.8543, 0.8888, 0.5808, 0.5253, 0.6272, 0.1826, 0.8147, 0.4937, 0.8284, 0.7371, 0.9621, 0.2708, 0.5079, 0.1905, 0.6925, 0.0174, 0.7505, 0.1376, 0.2606, 0.1352, 0.523, 0.8052, 0.018, 0.5632, 0.7726, 0.7949, 0.4381, 0.8963, 0.6093, 0.8539, 0.2137, 0.0837, 0.8966, 0.3308, 0.1851, 0.9861, 0.731, 0.5666, 0.214, 0.9969, 0.0986, 0.9827, 0.6304, 0.2638, 0.4658, 0.0315, 0.5494, 0.7904, 0.1782, 0.4998, 0.1796, 0.8377, 0.3263, 0.873, 0.2257, 0.6035, 0.1654, 0.6011, 0.6273, 0.1087, 0.2727, 0.1433, 0.1672, 0.5897, 0.3673, 0.609, 0.9361, 0.4635, 0.1261, 0.6636, 0.2436, 0.1089, 0.3856, 0.1208, 0.3295, 0.2919, 0.8362, 0.3044, 0.1508, 0.0511, 0.6881, 0.832, 0.5896, 0.2544, 0.8145, 0.9428, 0.664, 0.8421, 0.566, 0.8751, 0.7081, 0.9759, 0.7859, 0.085, 0.0333, 0.9319, 0.5581, 0.2856, 0.2819, 0.5916, 0.8688, 0.3929, 0.5414, 0.8165, 0.6751, 0.4604, 0.2999, 0.8199, 0.8389, 0.6024, 0.4926, 0.8938, 0.0054, 0.7205, 0.2142, 0.4893, 0.7855, 0.571, 0.153, 0.7053, 0.5349, 0.3422, 0.4415, 0.6944, 0.6145, 0.4457, 0.4109, 0.3626, 0.2617, 0.6693, 0.6878, 0.0065, 0.1086, 0.1858, 0.1775, 0.2115, 0.9396, 0.1698, 0.7419, 0.4156, 0.4991, 0.9319, 0.7971, 0.033, 0.0306, 0.5512, 0.6327, 0.9284, 0.7574, 0.9577, 0.9864, 0.3325, 0.6996, 0.2965, 0.2929, 0.9992, 0.063, 0.1938]])
print (np.array2string(model.predict([in0Ave78275,in1Ave78275,in0Up_21378,in0Up_8103,in0Loc26278,in0Con80587,in0Con25896],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min20862.png')

LAve78275 = average_layer([[[[[0.1898], [0.6483]], [[0.5898], [0.0845]]]], [[[[0.5281], [0.5723]], [[0.9652], [0.0818]]]]], Ave78275), 
LRes20719 = reshape_layer(Ave78275, [2, 2], Res20719), 
LPer25638 = permute_layer(Res20719, 1,2, Per25638), 
LRes85510 = reshape_layer(Per25638, [2, 2, 1], Res85510), 
LRes51261 = reshape_layer(Res85510, [2, 2, 1, 1], Res51261), 
LZer74449 = zero_padding3D_layer(Res51261, 4, 0, 4, 0, 5, 0, Zer74449), 
LUp_21378 = up_sampling3D_layer([[[[[1.1305], [1.9808], [1.5252]], [[1.3256], [1.3], [1.6139]], [[1.8305], [1.7508], [1.957]]], [[[1.9138], [1.7228], [1.8633]], [[1.5725], [1.0638], [1.6654]], [[1.7047], [1.1482], [1.5231]]], [[[1.142], [1.8435], [1.6628]], [[1.7979], [1.3407], [1.5405]], [[1.3704], [1.9176], [1.6536]]]]], 2, 2, 2, Up_21378), 
LAdd67842 = add_layer([Zer74449,Up_21378], Add67842), 
LRes26531 = reshape_layer(Add67842, [6, 6, 6], Res26531), 
LRes54840 = reshape_layer(Res26531, [6, 36], Res54840), 
LFla94415 = flatten_layer(Res54840, Fla94415), 
LUp_8103 = up_sampling2D_layer([[[[1.4199], [1.2249], [1.9749]], [[1.2277], [1.8205], [1.4837]], [[1.1319], [1.9196], [1.4953]], [[1.2403], [1.6942], [1.5257]]]], 2, 1, Up_8103), 
LRes68532 = reshape_layer(Up_8103, [8, 3], Res68532), 
LFla67975 = flatten_layer(Res68532, Fla67975), 
LLoc26278 = locally_connected1D_layer([[[0.4846, 0.2331]]], 1,[[[0.1662, 0.2851, 0.1552, 0.753], [0.2592, 0.1956, 0.4646, 0.505]]],[[0, 0, 0, 0]], 1, Loc26278), 
LGlo24711 = global_average_pooling1D_layer(Loc26278, Glo24711), 
LCon80587 = concatenate_layer([Glo24711,[[0.3499, 0.8606, 0.1652, 0.9243, 0.8916, 0.8727, 0.7134, 0.6676, 0.9835, 0.9166, 0.1616, 0.011, 0.2879, 0.1038, 0.6978, 0.214, 0.3499, 0.6041, 0.6656, 0.4299]]], 1, Con80587), 
LMul75491 = multiply_layer([Fla67975,Con80587], Mul75491), 
LCon25896 = concatenate_layer([Mul75491,[[0.2711, 0.4461, 0.5383, 0.2989, 0.453, 0.827, 0.0343, 0.7791, 0.1938, 0.4393, 0.8519, 0.4528, 0.9922, 0.0162, 0.9182, 0.9645, 0.3518, 0.6669, 0.319, 0.1654, 0.1001, 0.0772, 0.8856, 0.8761, 0.4234, 0.1044, 0.5455, 0.1933, 0.4076, 0.1217, 0.9143, 0.3882, 0.6651, 0.3297, 0.8543, 0.8888, 0.5808, 0.5253, 0.6272, 0.1826, 0.8147, 0.4937, 0.8284, 0.7371, 0.9621, 0.2708, 0.5079, 0.1905, 0.6925, 0.0174, 0.7505, 0.1376, 0.2606, 0.1352, 0.523, 0.8052, 0.018, 0.5632, 0.7726, 0.7949, 0.4381, 0.8963, 0.6093, 0.8539, 0.2137, 0.0837, 0.8966, 0.3308, 0.1851, 0.9861, 0.731, 0.5666, 0.214, 0.9969, 0.0986, 0.9827, 0.6304, 0.2638, 0.4658, 0.0315, 0.5494, 0.7904, 0.1782, 0.4998, 0.1796, 0.8377, 0.3263, 0.873, 0.2257, 0.6035, 0.1654, 0.6011, 0.6273, 0.1087, 0.2727, 0.1433, 0.1672, 0.5897, 0.3673, 0.609, 0.9361, 0.4635, 0.1261, 0.6636, 0.2436, 0.1089, 0.3856, 0.1208, 0.3295, 0.2919, 0.8362, 0.3044, 0.1508, 0.0511, 0.6881, 0.832, 0.5896, 0.2544, 0.8145, 0.9428, 0.664, 0.8421, 0.566, 0.8751, 0.7081, 0.9759, 0.7859, 0.085, 0.0333, 0.9319, 0.5581, 0.2856, 0.2819, 0.5916, 0.8688, 0.3929, 0.5414, 0.8165, 0.6751, 0.4604, 0.2999, 0.8199, 0.8389, 0.6024, 0.4926, 0.8938, 0.0054, 0.7205, 0.2142, 0.4893, 0.7855, 0.571, 0.153, 0.7053, 0.5349, 0.3422, 0.4415, 0.6944, 0.6145, 0.4457, 0.4109, 0.3626, 0.2617, 0.6693, 0.6878, 0.0065, 0.1086, 0.1858, 0.1775, 0.2115, 0.9396, 0.1698, 0.7419, 0.4156, 0.4991, 0.9319, 0.7971, 0.033, 0.0306, 0.5512, 0.6327, 0.9284, 0.7574, 0.9577, 0.9864, 0.3325, 0.6996, 0.2965, 0.2929, 0.9992, 0.063, 0.1938]]], 1, Con25896), 
LMin20862 = minimum_layer([Fla94415,Con25896], Min20862), 
exec_layers([LAve78275,LRes20719,LPer25638,LRes85510,LRes51261,LZer74449,LUp_21378,LAdd67842,LRes26531,LRes54840,LFla94415,LUp_8103,LRes68532,LFla67975,LLoc26278,LGlo24711,LCon80587,LMul75491,LCon25896,LMin20862],["Ave78275","Res20719","Per25638","Res85510","Res51261","Zer74449","Up_21378","Add67842","Res26531","Res54840","Fla94415","Up_8103","Res68532","Fla67975","Loc26278","Glo24711","Con80587","Mul75491","Con25896","Min20862"],Min20862,"Min20862")

Actual (Unparsed): [[0.2001492, 0.2250801, 0.3624103, 0.6852711, 0.4285925, 1.5252000, 0.2028160, 1.1305000, 1.3228670, 1.0714138, 1.2987447, 0.9905181, 1.1132236, 1.3256000, 0.2416405, 0.0124509, 0.5526528, 0.1552121, 0.8654814, 0.3625588, 0.5338424, 0.7492653, 1.1276595, 0.6558984, 0.2711000, 0.4461000, 0.5383000, 0.2989000, 0.4530000, 0.8270000, 0.0343000, 0.7791000, 0.1938000, 0.4393000, 0.8519000, 0.4528000, 0.9922000, 0.0162000, 0.9182000, 0.9645000, 0.3518000, 0.6669000, 0.3190000, 0.1654000, 0.1001000, 0.0772000, 0.8856000, 0.8761000, 0.4234000, 0.1044000, 0.5455000, 0.1933000, 0.4076000, 0.1217000, 0.9143000, 0.3882000, 0.6651000, 0.3297000, 0.8543000, 0.8888000, 0.5808000, 0.5253000, 0.6272000, 0.1826000, 0.8147000, 0.4937000, 0.8284000, 0.7371000, 0.9621000, 0.2708000, 0.5079000, 0.1905000, 0.6925000, 0.0174000, 0.7505000, 0.1376000, 0.2606000, 0.1352000, 0.5230000, 0.8052000, 0.0180000, 0.5632000, 0.7726000, 0.7949000, 0.4381000, 0.8963000, 0.6093000, 0.8539000, 0.2137000, 0.0837000, 0.8966000, 0.3308000, 0.1851000, 0.9861000, 0.7310000, 0.5666000, 0.2140000, 0.9969000, 0.0986000, 0.9827000, 0.6304000, 0.2638000, 0.4658000, 0.0315000, 0.5494000, 0.7904000, 0.1782000, 0.4998000, 0.1796000, 0.8377000, 0.3263000, 0.8730000, 0.2257000, 0.6035000, 0.1654000, 0.6011000, 0.6273000, 0.1087000, 0.2727000, 0.1433000, 0.1672000, 0.5897000, 0.3673000, 0.6090000, 0.9361000, 0.4635000, 0.1261000, 0.6636000, 0.2436000, 0.1089000, 0.3856000, 0.1208000, 0.3295000, 0.2919000, 0.8362000, 0.3044000, 0.1508000, 0.0511000, 0.6881000, 0.8320000, 0.5896000, 0.2544000, 0.8145000, 0.9428000, 0.6640000, 0.8421000, 0.5660000, 0.8751000, 0.7081000, 0.9759000, 0.7859000, 0.0850000, 0.0333000, 0.9319000, 0.5581000, 0.2856000, 0.2819000, 0.5916000, 0.8688000, 0.3929000, 0.5414000, 0.8165000, 0.6751000, 0.4604000, 0.2999000, 0.8199000, 0.8389000, 0.6024000, 0.4926000, 0.8938000, 0.0054000, 0.7205000, 0.2142000, 0.4893000, 0.7855000, 0.5710000, 0.1530000, 0.7053000, 0.5349000, 0.3422000, 0.4415000, 0.6944000, 0.6145000, 0.4457000, 0.4109000, 0.3626000, 0.2617000, 0.6693000, 0.6878000, 0.0065000, 0.1086000, 0.1858000, 0.1775000, 0.2115000, 0.9396000, 0.1698000, 0.7419000, 0.4156000, 0.4991000, 0.9319000, 0.7971000, 0.0330000, 0.0306000, 0.5512000, 0.6327000, 0.9284000, 0.7574000, 0.9577000, 0.9864000, 0.3325000, 0.6996000, 0.2965000, 0.2929000, 0.9992000, 0.0630000, 0.1938000]]

Expected (Unparsed): [[0.20014916079599995,0.22508005411800003,0.3624103046820001,0.6852711440699999,0.42859251000000004,1.5252,0.20281604000000003,1.1305,1.3228669199999998,1.07141379,1.2987447,0.99051812,1.11322365,1.3256,0.24164048,0.012450899999999997,0.5526528399999999,0.15521214000000003,0.86548134,0.36255879999999996,0.53384243,0.7492652299999999,1.12765952,0.65589843,0.2711,0.4461,0.5383,0.2989,0.453,0.827,0.0343,0.7791,0.1938,0.4393,0.8519,0.4528,0.9922,0.0162,0.9182,0.9645,0.3518,0.6669,0.319,0.1654,0.1001,0.0772,0.8856,0.8761,0.4234,0.1044,0.5455,0.1933,0.4076,0.1217,0.9143,0.3882,0.6651,0.3297,0.8543,0.8888,0.5808,0.5253,0.6272,0.1826,0.8147,0.4937,0.8284,0.7371,0.9621,0.2708,0.5079,0.1905,0.6925,0.0174,0.7505,0.1376,0.2606,0.1352,0.523,0.8052,0.018,0.5632,0.7726,0.7949,0.4381,0.8963,0.6093,0.8539,0.2137,0.0837,0.8966,0.3308,0.1851,0.9861,0.731,0.5666,0.214,0.9969,0.0986,0.9827,0.6304,0.2638,0.4658,0.0315,0.5494,0.7904,0.1782,0.4998,0.1796,0.8377,0.3263,0.873,0.2257,0.6035,0.1654,0.6011,0.6273,0.1087,0.2727,0.1433,0.1672,0.5897,0.3673,0.609,0.9361,0.4635,0.1261,0.6636,0.2436,0.1089,0.3856,0.1208,0.3295,0.2919,0.8362,0.3044,0.1508,0.0511,0.6881,0.832,0.5896,0.2544,0.8145,0.9428,0.664,0.8421,0.566,0.8751,0.7081,0.9759,0.7859,0.085,0.0333,0.9319,0.5581,0.2856,0.2819,0.5916,0.8688,0.3929,0.5414,0.8165,0.6751,0.4604,0.2999,0.8199,0.8389,0.6024,0.4926,0.8938,0.0054,0.7205,0.2142,0.4893,0.7855,0.571,0.153,0.7053,0.5349,0.3422,0.4415,0.6944,0.6145,0.4457,0.4109,0.3626,0.2617,0.6693,0.6878,0.0065,0.1086,0.1858,0.1775,0.2115,0.9396,0.1698,0.7419,0.4156,0.4991,0.9319,0.7971,0.033,0.0306,0.5512,0.6327,0.9284,0.7574,0.9577,0.9864,0.3325,0.6996,0.2965,0.2929,0.9992,0.063,0.1938]]

Actual:   [[0.2002, 0.2251, 0.3625, 0.6853, 0.4286, 1.5252, 0.2029, 1.1305, 1.3229, 1.0715, 1.2988, 0.9906, 1.1133, 1.3256, 0.2417, 0.0125, 0.5527, 0.1553, 0.8655, 0.3626, 0.5339, 0.7493, 1.1277, 0.6559, 0.2711, 0.4461, 0.5383, 0.2989, 0.453, 0.827, 0.0343, 0.7791, 0.1938, 0.4393, 0.8519, 0.4528, 0.9922, 0.0162, 0.9182, 0.9645, 0.3518, 0.6669, 0.319, 0.1654, 0.1001, 0.0772, 0.8856, 0.8761, 0.4234, 0.1044, 0.5455, 0.1933, 0.4076, 0.1217, 0.9143, 0.3882, 0.6651, 0.3297, 0.8543, 0.8888, 0.5808, 0.5253, 0.6272, 0.1826, 0.8147, 0.4937, 0.8284, 0.7371, 0.9621, 0.2708, 0.5079, 0.1905, 0.6925, 0.0174, 0.7505, 0.1376, 0.2606, 0.1352, 0.523, 0.8052, 0.018, 0.5632, 0.7726, 0.7949, 0.4381, 0.8963, 0.6093, 0.8539, 0.2137, 0.0837, 0.8966, 0.3308, 0.1851, 0.9861, 0.731, 0.5666, 0.214, 0.9969, 0.0986, 0.9827, 0.6304, 0.2638, 0.4658, 0.0315, 0.5494, 0.7904, 0.1782, 0.4998, 0.1796, 0.8377, 0.3263, 0.873, 0.2257, 0.6035, 0.1654, 0.6011, 0.6273, 0.1087, 0.2727, 0.1433, 0.1672, 0.5897, 0.3673, 0.609, 0.9361, 0.4635, 0.1261, 0.6636, 0.2436, 0.1089, 0.3856, 0.1208, 0.3295, 0.2919, 0.8362, 0.3044, 0.1508, 0.0511, 0.6881, 0.832, 0.5896, 0.2544, 0.8145, 0.9428, 0.664, 0.8421, 0.566, 0.8751, 0.7081, 0.9759, 0.7859, 0.085, 0.0333, 0.9319, 0.5581, 0.2856, 0.2819, 0.5916, 0.8688, 0.3929, 0.5414, 0.8165, 0.6751, 0.4604, 0.2999, 0.8199, 0.8389, 0.6024, 0.4926, 0.8938, 0.0054, 0.7205, 0.2142, 0.4893, 0.7855, 0.571, 0.153, 0.7053, 0.5349, 0.3422, 0.4415, 0.6944, 0.6145, 0.4457, 0.4109, 0.3626, 0.2617, 0.6693, 0.6878, 0.0065, 0.1086, 0.1858, 0.1775, 0.2115, 0.9396, 0.1698, 0.7419, 0.4156, 0.4991, 0.9319, 0.7971, 0.033, 0.0306, 0.5512, 0.6327, 0.9284, 0.7574, 0.9577, 0.9864, 0.3325, 0.6996, 0.2965, 0.2929, 0.9992, 0.063, 0.1938]]

Expected: [[0.2002, 0.2251, 0.3625, 0.6853, 0.4286, 1.5252, 0.2029, 1.1305, 1.3229, 1.0715, 1.2988, 0.9906, 1.1133, 1.3256, 0.2417, 0.0125, 0.5527, 0.1553, 0.8655, 0.3626, 0.5339, 0.7493, 1.1277, 0.6559, 0.2711, 0.4461, 0.5383, 0.2989, 0.453, 0.827, 0.0343, 0.7791, 0.1938, 0.4393, 0.8519, 0.4528, 0.9922, 0.0162, 0.9182, 0.9645, 0.3518, 0.6669, 0.319, 0.1654, 0.1001, 0.0772, 0.8856, 0.8761, 0.4234, 0.1044, 0.5455, 0.1933, 0.4076, 0.1217, 0.9143, 0.3882, 0.6651, 0.3297, 0.8543, 0.8888, 0.5808, 0.5253, 0.6272, 0.1826, 0.8147, 0.4937, 0.8284, 0.7371, 0.9621, 0.2708, 0.5079, 0.1905, 0.6925, 0.0174, 0.7505, 0.1376, 0.2606, 0.1352, 0.523, 0.8052, 0.018, 0.5632, 0.7726, 0.7949, 0.4381, 0.8963, 0.6093, 0.8539, 0.2137, 0.0837, 0.8966, 0.3308, 0.1851, 0.9861, 0.731, 0.5666, 0.214, 0.9969, 0.0986, 0.9827, 0.6304, 0.2638, 0.4658, 0.0315, 0.5494, 0.7904, 0.1782, 0.4998, 0.1796, 0.8377, 0.3263, 0.873, 0.2257, 0.6035, 0.1654, 0.6011, 0.6273, 0.1087, 0.2727, 0.1433, 0.1672, 0.5897, 0.3673, 0.609, 0.9361, 0.4635, 0.1261, 0.6636, 0.2436, 0.1089, 0.3856, 0.1208, 0.3295, 0.2919, 0.8362, 0.3044, 0.1508, 0.0511, 0.6881, 0.832, 0.5896, 0.2544, 0.8145, 0.9428, 0.664, 0.8421, 0.566, 0.8751, 0.7081, 0.9759, 0.7859, 0.085, 0.0333, 0.9319, 0.5581, 0.2856, 0.2819, 0.5916, 0.8688, 0.3929, 0.5414, 0.8165, 0.6751, 0.4604, 0.2999, 0.8199, 0.8389, 0.6024, 0.4926, 0.8938, 0.0054, 0.7205, 0.2142, 0.4893, 0.7855, 0.571, 0.153, 0.7053, 0.5349, 0.3422, 0.4415, 0.6944, 0.6145, 0.4457, 0.4109, 0.3626, 0.2617, 0.6693, 0.6878, 0.0065, 0.1086, 0.1858, 0.1775, 0.2115, 0.9396, 0.1698, 0.7419, 0.4156, 0.4991, 0.9319, 0.7971, 0.033, 0.0306, 0.5512, 0.6327, 0.9284, 0.7574, 0.9577, 0.9864, 0.3325, 0.6996, 0.2965, 0.2929, 0.9992, 0.063, 0.1938]]