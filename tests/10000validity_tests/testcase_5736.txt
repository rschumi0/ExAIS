import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat80741 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Mul32210 = tf.keras.layers.Input(shape=([1, 1, 1]))
in1Mul32210 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0PRe91101 = tf.keras.layers.Input(shape=([2, 2]))
in0Con69521 = tf.keras.layers.Input(shape=([2, 1, 2]))

Bat80741 = keras.layers.BatchNormalization(axis=3, epsilon=0.31270258927787836,  name = 'Bat80741', )(in0Bat80741)
Mul32210 = keras.layers.Multiply(name = 'Mul32210', )([in0Mul32210,in1Mul32210])
Zer22825 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer22825', )(Mul32210)
Add46760 = keras.layers.Add(name = 'Add46760', )([Bat80741,Zer22825])
Sep92834 = keras.layers.SeparableConv2D(3, (1, 1),strides=(1, 1), padding='valid', name = 'Sep92834', )(Add46760)
PRe91101 = keras.layers.PReLU(name = 'PRe91101', input_shape=(2, 2))(in0PRe91101)
Res48355 = keras.layers.Reshape((2, 2, 1), name = 'Res48355', )(PRe91101)
Dep9919 = keras.layers.DepthwiseConv2D((1, 2),strides=(2, 2), padding='same', name = 'Dep9919', )(Res48355)
Zer91855 = keras.layers.ZeroPadding2D(padding=((1, 0), (0, 0)), name = 'Zer91855', )(Dep9919)
Con69521 = keras.layers.Concatenate(axis=3, name = 'Con69521', )([Zer91855,in0Con69521])
Min64812 = keras.layers.Minimum(name = 'Min64812', )([Sep92834,Con69521])
model = tf.keras.models.Model(inputs=[in0Bat80741,in0Mul32210,in1Mul32210,in0PRe91101,in0Con69521], outputs=Min64812)
w = model.get_layer('Bat80741').get_weights() 
w[0] = np.array([0.1787])
w[1] = np.array([0.3082])
w[2] = np.array([0.9547])
w[3] = np.array([0.8427])
model.get_layer('Bat80741').set_weights(w) 
w = model.get_layer('Sep92834').get_weights() 
w[0] = np.array([[[[0.7061]]]])
w[1] = np.array([[[[0.6475, 0.576, 0.7934]]]])
w[2] = np.array([0, 0, 0])
model.get_layer('Sep92834').set_weights(w) 
w = model.get_layer('PRe91101').get_weights() 
w[0] = np.array([[0.7308, 0.7322], [0.0849, 0.7344]])
model.get_layer('PRe91101').set_weights(w) 
w = model.get_layer('Dep9919').get_weights() 
w[0] = np.array([[[[0.3105]], [[0.0575]]]])
w[1] = np.array([0])
model.get_layer('Dep9919').set_weights(w) 
in0Bat80741 = tf.constant([[[[1.5805]], [[1.7212]]]])
in0Mul32210 = tf.constant([[[[0.0025]]]])
in1Mul32210 = tf.constant([[[[0.1648]]]])
in0PRe91101 = tf.constant([[[0.7689, 0.498], [0.9851, 0.2104]]])
in0Con69521 = tf.constant([[[[0.0884, 0.9969]], [[0.8739, 0.5873]]]])
print (np.array2string(model.predict([in0Bat80741,in0Mul32210,in1Mul32210,in0PRe91101,in0Con69521],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min64812.png')

LBat80741 = batch_normalization_layer([[[[1.5805]], [[1.7212]]]], 3, 0.31270258927787836, [0.1787], [0.3082], [0.9547], [0.8427], Bat80741), 
LMul32210 = multiply_layer([[[[[0.0025]]]], [[[[0.1648]]]]], Mul32210), 
LZer22825 = zero_padding2D_layer(Mul32210, 1, 0, 0, 0, Zer22825), 
LAdd46760 = add_layer([Bat80741,Zer22825], Add46760), 
LSep92834 = separable_conv2D_layer(Add46760, 1, 1,[[[[[0.7061]]]],[[[[0.6475, 0.576, 0.7934]]]]],[0, 0, 0], 1, 1, false, Sep92834), 
LPRe91101 = prelu_layer([[[0.7689, 0.498], [0.9851, 0.2104]]], [[0.7308, 0.7322], [0.0849, 0.7344]], PRe91101), 
LRes48355 = reshape_layer(PRe91101, [2, 2, 1], Res48355), 
LDep9919 = depthwise_conv2D_layer(Res48355, 1, 2,[[[[0.3105]], [[0.0575]]]],[0], 2, 2, true, Dep9919), 
LZer91855 = zero_padding2D_layer(Dep9919, 1, 0, 0, 0, Zer91855), 
LCon69521 = concatenate_layer([Zer91855,[[[[0.0884, 0.9969]], [[0.8739, 0.5873]]]]], 3, Con69521), 
LMin64812 = minimum_layer([Sep92834,Con69521], Min64812), 
exec_layers([LBat80741,LMul32210,LZer22825,LAdd46760,LSep92834,LPRe91101,LRes48355,LDep9919,LZer91855,LCon69521,LMin64812],["Bat80741","Mul32210","Zer22825","Add46760","Sep92834","PRe91101","Res48355","Dep9919","Zer91855","Con69521","Min64812"],Min64812,"Min64812")

Actual (Unparsed): [[[[0.0000000, 0.0884000, 0.2309441]], [[0.1993581, 0.1773440, 0.2442791]]]]

Expected (Unparsed): [[[[0,0.0884,0.2309440595388764]],[[0.19935807343020165,0.17734401590084348,0.24427906634675212]]]]

Actual:   [[[[0, 0.0884, 0.231]], [[0.1994, 0.1774, 0.2443]]]]

Expected: [[[[0, 0.0884, 0.231]], [[0.1994, 0.1774, 0.2443]]]]