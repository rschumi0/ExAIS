import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Dot34448 = tf.keras.layers.Input(shape=([3, 3]))
in1Dot34448 = tf.keras.layers.Input(shape=([3, 3]))
in0Con49152 = tf.keras.layers.Input(shape=([3, 9]))
in0Ave8293 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Ave8293 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con44438 = tf.keras.layers.Input(shape=([2, 2, 3, 1]))
in0Sub34194 = tf.keras.layers.Input(shape=([2, 2, 3, 2]))
in1Sub34194 = tf.keras.layers.Input(shape=([2, 2, 3, 2]))
in0Min74096 = tf.keras.layers.Input(shape=([2, 2]))
in1Min74096 = tf.keras.layers.Input(shape=([2, 2]))
in0Con73089 = tf.keras.layers.Input(shape=([2, 10]))

Dot34448 = keras.layers.Dot(axes=(1, 2), name = 'Dot34448', )([in0Dot34448,in1Dot34448])
Con49152 = keras.layers.Concatenate(axis=2, name = 'Con49152', )([Dot34448,in0Con49152])
Ave8293 = keras.layers.Average(name = 'Ave8293', )([in0Ave8293,in1Ave8293])
Res45048 = keras.layers.Reshape((2, 1), name = 'Res45048', )(Ave8293)
Per81038 = keras.layers.Permute((2,1), name = 'Per81038',)(Res45048)
Res82624 = keras.layers.Reshape((1, 2, 1), name = 'Res82624', )(Per81038)
Res63759 = keras.layers.Reshape((1, 2, 1, 1), name = 'Res63759', )(Res82624)
Zer72930 = keras.layers.ZeroPadding3D(padding=((1, 0), (0, 0), (2, 0)), name = 'Zer72930', )(Res63759)
Con44438 = keras.layers.Concatenate(axis=4, name = 'Con44438', )([Zer72930,in0Con44438])
Sub34194 = keras.layers.Subtract(name = 'Sub34194', )([in0Sub34194,in1Sub34194])
Max95007 = keras.layers.Maximum(name = 'Max95007', )([Con44438,Sub34194])
Res71126 = keras.layers.Reshape((2, 2, 6), name = 'Res71126', )(Max95007)
Res40053 = keras.layers.Reshape((2, 12), name = 'Res40053', )(Res71126)
Min74096 = keras.layers.Minimum(name = 'Min74096', )([in0Min74096,in1Min74096])
Con73089 = keras.layers.Concatenate(axis=2, name = 'Con73089', )([Min74096,in0Con73089])
Ave38200 = keras.layers.Average(name = 'Ave38200', )([Res40053,Con73089])
Zer25818 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer25818', )(Ave38200)
Min63853 = keras.layers.Minimum(name = 'Min63853', )([Con49152,Zer25818])
model = tf.keras.models.Model(inputs=[in0Dot34448,in1Dot34448,in0Con49152,in0Ave8293,in1Ave8293,in0Con44438,in0Sub34194,in1Sub34194,in0Min74096,in1Min74096,in0Con73089], outputs=Min63853)
in0Dot34448 = tf.constant([[[0.4269, 0.4086, 0.1488], [0.1253, 0.6533, 0.6641], [0.4234, 0.0902, 0.3517]]])
in1Dot34448 = tf.constant([[[0.3926, 0.351, 0.9855], [0.3019, 0.6925, 0.557], [0.839, 0.3849, 0.4143]]])
in0Con49152 = tf.constant([[[0.0925, 0.7977, 0.0362, 0.4672, 0.1058, 0.6213, 0.754, 0.0669, 0.4668], [0.2472, 0.3529, 0.1439, 0.7797, 0.1648, 0.1752, 0.5813, 0.8073, 0.3203], [0.1792, 0.8792, 0.8482, 0.7491, 0.2132, 0.5741, 0.5935, 0.8036, 0.7543]]])
in0Ave8293 = tf.constant([[[[0.9679]], [[0.5388]]]])
in1Ave8293 = tf.constant([[[[0.7161]], [[0.8885]]]])
in0Con44438 = tf.constant([[[[[0.2467], [0.7409], [0.1814]], [[0.8525], [0.0276], [0.3278]]], [[[0.6967], [0.4226], [0.062]], [[0.4518], [0.5749], [0.4331]]]]])
in0Sub34194 = tf.constant([[[[[0.8282, 0.3677], [0.8521, 0.4187], [0.8614, 0.5213]], [[0.1754, 0.9344], [0.9856, 0.7075], [0.9967, 0.7396]]], [[[0.1987, 0.8582], [0.1341, 0.8652], [0.7334, 0.4462]], [[0.7319, 0.1349], [0.3496, 0.8913], [0.8597, 0.6876]]]]])
in1Sub34194 = tf.constant([[[[[0.6784, 0.0672], [0.0017, 0.3665], [0.8619, 0.9726]], [[0.8844, 0.0776], [0.3427, 0.2202], [0.2228, 0.9532]]], [[[0.5501, 0.1146], [0.8679, 0.9088], [0.4, 0.737]], [[0.5301, 0.9764], [0.983, 0.6399], [0.7196, 0.617]]]]])
in0Min74096 = tf.constant([[[0.5476, 0.4619], [0.7993, 0.0664]]])
in1Min74096 = tf.constant([[[0.9043, 0.0202], [0.0759, 0.6541]]])
in0Con73089 = tf.constant([[[0.4336, 0.4411, 0.2168, 0.2417, 0.8432, 0.9134, 0.1705, 0.2319, 0.0835, 0.4451], [0.792, 0.1354, 0.622, 0.5491, 0.9219, 0.6865, 0.399, 0.1632, 0.4313, 0.5479]]])
print (np.array2string(model.predict([in0Dot34448,in1Dot34448,in0Con49152,in0Ave8293,in1Ave8293,in0Con44438,in0Sub34194,in1Sub34194,in0Min74096,in1Min74096,in0Con73089],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min63853.png')

LDot34448 = dot_layer([[[0.4269, 0.4086, 0.1488], [0.1253, 0.6533, 0.6641], [0.4234, 0.0902, 0.3517]]], [[[0.3926, 0.351, 0.9855], [0.3019, 0.6925, 0.557], [0.839, 0.3849, 0.4143]]], 1, 2, Dot34448), 
LCon49152 = concatenate_layer([Dot34448,[[[0.0925, 0.7977, 0.0362, 0.4672, 0.1058, 0.6213, 0.754, 0.0669, 0.4668], [0.2472, 0.3529, 0.1439, 0.7797, 0.1648, 0.1752, 0.5813, 0.8073, 0.3203], [0.1792, 0.8792, 0.8482, 0.7491, 0.2132, 0.5741, 0.5935, 0.8036, 0.7543]]]], 2, Con49152), 
LAve8293 = average_layer([[[[[0.9679]], [[0.5388]]]], [[[[0.7161]], [[0.8885]]]]], Ave8293), 
LRes45048 = reshape_layer(Ave8293, [2, 1], Res45048), 
LPer81038 = permute_layer(Res45048, 2,1, Per81038), 
LRes82624 = reshape_layer(Per81038, [1, 2, 1], Res82624), 
LRes63759 = reshape_layer(Res82624, [1, 2, 1, 1], Res63759), 
LZer72930 = zero_padding3D_layer(Res63759, 1, 0, 0, 0, 2, 0, Zer72930), 
LCon44438 = concatenate_layer([Zer72930,[[[[[0.2467], [0.7409], [0.1814]], [[0.8525], [0.0276], [0.3278]]], [[[0.6967], [0.4226], [0.062]], [[0.4518], [0.5749], [0.4331]]]]]], 4, Con44438), 
LSub34194 = subtract_layer([[[[[0.8282, 0.3677], [0.8521, 0.4187], [0.8614, 0.5213]], [[0.1754, 0.9344], [0.9856, 0.7075], [0.9967, 0.7396]]], [[[0.1987, 0.8582], [0.1341, 0.8652], [0.7334, 0.4462]], [[0.7319, 0.1349], [0.3496, 0.8913], [0.8597, 0.6876]]]]], [[[[[0.6784, 0.0672], [0.0017, 0.3665], [0.8619, 0.9726]], [[0.8844, 0.0776], [0.3427, 0.2202], [0.2228, 0.9532]]], [[[0.5501, 0.1146], [0.8679, 0.9088], [0.4, 0.737]], [[0.5301, 0.9764], [0.983, 0.6399], [0.7196, 0.617]]]]], Sub34194), 
LMax95007 = maximum_layer([Con44438,Sub34194], Max95007), 
LRes71126 = reshape_layer(Max95007, [2, 2, 6], Res71126), 
LRes40053 = reshape_layer(Res71126, [2, 12], Res40053), 
LMin74096 = minimum_layer([[[[0.5476, 0.4619], [0.7993, 0.0664]]], [[[0.9043, 0.0202], [0.0759, 0.6541]]]], Min74096), 
LCon73089 = concatenate_layer([Min74096,[[[0.4336, 0.4411, 0.2168, 0.2417, 0.8432, 0.9134, 0.1705, 0.2319, 0.0835, 0.4451], [0.792, 0.1354, 0.622, 0.5491, 0.9219, 0.6865, 0.399, 0.1632, 0.4313, 0.5479]]]], 2, Con73089), 
LAve38200 = average_layer([Res40053,Con73089], Ave38200), 
LZer25818 = zero_padding1D_layer(Ave38200, 1, 0, Zer25818), 
LMin63853 = minimum_layer([Con49152,Zer25818], Min63853), 
exec_layers([LDot34448,LCon49152,LAve8293,LRes45048,LPer81038,LRes82624,LRes63759,LZer72930,LCon44438,LSub34194,LMax95007,LRes71126,LRes40053,LMin74096,LCon73089,LAve38200,LZer25818,LMin63853],["Dot34448","Con49152","Ave8293","Res45048","Per81038","Res82624","Res63759","Zer72930","Con44438","Sub34194","Max95007","Res71126","Res40053","Min74096","Con73089","Ave38200","Zer25818","Min63853"],Min63853,"Min63853")

Actual (Unparsed): [[[0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000], [0.3487000, 0.1603500, 0.6316404, 0.2472000, 0.1084000, 0.1439000, 0.4216000, 0.1648000, 0.1752000, 0.3596000, 0.4287000, 0.3203000], [0.0379500, 0.4050000, 0.3960000, 0.1792000, 0.7320000, 0.3055500, 0.5618500, 0.2132000, 0.1995000, 0.3690500, 0.5724750, 0.4905000]]]

Expected (Unparsed): [[[0,0,0,0,0,0,0,0,0,0,0,0],[0.3487,0.16035000000000002,0.6316404299999999,0.2472,0.1084,0.1439,0.4216,0.1648,0.1752,0.35960000000000003,0.4287,0.3203],[0.03795,0.40499999999999997,0.396,0.1792,0.732,0.30555,0.56185,0.2132,0.1995,0.36905,0.572475,0.49050000000000005]]]

Actual:   [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.3487, 0.1604, 0.6317, 0.2472, 0.1084, 0.1439, 0.4216, 0.1648, 0.1752, 0.3596, 0.4287, 0.3203], [0.038, 0.405, 0.396, 0.1792, 0.732, 0.3056, 0.5619, 0.2132, 0.1995, 0.3691, 0.5725, 0.4905]]]

Expected: [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.3487, 0.1604, 0.6317, 0.2472, 0.1084, 0.1439, 0.4216, 0.1648, 0.1752, 0.3597, 0.4287, 0.3203], [0.038, 0.405, 0.396, 0.1792, 0.732, 0.3056, 0.5619, 0.2132, 0.1995, 0.3691, 0.5725, 0.4906]]]