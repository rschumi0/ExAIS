import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0PRe70262 = tf.keras.layers.Input(shape=([2, 1, 1, 1]))
in0Con54533 = tf.keras.layers.Input(shape=([3]))
in0Add89991 = tf.keras.layers.Input(shape=([2, 2]))
in1Add89991 = tf.keras.layers.Input(shape=([2, 2]))
in0Glo23272 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in0Con41548 = tf.keras.layers.Input(shape=([3]))

PRe70262 = keras.layers.PReLU(name = 'PRe70262', input_shape=(2, 1, 1, 1))(in0PRe70262)
Res38696 = keras.layers.Reshape((2, 1, 1), name = 'Res38696', )(PRe70262)
Max53765 = keras.layers.MaxPool2D(pool_size=(2, 1), strides=(2, 1), padding='same', name = 'Max53765', )(Res38696)
Res98228 = keras.layers.Reshape((1, 1), name = 'Res98228', )(Max53765)
Fla18259 = keras.layers.Flatten(name = 'Fla18259', )(Res98228)
Con54533 = keras.layers.Concatenate(axis=1, name = 'Con54533', )([Fla18259,in0Con54533])
Add89991 = keras.layers.Add(name = 'Add89991', )([in0Add89991,in1Add89991])
Fla43734 = keras.layers.Flatten(name = 'Fla43734', )(Add89991)
Glo23272 = keras.layers.GlobalAveragePooling3D(name = 'Glo23272', )(in0Glo23272)
Con41548 = keras.layers.Concatenate(axis=1, name = 'Con41548', )([Glo23272,in0Con41548])
Min13433 = keras.layers.Minimum(name = 'Min13433', )([Fla43734,Con41548])
Min16940 = keras.layers.Minimum(name = 'Min16940', )([Con54533,Min13433])
Lay12914 = keras.layers.LayerNormalization(axis=1, epsilon=2.775833059373019, name = 'Lay12914', )(Min16940)
model = tf.keras.models.Model(inputs=[in0PRe70262,in0Con54533,in0Add89991,in1Add89991,in0Glo23272,in0Con41548], outputs=Lay12914)
w = model.get_layer('PRe70262').get_weights() 
w[0] = np.array([[[[0.3183]]], [[[0.5876]]]])
model.get_layer('PRe70262').set_weights(w) 
in0PRe70262 = tf.constant([[[[[0.8546]]], [[[0.0886]]]]])
in0Con54533 = tf.constant([[0.5705, 0.598, 0.7102]])
in0Add89991 = tf.constant([[[0.3624, 0.4203], [0.5662, 0.0616]]])
in1Add89991 = tf.constant([[[0.3803, 0.9154], [0.8504, 0.5533]]])
in0Glo23272 = tf.constant([[[[[1.2893], [1.1549]], [[1.3282], [1.7744]]], [[[1.3051], [1.1889]], [[1.3887], [1.3751]]]]])
in0Con41548 = tf.constant([[0.4208, 0.4949, 0.9919]])
print (np.array2string(model.predict([in0PRe70262,in0Con54533,in0Add89991,in1Add89991,in0Glo23272,in0Con41548],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Lay12914.png')

LPRe70262 = prelu_layer([[[[[0.8546]]], [[[0.0886]]]]], [[[[0.3183]]], [[[0.5876]]]], PRe70262), 
LRes38696 = reshape_layer(PRe70262, [2, 1, 1], Res38696), 
LMax53765 = max_pool2D_layer(Res38696, 2, 1, 2, 1, true, Max53765), 
LRes98228 = reshape_layer(Max53765, [1, 1], Res98228), 
LFla18259 = flatten_layer(Res98228, Fla18259), 
LCon54533 = concatenate_layer([Fla18259,[[0.5705, 0.598, 0.7102]]], 1, Con54533), 
LAdd89991 = add_layer([[[[0.3624, 0.4203], [0.5662, 0.0616]]], [[[0.3803, 0.9154], [0.8504, 0.5533]]]], Add89991), 
LFla43734 = flatten_layer(Add89991, Fla43734), 
LGlo23272 = global_average_pooling3D_layer([[[[[1.2893], [1.1549]], [[1.3282], [1.7744]]], [[[1.3051], [1.1889]], [[1.3887], [1.3751]]]]], Glo23272), 
LCon41548 = concatenate_layer([Glo23272,[[0.4208, 0.4949, 0.9919]]], 1, Con41548), 
LMin13433 = minimum_layer([Fla43734,Con41548], Min13433), 
LMin16940 = minimum_layer([Con54533,Min13433], Min16940), 
LLay12914 = layer_normalization_layer(Min16940, 1, 2.775833059373019, Lay12914), 
exec_layers([LPRe70262,LRes38696,LMax53765,LRes98228,LFla18259,LCon54533,LAdd89991,LFla43734,LGlo23272,LCon41548,LMin13433,LMin16940,LLay12914],["PRe70262","Res38696","Max53765","Res98228","Fla18259","Con54533","Add89991","Fla43734","Glo23272","Con41548","Min13433","Min16940","Lay12914"],Lay12914,"Lay12914")

Actual (Unparsed): [[0.1043812, -0.0883088, -0.0439524, 0.0278799]]

Expected (Unparsed): [[0.1043812585859202,-0.0883087895219376,-0.04395236651854443,0.027879897454561924]]

Actual:   [[0.1044, -0.0883, -0.0439, 0.0279]]

Expected: [[0.1044, -0.0883, -0.0439, 0.0279]]