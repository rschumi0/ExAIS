import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sof66424 = tf.keras.layers.Input(shape=([1, 1, 2, 2]))
in0Min97176 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))
in1Min97176 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))
in0Dot81316 = tf.keras.layers.Input(shape=([3]))
in1Dot81316 = tf.keras.layers.Input(shape=([3]))
in0Con34602 = tf.keras.layers.Input(shape=([3]))
in0Fla24827 = tf.keras.layers.Input(shape=([2, 3, 2]))
in0Con71339 = tf.keras.layers.Input(shape=([12, 23]))

Sof66424 = keras.layers.Softmax(axis=1, name = 'Sof66424', input_shape=(1, 1, 2, 2))(in0Sof66424)
Zer77721 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer77721', )(Sof66424)
Res17185 = keras.layers.Reshape((3, 3, 8), name = 'Res17185', )(Zer77721)
Res27324 = keras.layers.Reshape((3, 24), name = 'Res27324', )(Res17185)
Zer59057 = keras.layers.ZeroPadding1D(padding=((9, 0)), name = 'Zer59057', )(Res27324)
Min97176 = keras.layers.Minimum(name = 'Min97176', )([in0Min97176,in1Min97176])
Res63362 = keras.layers.Reshape((2, 1, 2), name = 'Res63362', )(Min97176)
Res83052 = keras.layers.Reshape((2, 2), name = 'Res83052', )(Res63362)
Fla56112 = keras.layers.Flatten(name = 'Fla56112', )(Res83052)
Dot81316 = keras.layers.Dot(axes=(1, 1), name = 'Dot81316', )([in0Dot81316,in1Dot81316])
Con34602 = keras.layers.Concatenate(axis=1, name = 'Con34602', )([Dot81316,in0Con34602])
Mul74878 = keras.layers.Multiply(name = 'Mul74878', )([Fla56112,Con34602])
Res13552 = keras.layers.Reshape((4, 1), name = 'Res13552', )(Mul74878)
Zer37047 = keras.layers.ZeroPadding1D(padding=((8, 0)), name = 'Zer37047', )(Res13552)
Fla24827 = keras.layers.Flatten(name = 'Fla24827', )(in0Fla24827)
Res41432 = keras.layers.Reshape((12, 1), name = 'Res41432', )(Fla24827)
PRe64253 = keras.layers.PReLU(name = 'PRe64253', )(Res41432)
Add88132 = keras.layers.Add(name = 'Add88132', )([Zer37047,PRe64253])
Con71339 = keras.layers.Concatenate(axis=2, name = 'Con71339', )([Add88132,in0Con71339])
Ave59545 = keras.layers.Average(name = 'Ave59545', )([Zer59057,Con71339])
model = tf.keras.models.Model(inputs=[in0Sof66424,in0Min97176,in1Min97176,in0Dot81316,in1Dot81316,in0Con34602,in0Fla24827,in0Con71339], outputs=Ave59545)
w = model.get_layer('PRe64253').get_weights() 
w[0] = np.array([[0.1584], [0.2282], [0.3029], [0.4219], [0.5167], [0.4036], [0.3617], [0.5908], [0.3463], [0.4559], [0.4765], [0.4979]])
model.get_layer('PRe64253').set_weights(w) 
in0Sof66424 = tf.constant([[[[[0.2613, 0.0804], [0.6354, 0.9756]]]]])
in0Min97176 = tf.constant([[[[[0.1914, 0.9036]]], [[[0.4439, 0.3162]]]]])
in1Min97176 = tf.constant([[[[[0.897, 0.4961]]], [[[0.9916, 0.5222]]]]])
in0Dot81316 = tf.constant([[0.8314, 0.9273, 0.8565]])
in1Dot81316 = tf.constant([[0.0176, 0.8858, 0.0987]])
in0Con34602 = tf.constant([[0.7344, 0.0069, 0.4914]])
in0Fla24827 = tf.constant([[[[1.5739, 1.9221], [1.5259, 1.224], [1.0956, 1.9306]], [[1.3671, 1.3095], [1.4047, 1.359], [1.564, 1.0664]]]])
in0Con71339 = tf.constant([[[0.4043, 0.443, 0.3881, 0.7781, 0.6046, 0.3746, 0.9479, 0.4304, 0.1106, 0.3085, 0.801, 0.189, 0.5667, 0.2005, 0.8474, 0.0812, 0.3756, 0.3648, 0.7661, 0.1053, 0.8768, 0.7679, 0.8143], [0.4435, 0.7542, 0.4073, 0.7173, 0.9823, 0.2133, 0.987, 0.0624, 0.9116, 0.4978, 0.5792, 0.8363, 0.9809, 0.001, 0.3359, 0.1376, 0.1951, 0.5641, 0.6058, 0.6381, 0.3489, 0.5563, 0.001], [0.0659, 0.8192, 0.98, 0.0568, 0.8428, 0.4599, 0.1569, 0.1343, 0.0169, 0.2784, 0.5147, 0.126, 0.8045, 0.8124, 0.6187, 0.3399, 0.3773, 0.7681, 0.8676, 0.6661, 0.0151, 0.5384, 0.2105], [0.7535, 0.3788, 0.6705, 0.8309, 0.4666, 0.4553, 0.2233, 0.9907, 0.329, 0.675, 0.2208, 0.1325, 0.0141, 0.8086, 0.0868, 0.8951, 0.194, 0.5124, 0.0288, 0.9156, 0.2219, 0.812, 0.8269], [0.161, 0.1886, 0.3882, 0.3822, 0.064, 0.8685, 0.2589, 0.6766, 0.9174, 0.9502, 0.3424, 0.5076, 0.8282, 0.7324, 0.4271, 0.4748, 0.0238, 0.1582, 0.276, 0.2136, 0.4604, 0.6618, 0.9492], [0.8019, 0.4905, 0.8009, 0.9408, 0.5941, 0.8147, 0.0676, 0.3958, 0.4811, 0.0614, 0.5787, 0.4963, 0.7153, 0.121, 0.5778, 0.0911, 0.9957, 0.7917, 0.8066, 0.7761, 0.4635, 0.3873, 0.8412], [0.9304, 0.6238, 0.703, 0.4298, 0.6612, 0.9794, 0.1397, 0.72, 0.2185, 0.3405, 0.8465, 0.0141, 0.2014, 0.3539, 0.4557, 0.3575, 0.7991, 0.7895, 0.3586, 0.8266, 0.3824, 0.5122, 0.4984], [0.8618, 0.9949, 0.8733, 0.3383, 0.3679, 0.6808, 0.461, 0.0087, 0.5907, 0.127, 0.7642, 0.6299, 0.9712, 0.8034, 0.3256, 0.462, 0.2792, 0.6342, 0.3857, 0.8438, 0.329, 0.2536, 0.8518], [0.8471, 0.4955, 0.0609, 0.6669, 0.1953, 0.0631, 0.621, 0.2986, 0.2739, 0.165, 0.434, 0.1178, 0.9949, 0.7001, 0.7374, 0.8982, 0.8669, 0.1504, 0.7972, 0.5294, 0.8722, 0.6652, 0.0948], [0.3078, 0.652, 0.1256, 0.9233, 0.847, 0.0647, 0.1588, 0.1691, 0.7301, 0.3932, 0.2326, 0.4734, 0.5191, 0.3541, 0.0278, 0.5447, 0.6279, 0.586, 0.259, 0.1226, 0.8715, 0.4814, 0.9966], [0.984, 0.208, 0.0654, 0.3248, 0.4223, 0.3079, 0.1241, 0.8689, 0.8368, 0.1016, 0.9349, 0.3161, 0.4177, 0.388, 0.7662, 0.566, 0.4336, 0.9149, 0.773, 0.5548, 0.2903, 0.0839, 0.0437], [0.1125, 0.3581, 0.5785, 0.3259, 0.4424, 0.5464, 0.7642, 0.398, 0.9344, 0.7419, 0.668, 0.1417, 0.0658, 0.518, 0.7093, 0.1179, 0.0826, 0.9786, 0.1247, 0.8537, 0.0035, 0.1993, 0.2055]]])
print (np.array2string(model.predict([in0Sof66424,in0Min97176,in1Min97176,in0Dot81316,in1Dot81316,in0Con34602,in0Fla24827,in0Con71339],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Ave59545.png')

LSof66424 = softmax_layer([[[[[0.2613, 0.0804], [0.6354, 0.9756]]]]], 1, Sof66424), 
LZer77721 = zero_padding3D_layer(Sof66424, 1, 1, 1, 1, 1, 1, Zer77721), 
LRes17185 = reshape_layer(Zer77721, [3, 3, 8], Res17185), 
LRes27324 = reshape_layer(Res17185, [3, 24], Res27324), 
LZer59057 = zero_padding1D_layer(Res27324, 9, 0, Zer59057), 
LMin97176 = minimum_layer([[[[[[0.1914, 0.9036]]], [[[0.4439, 0.3162]]]]], [[[[[0.897, 0.4961]]], [[[0.9916, 0.5222]]]]]], Min97176), 
LRes63362 = reshape_layer(Min97176, [2, 1, 2], Res63362), 
LRes83052 = reshape_layer(Res63362, [2, 2], Res83052), 
LFla56112 = flatten_layer(Res83052, Fla56112), 
LDot81316 = dot_layer([[0.8314, 0.9273, 0.8565]], [[0.0176, 0.8858, 0.0987]], 1, 1, Dot81316), 
LCon34602 = concatenate_layer([Dot81316,[[0.7344, 0.0069, 0.4914]]], 1, Con34602), 
LMul74878 = multiply_layer([Fla56112,Con34602], Mul74878), 
LRes13552 = reshape_layer(Mul74878, [4, 1], Res13552), 
LZer37047 = zero_padding1D_layer(Res13552, 8, 0, Zer37047), 
LFla24827 = flatten_layer([[[[1.5739, 1.9221], [1.5259, 1.224], [1.0956, 1.9306]], [[1.3671, 1.3095], [1.4047, 1.359], [1.564, 1.0664]]]], Fla24827), 
LRes41432 = reshape_layer(Fla24827, [12, 1], Res41432), 
LPRe64253 = prelu_layer(Res41432, [[0.1584], [0.2282], [0.3029], [0.4219], [0.5167], [0.4036], [0.3617], [0.5908], [0.3463], [0.4559], [0.4765], [0.4979]], PRe64253), 
LAdd88132 = add_layer([Zer37047,PRe64253], Add88132), 
LCon71339 = concatenate_layer([Add88132,[[[0.4043, 0.443, 0.3881, 0.7781, 0.6046, 0.3746, 0.9479, 0.4304, 0.1106, 0.3085, 0.801, 0.189, 0.5667, 0.2005, 0.8474, 0.0812, 0.3756, 0.3648, 0.7661, 0.1053, 0.8768, 0.7679, 0.8143], [0.4435, 0.7542, 0.4073, 0.7173, 0.9823, 0.2133, 0.987, 0.0624, 0.9116, 0.4978, 0.5792, 0.8363, 0.9809, 0.001, 0.3359, 0.1376, 0.1951, 0.5641, 0.6058, 0.6381, 0.3489, 0.5563, 0.001], [0.0659, 0.8192, 0.98, 0.0568, 0.8428, 0.4599, 0.1569, 0.1343, 0.0169, 0.2784, 0.5147, 0.126, 0.8045, 0.8124, 0.6187, 0.3399, 0.3773, 0.7681, 0.8676, 0.6661, 0.0151, 0.5384, 0.2105], [0.7535, 0.3788, 0.6705, 0.8309, 0.4666, 0.4553, 0.2233, 0.9907, 0.329, 0.675, 0.2208, 0.1325, 0.0141, 0.8086, 0.0868, 0.8951, 0.194, 0.5124, 0.0288, 0.9156, 0.2219, 0.812, 0.8269], [0.161, 0.1886, 0.3882, 0.3822, 0.064, 0.8685, 0.2589, 0.6766, 0.9174, 0.9502, 0.3424, 0.5076, 0.8282, 0.7324, 0.4271, 0.4748, 0.0238, 0.1582, 0.276, 0.2136, 0.4604, 0.6618, 0.9492], [0.8019, 0.4905, 0.8009, 0.9408, 0.5941, 0.8147, 0.0676, 0.3958, 0.4811, 0.0614, 0.5787, 0.4963, 0.7153, 0.121, 0.5778, 0.0911, 0.9957, 0.7917, 0.8066, 0.7761, 0.4635, 0.3873, 0.8412], [0.9304, 0.6238, 0.703, 0.4298, 0.6612, 0.9794, 0.1397, 0.72, 0.2185, 0.3405, 0.8465, 0.0141, 0.2014, 0.3539, 0.4557, 0.3575, 0.7991, 0.7895, 0.3586, 0.8266, 0.3824, 0.5122, 0.4984], [0.8618, 0.9949, 0.8733, 0.3383, 0.3679, 0.6808, 0.461, 0.0087, 0.5907, 0.127, 0.7642, 0.6299, 0.9712, 0.8034, 0.3256, 0.462, 0.2792, 0.6342, 0.3857, 0.8438, 0.329, 0.2536, 0.8518], [0.8471, 0.4955, 0.0609, 0.6669, 0.1953, 0.0631, 0.621, 0.2986, 0.2739, 0.165, 0.434, 0.1178, 0.9949, 0.7001, 0.7374, 0.8982, 0.8669, 0.1504, 0.7972, 0.5294, 0.8722, 0.6652, 0.0948], [0.3078, 0.652, 0.1256, 0.9233, 0.847, 0.0647, 0.1588, 0.1691, 0.7301, 0.3932, 0.2326, 0.4734, 0.5191, 0.3541, 0.0278, 0.5447, 0.6279, 0.586, 0.259, 0.1226, 0.8715, 0.4814, 0.9966], [0.984, 0.208, 0.0654, 0.3248, 0.4223, 0.3079, 0.1241, 0.8689, 0.8368, 0.1016, 0.9349, 0.3161, 0.4177, 0.388, 0.7662, 0.566, 0.4336, 0.9149, 0.773, 0.5548, 0.2903, 0.0839, 0.0437], [0.1125, 0.3581, 0.5785, 0.3259, 0.4424, 0.5464, 0.7642, 0.398, 0.9344, 0.7419, 0.668, 0.1417, 0.0658, 0.518, 0.7093, 0.1179, 0.0826, 0.9786, 0.1247, 0.8537, 0.0035, 0.1993, 0.2055]]]], 2, Con71339), 
LAve59545 = average_layer([Zer59057,Con71339], Ave59545), 
exec_layers([LSof66424,LZer77721,LRes17185,LRes27324,LZer59057,LMin97176,LRes63362,LRes83052,LFla56112,LDot81316,LCon34602,LMul74878,LRes13552,LZer37047,LFla24827,LRes41432,LPRe64253,LAdd88132,LCon71339,LAve59545],["Sof66424","Zer77721","Res17185","Res27324","Zer59057","Min97176","Res63362","Res83052","Fla56112","Dot81316","Con34602","Mul74878","Res13552","Zer37047","Fla24827","Res41432","PRe64253","Add88132","Con71339","Ave59545"],Ave59545,"Ave59545")

Actual (Unparsed): [[[0.7869500, 0.2021500, 0.2215000, 0.1940500, 0.3890500, 0.3023000, 0.1873000, 0.4739500, 0.2152000, 0.0553000, 0.1542500, 0.4005000, 0.0945000, 0.2833500, 0.1002500, 0.4237000, 0.0406000, 0.1878000, 0.1824000, 0.3830500, 0.0526500, 0.4384000, 0.3839500, 0.4071500], [0.9610500, 0.2217500, 0.3771000, 0.2036500, 0.3586500, 0.4911500, 0.1066500, 0.4935000, 0.0312000, 0.4558000, 0.2489000, 0.2896000, 0.4181500, 0.4904500, 0.0005000, 0.1679500, 0.0688000, 0.0975500, 0.2820500, 0.3029000, 0.3190500, 0.1744500, 0.2781500, 0.0005000], [0.7629500, 0.0329500, 0.4096000, 0.4900000, 0.0284000, 0.4214000, 0.2299500, 0.0784500, 0.0671500, 0.0084500, 0.1392000, 0.2573500, 0.0630000, 0.4022500, 0.4062000, 0.3093500, 0.1699500, 0.1886500, 0.3840500, 0.4338000, 0.3330500, 0.0075500, 0.2692000, 0.1052500], [0.6120000, 0.3767500, 0.1894000, 0.3352500, 0.4154500, 0.2333000, 0.2276500, 0.1116500, 0.4953500, 0.1645000, 0.3375000, 0.1104000, 0.0662500, 0.0070500, 0.4043000, 0.0434000, 0.4475500, 0.0970000, 0.2562000, 0.0144000, 0.4578000, 0.1109500, 0.4060000, 0.4134500], [0.5478000, 0.0805000, 0.0943000, 0.1941000, 0.1911000, 0.0320000, 0.4342500, 0.1294500, 0.3383000, 0.4587000, 0.4751000, 0.1712000, 0.2538000, 0.4141000, 0.3662000, 0.2135500, 0.2374000, 0.0119000, 0.0791000, 0.1380000, 0.1068000, 0.2302000, 0.3309000, 0.4746000], [0.9653000, 0.4009500, 0.2452500, 0.4004500, 0.4704000, 0.2970500, 0.4073500, 0.0338000, 0.1979000, 0.2405500, 0.0307000, 0.2893500, 0.2481500, 0.3576500, 0.0605000, 0.2889000, 0.0455500, 0.4978500, 0.3958500, 0.4033000, 0.3880500, 0.2317500, 0.1936500, 0.4206000], [0.6835500, 0.4652000, 0.3119000, 0.3515000, 0.2149000, 0.3306000, 0.4897000, 0.0698500, 0.3600000, 0.1092500, 0.1702500, 0.4232500, 0.0070500, 0.1007000, 0.1769500, 0.2278500, 0.1787500, 0.3995500, 0.3947500, 0.1793000, 0.4133000, 0.1912000, 0.2561000, 0.2492000], [0.6547500, 0.4309000, 0.4974500, 0.4366500, 0.1691500, 0.1839500, 0.3404000, 0.2305000, 0.0043500, 0.2953500, 0.0635000, 0.3821000, 0.3149500, 0.4856000, 0.4017000, 0.1628000, 0.2310000, 0.1396000, 0.3171000, 0.1928500, 0.4219000, 0.1645000, 0.1268000, 0.4259000], [0.7904487, 0.4235500, 0.2477500, 0.0304500, 0.3334500, 0.0976500, 0.0315500, 0.3105000, 0.1493000, 0.1369500, 0.0825000, 0.2170000, 0.0589000, 0.4974500, 0.3500500, 0.3687000, 0.4491000, 0.4334500, 0.0752000, 0.3986000, 0.2647000, 0.4361000, 0.3326000, 0.0474000], [0.8616679, 0.1539000, 0.3260000, 0.0628000, 0.4616500, 0.4235000, 0.0323500, 0.0794000, 0.0845500, 0.3650500, 0.1966000, 0.1163000, 0.2367000, 0.2595500, 0.1770500, 0.0139000, 0.2723500, 0.3139500, 0.2930000, 0.1295000, 0.0613000, 0.4357500, 0.2407000, 0.4983000], [0.7835315, 0.4920000, 0.1040000, 0.0327000, 0.1624000, 0.2111500, 0.1539500, 0.0620500, 0.4344500, 0.4184000, 0.5508000, 0.9674500, 0.6580500, 0.7088500, 0.1940000, 0.3831000, 0.2830000, 0.2168000, 0.4574500, 0.3865000, 0.2774000, 0.1451500, 0.0419500, 0.0218500], [0.6108904, 0.0562500, 0.1790500, 0.2892500, 0.1629500, 0.2212000, 0.2732000, 0.3821000, 0.1990000, 0.4672000, 0.3709500, 0.3340000, 0.0708500, 0.0329000, 0.2590000, 0.3546500, 0.0589500, 0.0413000, 0.4893000, 0.0623500, 0.4268500, 0.0017500, 0.0996500, 0.1027500]]]

Expected (Unparsed): [[[0.78695,0.20215,0.2215,0.19405,0.38905,0.3023,0.1873,0.47395,0.2152,0.0553,0.15425,0.4005,0.0945,0.28335,0.10025,0.4237,0.0406,0.1878,0.1824,0.38305,0.05265,0.4384,0.38395,0.40715],[0.96105,0.22175,0.3771,0.20365,0.35865,0.49115,0.10665,0.4935,0.0312,0.4558,0.2489,0.2896,0.41815,0.49045,0.0005,0.16795,0.0688,0.09755,0.28205,0.3029,0.31905,0.17445,0.27815,0.0005],[0.76295,0.03295,0.4096,0.49,0.0284,0.4214,0.22995,0.07845,0.06715,0.00845,0.1392,0.25735,0.063,0.40225,0.4062,0.30935,0.16995,0.18865,0.38405,0.4338,0.33305,0.00755,0.2692,0.10525],[0.612,0.37675,0.1894,0.33525,0.41545,0.2333,0.22765,0.11165,0.49535,0.1645,0.3375,0.1104,0.06625,0.00705,0.4043,0.0434,0.44755,0.097,0.2562,0.0144,0.4578,0.11095,0.406,0.41345],[0.5478,0.0805,0.0943,0.1941,0.1911,0.032,0.43425,0.12945,0.3383,0.4587,0.4751,0.1712,0.2538,0.4141,0.3662,0.21355,0.2374,0.0119,0.0791,0.138,0.1068,0.2302,0.3309,0.4746],[0.9653,0.40095,0.24525,0.40045,0.4704,0.29705,0.40735,0.0338,0.1979,0.24055,0.0307,0.28935,0.24815,0.35765,0.0605,0.2889,0.04555,0.49785,0.39585,0.4033,0.38805,0.23175,0.19365,0.4206],[0.68355,0.4652,0.3119,0.3515,0.2149,0.3306,0.4897,0.06985,0.36,0.10925,0.17025,0.42325,0.00705,0.1007,0.17695,0.22785,0.17875,0.39955,0.39475,0.1793,0.4133,0.1912,0.2561,0.2492],[0.65475,0.4309,0.49745,0.43665,0.16915,0.18395,0.3404,0.2305,0.00435,0.29535,0.0635,0.3821,0.31495,0.4856,0.4017,0.1628,0.231,0.1396,0.3171,0.19285,0.4219,0.1645,0.1268,0.4259],[0.790448695421,0.42355,0.24775,0.03045,0.33345,0.09765,0.03155,0.3105,0.1493,0.13695,0.0825,0.217,0.0589,0.49745,0.35005,0.3687,0.4491,0.43345,0.0752,0.3986,0.2647,0.4361,0.3326,0.0474],[0.86166792,0.1539,0.326,0.0628,0.46165,0.4235,0.03235,0.0794,0.08455,0.36505,0.1966,0.1163,0.2367,0.25955,0.17705,0.0139,0.27235,0.31395,0.293,0.1295,0.0613,0.43575,0.2407,0.4983],[0.783531455,0.492,0.104,0.0327,0.1624,0.21115,0.15395,0.06205,0.43445,0.4184,0.5508,0.9674499999999999,0.65805,0.70885,0.194,0.3831,0.283,0.2168,0.45745,0.3865,0.2774,0.14515,0.04195,0.02185],[0.61089034,0.05625,0.17905,0.28925,0.16295,0.2212,0.2732,0.3821,0.199,0.4672,0.37095,0.334,0.07085,0.0329,0.259,0.35465,0.05895,0.0413,0.4893,0.06235,0.42685,0.00175,0.09965,0.10275]]]

Actual:   [[[0.787, 0.2022, 0.2215, 0.1941, 0.3891, 0.3023, 0.1873, 0.474, 0.2152, 0.0553, 0.1543, 0.4005, 0.0945, 0.2834, 0.1003, 0.4237, 0.0406, 0.1878, 0.1824, 0.3831, 0.0527, 0.4384, 0.384, 0.4072], [0.9611, 0.2218, 0.3771, 0.2037, 0.3587, 0.4912, 0.1067, 0.4935, 0.0312, 0.4558, 0.2489, 0.2896, 0.4182, 0.4905, 0.0005, 0.168, 0.0688, 0.0976, 0.2821, 0.3029, 0.3191, 0.1745, 0.2782, 0.0005], [0.763, 0.033, 0.4096, 0.49, 0.0284, 0.4214, 0.23, 0.0785, 0.0672, 0.0085, 0.1392, 0.2574, 0.063, 0.4023, 0.4062, 0.3094, 0.17, 0.1887, 0.3841, 0.4338, 0.3331, 0.0076, 0.2692, 0.1053], [0.612, 0.3768, 0.1894, 0.3353, 0.4155, 0.2333, 0.2277, 0.1117, 0.4954, 0.1645, 0.3375, 0.1104, 0.0663, 0.0071, 0.4043, 0.0434, 0.4476, 0.097, 0.2562, 0.0144, 0.4578, 0.111, 0.406, 0.4135], [0.5478, 0.0805, 0.0943, 0.1941, 0.1911, 0.032, 0.4343, 0.1295, 0.3383, 0.4587, 0.4751, 0.1712, 0.2538, 0.4141, 0.3662, 0.2136, 0.2374, 0.0119, 0.0791, 0.138, 0.1068, 0.2302, 0.3309, 0.4746], [0.9653, 0.401, 0.2453, 0.4005, 0.4704, 0.2971, 0.4074, 0.0338, 0.1979, 0.2406, 0.0307, 0.2894, 0.2482, 0.3577, 0.0605, 0.2889, 0.0456, 0.4979, 0.3959, 0.4033, 0.3881, 0.2318, 0.1937, 0.4206], [0.6836, 0.4652, 0.3119, 0.3515, 0.2149, 0.3306, 0.4897, 0.0699, 0.36, 0.1093, 0.1703, 0.4233, 0.0071, 0.1007, 0.177, 0.2279, 0.1788, 0.3996, 0.3948, 0.1793, 0.4133, 0.1912, 0.2561, 0.2492], [0.6548, 0.4309, 0.4975, 0.4367, 0.1692, 0.184, 0.3404, 0.2305, 0.0044, 0.2954, 0.0635, 0.3821, 0.315, 0.4856, 0.4017, 0.1628, 0.231, 0.1396, 0.3171, 0.1929, 0.4219, 0.1645, 0.1268, 0.4259], [0.7905, 0.4236, 0.2478, 0.0305, 0.3335, 0.0977, 0.0316, 0.3105, 0.1493, 0.137, 0.0825, 0.217, 0.0589, 0.4975, 0.3501, 0.3687, 0.4491, 0.4335, 0.0752, 0.3986, 0.2647, 0.4361, 0.3326, 0.0474], [0.8617, 0.1539, 0.326, 0.0628, 0.4617, 0.4235, 0.0324, 0.0794, 0.0846, 0.3651, 0.1966, 0.1163, 0.2367, 0.2596, 0.1771, 0.0139, 0.2724, 0.314, 0.293, 0.1295, 0.0613, 0.4358, 0.2407, 0.4983], [0.7836, 0.492, 0.104, 0.0327, 0.1624, 0.2112, 0.154, 0.0621, 0.4345, 0.4184, 0.5508, 0.9675, 0.6581, 0.7089, 0.194, 0.3831, 0.283, 0.2168, 0.4575, 0.3865, 0.2774, 0.1452, 0.042, 0.0219], [0.6109, 0.0563, 0.1791, 0.2893, 0.163, 0.2212, 0.2732, 0.3821, 0.199, 0.4672, 0.371, 0.334, 0.0709, 0.0329, 0.259, 0.3547, 0.059, 0.0413, 0.4893, 0.0624, 0.4269, 0.0018, 0.0997, 0.1028]]]

Expected: [[[0.787, 0.2022, 0.2215, 0.1941, 0.3891, 0.3023, 0.1873, 0.474, 0.2152, 0.0553, 0.1543, 0.4005, 0.0945, 0.2834, 0.1003, 0.4237, 0.0406, 0.1878, 0.1824, 0.3831, 0.0527, 0.4384, 0.384, 0.4072], [0.9611, 0.2218, 0.3771, 0.2037, 0.3587, 0.4912, 0.1067, 0.4935, 0.0312, 0.4558, 0.2489, 0.2896, 0.4182, 0.4905, 0.0005, 0.168, 0.0688, 0.0976, 0.2821, 0.3029, 0.3191, 0.1745, 0.2782, 0.0005], [0.763, 0.033, 0.4096, 0.49, 0.0284, 0.4214, 0.23, 0.0785, 0.0672, 0.0085, 0.1392, 0.2574, 0.063, 0.4023, 0.4062, 0.3094, 0.17, 0.1887, 0.3841, 0.4338, 0.3331, 0.0076, 0.2692, 0.1053], [0.612, 0.3768, 0.1894, 0.3353, 0.4155, 0.2333, 0.2277, 0.1117, 0.4954, 0.1645, 0.3375, 0.1104, 0.0663, 0.0071, 0.4043, 0.0434, 0.4476, 0.097, 0.2562, 0.0144, 0.4578, 0.111, 0.406, 0.4135], [0.5478, 0.0805, 0.0943, 0.1941, 0.1911, 0.032, 0.4343, 0.1295, 0.3383, 0.4587, 0.4751, 0.1712, 0.2538, 0.4141, 0.3662, 0.2136, 0.2374, 0.0119, 0.0791, 0.138, 0.1068, 0.2302, 0.3309, 0.4746], [0.9653, 0.401, 0.2453, 0.4005, 0.4704, 0.2971, 0.4074, 0.0338, 0.1979, 0.2406, 0.0307, 0.2894, 0.2482, 0.3577, 0.0605, 0.2889, 0.0456, 0.4979, 0.3959, 0.4033, 0.3881, 0.2318, 0.1937, 0.4206], [0.6836, 0.4652, 0.3119, 0.3515, 0.2149, 0.3306, 0.4897, 0.0699, 0.36, 0.1093, 0.1703, 0.4233, 0.0071, 0.1007, 0.177, 0.2279, 0.1788, 0.3996, 0.3948, 0.1793, 0.4133, 0.1912, 0.2561, 0.2492], [0.6548, 0.4309, 0.4975, 0.4367, 0.1692, 0.184, 0.3404, 0.2305, 0.0044, 0.2954, 0.0635, 0.3821, 0.315, 0.4856, 0.4017, 0.1628, 0.231, 0.1396, 0.3171, 0.1929, 0.4219, 0.1645, 0.1268, 0.4259], [0.7905, 0.4236, 0.2478, 0.0305, 0.3335, 0.0977, 0.0316, 0.3105, 0.1493, 0.137, 0.0825, 0.217, 0.0589, 0.4975, 0.3501, 0.3687, 0.4491, 0.4335, 0.0752, 0.3986, 0.2647, 0.4361, 0.3326, 0.0474], [0.8617, 0.1539, 0.326, 0.0628, 0.4617, 0.4235, 0.0324, 0.0794, 0.0846, 0.3651, 0.1966, 0.1163, 0.2367, 0.2596, 0.1771, 0.0139, 0.2724, 0.314, 0.293, 0.1295, 0.0613, 0.4358, 0.2407, 0.4983], [0.7836, 0.492, 0.104, 0.0327, 0.1624, 0.2112, 0.154, 0.0621, 0.4345, 0.4184, 0.5508, 0.9675, 0.6581, 0.7089, 0.194, 0.3831, 0.283, 0.2168, 0.4575, 0.3865, 0.2774, 0.1452, 0.042, 0.0219], [0.6109, 0.0563, 0.1791, 0.2893, 0.163, 0.2212, 0.2732, 0.3821, 0.199, 0.4672, 0.371, 0.334, 0.0709, 0.0329, 0.259, 0.3547, 0.059, 0.0413, 0.4893, 0.0624, 0.4269, 0.0018, 0.0997, 0.1028]]]