import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sof68063 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0Con49638 = tf.keras.layers.Input(shape=([14, 3, 1, 1]))
in0Con44046 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))

Sof68063 = keras.layers.Softmax(axis=1, name = 'Sof68063', input_shape=(2, 2, 1, 2))(in0Sof68063)
Bat60010 = keras.layers.BatchNormalization(axis=3, epsilon=0.83778449761757,  name = 'Bat60010', )(Sof68063)
Lay47656 = keras.layers.LayerNormalization(axis=1, epsilon=1.6643817940527545, name = 'Lay47656', )(Bat60010)
Sof50911 = keras.layers.Softmax(axis=1, name = 'Sof50911', )(Lay47656)
Zer53875 = keras.layers.ZeroPadding3D(padding=((12, 0), (1, 0), (0, 0)), name = 'Zer53875', )(Sof50911)
Con49638 = keras.layers.Concatenate(axis=4, name = 'Con49638', )([Zer53875,in0Con49638])
Con44046 = keras.layers.Conv3DTranspose(3, (2, 2, 1),strides=(7, 1, 1), padding='valid', name = 'Con44046', )(in0Con44046)
ReL52543 = keras.layers.ReLU(max_value=1.071838977566189, negative_slope=5.256959278773029, threshold=9.653182897646786, name = 'ReL52543', )(Con44046)
Mul91088 = keras.layers.Multiply(name = 'Mul91088', )([Con49638,ReL52543])
model = tf.keras.models.Model(inputs=[in0Sof68063,in0Con49638,in0Con44046], outputs=Mul91088)
w = model.get_layer('Bat60010').get_weights() 
w[0] = np.array([0.2349])
w[1] = np.array([0.9549])
w[2] = np.array([0.346])
w[3] = np.array([0.638])
model.get_layer('Bat60010').set_weights(w) 
w = model.get_layer('Con44046').get_weights() 
w[0] = np.array([[[[[0.055, 0.5384], [0.6883, 0.093], [0.9737, 0.1911]]], [[[0.6804, 0.1641], [0.9493, 0.9004], [0.7899, 0.3814]]]], [[[[0.2086, 0.8469], [0.8859, 0.6274], [0.771, 0.288]]], [[[0.0126, 0.2517], [0.1728, 0.0096], [0.3203, 0.2327]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con44046').set_weights(w) 
in0Sof68063 = tf.constant([[[[[0.0983, 0.417]], [[0.318, 0.6845]]], [[[0.257, 0.1048]], [[0.0894, 0.7328]]]]])
in0Con49638 = tf.constant([[[[[0.8361]], [[0.5289]], [[0.5537]]], [[[0.5694]], [[0.5808]], [[0.0439]]], [[[0.6963]], [[0.7109]], [[0.8646]]], [[[0.0062]], [[0.3683]], [[0.1216]]], [[[0.1049]], [[0.3206]], [[0.7252]]], [[[0.4543]], [[0.1453]], [[0.2336]]], [[[0.729]], [[0.7171]], [[0.2538]]], [[[0.685]], [[0.0749]], [[0.0015]]], [[[0.6249]], [[0.7527]], [[0.2263]]], [[[0.3138]], [[0.8888]], [[0.6259]]], [[[0.2766]], [[0.8088]], [[0.88]]], [[[0.8965]], [[0.872]], [[0.4644]]], [[[0.4511]], [[0.3433]], [[0.2256]]], [[[0.5115]], [[0.431]], [[0.7961]]]]])
in0Con44046 = tf.constant([[[[[0.7122, 0.2044]], [[0.6089, 0.3213]]], [[[0.6113, 0.1858]], [[0.5435, 0.3313]]]]])
print (np.array2string(model.predict([in0Sof68063,in0Con49638,in0Con44046],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul91088.png')

LSof68063 = softmax_layer([[[[[0.0983, 0.417]], [[0.318, 0.6845]]], [[[0.257, 0.1048]], [[0.0894, 0.7328]]]]], 1, Sof68063), 
LBat60010 = batch_normalization_layer(Sof68063, 3, 0.83778449761757, [0.2349], [0.9549], [0.346], [0.638], Bat60010), 
LLay47656 = layer_normalization_layer(Bat60010, 1, 1.6643817940527545, Lay47656), 
LSof50911 = softmax_layer(Lay47656, 1, Sof50911), 
LZer53875 = zero_padding3D_layer(Sof50911, 12, 0, 1, 0, 0, 0, Zer53875), 
LCon49638 = concatenate_layer([Zer53875,[[[[[0.8361]], [[0.5289]], [[0.5537]]], [[[0.5694]], [[0.5808]], [[0.0439]]], [[[0.6963]], [[0.7109]], [[0.8646]]], [[[0.0062]], [[0.3683]], [[0.1216]]], [[[0.1049]], [[0.3206]], [[0.7252]]], [[[0.4543]], [[0.1453]], [[0.2336]]], [[[0.729]], [[0.7171]], [[0.2538]]], [[[0.685]], [[0.0749]], [[0.0015]]], [[[0.6249]], [[0.7527]], [[0.2263]]], [[[0.3138]], [[0.8888]], [[0.6259]]], [[[0.2766]], [[0.8088]], [[0.88]]], [[[0.8965]], [[0.872]], [[0.4644]]], [[[0.4511]], [[0.3433]], [[0.2256]]], [[[0.5115]], [[0.431]], [[0.7961]]]]]], 4, Con49638), 
LCon44046 = conv3D_transpose_layer([[[[[0.7122, 0.2044]], [[0.6089, 0.3213]]], [[[0.6113, 0.1858]], [[0.5435, 0.3313]]]]], 2, 2, 1,[[[[[0.055, 0.5384], [0.6883, 0.093], [0.9737, 0.1911]]], [[[0.6804, 0.1641], [0.9493, 0.9004], [0.7899, 0.3814]]]], [[[[0.2086, 0.8469], [0.8859, 0.6274], [0.771, 0.288]]], [[[0.0126, 0.2517], [0.1728, 0.0096], [0.3203, 0.2327]]]]],[0, 0, 0], 7, 1, 1, false, Con44046), 
LReL52543 = relu_layer(Con44046, 1.071838977566189, 5.256959278773029, 9.653182897646786, ReL52543), 
LMul91088 = multiply_layer([Con49638,ReL52543], Mul91088), 
exec_layers([LSof68063,LBat60010,LLay47656,LSof50911,LZer53875,LCon49638,LCon44046,LReL52543,LMul91088],["Sof68063","Bat60010","Lay47656","Sof50911","Zer53875","Con49638","Con44046","ReL52543","Mul91088"],Mul91088,"Mul91088")

Actual (Unparsed): [[[[[-0.0000000, -0.0000000, -39.2093344]], [[-0.0000000, -0.0000000, -23.2396658]], [[-0.0000000, -0.0000000, -26.3415791]]], [[[-0.0000000, -0.0000000, -27.0751403]], [[-0.0000000, -0.0000000, -26.9158697]], [[-0.0000000, -0.0000000, -2.1655027]]], [[[-0.0000000, -0.0000000, -35.3347125]], [[-0.0000000, -0.0000000, -36.0756087]], [[-0.0000000, -0.0000000, -43.8753284]]], [[[-0.0000000, -0.0000000, -0.3146276]], [[-0.0000000, -0.0000000, -18.6898948]], [[-0.0000000, -0.0000000, -6.1707611]]], [[[-0.0000000, -0.0000000, -5.3232964]], [[-0.0000000, -0.0000000, -16.2692926]], [[-0.0000000, -0.0000000, -36.8012815]]], [[[-0.0000000, -0.0000000, -23.0540840]], [[-0.0000000, -0.0000000, -7.3734504]], [[-0.0000000, -0.0000000, -11.8543568]]], [[[-0.0000000, -0.0000000, -36.9941165]], [[-0.0000000, -0.0000000, -36.3902371]], [[-0.0000000, -0.0000000, -12.8794339]]], [[[-0.0000000, -0.0000000, -32.4900103]], [[-0.0000000, -0.0000000, -3.3495740]], [[-0.0000000, -0.0000000, -0.0717379]]], [[[-0.0000000, -0.0000000, -29.9873366]], [[-0.0000000, -0.0000000, -35.2153195]], [[-0.0000000, -0.0000000, -11.1850958]]], [[[-0.0000000, -0.0000000, -15.9242174]], [[-0.0000000, -0.0000000, -45.1033922]], [[-0.0000000, -0.0000000, -31.7621636]]], [[[-0.0000000, -0.0000000, -14.0364515]], [[-0.0000000, -0.0000000, -41.0436788]], [[-0.0000000, -0.0000000, -44.6568224]]], [[[-0.0000000, -0.0000000, -45.4941377]], [[-0.0000000, -0.0000000, -44.2508505]], [[-0.0000000, -0.0000000, -23.5666229]]], [[[-0.0000000, -0.0000000, -22.8916958]], [[-25.2226331, -25.6675940, -17.4212362]], [[-25.5895784, -25.3272831, -11.4483857]]], [[[-0.0000000, -0.0000000, -25.9567782]], [[-25.5237563, -25.0787954, -21.8716935]], [[-25.1568110, -25.4191063, -40.3992016]]]]]

Expected (Unparsed): [[[[[-0.0,-0.0,-39.20933518203531]],[[-0.0,-0.0,-23.239664555573327]],[[-0.0,-0.0,-26.341580529734703]]],[[[-0.0,-0.0,-27.075139679548855]],[[-0.0,-0.0,-26.915869844610658]],[[-0.0,-0.0,-2.165502563384873]]],[[[-0.0,-0.0,-35.334710941641305]],[[-0.0,-0.0,-36.075608226932076]],[[-0.0,-0.0,-43.87532827824655]]],[[[-0.0,-0.0,-0.3146276143015598]],[[-0.0,-0.0,-18.689895217300723]],[[-0.0,-0.0,-6.17076095146285]]],[[[-0.0,-0.0,-5.323296248424778]],[[-0.0,-0.0,-16.26929244275485]],[[-0.0,-0.0,-36.8012815954018]]],[[[-0.0,-0.0,-23.054084705999777]],[[-0.0,-0.0,-7.373450380325265]],[[-0.0,-0.0,-11.854356564652317]]],[[[-0.0,-0.0,-36.99411787513501]],[[-0.0,-0.0,-36.39023584123363]],[[-0.0,-0.0,-12.879433630602563]]],[[[-0.0,-0.0,-32.49001013896402]],[[-0.0,-0.0,-3.349573962833404]],[[-0.0,-0.0,-0.07173789432628391]]],[[[-0.0,-0.0,-29.987337408841945]],[[-0.0,-0.0,-35.21532085158078]],[[-0.0,-0.0,-11.185095756341903]]],[[[-0.0,-0.0,-15.924216994811205]],[[-0.0,-0.0,-45.103390901810705]],[[-0.0,-0.0,-31.762165127636496]]],[[[-0.0,-0.0,-14.036451309001846]],[[-0.0,-0.0,-41.04367974953251]],[[-0.0,-0.0,-44.6568226750601]]],[[[-0.0,-0.0,-45.49413810021748]],[[-0.0,-0.0,-44.250851559832284]],[[-0.0,-0.0,-23.5666232389749]]],[[[-0.0,-0.0,-22.89169625990865]],[[-25.222633092984843,-25.66759402208546,-17.42123548221379]],[[-25.58957842844157,-25.32728317294958,-11.448385449424498]]],[[[-0.0,-0.0,-25.956778179878683]],[[-25.52375631049255,-25.078795381391927,-21.871693832898753]],[[-25.15681097503582,-25.41910623052781,-40.39920060410835]]]]]

Actual:   [[[[[-0, -0, -39.2093]], [[-0, -0, -23.2396]], [[-0, -0, -26.3415]]], [[[-0, -0, -27.0751]], [[-0, -0, -26.9158]], [[-0, -0, -2.1655]]], [[[-0, -0, -35.3347]], [[-0, -0, -36.0756]], [[-0, -0, -43.8753]]], [[[-0, -0, -0.3146]], [[-0, -0, -18.6898]], [[-0, -0, -6.1707]]], [[[-0, -0, -5.3232]], [[-0, -0, -16.2692]], [[-0, -0, -36.8012]]], [[[-0, -0, -23.054]], [[-0, -0, -7.3734]], [[-0, -0, -11.8543]]], [[[-0, -0, -36.9941]], [[-0, -0, -36.3902]], [[-0, -0, -12.8794]]], [[[-0, -0, -32.49]], [[-0, -0, -3.3495]], [[-0, -0, -0.0717]]], [[[-0, -0, -29.9873]], [[-0, -0, -35.2153]], [[-0, -0, -11.185]]], [[[-0, -0, -15.9242]], [[-0, -0, -45.1033]], [[-0, -0, -31.7621]]], [[[-0, -0, -14.0364]], [[-0, -0, -41.0436]], [[-0, -0, -44.6568]]], [[[-0, -0, -45.4941]], [[-0, -0, -44.2508]], [[-0, -0, -23.5666]]], [[[-0, -0, -22.8916]], [[-25.2226, -25.6675, -17.4212]], [[-25.5895, -25.3272, -11.4483]]], [[[-0, -0, -25.9567]], [[-25.5237, -25.0787, -21.8716]], [[-25.1568, -25.4191, -40.3992]]]]]

Expected: [[[[[-0, -0, -39.2093]], [[-0, -0, -23.2396]], [[-0, -0, -26.3415]]], [[[-0, -0, -27.0751]], [[-0, -0, -26.9158]], [[-0, -0, -2.1655]]], [[[-0, -0, -35.3347]], [[-0, -0, -36.0756]], [[-0, -0, -43.8753]]], [[[-0, -0, -0.3146]], [[-0, -0, -18.6898]], [[-0, -0, -6.1707]]], [[[-0, -0, -5.3232]], [[-0, -0, -16.2692]], [[-0, -0, -36.8012]]], [[[-0, -0, -23.054]], [[-0, -0, -7.3734]], [[-0, -0, -11.8543]]], [[[-0, -0, -36.9941]], [[-0, -0, -36.3902]], [[-0, -0, -12.8794]]], [[[-0, -0, -32.49]], [[-0, -0, -3.3495]], [[-0, -0, -0.0717]]], [[[-0, -0, -29.9873]], [[-0, -0, -35.2153]], [[-0, -0, -11.185]]], [[[-0, -0, -15.9242]], [[-0, -0, -45.1033]], [[-0, -0, -31.7621]]], [[[-0, -0, -14.0364]], [[-0, -0, -41.0436]], [[-0, -0, -44.6568]]], [[[-0, -0, -45.4941]], [[-0, -0, -44.2508]], [[-0, -0, -23.5666]]], [[[-0, -0, -22.8916]], [[-25.2226, -25.6675, -17.4212]], [[-25.5895, -25.3272, -11.4483]]], [[[-0, -0, -25.9567]], [[-25.5237, -25.0787, -21.8716]], [[-25.1568, -25.4191, -40.3992]]]]]