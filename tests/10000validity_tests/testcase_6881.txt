import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Max46893 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Min41067 = tf.keras.layers.Input(shape=([1, 1, 1]))
in1Min41067 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Con33994 = tf.keras.layers.Input(shape=([9, 11]))

Max46893 = keras.layers.MaxPool2D(pool_size=(2, 2), name = 'Max46893', )(in0Max46893)
Res94575 = keras.layers.Reshape((1, 1, 2, 1), name = 'Res94575', )(Max46893)
Con7447 = keras.layers.Conv3DTranspose(3, (1, 1, 1),strides=(9, 1, 2), padding='same', name = 'Con7447', )(Res94575)
Res16930 = keras.layers.Reshape((9, 1, 12), name = 'Res16930', )(Con7447)
Res34979 = keras.layers.Reshape((9, 12), name = 'Res34979', )(Res16930)
Min41067 = keras.layers.Minimum(name = 'Min41067', )([in0Min41067,in1Min41067])
Res45154 = keras.layers.Reshape((1, 1), name = 'Res45154', )(Min41067)
Max89393 = keras.layers.MaxPool1D(pool_size=(1), name = 'Max89393', )(Res45154)
Zer99582 = keras.layers.ZeroPadding1D(padding=((8, 0)), name = 'Zer99582', )(Max89393)
Con33994 = keras.layers.Concatenate(axis=2, name = 'Con33994', )([Zer99582,in0Con33994])
Add46159 = keras.layers.Add(name = 'Add46159', )([Res34979,Con33994])
model = tf.keras.models.Model(inputs=[in0Max46893,in0Min41067,in1Min41067,in0Con33994], outputs=Add46159)
w = model.get_layer('Con7447').get_weights() 
w[0] = np.array([[[[[0.478], [0.8798], [0.5679]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con7447').set_weights(w) 
in0Max46893 = tf.constant([[[[1.1644, 1.9108], [1.9083, 1.5282]], [[1.2674, 1.2608], [1.378, 1.4639]]]])
in0Min41067 = tf.constant([[[[0.4112]]]])
in1Min41067 = tf.constant([[[[0.0852]]]])
in0Con33994 = tf.constant([[[0.9087, 0.8953, 0.3838, 0.4123, 0.4672, 0.931, 0.2946, 0.4287, 0.2119, 0.1005, 0.9331], [0.3629, 0.1221, 0.204, 0.9439, 0.234, 0.5066, 0.3946, 0.0442, 0.0524, 0.6655, 0.1845], [0.4377, 0.1978, 0.1348, 0.0528, 0.7387, 0.3399, 0.542, 0.6338, 0.7032, 0.2762, 0.2987], [0.9806, 0.2147, 0.6596, 0.7146, 0.3293, 0.7825, 0.0908, 0.6291, 0.1198, 0.2761, 0.4664], [0.3256, 0.769, 0.7433, 0.7852, 0.3194, 0.839, 0.9332, 0.8438, 0.5905, 0.7919, 0.5854], [0.3805, 0.9714, 0.4843, 0.6341, 0.2607, 0.6936, 0.9157, 0.223, 0.244, 0.5457, 0.5169], [0.8325, 0.7168, 0.7046, 0.4426, 0.8771, 0.533, 0.0616, 0.9119, 0.8493, 0.764, 0.786], [0.6335, 0.4579, 0.7281, 0.9424, 0.7453, 0.2347, 0.1423, 0.2114, 0.5012, 0.7717, 0.6192], [0.1485, 0.1449, 0.0887, 0.019, 0.9629, 0.0253, 0.6308, 0.3571, 0.4946, 0.03, 0.0456]]])
print (np.array2string(model.predict([in0Max46893,in0Min41067,in1Min41067,in0Con33994],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add46159.png')

LMax46893 = max_pool2D_layer([[[[1.1644, 1.9108], [1.9083, 1.5282]], [[1.2674, 1.2608], [1.378, 1.4639]]]], 2, 2, Max46893), 
LRes94575 = reshape_layer(Max46893, [1, 1, 2, 1], Res94575), 
LCon7447 = conv3D_transpose_layer(Res94575, 1, 1, 1,[[[[[0.478], [0.8798], [0.5679]]]]],[0, 0, 0], 9, 1, 2, true, Con7447), 
LRes16930 = reshape_layer(Con7447, [9, 1, 12], Res16930), 
LRes34979 = reshape_layer(Res16930, [9, 12], Res34979), 
LMin41067 = minimum_layer([[[[[0.4112]]]], [[[[0.0852]]]]], Min41067), 
LRes45154 = reshape_layer(Min41067, [1, 1], Res45154), 
LMax89393 = max_pool1D_layer(Res45154, 1, Max89393), 
LZer99582 = zero_padding1D_layer(Max89393, 8, 0, Zer99582), 
LCon33994 = concatenate_layer([Zer99582,[[[0.9087, 0.8953, 0.3838, 0.4123, 0.4672, 0.931, 0.2946, 0.4287, 0.2119, 0.1005, 0.9331], [0.3629, 0.1221, 0.204, 0.9439, 0.234, 0.5066, 0.3946, 0.0442, 0.0524, 0.6655, 0.1845], [0.4377, 0.1978, 0.1348, 0.0528, 0.7387, 0.3399, 0.542, 0.6338, 0.7032, 0.2762, 0.2987], [0.9806, 0.2147, 0.6596, 0.7146, 0.3293, 0.7825, 0.0908, 0.6291, 0.1198, 0.2761, 0.4664], [0.3256, 0.769, 0.7433, 0.7852, 0.3194, 0.839, 0.9332, 0.8438, 0.5905, 0.7919, 0.5854], [0.3805, 0.9714, 0.4843, 0.6341, 0.2607, 0.6936, 0.9157, 0.223, 0.244, 0.5457, 0.5169], [0.8325, 0.7168, 0.7046, 0.4426, 0.8771, 0.533, 0.0616, 0.9119, 0.8493, 0.764, 0.786], [0.6335, 0.4579, 0.7281, 0.9424, 0.7453, 0.2347, 0.1423, 0.2114, 0.5012, 0.7717, 0.6192], [0.1485, 0.1449, 0.0887, 0.019, 0.9629, 0.0253, 0.6308, 0.3571, 0.4946, 0.03, 0.0456]]]], 2, Con33994), 
LAdd46159 = add_layer([Res34979,Con33994], Add46159), 
exec_layers([LMax46893,LRes94575,LCon7447,LRes16930,LRes34979,LMin41067,LRes45154,LMax89393,LZer99582,LCon33994,LAdd46159],["Max46893","Res94575","Con7447","Res16930","Res34979","Min41067","Res45154","Max89393","Zer99582","Con33994","Add46159"],Add46159,"Add46159")

Actual (Unparsed): [[[0.9121674, 2.5876224, 1.9790236, 0.3838000, 0.4123000, 0.4672000, 1.8443624, 1.9757218, 1.5138433, 0.2119000, 0.1005000, 0.9331000], [0.0000000, 0.3629000, 0.1221000, 0.2040000, 0.9439000, 0.2340000, 0.5066000, 0.3946000, 0.0442000, 0.0524000, 0.6655000, 0.1845000], [0.0000000, 0.4377000, 0.1978000, 0.1348000, 0.0528000, 0.7387000, 0.3399000, 0.5420000, 0.6338000, 0.7032000, 0.2762000, 0.2987000], [0.0000000, 0.9806000, 0.2147000, 0.6596000, 0.7146000, 0.3293000, 0.7825000, 0.0908000, 0.6291000, 0.1198000, 0.2761000, 0.4664000], [0.0000000, 0.3256000, 0.7690000, 0.7433000, 0.7852000, 0.3194000, 0.8390000, 0.9332000, 0.8438000, 0.5905000, 0.7919000, 0.5854000], [0.0000000, 0.3805000, 0.9714000, 0.4843000, 0.6341000, 0.2607000, 0.6936000, 0.9157000, 0.2230000, 0.2440000, 0.5457000, 0.5169000], [0.0000000, 0.8325000, 0.7168000, 0.7046000, 0.4426000, 0.8771000, 0.5330000, 0.0616000, 0.9119000, 0.8493000, 0.7640000, 0.7860000], [0.0000000, 0.6335000, 0.4579000, 0.7281000, 0.9424000, 0.7453000, 0.2347000, 0.1423000, 0.2114000, 0.5012000, 0.7717000, 0.6192000], [0.0852000, 0.1485000, 0.1449000, 0.0887000, 0.0190000, 0.9629000, 0.0253000, 0.6308000, 0.3571000, 0.4946000, 0.0300000, 0.0456000]]]

Expected (Unparsed): [[[0.9121674,2.5876223400000002,1.97902357,0.3838,0.4123,0.4672,1.8443624,1.97572184,1.51384332,0.2119,0.1005,0.9331],[0,0.3629,0.1221,0.204,0.9439,0.234,0.5066,0.3946,0.0442,0.0524,0.6655,0.1845],[0,0.4377,0.1978,0.1348,0.0528,0.7387,0.3399,0.542,0.6338,0.7032,0.2762,0.2987],[0,0.9806,0.2147,0.6596,0.7146,0.3293,0.7825,0.0908,0.6291,0.1198,0.2761,0.4664],[0,0.3256,0.769,0.7433,0.7852,0.3194,0.839,0.9332,0.8438,0.5905,0.7919,0.5854],[0,0.3805,0.9714,0.4843,0.6341,0.2607,0.6936,0.9157,0.223,0.244,0.5457,0.5169],[0,0.8325,0.7168,0.7046,0.4426,0.8771,0.533,0.0616,0.9119,0.8493,0.764,0.786],[0,0.6335,0.4579,0.7281,0.9424,0.7453,0.2347,0.1423,0.2114,0.5012,0.7717,0.6192],[0.0852,0.1485,0.1449,0.0887,0.019,0.9629,0.0253,0.6308,0.3571,0.4946,0.03,0.0456]]]

Actual:   [[[0.9122, 2.5877, 1.9791, 0.3838, 0.4123, 0.4672, 1.8444, 1.9758, 1.5139, 0.2119, 0.1005, 0.9331], [0, 0.3629, 0.1221, 0.204, 0.9439, 0.234, 0.5066, 0.3946, 0.0442, 0.0524, 0.6655, 0.1845], [0, 0.4377, 0.1978, 0.1348, 0.0528, 0.7387, 0.3399, 0.542, 0.6338, 0.7032, 0.2762, 0.2987], [0, 0.9806, 0.2147, 0.6596, 0.7146, 0.3293, 0.7825, 0.0908, 0.6291, 0.1198, 0.2761, 0.4664], [0, 0.3256, 0.769, 0.7433, 0.7852, 0.3194, 0.839, 0.9332, 0.8438, 0.5905, 0.7919, 0.5854], [0, 0.3805, 0.9714, 0.4843, 0.6341, 0.2607, 0.6936, 0.9157, 0.223, 0.244, 0.5457, 0.5169], [0, 0.8325, 0.7168, 0.7046, 0.4426, 0.8771, 0.533, 0.0616, 0.9119, 0.8493, 0.764, 0.786], [0, 0.6335, 0.4579, 0.7281, 0.9424, 0.7453, 0.2347, 0.1423, 0.2114, 0.5012, 0.7717, 0.6192], [0.0852, 0.1485, 0.1449, 0.0887, 0.019, 0.9629, 0.0253, 0.6308, 0.3571, 0.4946, 0.03, 0.0456]]]

Expected: [[[0.9122, 2.5877, 1.9791, 0.3838, 0.4123, 0.4672, 1.8444, 1.9758, 1.5139, 0.2119, 0.1005, 0.9331], [0, 0.3629, 0.1221, 0.204, 0.9439, 0.234, 0.5066, 0.3946, 0.0442, 0.0524, 0.6655, 0.1845], [0, 0.4377, 0.1978, 0.1348, 0.0528, 0.7387, 0.3399, 0.542, 0.6338, 0.7032, 0.2762, 0.2987], [0, 0.9806, 0.2147, 0.6596, 0.7146, 0.3293, 0.7825, 0.0908, 0.6291, 0.1198, 0.2761, 0.4664], [0, 0.3256, 0.769, 0.7433, 0.7852, 0.3194, 0.839, 0.9332, 0.8438, 0.5905, 0.7919, 0.5854], [0, 0.3805, 0.9714, 0.4843, 0.6341, 0.2607, 0.6936, 0.9157, 0.223, 0.244, 0.5457, 0.5169], [0, 0.8325, 0.7168, 0.7046, 0.4426, 0.8771, 0.533, 0.0616, 0.9119, 0.8493, 0.764, 0.786], [0, 0.6335, 0.4579, 0.7281, 0.9424, 0.7453, 0.2347, 0.1423, 0.2114, 0.5012, 0.7717, 0.6192], [0.0852, 0.1485, 0.1449, 0.0887, 0.019, 0.9629, 0.0253, 0.6308, 0.3571, 0.4946, 0.03, 0.0456]]]