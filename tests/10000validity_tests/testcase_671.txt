import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min26019 = tf.keras.layers.Input(shape=([1, 2]))
in1Min26019 = tf.keras.layers.Input(shape=([1, 2]))
in0Lea19294 = tf.keras.layers.Input(shape=([1, 2]))
in0Glo49932 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))
in0Con2254 = tf.keras.layers.Input(shape=([1]))
in0Add42666 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))
in1Add42666 = tf.keras.layers.Input(shape=([2, 1, 1, 2]))

Min26019 = keras.layers.Minimum(name = 'Min26019', )([in0Min26019,in1Min26019])
Res35354 = keras.layers.Reshape((1, 2, 1), name = 'Res35354', )(Min26019)
Res82492 = keras.layers.Reshape((1, 2, 1, 1), name = 'Res82492', )(Res35354)
Zer25631 = keras.layers.ZeroPadding3D(padding=((3, 0), (1, 0), (2, 0)), name = 'Zer25631', )(Res82492)
Lea19294 = keras.layers.LeakyReLU(alpha=1.9510063287445663, name = 'Lea19294', input_shape=(1, 2))(in0Lea19294)
Fla45737 = keras.layers.Flatten(name = 'Fla45737', )(Lea19294)
Glo49932 = keras.layers.GlobalAveragePooling3D(name = 'Glo49932', )(in0Glo49932)
Con2254 = keras.layers.Concatenate(axis=1, name = 'Con2254', )([Glo49932,in0Con2254])
Sub38253 = keras.layers.Subtract(name = 'Sub38253', )([Fla45737,Con2254])
Res21668 = keras.layers.Reshape((2, 1), name = 'Res21668', )(Sub38253)
Res16793 = keras.layers.Reshape((2, 1, 1), name = 'Res16793', )(Res21668)
Res72456 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res72456', )(Res16793)
Zer24358 = keras.layers.ZeroPadding3D(padding=((1, 1), (1, 1), (1, 1)), name = 'Zer24358', )(Res72456)
Sub9763 = keras.layers.Subtract(name = 'Sub9763', )([Zer25631,Zer24358])
Res4199 = keras.layers.Reshape((4, 3, 3), name = 'Res4199', )(Sub9763)
Res13481 = keras.layers.Reshape((4, 9), name = 'Res13481', )(Res4199)
Add42666 = keras.layers.Add(name = 'Add42666', )([in0Add42666,in1Add42666])
Res32780 = keras.layers.Reshape((2, 1, 2), name = 'Res32780', )(Add42666)
Res42631 = keras.layers.Reshape((2, 2), name = 'Res42631', )(Res32780)
Zer64319 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer64319', )(Res42631)
Dot40103 = keras.layers.Dot(axes=(1, 1), name = 'Dot40103', )([Res13481,Zer64319])
model = tf.keras.models.Model(inputs=[in0Min26019,in1Min26019,in0Lea19294,in0Glo49932,in0Con2254,in0Add42666,in1Add42666], outputs=Dot40103)
in0Min26019 = tf.constant([[[0.3637, 0.8654]]])
in1Min26019 = tf.constant([[[0.543, 0.381]]])
in0Lea19294 = tf.constant([[[0.1692, 0.1677]]])
in0Glo49932 = tf.constant([[[[[1.9724]]]]])
in0Con2254 = tf.constant([[0.4806]])
in0Add42666 = tf.constant([[[[[0.8498, 0.8388]]], [[[0.444, 0.6644]]]]])
in1Add42666 = tf.constant([[[[[0.2559, 0.4157]]], [[[0.3941, 0.2667]]]]])
print (np.array2string(model.predict([in0Min26019,in1Min26019,in0Lea19294,in0Glo49932,in0Con2254,in0Add42666,in1Add42666],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Dot40103.png')

LMin26019 = minimum_layer([[[[0.3637, 0.8654]]], [[[0.543, 0.381]]]], Min26019), 
LRes35354 = reshape_layer(Min26019, [1, 2, 1], Res35354), 
LRes82492 = reshape_layer(Res35354, [1, 2, 1, 1], Res82492), 
LZer25631 = zero_padding3D_layer(Res82492, 3, 0, 1, 0, 2, 0, Zer25631), 
LLea19294 = leaky_relu_layer([[[0.1692, 0.1677]]], 1.9510063287445663, Lea19294), 
LFla45737 = flatten_layer(Lea19294, Fla45737), 
LGlo49932 = global_average_pooling3D_layer([[[[[1.9724]]]]], Glo49932), 
LCon2254 = concatenate_layer([Glo49932,[[0.4806]]], 1, Con2254), 
LSub38253 = subtract_layer(Fla45737,Con2254, Sub38253), 
LRes21668 = reshape_layer(Sub38253, [2, 1], Res21668), 
LRes16793 = reshape_layer(Res21668, [2, 1, 1], Res16793), 
LRes72456 = reshape_layer(Res16793, [2, 1, 1, 1], Res72456), 
LZer24358 = zero_padding3D_layer(Res72456, 1, 1, 1, 1, 1, 1, Zer24358), 
LSub9763 = subtract_layer(Zer25631,Zer24358, Sub9763), 
LRes4199 = reshape_layer(Sub9763, [4, 3, 3], Res4199), 
LRes13481 = reshape_layer(Res4199, [4, 9], Res13481), 
LAdd42666 = add_layer([[[[[[0.8498, 0.8388]]], [[[0.444, 0.6644]]]]], [[[[[0.2559, 0.4157]]], [[[0.3941, 0.2667]]]]]], Add42666), 
LRes32780 = reshape_layer(Add42666, [2, 1, 2], Res32780), 
LRes42631 = reshape_layer(Res32780, [2, 2], Res42631), 
LZer64319 = zero_padding1D_layer(Res42631, 2, 0, Zer64319), 
LDot40103 = dot_layer(Res13481,Zer64319, 1, 1, Dot40103), 
exec_layers([LMin26019,LRes35354,LRes82492,LZer25631,LLea19294,LFla45737,LGlo49932,LCon2254,LSub38253,LRes21668,LRes16793,LRes72456,LZer24358,LSub9763,LRes4199,LRes13481,LAdd42666,LRes32780,LRes42631,LZer64319,LDot40103],["Min26019","Res35354","Res82492","Zer25631","Lea19294","Fla45737","Glo49932","Con2254","Sub38253","Res21668","Res16793","Res72456","Zer24358","Sub9763","Res4199","Res13481","Add42666","Res32780","Res42631","Zer64319","Dot40103"],Dot40103,"Dot40103")

Actual (Unparsed): [[[0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.3459735, 0.3925331], [0.3048170, 0.3386411], [0.0000000, 0.0000000], [0.0000000, 0.0000000], [0.3193161, 0.3547491]]]

Expected (Unparsed): [[[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.34597353000000014,0.39253305000000005],[0.30481697,0.33864107000000004],[0.0,0.0],[0.0,0.0],[0.31931610000000005,0.35474910000000004]]]

Actual:   [[[0, 0], [0, 0], [0, 0], [0, 0], [0.346, 0.3926], [0.3049, 0.3387], [0, 0], [0, 0], [0.3194, 0.3548]]]

Expected: [[[0, 0], [0, 0], [0, 0], [0, 0], [0.346, 0.3926], [0.3049, 0.3387], [0, 0], [0, 0], [0.3194, 0.3548]]]