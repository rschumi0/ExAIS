import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul19270 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in1Mul19270 = tf.keras.layers.Input(shape=([2, 2, 2, 2]))
in0Add42588 = tf.keras.layers.Input(shape=([1, 2]))
in1Add42588 = tf.keras.layers.Input(shape=([1, 2]))
in0Con79781 = tf.keras.layers.Input(shape=([2, 6]))

Mul19270 = keras.layers.Multiply(name = 'Mul19270', )([in0Mul19270,in1Mul19270])
Res32634 = keras.layers.Reshape((2, 2, 4), name = 'Res32634', )(Mul19270)
Res9 = keras.layers.Reshape((2, 8), name = 'Res9', )(Res32634)
Add42588 = keras.layers.Add(name = 'Add42588', )([in0Add42588,in1Add42588])
Zer73480 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer73480', )(Add42588)
Con79781 = keras.layers.Concatenate(axis=2, name = 'Con79781', )([Zer73480,in0Con79781])
Add47602 = keras.layers.Add(name = 'Add47602', )([Res9,Con79781])
Fla99606 = keras.layers.Flatten(name = 'Fla99606', )(Add47602)
model = tf.keras.models.Model(inputs=[in0Mul19270,in1Mul19270,in0Add42588,in1Add42588,in0Con79781], outputs=Fla99606)
in0Mul19270 = tf.constant([[[[[0.7154, 0.2287], [0.17, 0.9392]], [[0.6029, 0.0959], [0.5786, 0.9846]]], [[[0.5843, 0.0773], [0.4185, 0.0192]], [[0.6876, 0.9969], [0.5116, 0.8783]]]]])
in1Mul19270 = tf.constant([[[[[0.2882, 0.1359], [0.1308, 0.6517]], [[0.8911, 0.5689], [0.8316, 0.8619]]], [[[0.4333, 0.9278], [0.2579, 0.3574]], [[0.5403, 0.9704], [0.4195, 0.9587]]]]])
in0Add42588 = tf.constant([[[0.6403, 0.5674]]])
in1Add42588 = tf.constant([[[0.7325, 0.5796]]])
in0Con79781 = tf.constant([[[0.3654, 0.2308, 0.5054, 0.8931, 0.7605, 0.504], [0.8321, 0.3934, 0.9123, 0.8702, 0.2884, 0.9529]]])
print (np.array2string(model.predict([in0Mul19270,in1Mul19270,in0Add42588,in1Add42588,in0Con79781],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Fla99606.png')

LMul19270 = multiply_layer([[[[[[0.7154, 0.2287], [0.17, 0.9392]], [[0.6029, 0.0959], [0.5786, 0.9846]]], [[[0.5843, 0.0773], [0.4185, 0.0192]], [[0.6876, 0.9969], [0.5116, 0.8783]]]]], [[[[[0.2882, 0.1359], [0.1308, 0.6517]], [[0.8911, 0.5689], [0.8316, 0.8619]]], [[[0.4333, 0.9278], [0.2579, 0.3574]], [[0.5403, 0.9704], [0.4195, 0.9587]]]]]], Mul19270), 
LRes32634 = reshape_layer(Mul19270, [2, 2, 4], Res32634), 
LRes9 = reshape_layer(Res32634, [2, 8], Res9), 
LAdd42588 = add_layer([[[[0.6403, 0.5674]]], [[[0.7325, 0.5796]]]], Add42588), 
LZer73480 = zero_padding1D_layer(Add42588, 1, 0, Zer73480), 
LCon79781 = concatenate_layer([Zer73480,[[[0.3654, 0.2308, 0.5054, 0.8931, 0.7605, 0.504], [0.8321, 0.3934, 0.9123, 0.8702, 0.2884, 0.9529]]]], 2, Con79781), 
LAdd47602 = add_layer([Res9,Con79781], Add47602), 
LFla99606 = flatten_layer(Add47602, Fla99606), 
exec_layers([LMul19270,LRes32634,LRes9,LAdd42588,LZer73480,LCon79781,LAdd47602,LFla99606],["Mul19270","Res32634","Res9","Add42588","Zer73480","Con79781","Add47602","Fla99606"],Fla99606,"Fla99606")

Actual (Unparsed): [[0.2061783, 0.0310803, 0.3876360, 0.8428767, 1.0426442, 0.9476575, 1.2416638, 1.3526267, 1.6259772, 1.2187189, 0.9400311, 0.4002621, 1.2838103, 1.8375917, 0.5030162, 1.7949262]]

Expected (Unparsed): [[0.20617828000000002,0.031080329999999996,0.387636,0.84287664,1.0426441899999999,0.94765751,1.24166376,1.35262674,1.62597719,1.21871894,0.9400311499999999,0.40026208,1.28381028,1.83759176,0.5030162,1.7949262099999999]]

Actual:   [[0.2062, 0.0311, 0.3877, 0.8429, 1.0427, 0.9477, 1.2417, 1.3527, 1.626, 1.2188, 0.9401, 0.4003, 1.2839, 1.8376, 0.5031, 1.795]]

Expected: [[0.2062, 0.0311, 0.3877, 0.8429, 1.0427, 0.9477, 1.2417, 1.3527, 1.626, 1.2188, 0.9401, 0.4003, 1.2839, 1.8376, 0.5031, 1.795]]