import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0PRe77604 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in0Add51071 = tf.keras.layers.Input(shape=([2, 2]))
in1Add51071 = tf.keras.layers.Input(shape=([2, 2]))
in0Con24493 = tf.keras.layers.Input(shape=([2, 6]))

PRe77604 = keras.layers.PReLU(name = 'PRe77604', input_shape=(1, 2, 2, 2))(in0PRe77604)
ELU9457 = keras.layers.ELU(alpha=-1.9061962693106356, name = 'ELU9457', )(PRe77604)
Res4037 = keras.layers.Reshape((1, 2, 4), name = 'Res4037', )(ELU9457)
Res91430 = keras.layers.Reshape((1, 8), name = 'Res91430', )(Res4037)
Zer99968 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer99968', )(Res91430)
Add51071 = keras.layers.Add(name = 'Add51071', )([in0Add51071,in1Add51071])
Con24493 = keras.layers.Concatenate(axis=2, name = 'Con24493', )([Add51071,in0Con24493])
Mul27586 = keras.layers.Multiply(name = 'Mul27586', )([Zer99968,Con24493])
Sim90320 = keras.layers.SimpleRNN(2,name = 'Sim90320', )(Mul27586)
model = tf.keras.models.Model(inputs=[in0PRe77604,in0Add51071,in1Add51071,in0Con24493], outputs=Sim90320)
w = model.get_layer('PRe77604').get_weights() 
w[0] = np.array([[[[0.642, 0.3391], [0.9276, 0.0469]], [[0.8629, 0.1188], [0.1517, 0.3465]]]])
model.get_layer('PRe77604').set_weights(w) 
w = model.get_layer('Sim90320').get_weights() 
w[0] = np.array([[5, 7], [6, 3], [9, 6], [1, 9], [6, 4], [3, 8], [6, 7], [1, 4]])
w[1] = np.array([[3, 9], [10, 5]])
w[2] = np.array([10, 4])
model.get_layer('Sim90320').set_weights(w) 
in0PRe77604 = tf.constant([[[[[0.0176, 0.1078], [0.1517, 0.3392]], [[0.0776, 0.9241], [0.9035, 0.0812]]]]])
in0Add51071 = tf.constant([[[0.5488, 0.4419], [0.1154, 0.826]]])
in1Add51071 = tf.constant([[[0.622, 0.0273], [0.0187, 0.2748]]])
in0Con24493 = tf.constant([[[0.4597, 0.0162, 0.1615, 0.8122, 0.4312, 0.1083], [0.8666, 0.7879, 0.0786, 0.9668, 0.0074, 0.2334]]])
print (np.array2string(model.predict([in0PRe77604,in0Add51071,in1Add51071,in0Con24493],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sim90320.png')

LPRe77604 = prelu_layer([[[[[0.0176, 0.1078], [0.1517, 0.3392]], [[0.0776, 0.9241], [0.9035, 0.0812]]]]], [[[[0.642, 0.3391], [0.9276, 0.0469]], [[0.8629, 0.1188], [0.1517, 0.3465]]]], PRe77604), 
LELU9457 = elu_layer(PRe77604, -1.9061962693106356, ELU9457), 
LRes4037 = reshape_layer(ELU9457, [1, 2, 4], Res4037), 
LRes91430 = reshape_layer(Res4037, [1, 8], Res91430), 
LZer99968 = zero_padding1D_layer(Res91430, 1, 0, Zer99968), 
LAdd51071 = add_layer([[[[0.5488, 0.4419], [0.1154, 0.826]]], [[[0.622, 0.0273], [0.0187, 0.2748]]]], Add51071), 
LCon24493 = concatenate_layer([Add51071,[[[0.4597, 0.0162, 0.1615, 0.8122, 0.4312, 0.1083], [0.8666, 0.7879, 0.0786, 0.9668, 0.0074, 0.2334]]]], 2, Con24493), 
LMul27586 = multiply_layer([Zer99968,Con24493], Mul27586), 
LSim90320 = simple_rnn_layer(Mul27586,[[5, 7], [6, 3], [9, 6], [1, 9], [6, 4], [3, 8], [6, 7], [1, 4]],[[3, 9], [10, 5]],[10, 4], Sim90320), 
exec_layers([LPRe77604,LELU9457,LRes4037,LRes91430,LZer99968,LAdd51071,LCon24493,LMul27586,LSim90320],["PRe77604","ELU9457","Res4037","Res91430","Zer99968","Add51071","Con24493","Mul27586","Sim90320"],Sim90320,"Sim90320")

Actual (Unparsed): [[1.0000000, 1.0000000]]

Expected (Unparsed): [[1.0,1.0]]

Actual:   [[1, 1]]

Expected: [[1, 1]]