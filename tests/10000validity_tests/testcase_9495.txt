import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Up_55645 = tf.keras.layers.Input(shape=([3, 4, 2]))
in0Max89591 = tf.keras.layers.Input(shape=([2, 1]))
in0Con73131 = tf.keras.layers.Input(shape=([95]))

Up_55645 = keras.layers.UpSampling2D(size=(2, 2), name = 'Up_55645', )(in0Up_55645)
Res80032 = keras.layers.Reshape((6, 16), name = 'Res80032', )(Up_55645)
Fla81888 = keras.layers.Flatten(name = 'Fla81888', )(Res80032)
Max89591 = keras.layers.MaxPool1D(pool_size=(1), name = 'Max89591', )(in0Max89591)
Glo16183 = keras.layers.GlobalMaxPool1D(name = 'Glo16183', )(Max89591)
Con73131 = keras.layers.Concatenate(axis=1, name = 'Con73131', )([Glo16183,in0Con73131])
Mul348 = keras.layers.Multiply(name = 'Mul348', )([Fla81888,Con73131])
model = tf.keras.models.Model(inputs=[in0Up_55645,in0Max89591,in0Con73131], outputs=Mul348)
in0Up_55645 = tf.constant([[[[1.4008, 1.6812], [1.3127, 1.6637], [1.0494, 1.5418], [1.6231, 1.0546]], [[1.3307, 1.904], [1.0766, 1.5201], [1.0935, 1.2519], [1.849, 1.0818]], [[1.0531, 1.9608], [1.1776, 1.7364], [1.4822, 1.0493], [1.1258, 1.5118]]]])
in0Max89591 = tf.constant([[[1.9098], [1.5025]]])
in0Con73131 = tf.constant([[0.455, 0.8323, 0.2211, 0.4709, 0.9821, 0.7907, 0.5303, 0.6265, 0.8591, 0.9186, 0.743, 0.1964, 0.5607, 0.4438, 0.1147, 0.5968, 0.7303, 0.7013, 0.2065, 0.4881, 0.2164, 0.1251, 0.7516, 0.3908, 0.9188, 0.8355, 0.3538, 0.3988, 0.2361, 0.8162, 0.1836, 0.2503, 0.4727, 0.3401, 0.1649, 0.0719, 0.9051, 0.9993, 0.7572, 0.698, 0.3374, 0.4204, 0.3291, 0.5866, 0.8775, 0.5075, 0.2919, 1, 0.3599, 0.8446, 0.6152, 0.3031, 0.306, 0.7086, 0.0848, 0.9404, 0.5678, 0.0001, 0.675, 0.897, 0.8278, 0.2792, 0.7102, 0.2259, 0.949, 0.0112, 0.0663, 0.5247, 0.7547, 0.0726, 0.524, 0.0861, 0.2023, 0.5448, 0.529, 0.8127, 0.0653, 0.8327, 0.0334, 0.886, 0.1824, 0.1845, 0.8012, 0.6105, 0.0464, 0.7604, 0.5424, 0.817, 0.0124, 0.5017, 0.5089, 0.6989, 0.6816, 0.1836, 0.7325]])
print (np.array2string(model.predict([in0Up_55645,in0Max89591,in0Con73131],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul348.png')

LUp_55645 = up_sampling2D_layer([[[[1.4008, 1.6812], [1.3127, 1.6637], [1.0494, 1.5418], [1.6231, 1.0546]], [[1.3307, 1.904], [1.0766, 1.5201], [1.0935, 1.2519], [1.849, 1.0818]], [[1.0531, 1.9608], [1.1776, 1.7364], [1.4822, 1.0493], [1.1258, 1.5118]]]], 2, 2, Up_55645), 
LRes80032 = reshape_layer(Up_55645, [6, 16], Res80032), 
LFla81888 = flatten_layer(Res80032, Fla81888), 
LMax89591 = max_pool1D_layer([[[1.9098], [1.5025]]], 1, Max89591), 
LGlo16183 = global_max_pool1D_layer(Max89591, Glo16183), 
LCon73131 = concatenate_layer([Glo16183,[[0.455, 0.8323, 0.2211, 0.4709, 0.9821, 0.7907, 0.5303, 0.6265, 0.8591, 0.9186, 0.743, 0.1964, 0.5607, 0.4438, 0.1147, 0.5968, 0.7303, 0.7013, 0.2065, 0.4881, 0.2164, 0.1251, 0.7516, 0.3908, 0.9188, 0.8355, 0.3538, 0.3988, 0.2361, 0.8162, 0.1836, 0.2503, 0.4727, 0.3401, 0.1649, 0.0719, 0.9051, 0.9993, 0.7572, 0.698, 0.3374, 0.4204, 0.3291, 0.5866, 0.8775, 0.5075, 0.2919, 1, 0.3599, 0.8446, 0.6152, 0.3031, 0.306, 0.7086, 0.0848, 0.9404, 0.5678, 0.0001, 0.675, 0.897, 0.8278, 0.2792, 0.7102, 0.2259, 0.949, 0.0112, 0.0663, 0.5247, 0.7547, 0.0726, 0.524, 0.0861, 0.2023, 0.5448, 0.529, 0.8127, 0.0653, 0.8327, 0.0334, 0.886, 0.1824, 0.1845, 0.8012, 0.6105, 0.0464, 0.7604, 0.5424, 0.817, 0.0124, 0.5017, 0.5089, 0.6989, 0.6816, 0.1836, 0.7325]]], 1, Con73131), 
LMul348 = multiply_layer([Fla81888,Con73131], Mul348), 
exec_layers([LUp_55645,LRes80032,LFla81888,LMax89591,LGlo16183,LCon73131,LMul348],["Up_55645","Res80032","Fla81888","Max89591","Glo16183","Con73131","Mul348"],Mul348,"Mul348")

Actual (Unparsed): [[2.6752479, 0.7649460, 1.1658858, 0.3717133, 0.6181504, 1.6339198, 1.0379519, 0.8822601, 0.6574491, 1.3245604, 0.9639788, 1.1455574, 0.3187769, 0.5913142, 0.7203318, 0.1209626, 0.8359975, 1.2277804, 0.9823811, 0.3471678, 0.6407289, 0.3600247, 0.1642188, 1.2504370, 0.4101055, 1.4166059, 0.8767737, 0.5454888, 0.6472923, 0.2489911, 1.3247743, 0.1936246, 0.3330742, 0.9000208, 0.4525711, 0.3139696, 0.0774075, 1.3758425, 1.0758463, 1.1510197, 0.7632630, 0.4223910, 0.4597074, 0.4120003, 1.0846234, 0.9492795, 0.9383675, 0.3157774, 1.3307000, 0.6852496, 1.1239093, 1.1713408, 0.3263174, 0.4651506, 0.7628787, 0.1289045, 1.0283274, 0.7108288, 0.0001093, 0.8450325, 1.6585530, 0.8955140, 0.5162408, 0.7682944, 0.2378953, 1.8607993, 0.0117947, 0.1300010, 0.6178867, 1.3104611, 0.0854938, 0.9098736, 0.1276174, 0.2122734, 0.8075025, 0.5550797, 0.9149376, 0.0987205, 0.9374537, 0.0504941, 0.9330466, 0.3576499, 0.1942969, 1.5709929, 0.7189248, 0.0805690, 0.8954471, 0.9418234, 1.2109574, 0.0130113, 0.7436197, 0.5339887, 0.7868216, 1.0304429, 0.2066969, 1.1073936]]

Expected (Unparsed): [[2.67524784,0.764946,1.16588584,0.37171332,0.6181504299999999,1.6339197699999999,1.03795189,0.8822601099999999,0.6574491,1.32456038,0.9639788400000001,1.1455574,0.31877684,0.59131422,0.72033178,0.12096261999999999,0.83599744,1.22778036,0.98238104,0.34716779999999997,0.64072887,0.36002468,0.16421877,1.25043692,0.41010552,1.41660584,0.8767737000000001,0.54548884,0.6472922799999999,0.24899106000000001,1.3247742200000001,0.19362456,0.33307421000000004,0.9000208,0.45257107,0.31396959999999996,0.07740754000000001,1.37584251,1.07584638,1.15101972,0.7632629999999999,0.42239106,0.45970739999999993,0.41200029,1.0846234,0.9492795,0.9383674999999999,0.31577742000000003,1.3307,0.6852496,1.12390922,1.1713407999999998,0.32631746,0.46515059999999997,0.76287876,0.12890448,1.0283274,0.7108288199999999,0.00010935,0.8450325000000001,1.658553,0.89551404,0.5162408,0.7682943600000002,0.23789528999999998,1.8607992,0.01179472,0.13000104,0.61788672,1.31046108,0.08549376,0.9098736000000001,0.12761741999999998,0.21227338999999998,0.8075025599999999,0.5550797,0.9149376599999999,0.09872054,0.93745366,0.050494119999999997,0.9330466,0.35764992,0.19429695,1.57099296,0.7189248,0.08056896,0.89544704,0.94182336,1.2109573999999999,0.013011319999999998,0.7436197400000001,0.53398877,0.7868216199999999,1.03044288,0.20669688,1.1073935000000001]]

Actual:   [[2.6753, 0.765, 1.1659, 0.3718, 0.6182, 1.634, 1.038, 0.8823, 0.6575, 1.3246, 0.964, 1.1456, 0.3188, 0.5914, 0.7204, 0.121, 0.836, 1.2278, 0.9824, 0.3472, 0.6408, 0.3601, 0.1643, 1.2505, 0.4102, 1.4167, 0.8768, 0.5455, 0.6473, 0.249, 1.3248, 0.1937, 0.3331, 0.9001, 0.4526, 0.314, 0.0775, 1.3759, 1.0759, 1.1511, 0.7633, 0.4224, 0.4598, 0.4121, 1.0847, 0.9493, 0.9384, 0.3158, 1.3307, 0.6853, 1.124, 1.1714, 0.3264, 0.4652, 0.7629, 0.129, 1.0284, 0.7109, 0.0002, 0.8451, 1.6586, 0.8956, 0.5163, 0.7683, 0.2379, 1.8608, 0.0118, 0.1301, 0.6179, 1.3105, 0.0855, 0.9099, 0.1277, 0.2123, 0.8076, 0.5551, 0.915, 0.0988, 0.9375, 0.0505, 0.9331, 0.3577, 0.1943, 1.571, 0.719, 0.0806, 0.8955, 0.9419, 1.211, 0.0131, 0.7437, 0.534, 0.7869, 1.0305, 0.2067, 1.1074]]

Expected: [[2.6753, 0.765, 1.1659, 0.3718, 0.6182, 1.634, 1.038, 0.8823, 0.6575, 1.3246, 0.964, 1.1456, 0.3188, 0.5914, 0.7204, 0.121, 0.836, 1.2278, 0.9824, 0.3472, 0.6408, 0.3601, 0.1643, 1.2505, 0.4102, 1.4167, 0.8768, 0.5455, 0.6473, 0.249, 1.3248, 0.1937, 0.3331, 0.9001, 0.4526, 0.314, 0.0775, 1.3759, 1.0759, 1.1511, 0.7633, 0.4224, 0.4598, 0.4121, 1.0847, 0.9493, 0.9384, 0.3158, 1.3307, 0.6853, 1.124, 1.1714, 0.3264, 0.4652, 0.7629, 0.129, 1.0284, 0.7109, 0.0002, 0.8451, 1.6586, 0.8956, 0.5163, 0.7683, 0.2379, 1.8608, 0.0118, 0.1301, 0.6179, 1.3105, 0.0855, 0.9099, 0.1277, 0.2123, 0.8076, 0.5551, 0.915, 0.0988, 0.9375, 0.0505, 0.9331, 0.3577, 0.1943, 1.571, 0.719, 0.0806, 0.8955, 0.9419, 1.211, 0.0131, 0.7437, 0.534, 0.7869, 1.0305, 0.2067, 1.1074]]