import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Bat40543 = tf.keras.layers.Input(shape=([2, 1, 3]))
in0Min93733 = tf.keras.layers.Input(shape=([2, 2, 1]))
in1Min93733 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Con26855 = tf.keras.layers.Input(shape=([2, 2, 2]))

Bat40543 = keras.layers.BatchNormalization(axis=2, epsilon=0.9049034491804262,  name = 'Bat40543', )(in0Bat40543)
Zer21682 = keras.layers.ZeroPadding2D(padding=((0, 0), (1, 0)), name = 'Zer21682', )(Bat40543)
Min93733 = keras.layers.Minimum(name = 'Min93733', )([in0Min93733,in1Min93733])
Thr79898 = keras.layers.ThresholdedReLU(theta=5.143885158712969, name = 'Thr79898', )(Min93733)
Con26855 = keras.layers.Concatenate(axis=3, name = 'Con26855', )([Thr79898,in0Con26855])
Add40015 = keras.layers.Add(name = 'Add40015', )([Zer21682,Con26855])
model = tf.keras.models.Model(inputs=[in0Bat40543,in0Min93733,in1Min93733,in0Con26855], outputs=Add40015)
w = model.get_layer('Bat40543').get_weights() 
w[0] = np.array([0.9336])
w[1] = np.array([0.9457])
w[2] = np.array([0.6523])
w[3] = np.array([0.5721])
model.get_layer('Bat40543').set_weights(w) 
in0Bat40543 = tf.constant([[[[1.3621, 1.2649, 1.5602]], [[1.9253, 1.0539, 1.7746]]]])
in0Min93733 = tf.constant([[[[0.8448], [0.1492]], [[0.664], [0.8351]]]])
in1Min93733 = tf.constant([[[[0.3876], [0.9406]], [[0.4579], [0.5916]]]])
in0Con26855 = tf.constant([[[[0.594, 0.8589], [0.5366, 0.9858]], [[0.5282, 0.7481], [0.0825, 0.2171]]]])
print (np.array2string(model.predict([in0Bat40543,in0Min93733,in1Min93733,in0Con26855],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add40015.png')

LBat40543 = batch_normalization_layer([[[[1.3621, 1.2649, 1.5602]], [[1.9253, 1.0539, 1.7746]]]], 2, 0.9049034491804262, [0.9336], [0.9457], [0.6523], [0.5721], Bat40543), 
LZer21682 = zero_padding2D_layer(Bat40543, 0, 0, 1, 0, Zer21682), 
LMin93733 = minimum_layer([[[[[0.8448], [0.1492]], [[0.664], [0.8351]]]], [[[[0.3876], [0.9406]], [[0.4579], [0.5916]]]]], Min93733), 
LThr79898 = thresholded_relu_layer(Min93733, 5.143885158712969, Thr79898), 
LCon26855 = concatenate_layer([Thr79898,[[[[0.594, 0.8589], [0.5366, 0.9858]], [[0.5282, 0.7481], [0.0825, 0.2171]]]]], 3, Con26855), 
LAdd40015 = add_layer([Zer21682,Con26855], Add40015), 
exec_layers([LBat40543,LZer21682,LMin93733,LThr79898,LCon26855,LAdd40015],["Bat40543","Zer21682","Min93733","Thr79898","Con26855","Add40015"],Add40015,"Add40015")

Actual (Unparsed): [[[[0.0000000, 0.5940000, 0.8589000], [1.4909631, 1.9528947, 2.6289420]], [[0.0000000, 0.5282000, 0.7481000], [1.9236091, 1.3367061, 2.0249425]]]]

Expected (Unparsed): [[[[0,0.594,0.8589],[1.490963068554378,1.9528947531648517,2.628942011750521]],[[0,0.5282,0.7481],[1.9236091099883388,1.3367061261361484,2.0249424934327673]]]]

Actual:   [[[[0, 0.594, 0.8589], [1.491, 1.9529, 2.629]], [[0, 0.5282, 0.7481], [1.9237, 1.3368, 2.025]]]]

Expected: [[[[0, 0.594, 0.8589], [1.491, 1.9529, 2.629]], [[0, 0.5282, 0.7481], [1.9237, 1.3368, 2.025]]]]