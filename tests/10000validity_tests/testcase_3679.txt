import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Thr7324 = tf.keras.layers.Input(shape=([1, 2, 2, 1]))
in0Dot13304 = tf.keras.layers.Input(shape=([2]))
in1Dot13304 = tf.keras.layers.Input(shape=([2]))
in0Con21703 = tf.keras.layers.Input(shape=([7]))

Thr7324 = keras.layers.ThresholdedReLU(theta=7.103650042817193, name = 'Thr7324', input_shape=(1, 2, 2, 1))(in0Thr7324)
Res52210 = keras.layers.Reshape((1, 2, 2), name = 'Res52210', )(Thr7324)
PRe67458 = keras.layers.PReLU(name = 'PRe67458', )(Res52210)
Res2997 = keras.layers.Reshape((1, 4), name = 'Res2997', )(PRe67458)
Zer15803 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer15803', )(Res2997)
ELU14833 = keras.layers.ELU(alpha=8.984026846195462, name = 'ELU14833', )(Zer15803)
Fla40486 = keras.layers.Flatten(name = 'Fla40486', )(ELU14833)
Dot13304 = keras.layers.Dot(axes=(1, 1), name = 'Dot13304', )([in0Dot13304,in1Dot13304])
Con21703 = keras.layers.Concatenate(axis=1, name = 'Con21703', )([Dot13304,in0Con21703])
Add60091 = keras.layers.Add(name = 'Add60091', )([Fla40486,Con21703])
Res78405 = keras.layers.Reshape((8, 1), name = 'Res78405', )(Add60091)
Res26472 = keras.layers.Reshape((8, 1, 1), name = 'Res26472', )(Res78405)
Zer79263 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer79263', )(Res26472)
model = tf.keras.models.Model(inputs=[in0Thr7324,in0Dot13304,in1Dot13304,in0Con21703], outputs=Zer79263)
w = model.get_layer('PRe67458').get_weights() 
w[0] = np.array([[[0.5314, 0.4146], [0.0817, 0.021]]])
model.get_layer('PRe67458').set_weights(w) 
in0Thr7324 = tf.constant([[[[[0.0765], [0.3278]], [[0.1803], [0.749]]]]])
in0Dot13304 = tf.constant([[0.6942, 0.2088]])
in1Dot13304 = tf.constant([[0.6044, 0.1631]])
in0Con21703 = tf.constant([[0.0831, 0.9951, 0.2622, 0.631, 0.1032, 0.5726, 0.2443]])
print (np.array2string(model.predict([in0Thr7324,in0Dot13304,in1Dot13304,in0Con21703],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Zer79263.png')

LThr7324 = thresholded_relu_layer([[[[[0.0765], [0.3278]], [[0.1803], [0.749]]]]], 7.103650042817193, Thr7324), 
LRes52210 = reshape_layer(Thr7324, [1, 2, 2], Res52210), 
LPRe67458 = prelu_layer(Res52210, [[[0.5314, 0.4146], [0.0817, 0.021]]], PRe67458), 
LRes2997 = reshape_layer(PRe67458, [1, 4], Res2997), 
LZer15803 = zero_padding1D_layer(Res2997, 1, 0, Zer15803), 
LELU14833 = elu_layer(Zer15803, 8.984026846195462, ELU14833), 
LFla40486 = flatten_layer(ELU14833, Fla40486), 
LDot13304 = dot_layer([[0.6942, 0.2088]], [[0.6044, 0.1631]], 1, 1, Dot13304), 
LCon21703 = concatenate_layer([Dot13304,[[0.0831, 0.9951, 0.2622, 0.631, 0.1032, 0.5726, 0.2443]]], 1, Con21703), 
LAdd60091 = add_layer([Fla40486,Con21703], Add60091), 
LRes78405 = reshape_layer(Add60091, [8, 1], Res78405), 
LRes26472 = reshape_layer(Res78405, [8, 1, 1], Res26472), 
LZer79263 = zero_padding2D_layer(Res26472, 1, 1, 1, 1, Zer79263), 
exec_layers([LThr7324,LRes52210,LPRe67458,LRes2997,LZer15803,LELU14833,LFla40486,LDot13304,LCon21703,LAdd60091,LRes78405,LRes26472,LZer79263],["Thr7324","Res52210","PRe67458","Res2997","Zer15803","ELU14833","Fla40486","Dot13304","Con21703","Add60091","Res78405","Res26472","Zer79263"],Zer79263,"Zer79263")

Actual (Unparsed): [[[[0.0000000], [0.0000000], [0.0000000]], [[0.0000000], [0.4536297], [0.0000000]], [[0.0000000], [0.0831000], [0.0000000]], [[0.0000000], [0.9951000], [0.0000000]], [[0.0000000], [0.2622000], [0.0000000]], [[0.0000000], [0.6310000], [0.0000000]], [[0.0000000], [0.1032000], [0.0000000]], [[0.0000000], [0.5726000], [0.0000000]], [[0.0000000], [0.2443000], [0.0000000]], [[0.0000000], [0.0000000], [0.0000000]]]]

Expected (Unparsed): [[[[0],[0],[0]],[[0],[0.4536297600000001],[0]],[[0],[0.0831],[0]],[[0],[0.9951],[0]],[[0],[0.2622],[0]],[[0],[0.631],[0]],[[0],[0.1032],[0]],[[0],[0.5726],[0]],[[0],[0.2443],[0]],[[0],[0],[0]]]]

Actual:   [[[[0], [0], [0]], [[0], [0.4537], [0]], [[0], [0.0831], [0]], [[0], [0.9951], [0]], [[0], [0.2622], [0]], [[0], [0.631], [0]], [[0], [0.1032], [0]], [[0], [0.5726], [0]], [[0], [0.2443], [0]], [[0], [0], [0]]]]

Expected: [[[[0], [0], [0]], [[0], [0.4537], [0]], [[0], [0.0831], [0]], [[0], [0.9951], [0]], [[0], [0.2622], [0]], [[0], [0.631], [0]], [[0], [0.1032], [0]], [[0], [0.5726], [0]], [[0], [0.2443], [0]], [[0], [0], [0]]]]