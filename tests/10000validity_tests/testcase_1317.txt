import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0ELU52790 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Sub61026 = tf.keras.layers.Input(shape=([2, 2]))
in1Sub61026 = tf.keras.layers.Input(shape=([2, 2]))

ELU52790 = keras.layers.ELU(alpha=9.394128463970148, name = 'ELU52790', input_shape=(1, 2, 1))(in0ELU52790)
Res80619 = keras.layers.Reshape((1, 2), name = 'Res80619', )(ELU52790)
Zer11379 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer11379', )(Res80619)
Sub61026 = keras.layers.Subtract(name = 'Sub61026', )([in0Sub61026,in1Sub61026])
Dot25942 = keras.layers.Dot(axes=(2, 2), name = 'Dot25942', )([Zer11379,Sub61026])
Bat27260 = keras.layers.BatchNormalization(axis=1, epsilon=0.8697883469521491,  name = 'Bat27260', )(Dot25942)
model = tf.keras.models.Model(inputs=[in0ELU52790,in0Sub61026,in1Sub61026], outputs=Bat27260)
w = model.get_layer('Bat27260').get_weights() 
w[0] = np.array([0.0312, 0.8742])
w[1] = np.array([0.7069, 0.9373])
w[2] = np.array([0.4964, 0.2674])
w[3] = np.array([0.1871, 0.6688])
model.get_layer('Bat27260').set_weights(w) 
in0ELU52790 = tf.constant([[[[0.1623], [0.2024]]]])
in0Sub61026 = tf.constant([[[0.7714, 0.6737], [0.6997, 0.0817]]])
in1Sub61026 = tf.constant([[[0.4044, 0.2158], [0.1123, 0.0288]]])
print (np.array2string(model.predict([in0ELU52790,in0Sub61026,in1Sub61026],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat27260.png')

LELU52790 = elu_layer([[[[0.1623], [0.2024]]]], 9.394128463970148, ELU52790), 
LRes80619 = reshape_layer(ELU52790, [1, 2], Res80619), 
LZer11379 = zero_padding1D_layer(Res80619, 1, 0, Zer11379), 
LSub61026 = subtract_layer([[[0.7714, 0.6737], [0.6997, 0.0817]]], [[[0.4044, 0.2158], [0.1123, 0.0288]]], Sub61026), 
LDot25942 = dot_layer(Zer11379,Sub61026, 2, 2, Dot25942), 
LBat27260 = batch_normalization_layer(Dot25942, 1, 0.8697883469521491, [0.0312, 0.8742], [0.7069, 0.9373], [0.4964, 0.2674], [0.1871, 0.6688], Bat27260), 
exec_layers([LELU52790,LRes80619,LZer11379,LSub61026,LDot25942,LBat27260],["ELU52790","Res80619","Zer11379","Sub61026","Dot25942","Bat27260"],Bat27260,"Bat27260")

Actual (Unparsed): [[[0.6918349, 0.6918349], [0.8561404, 0.8235791]]]

Expected (Unparsed): [[[0.6918349071701113,0.6918349071701113],[0.8561404372039415,0.8235791390875994]]]

Actual:   [[[0.6919, 0.6919], [0.8562, 0.8236]]]

Expected: [[[0.6919, 0.6919], [0.8562, 0.8236]]]