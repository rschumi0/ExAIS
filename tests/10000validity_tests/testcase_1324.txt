import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave10608 = tf.keras.layers.Input(shape=([1, 2]))
in1Ave10608 = tf.keras.layers.Input(shape=([1, 2]))
in0Con36532 = tf.keras.layers.Input(shape=([6]))
in0Loc77501 = tf.keras.layers.Input(shape=([2, 2]))
in0Sub84246 = tf.keras.layers.Input(shape=([2, 3, 2, 2]))
in1Sub84246 = tf.keras.layers.Input(shape=([2, 3, 2, 2]))
in0Con39412 = tf.keras.layers.Input(shape=([5]))

Ave10608 = keras.layers.Average(name = 'Ave10608', )([in0Ave10608,in1Ave10608])
Fla92801 = keras.layers.Flatten(name = 'Fla92801', )(Ave10608)
Con36532 = keras.layers.Concatenate(axis=1, name = 'Con36532', )([Fla92801,in0Con36532])
Loc77501 = keras.layers.LocallyConnected1D(4, (1),strides=(1), name = 'Loc77501', )(in0Loc77501)
Fla71014 = keras.layers.Flatten(name = 'Fla71014', )(Loc77501)
Sub84246 = keras.layers.Subtract(name = 'Sub84246', )([in0Sub84246,in1Sub84246])
Lea94548 = keras.layers.LeakyReLU(alpha=9.511276087253105, name = 'Lea94548', )(Sub84246)
Res32503 = keras.layers.Reshape((2, 3, 4), name = 'Res32503', )(Lea94548)
Res72267 = keras.layers.Reshape((2, 12), name = 'Res72267', )(Res32503)
GRU6085 = keras.layers.GRU(3,reset_after=False, recurrent_activation='sigmoid', name = 'GRU6085', )(Res72267)
Con39412 = keras.layers.Concatenate(axis=1, name = 'Con39412', )([GRU6085,in0Con39412])
Min78792 = keras.layers.Minimum(name = 'Min78792', )([Fla71014,Con39412])
Min93464 = keras.layers.Minimum(name = 'Min93464', )([Con36532,Min78792])
model = tf.keras.models.Model(inputs=[in0Ave10608,in1Ave10608,in0Con36532,in0Loc77501,in0Sub84246,in1Sub84246,in0Con39412], outputs=Min93464)
w = model.get_layer('Loc77501').get_weights() 
w[0] = np.array([[[0.7322, 0.7652, 0.3388, 0.6135], [0.5401, 0.4945, 0.4041, 0.9746]], [[0.6942, 0.2441, 0.3327, 0.8074], [0.9097, 0.7816, 0.9084, 0.383]]])
w[1] = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])
model.get_layer('Loc77501').set_weights(w) 
w = model.get_layer('GRU6085').get_weights() 
w[0] = np.array([[6, 9, 4, 3, 6, 2, 3, 4, 10], [9, 8, 1, 6, 9, 3, 5, 8, 7], [1, 4, 8, 6, 6, 2, 5, 7, 1], [2, 6, 4, 10, 8, 4, 9, 6, 1], [4, 8, 5, 3, 8, 1, 6, 2, 7], [6, 5, 1, 5, 1, 1, 2, 10, 6], [5, 5, 2, 8, 9, 8, 1, 9, 1], [10, 6, 7, 3, 7, 6, 7, 4, 4], [6, 4, 7, 5, 2, 8, 2, 7, 4], [2, 8, 5, 5, 4, 5, 2, 1, 6], [4, 7, 3, 3, 1, 2, 1, 7, 7], [10, 2, 2, 4, 3, 8, 8, 2, 3]])
w[1] = np.array([[1, 7, 8, 3, 6, 5, 6, 5, 8], [4, 10, 4, 1, 10, 4, 5, 2, 1], [10, 8, 3, 1, 5, 4, 6, 2, 3]])
w[2] = np.array([8, 2, 6, 9, 5, 10, 9, 4, 4])
model.get_layer('GRU6085').set_weights(w) 
in0Ave10608 = tf.constant([[[0.8975, 0.8248]]])
in1Ave10608 = tf.constant([[[0.3194, 0.2706]]])
in0Con36532 = tf.constant([[0.2184, 0.9464, 0.4671, 0.035, 0.0252, 0.0838]])
in0Loc77501 = tf.constant([[[0.7943, 0.306], [0.3446, 0.5607]]])
in0Sub84246 = tf.constant([[[[[0.7696, 0.6591], [0.9582, 0.3905]], [[0.9141, 0.2313], [0.1199, 0.3275]], [[0.9555, 0.692], [0.131, 0.1703]]], [[[0.7508, 0.4771], [0.3568, 0.6839]], [[0.504, 0.1569], [0.4428, 0.383]], [[0.8537, 0.0078], [0.3103, 0.9141]]]]])
in1Sub84246 = tf.constant([[[[[0.9253, 0.3396], [0.1249, 0.9412]], [[0.5476, 0.8072], [0.9851, 0.6894]], [[0.0988, 0.0172], [0.2991, 0.4655]]], [[[0.8633, 0.2322], [0.6869, 0.5398]], [[0.357, 0.8656], [0.7739, 0.7491]], [[0.8107, 0.7686], [0.428, 0.0586]]]]])
in0Con39412 = tf.constant([[0.1917, 0.9459, 0.362, 0.7466, 0.5885]])
print (np.array2string(model.predict([in0Ave10608,in1Ave10608,in0Con36532,in0Loc77501,in0Sub84246,in1Sub84246,in0Con39412],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Min93464.png')

LAve10608 = average_layer([[[[0.8975, 0.8248]]], [[[0.3194, 0.2706]]]], Ave10608), 
LFla92801 = flatten_layer(Ave10608, Fla92801), 
LCon36532 = concatenate_layer([Fla92801,[[0.2184, 0.9464, 0.4671, 0.035, 0.0252, 0.0838]]], 1, Con36532), 
LLoc77501 = locally_connected1D_layer([[[0.7943, 0.306], [0.3446, 0.5607]]], 1,[[[0.7322, 0.7652, 0.3388, 0.6135], [0.5401, 0.4945, 0.4041, 0.9746]], [[0.6942, 0.2441, 0.3327, 0.8074], [0.9097, 0.7816, 0.9084, 0.383]]],[[0, 0, 0, 0], [0, 0, 0, 0]], 1, Loc77501), 
LFla71014 = flatten_layer(Loc77501, Fla71014), 
LSub84246 = subtract_layer([[[[[0.7696, 0.6591], [0.9582, 0.3905]], [[0.9141, 0.2313], [0.1199, 0.3275]], [[0.9555, 0.692], [0.131, 0.1703]]], [[[0.7508, 0.4771], [0.3568, 0.6839]], [[0.504, 0.1569], [0.4428, 0.383]], [[0.8537, 0.0078], [0.3103, 0.9141]]]]], [[[[[0.9253, 0.3396], [0.1249, 0.9412]], [[0.5476, 0.8072], [0.9851, 0.6894]], [[0.0988, 0.0172], [0.2991, 0.4655]]], [[[0.8633, 0.2322], [0.6869, 0.5398]], [[0.357, 0.8656], [0.7739, 0.7491]], [[0.8107, 0.7686], [0.428, 0.0586]]]]], Sub84246), 
LLea94548 = leaky_relu_layer(Sub84246, 9.511276087253105, Lea94548), 
LRes32503 = reshape_layer(Lea94548, [2, 3, 4], Res32503), 
LRes72267 = reshape_layer(Res32503, [2, 12], Res72267), 
LGRU6085 = gru_layer(Res72267,[[6, 9, 4, 3, 6, 2, 3, 4, 10], [9, 8, 1, 6, 9, 3, 5, 8, 7], [1, 4, 8, 6, 6, 2, 5, 7, 1], [2, 6, 4, 10, 8, 4, 9, 6, 1], [4, 8, 5, 3, 8, 1, 6, 2, 7], [6, 5, 1, 5, 1, 1, 2, 10, 6], [5, 5, 2, 8, 9, 8, 1, 9, 1], [10, 6, 7, 3, 7, 6, 7, 4, 4], [6, 4, 7, 5, 2, 8, 2, 7, 4], [2, 8, 5, 5, 4, 5, 2, 1, 6], [4, 7, 3, 3, 1, 2, 1, 7, 7], [10, 2, 2, 4, 3, 8, 8, 2, 3]],[[1, 7, 8, 3, 6, 5, 6, 5, 8], [4, 10, 4, 1, 10, 4, 5, 2, 1], [10, 8, 3, 1, 5, 4, 6, 2, 3]],[8, 2, 6, 9, 5, 10, 9, 4, 4], false, GRU6085), 
LCon39412 = concatenate_layer([GRU6085,[[0.1917, 0.9459, 0.362, 0.7466, 0.5885]]], 1, Con39412), 
LMin78792 = minimum_layer([Fla71014,Con39412], Min78792), 
LMin93464 = minimum_layer([Con36532,Min78792], Min93464), 
exec_layers([LAve10608,LFla92801,LCon36532,LLoc77501,LFla71014,LSub84246,LLea94548,LRes32503,LRes72267,LGRU6085,LCon39412,LMin78792,LMin93464],["Ave10608","Fla92801","Con36532","Loc77501","Fla71014","Sub84246","Lea94548","Res32503","Res72267","GRU6085","Con39412","Min78792","Min93464"],Min93464,"Min93464")

Actual (Unparsed): [[-1.0000000, -1.0000000, -1.0000000, 0.1917000, 0.4671000, 0.0350000, 0.0252000, 0.0838000]]

Expected (Unparsed): [[-1.0,-1.0,-1.0,0.1917,0.4671,0.035,0.0252,0.0838]]

Actual:   [[-1, -1, -1, 0.1917, 0.4671, 0.035, 0.0252, 0.0838]]

Expected: [[-1, -1, -1, 0.1917, 0.4671, 0.035, 0.0252, 0.0838]]