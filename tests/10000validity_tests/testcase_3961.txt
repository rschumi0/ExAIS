import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub24935 = tf.keras.layers.Input(shape=([3, 2, 2, 3]))
in1Sub24935 = tf.keras.layers.Input(shape=([3, 2, 2, 3]))
in0Max50845 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in1Max50845 = tf.keras.layers.Input(shape=([2, 2, 1, 2]))
in0Con12835 = tf.keras.layers.Input(shape=([34]))

Sub24935 = keras.layers.Subtract(name = 'Sub24935', )([in0Sub24935,in1Sub24935])
Res80193 = keras.layers.Reshape((3, 2, 6), name = 'Res80193', )(Sub24935)
Res72743 = keras.layers.Reshape((3, 12), name = 'Res72743', )(Res80193)
Fla87750 = keras.layers.Flatten(name = 'Fla87750', )(Res72743)
Max50845 = keras.layers.Maximum(name = 'Max50845', )([in0Max50845,in1Max50845])
Res96954 = keras.layers.Reshape((2, 2, 2), name = 'Res96954', )(Max50845)
Res66116 = keras.layers.Reshape((2, 4), name = 'Res66116', )(Res96954)
Sim40970 = keras.layers.SimpleRNN(2,name = 'Sim40970', )(Res66116)
Con12835 = keras.layers.Concatenate(axis=1, name = 'Con12835', )([Sim40970,in0Con12835])
Add77796 = keras.layers.Add(name = 'Add77796', )([Fla87750,Con12835])
model = tf.keras.models.Model(inputs=[in0Sub24935,in1Sub24935,in0Max50845,in1Max50845,in0Con12835], outputs=Add77796)
w = model.get_layer('Sim40970').get_weights() 
w[0] = np.array([[8, 10], [8, 6], [7, 10], [10, 3]])
w[1] = np.array([[6, 4], [2, 1]])
w[2] = np.array([6, 8])
model.get_layer('Sim40970').set_weights(w) 
in0Sub24935 = tf.constant([[[[[0.2023, 0.9107, 0.6253], [0.275, 0.9441, 0.2757]], [[0.0997, 0.6994, 0.0499], [0.8311, 0.3225, 0.2737]]], [[[0.5124, 0.1856, 0.3588], [0.274, 0.3472, 0.2685]], [[0.0305, 0.6024, 0.775], [0.0563, 0.4744, 0.9839]]], [[[0.0523, 0.879, 0.6297], [0.8073, 0.9694, 0.0734]], [[0.8383, 0.3172, 0.9349], [0.514, 0.9139, 0.5162]]]]])
in1Sub24935 = tf.constant([[[[[0.2582, 0.3404, 0.4901], [0.3138, 0.7118, 0.0196]], [[0.1943, 0.1728, 0.7019], [0.7387, 0.2078, 0.7465]]], [[[0.4138, 0.0013, 0.0739], [0.7743, 0.1067, 0.2224]], [[0.1925, 0.8083, 0.3316], [0.0566, 0.3012, 0.1816]]], [[[0.2185, 0.1771, 0.3826], [0.9975, 0.1389, 0.2293]], [[0.8649, 0.8151, 0.9866], [0.7216, 0.6805, 0.1425]]]]])
in0Max50845 = tf.constant([[[[[0.0396, 0.6913]], [[0.7387, 0.8054]]], [[[0.8688, 0.0816]], [[0.6309, 0.7566]]]]])
in1Max50845 = tf.constant([[[[[0.0371, 0.9028]], [[0.9371, 0.9132]]], [[[0.4022, 0.4138]], [[0.3311, 0.1652]]]]])
in0Con12835 = tf.constant([[0.4586, 0.3934, 0.4189, 0.6419, 0.3593, 0.3138, 0.5091, 0.9512, 0.1066, 0.22, 0.2991, 0.5729, 0.978, 0.5895, 0.135, 0.6743, 0.8824, 0.866, 0.7091, 0.7225, 0.6845, 0.9624, 0.1505, 0.9156, 0.3281, 0.0127, 0.2112, 0.9542, 0.0375, 0.7799, 0.5422, 0.5124, 0.5564, 0.099]])
print (np.array2string(model.predict([in0Sub24935,in1Sub24935,in0Max50845,in1Max50845,in0Con12835],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add77796.png')

LSub24935 = subtract_layer([[[[[0.2023, 0.9107, 0.6253], [0.275, 0.9441, 0.2757]], [[0.0997, 0.6994, 0.0499], [0.8311, 0.3225, 0.2737]]], [[[0.5124, 0.1856, 0.3588], [0.274, 0.3472, 0.2685]], [[0.0305, 0.6024, 0.775], [0.0563, 0.4744, 0.9839]]], [[[0.0523, 0.879, 0.6297], [0.8073, 0.9694, 0.0734]], [[0.8383, 0.3172, 0.9349], [0.514, 0.9139, 0.5162]]]]], [[[[[0.2582, 0.3404, 0.4901], [0.3138, 0.7118, 0.0196]], [[0.1943, 0.1728, 0.7019], [0.7387, 0.2078, 0.7465]]], [[[0.4138, 0.0013, 0.0739], [0.7743, 0.1067, 0.2224]], [[0.1925, 0.8083, 0.3316], [0.0566, 0.3012, 0.1816]]], [[[0.2185, 0.1771, 0.3826], [0.9975, 0.1389, 0.2293]], [[0.8649, 0.8151, 0.9866], [0.7216, 0.6805, 0.1425]]]]], Sub24935), 
LRes80193 = reshape_layer(Sub24935, [3, 2, 6], Res80193), 
LRes72743 = reshape_layer(Res80193, [3, 12], Res72743), 
LFla87750 = flatten_layer(Res72743, Fla87750), 
LMax50845 = maximum_layer([[[[[[0.0396, 0.6913]], [[0.7387, 0.8054]]], [[[0.8688, 0.0816]], [[0.6309, 0.7566]]]]], [[[[[0.0371, 0.9028]], [[0.9371, 0.9132]]], [[[0.4022, 0.4138]], [[0.3311, 0.1652]]]]]], Max50845), 
LRes96954 = reshape_layer(Max50845, [2, 2, 2], Res96954), 
LRes66116 = reshape_layer(Res96954, [2, 4], Res66116), 
LSim40970 = simple_rnn_layer(Res66116,[[8, 10], [8, 6], [7, 10], [10, 3]],[[6, 4], [2, 1]],[6, 8], Sim40970), 
LCon12835 = concatenate_layer([Sim40970,[[0.4586, 0.3934, 0.4189, 0.6419, 0.3593, 0.3138, 0.5091, 0.9512, 0.1066, 0.22, 0.2991, 0.5729, 0.978, 0.5895, 0.135, 0.6743, 0.8824, 0.866, 0.7091, 0.7225, 0.6845, 0.9624, 0.1505, 0.9156, 0.3281, 0.0127, 0.2112, 0.9542, 0.0375, 0.7799, 0.5422, 0.5124, 0.5564, 0.099]]], 1, Con12835), 
LAdd77796 = add_layer([Fla87750,Con12835], Add77796), 
exec_layers([LSub24935,LRes80193,LRes72743,LFla87750,LMax50845,LRes96954,LRes66116,LSim40970,LCon12835,LAdd77796],["Sub24935","Res80193","Res72743","Fla87750","Max50845","Res96954","Res66116","Sim40970","Con12835","Add77796"],Add77796,"Add77796")

Actual (Unparsed): [[0.9441000, 1.5703000, 0.5938000, 0.3546000, 0.6512001, 0.8980000, 0.2647000, 0.8404000, -0.1429000, 1.0436000, 0.2213000, -0.2528000, 0.3977000, 0.7572000, 1.2629000, 0.0892000, 0.3755000, 0.7204000, 0.7204000, 0.6601000, 1.1525000, 0.7222000, 0.8577000, 1.7647000, -0.0157000, 1.6175000, 0.5752000, -0.1775000, 1.0417000, 0.7983000, 0.0109000, 0.2820000, 0.4905000, 0.3048000, 0.7898000, 0.4727000]]

Expected (Unparsed): [[0.9441,1.5703,0.5938,0.3546,0.6512,0.898,0.2647,0.8404,-0.14289999999999992,1.0436,0.2213,-0.2528,0.39769999999999994,0.7572,1.2629000000000001,0.08920000000000006,0.3755,0.7204,0.7203999999999999,0.6601,1.1524999999999999,0.7222000000000001,0.8576999999999999,1.7647,-0.01570000000000002,1.6175,0.5752,-0.17750000000000005,1.0417,0.7983,0.010900000000000042,0.282,0.49049999999999994,0.30479999999999996,0.7898000000000001,0.4727]]

Actual:   [[0.9441, 1.5703, 0.5938, 0.3546, 0.6513, 0.898, 0.2647, 0.8404, -0.1429, 1.0436, 0.2213, -0.2528, 0.3977, 0.7572, 1.2629, 0.0892, 0.3755, 0.7204, 0.7204, 0.6601, 1.1525, 0.7222, 0.8577, 1.7647, -0.0157, 1.6175, 0.5752, -0.1775, 1.0417, 0.7983, 0.0109, 0.282, 0.4905, 0.3048, 0.7898, 0.4727]]

Expected: [[0.9441, 1.5703, 0.5938, 0.3546, 0.6512, 0.898, 0.2647, 0.8404, -0.1428, 1.0436, 0.2213, -0.2528, 0.3977, 0.7572, 1.263, 0.0893, 0.3755, 0.7204, 0.7204, 0.6601, 1.1525, 0.7223, 0.8577, 1.7647, -0.0157, 1.6175, 0.5752, -0.1775, 1.0417, 0.7983, 0.011, 0.282, 0.4905, 0.3048, 0.7899, 0.4727]]