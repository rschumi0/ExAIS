import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con57791 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in0Ave6170 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in1Ave6170 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0Con28326 = tf.keras.layers.Input(shape=([2, 1]))
in0Per47129 = tf.keras.layers.Input(shape=([2, 3]))
in0Con20135 = tf.keras.layers.Input(shape=([2, 9]))
in0Con85532 = tf.keras.layers.Input(shape=([2, 12, 1]))
in0PRe19837 = tf.keras.layers.Input(shape=([2, 1, 2]))

Con57791 = keras.layers.Conv3D(3, (2, 1, 1),strides=(1, 1, 1), padding='valid', dilation_rate=(1, 1, 1), name = 'Con57791', )(in0Con57791)
Res83241 = keras.layers.Reshape((1, 2, 6), name = 'Res83241', )(Con57791)
Res23204 = keras.layers.Reshape((1, 12), name = 'Res23204', )(Res83241)
Up_74877 = keras.layers.UpSampling1D(size=(2), name = 'Up_74877', )(Res23204)
Ave6170 = keras.layers.Average(name = 'Ave6170', )([in0Ave6170,in1Ave6170])
Res90979 = keras.layers.Reshape((1, 2, 1), name = 'Res90979', )(Ave6170)
Res74732 = keras.layers.Reshape((1, 2), name = 'Res74732', )(Res90979)
Zer36497 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer36497', )(Res74732)
Con28326 = keras.layers.Concatenate(axis=2, name = 'Con28326', )([Zer36497,in0Con28326])
Per47129 = keras.layers.Permute((1,2), name = 'Per47129',)(in0Per47129)
Max61639 = keras.layers.Maximum(name = 'Max61639', )([Con28326,Per47129])
Con20135 = keras.layers.Concatenate(axis=2, name = 'Con20135', )([Max61639,in0Con20135])
Min16755 = keras.layers.Minimum(name = 'Min16755', )([Up_74877,Con20135])
Res28308 = keras.layers.Reshape((2, 12, 1), name = 'Res28308', )(Min16755)
Con85532 = keras.layers.Concatenate(axis=3, name = 'Con85532', )([Res28308,in0Con85532])
PRe19837 = keras.layers.PReLU(name = 'PRe19837', input_shape=(2, 1, 2))(in0PRe19837)
ELU78838 = keras.layers.ELU(alpha=-0.58881992927002, name = 'ELU78838', )(PRe19837)
Zer26278 = keras.layers.ZeroPadding2D(padding=((0, 0), (11, 0)), name = 'Zer26278', )(ELU78838)
Sub18977 = keras.layers.Subtract(name = 'Sub18977', )([Con85532,Zer26278])
model = tf.keras.models.Model(inputs=[in0Con57791,in0Ave6170,in1Ave6170,in0Con28326,in0Per47129,in0Con20135,in0Con85532,in0PRe19837], outputs=Sub18977)
w = model.get_layer('Con57791').get_weights() 
w[0] = np.array([[[[[0.2819, 0.8384, 0.1658]]]], [[[[0.7861, 0.0045, 0.3267]]]]])
w[1] = np.array([0, 0, 0])
model.get_layer('Con57791').set_weights(w) 
w = model.get_layer('PRe19837').get_weights() 
w[0] = np.array([[[0.0292, 0.5785]], [[0.4653, 0.4397]]])
model.get_layer('PRe19837').set_weights(w) 
in0Con57791 = tf.constant([[[[[0.7331], [0.9484]], [[0.1285], [0.219]]], [[[0.7583], [0.8071]], [[0.8091], [0.7248]]]]])
in0Ave6170 = tf.constant([[[[[0.2465]], [[0.4055]]]]])
in1Ave6170 = tf.constant([[[[[0.0156]], [[0.2373]]]]])
in0Con28326 = tf.constant([[[0.7563], [0.1303]]])
in0Per47129 = tf.constant([[[1.5556, 1.8642, 1.5629], [1.5317, 1.7928, 1.9504]]])
in0Con20135 = tf.constant([[[0.1815, 0.2104, 0.3703, 0.6718, 0.0973, 0.004, 0.6242, 0.8193, 0.3232], [0.9466, 0.2061, 0.6355, 0.1982, 0.8739, 0.4407, 0.2788, 0.3177, 0.6229]]])
in0Con85532 = tf.constant([[[[0.2266], [0.5297], [0.3331], [0.5608], [0.9901], [0.3439], [0.7419], [0.9056], [0.3186], [0.3151], [0.9764], [0.7904]], [[0.9764], [0.6669], [0.0724], [0.2903], [0.441], [0.7051], [0.2762], [0.735], [0.0549], [0.2759], [0.9784], [0.0049]]]])
in0PRe19837 = tf.constant([[[[0.8629, 0.6305]], [[0.7118, 0.5221]]]])
print (np.array2string(model.predict([in0Con57791,in0Ave6170,in1Ave6170,in0Con28326,in0Per47129,in0Con20135,in0Con85532,in0PRe19837],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub18977.png')

LCon57791 = conv3D_layer([[[[[0.7331], [0.9484]], [[0.1285], [0.219]]], [[[0.7583], [0.8071]], [[0.8091], [0.7248]]]]], 2, 1, 1,[[[[[0.2819, 0.8384, 0.1658]]]], [[[[0.7861, 0.0045, 0.3267]]]]],[0, 0, 0], 1, 1, 1, false, 1, 1, 1, Con57791), 
LRes83241 = reshape_layer(Con57791, [1, 2, 6], Res83241), 
LRes23204 = reshape_layer(Res83241, [1, 12], Res23204), 
LUp_74877 = up_sampling1D_layer(Res23204, 2, Up_74877), 
LAve6170 = average_layer([[[[[[0.2465]], [[0.4055]]]]], [[[[[0.0156]], [[0.2373]]]]]], Ave6170), 
LRes90979 = reshape_layer(Ave6170, [1, 2, 1], Res90979), 
LRes74732 = reshape_layer(Res90979, [1, 2], Res74732), 
LZer36497 = zero_padding1D_layer(Res74732, 1, 0, Zer36497), 
LCon28326 = concatenate_layer([Zer36497,[[[0.7563], [0.1303]]]], 2, Con28326), 
LPer47129 = permute_layer([[[1.5556, 1.8642, 1.5629], [1.5317, 1.7928, 1.9504]]], 1,2, Per47129), 
LMax61639 = maximum_layer([Con28326,Per47129], Max61639), 
LCon20135 = concatenate_layer([Max61639,[[[0.1815, 0.2104, 0.3703, 0.6718, 0.0973, 0.004, 0.6242, 0.8193, 0.3232], [0.9466, 0.2061, 0.6355, 0.1982, 0.8739, 0.4407, 0.2788, 0.3177, 0.6229]]]], 2, Con20135), 
LMin16755 = minimum_layer([Up_74877,Con20135], Min16755), 
LRes28308 = reshape_layer(Min16755, [2, 12, 1], Res28308), 
LCon85532 = concatenate_layer([Res28308,[[[[0.2266], [0.5297], [0.3331], [0.5608], [0.9901], [0.3439], [0.7419], [0.9056], [0.3186], [0.3151], [0.9764], [0.7904]], [[0.9764], [0.6669], [0.0724], [0.2903], [0.441], [0.7051], [0.2762], [0.735], [0.0549], [0.2759], [0.9784], [0.0049]]]]], 3, Con85532), 
LPRe19837 = prelu_layer([[[[0.8629, 0.6305]], [[0.7118, 0.5221]]]], [[[0.0292, 0.5785]], [[0.4653, 0.4397]]], PRe19837), 
LELU78838 = elu_layer(PRe19837, -0.58881992927002, ELU78838), 
LZer26278 = zero_padding2D_layer(ELU78838, 0, 0, 11, 0, Zer26278), 
LSub18977 = subtract_layer(Con85532,Zer26278, Sub18977), 
exec_layers([LCon57791,LRes83241,LRes23204,LUp_74877,LAve6170,LRes90979,LRes74732,LZer36497,LCon28326,LPer47129,LMax61639,LCon20135,LMin16755,LRes28308,LCon85532,LPRe19837,LELU78838,LZer26278,LSub18977],["Con57791","Res83241","Res23204","Up_74877","Ave6170","Res90979","Res74732","Zer36497","Con28326","Per47129","Max61639","Con20135","Min16755","Res28308","Con85532","PRe19837","ELU78838","Zer26278","Sub18977"],Sub18977,"Sub18977")

Actual (Unparsed): [[[[0.8027605, 0.2266000], [0.6180434, 0.5297000], [0.3692846, 0.3331000], [0.1815000, 0.5608000], [0.2104000, 0.9901000], [0.3703000, 0.3439000], [0.6718000, 0.7419000], [0.0973000, 0.9056000], [0.0040000, 0.3186000], [0.6242000, 0.3151000], [0.1868712, 0.9764000], [-0.5897977, 0.1599000]], [[0.8027605, 0.9764000], [0.6180434, 0.6669000], [0.3692846, 0.0724000], [0.9018153, 0.2903000], [0.2061000, 0.4410000], [0.4209243, 0.7051000], [0.1982000, 0.2762000], [0.1113753, 0.7350000], [0.2856383, 0.0549000], [0.2788000, 0.2759000], [0.1868712, 0.9784000], [-0.4386976, -0.5172000]]]]

Expected (Unparsed): [[[[0.80276052,0.2266],[0.61804339,0.5297],[0.36928459,0.3331],[0.1815,0.5608],[0.2104,0.9901],[0.3703,0.3439],[0.6718,0.7419],[0.0973,0.9056],[0.004,0.3186],[0.6242,0.3151],[0.18687120000000002,0.9764],[-0.58979764,0.15990000000000004]],[[0.80276052,0.9764],[0.61804339,0.6669],[0.36928459,0.0724],[0.9018152700000001,0.2903],[0.2061,0.441],[0.42092429000000003,0.7051],[0.1982,0.2762],[0.11137535000000001,0.735],[0.28563826999999997,0.0549],[0.2788,0.2759],[0.18687120000000002,0.9784],[-0.43869764,-0.5172]]]]

Actual:   [[[[0.8028, 0.2266], [0.6181, 0.5297], [0.3693, 0.3331], [0.1815, 0.5608], [0.2104, 0.9901], [0.3703, 0.3439], [0.6718, 0.7419], [0.0973, 0.9056], [0.004, 0.3186], [0.6242, 0.3151], [0.1869, 0.9764], [-0.5897, 0.1599]], [[0.8028, 0.9764], [0.6181, 0.6669], [0.3693, 0.0724], [0.9019, 0.2903], [0.2061, 0.441], [0.421, 0.7051], [0.1982, 0.2762], [0.1114, 0.735], [0.2857, 0.0549], [0.2788, 0.2759], [0.1869, 0.9784], [-0.4386, -0.5172]]]]

Expected: [[[[0.8028, 0.2266], [0.6181, 0.5297], [0.3693, 0.3331], [0.1815, 0.5608], [0.2104, 0.9901], [0.3703, 0.3439], [0.6718, 0.7419], [0.0973, 0.9056], [0.004, 0.3186], [0.6242, 0.3151], [0.1869, 0.9764], [-0.5897, 0.16]], [[0.8028, 0.9764], [0.6181, 0.6669], [0.3693, 0.0724], [0.9019, 0.2903], [0.2061, 0.441], [0.421, 0.7051], [0.1982, 0.2762], [0.1114, 0.735], [0.2857, 0.0549], [0.2788, 0.2759], [0.1869, 0.9784], [-0.4386, -0.5172]]]]