import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo11118 = tf.keras.layers.Input(shape=([1, 1, 2]))
in0Con38470 = tf.keras.layers.Input(shape=([2, 3, 3, 1]))
in0Ave45284 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in1Ave45284 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))

Glo11118 = keras.layers.GlobalMaxPool2D(name = 'Glo11118', )(in0Glo11118)
Res58901 = keras.layers.Reshape((2, 1), name = 'Res58901', )(Glo11118)
Res17173 = keras.layers.Reshape((2, 1, 1), name = 'Res17173', )(Res58901)
Res68851 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res68851', )(Res17173)
Zer24439 = keras.layers.ZeroPadding3D(padding=((0, 0), (2, 0), (2, 0)), name = 'Zer24439', )(Res68851)
Con38470 = keras.layers.Concatenate(axis=4, name = 'Con38470', )([Zer24439,in0Con38470])
Ave45284 = keras.layers.Average(name = 'Ave45284', )([in0Ave45284,in1Ave45284])
Zer33773 = keras.layers.ZeroPadding3D(padding=((1, 0), (1, 0), (1, 0)), name = 'Zer33773', )(Ave45284)
Min97471 = keras.layers.Minimum(name = 'Min97471', )([Con38470,Zer33773])
Bat30066 = keras.layers.BatchNormalization(axis=1, epsilon=0.4279276620140581,  name = 'Bat30066', )(Min97471)
model = tf.keras.models.Model(inputs=[in0Glo11118,in0Con38470,in0Ave45284,in1Ave45284], outputs=Bat30066)
w = model.get_layer('Bat30066').get_weights() 
w[0] = np.array([0.1271, 0.9479])
w[1] = np.array([0.5257, 0.2154])
w[2] = np.array([0.0851, 0.4025])
w[3] = np.array([0.5274, 0.9362])
model.get_layer('Bat30066').set_weights(w) 
in0Glo11118 = tf.constant([[[[1.311, 1.2583]]]])
in0Con38470 = tf.constant([[[[[0.333], [0.5794], [0.465]], [[0.2553], [0.753], [0.5111]], [[0.0317], [0.3715], [0.2718]]], [[[0.3275], [0.025], [0.774]], [[0.168], [0.4383], [0.637]], [[0.4861], [0.8561], [0.8089]]]]])
in0Ave45284 = tf.constant([[[[[0.3778, 0.4653], [0.3219, 0.7247]], [[0.6886, 0.2429], [0.9413, 0.8218]]]]])
in1Ave45284 = tf.constant([[[[[0.9348, 0.911], [0.1922, 0.1331]], [[0.4637, 0.7586], [0.6145, 0.6668]]]]])
print (np.array2string(model.predict([in0Glo11118,in0Con38470,in0Ave45284,in1Ave45284],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat30066.png')

LGlo11118 = global_max_pool2D_layer([[[[1.311, 1.2583]]]], Glo11118), 
LRes58901 = reshape_layer(Glo11118, [2, 1], Res58901), 
LRes17173 = reshape_layer(Res58901, [2, 1, 1], Res17173), 
LRes68851 = reshape_layer(Res17173, [2, 1, 1, 1], Res68851), 
LZer24439 = zero_padding3D_layer(Res68851, 0, 0, 2, 0, 2, 0, Zer24439), 
LCon38470 = concatenate_layer([Zer24439,[[[[[0.333], [0.5794], [0.465]], [[0.2553], [0.753], [0.5111]], [[0.0317], [0.3715], [0.2718]]], [[[0.3275], [0.025], [0.774]], [[0.168], [0.4383], [0.637]], [[0.4861], [0.8561], [0.8089]]]]]], 4, Con38470), 
LAve45284 = average_layer([[[[[[0.3778, 0.4653], [0.3219, 0.7247]], [[0.6886, 0.2429], [0.9413, 0.8218]]]]], [[[[[0.9348, 0.911], [0.1922, 0.1331]], [[0.4637, 0.7586], [0.6145, 0.6668]]]]]], Ave45284), 
LZer33773 = zero_padding3D_layer(Ave45284, 1, 0, 1, 0, 1, 0, Zer33773), 
LMin97471 = minimum_layer([Con38470,Zer33773], Min97471), 
LBat30066 = batch_normalization_layer(Min97471, 1, 0.4279276620140581, [0.1271, 0.9479], [0.5257, 0.2154], [0.0851, 0.4025], [0.5274, 0.9362], Bat30066), 
exec_layers([LGlo11118,LRes58901,LRes17173,LRes68851,LZer24439,LCon38470,LAve45284,LZer33773,LMin97471,LBat30066],["Glo11118","Res58901","Res17173","Res68851","Zer24439","Con38470","Ave45284","Zer33773","Min97471","Bat30066"],Bat30066,"Bat30066")

Actual (Unparsed): [[[[[0.5146338, 0.5146338], [0.5146338, 0.5146338], [0.5146338, 0.5146338]], [[0.5146338, 0.5146338], [0.5146338, 0.5146338], [0.5146338, 0.5146338]], [[0.5146338, 0.5146338], [0.5146338, 0.5146338], [0.5146338, 0.5146338]]], [[[-0.1112637, -0.1112637], [-0.1112637, -0.1112637], [-0.1112637, -0.1112637]], [[-0.1112637, -0.1112637], [-0.1112637, 0.2444548], [-0.1112637, 0.2368259]], [[-0.1112637, -0.1112637], [-0.1112637, 0.2951384], [0.5200697, 0.4928004]]]]]

Expected (Unparsed): [[[[[0.5146337893212996,0.5146337893212996],[0.5146337893212996,0.5146337893212996],[0.5146337893212996,0.5146337893212996]],[[0.5146337893212996,0.5146337893212996],[0.5146337893212996,0.5146337893212996],[0.5146337893212996,0.5146337893212996]],[[0.5146337893212996,0.5146337893212996],[0.5146337893212996,0.5146337893212996],[0.5146337893212996,0.5146337893212996]]],[[[-0.11126371749808991,-0.11126371749808991],[-0.11126371749808991,-0.11126371749808991],[-0.11126371749808991,-0.11126371749808991]],[[-0.11126371749808991,-0.11126371749808991],[-0.11126371749808991,0.24445481015262516],[-0.11126371749808991,0.2368258935203716]],[[-0.11126371749808991,-0.11126371749808991],[-0.11126371749808991,0.2951384105445648],[0.5200697131646782,0.49280039413875065]]]]]

Actual:   [[[[[0.5147, 0.5147], [0.5147, 0.5147], [0.5147, 0.5147]], [[0.5147, 0.5147], [0.5147, 0.5147], [0.5147, 0.5147]], [[0.5147, 0.5147], [0.5147, 0.5147], [0.5147, 0.5147]]], [[[-0.1112, -0.1112], [-0.1112, -0.1112], [-0.1112, -0.1112]], [[-0.1112, -0.1112], [-0.1112, 0.2445], [-0.1112, 0.2369]], [[-0.1112, -0.1112], [-0.1112, 0.2952], [0.5201, 0.4929]]]]]

Expected: [[[[[0.5147, 0.5147], [0.5147, 0.5147], [0.5147, 0.5147]], [[0.5147, 0.5147], [0.5147, 0.5147], [0.5147, 0.5147]], [[0.5147, 0.5147], [0.5147, 0.5147], [0.5147, 0.5147]]], [[[-0.1112, -0.1112], [-0.1112, -0.1112], [-0.1112, -0.1112]], [[-0.1112, -0.1112], [-0.1112, 0.2445], [-0.1112, 0.2369]], [[-0.1112, -0.1112], [-0.1112, 0.2952], [0.5201, 0.4929]]]]]