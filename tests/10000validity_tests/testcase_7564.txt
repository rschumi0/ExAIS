import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Mul82694 = tf.keras.layers.Input(shape=([1, 2]))
in1Mul82694 = tf.keras.layers.Input(shape=([1, 2]))
in0Fla82410 = tf.keras.layers.Input(shape=([4, 3]))
in0Add20770 = tf.keras.layers.Input(shape=([2, 1]))
in1Add20770 = tf.keras.layers.Input(shape=([2, 1]))
in0Con6430 = tf.keras.layers.Input(shape=([12, 1]))

Mul82694 = keras.layers.Multiply(name = 'Mul82694', )([in0Mul82694,in1Mul82694])
Zer47165 = keras.layers.ZeroPadding1D(padding=((11, 0)), name = 'Zer47165', )(Mul82694)
Fla82410 = keras.layers.Flatten(name = 'Fla82410', )(in0Fla82410)
Res36816 = keras.layers.Reshape((12, 1), name = 'Res36816', )(Fla82410)
Add20770 = keras.layers.Add(name = 'Add20770', )([in0Add20770,in1Add20770])
Zer59111 = keras.layers.ZeroPadding1D(padding=((10, 0)), name = 'Zer59111', )(Add20770)
Sub16662 = keras.layers.Subtract(name = 'Sub16662', )([Res36816,Zer59111])
Con6430 = keras.layers.Concatenate(axis=2, name = 'Con6430', )([Sub16662,in0Con6430])
Sub20193 = keras.layers.Subtract(name = 'Sub20193', )([Zer47165,Con6430])
model = tf.keras.models.Model(inputs=[in0Mul82694,in1Mul82694,in0Fla82410,in0Add20770,in1Add20770,in0Con6430], outputs=Sub20193)
in0Mul82694 = tf.constant([[[0.1482, 0.6964]]])
in1Mul82694 = tf.constant([[[0.8206, 0.1942]]])
in0Fla82410 = tf.constant([[[1.7167, 1.7568, 1.0313], [1.9278, 1.1794, 1.2828], [1.6441, 1.0735, 1.3972], [1.6582, 1.4908, 1.6537]]])
in0Add20770 = tf.constant([[[0.7637], [0.6953]]])
in1Add20770 = tf.constant([[[0.217], [0.3353]]])
in0Con6430 = tf.constant([[[0.8071], [0.3397], [0.9959], [0.3983], [0.8391], [0.2724], [0.618], [0.0735], [0.4418], [0.4105], [0.2784], [0.9001]]])
print (np.array2string(model.predict([in0Mul82694,in1Mul82694,in0Fla82410,in0Add20770,in1Add20770,in0Con6430],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub20193.png')

LMul82694 = multiply_layer([[[[0.1482, 0.6964]]], [[[0.8206, 0.1942]]]], Mul82694), 
LZer47165 = zero_padding1D_layer(Mul82694, 11, 0, Zer47165), 
LFla82410 = flatten_layer([[[1.7167, 1.7568, 1.0313], [1.9278, 1.1794, 1.2828], [1.6441, 1.0735, 1.3972], [1.6582, 1.4908, 1.6537]]], Fla82410), 
LRes36816 = reshape_layer(Fla82410, [12, 1], Res36816), 
LAdd20770 = add_layer([[[[0.7637], [0.6953]]], [[[0.217], [0.3353]]]], Add20770), 
LZer59111 = zero_padding1D_layer(Add20770, 10, 0, Zer59111), 
LSub16662 = subtract_layer(Res36816,Zer59111, Sub16662), 
LCon6430 = concatenate_layer([Sub16662,[[[0.8071], [0.3397], [0.9959], [0.3983], [0.8391], [0.2724], [0.618], [0.0735], [0.4418], [0.4105], [0.2784], [0.9001]]]], 2, Con6430), 
LSub20193 = subtract_layer(Zer47165,Con6430, Sub20193), 
exec_layers([LMul82694,LZer47165,LFla82410,LRes36816,LAdd20770,LZer59111,LSub16662,LCon6430,LSub20193],["Mul82694","Zer47165","Fla82410","Res36816","Add20770","Zer59111","Sub16662","Con6430","Sub20193"],Sub20193,"Sub20193")

Actual (Unparsed): [[[-1.7167000, -0.8071000], [-1.7568001, -0.3397000], [-1.0312999, -0.9959000], [-1.9278001, -0.3983000], [-1.1794000, -0.8391000], [-1.2828000, -0.2724000], [-1.6441000, -0.6180000], [-1.0735000, -0.0735000], [-1.3972000, -0.4418000], [-1.6582000, -0.4105000], [-0.5101000, -0.2784000], [-0.5014871, -0.7648591]]]

Expected (Unparsed): [[[-1.7167,-0.8071],[-1.7568,-0.3397],[-1.0313,-0.9959],[-1.9278,-0.3983],[-1.1794,-0.8391],[-1.2828,-0.2724],[-1.6441,-0.618],[-1.0735,-0.0735],[-1.3972,-0.4418],[-1.6582,-0.4105],[-0.5100999999999999,-0.2784],[-0.50148708,-0.76485912]]]

Actual:   [[[-1.7167, -0.8071], [-1.7568, -0.3397], [-1.0312, -0.9959], [-1.9278, -0.3983], [-1.1794, -0.8391], [-1.2828, -0.2724], [-1.6441, -0.618], [-1.0735, -0.0735], [-1.3972, -0.4418], [-1.6582, -0.4105], [-0.5101, -0.2784], [-0.5014, -0.7648]]]

Expected: [[[-1.7167, -0.8071], [-1.7568, -0.3397], [-1.0313, -0.9959], [-1.9278, -0.3983], [-1.1794, -0.8391], [-1.2828, -0.2724], [-1.6441, -0.618], [-1.0735, -0.0735], [-1.3972, -0.4418], [-1.6582, -0.4105], [-0.51, -0.2784], [-0.5014, -0.7648]]]