import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo55338 = tf.keras.layers.Input(shape=([1, 1, 1, 1]))
in0Con11573 = tf.keras.layers.Input(shape=([60, 2]))
in0Zer62768 = tf.keras.layers.Input(shape=([4, 3, 2]))
in0GRU57578 = tf.keras.layers.Input(shape=([2, 2]))
in0Con63075 = tf.keras.layers.Input(shape=([57]))
in0Con30538 = tf.keras.layers.Input(shape=([60, 1]))
in0Sub80913 = tf.keras.layers.Input(shape=([3, 2]))
in1Sub80913 = tf.keras.layers.Input(shape=([3, 2]))

Glo55338 = keras.layers.GlobalAveragePooling3D(name = 'Glo55338', )(in0Glo55338)
ELU48115 = keras.layers.ELU(alpha=1.0053358735745572, name = 'ELU48115', )(Glo55338)
Res46349 = keras.layers.Reshape((1, 1), name = 'Res46349', )(ELU48115)
Zer75352 = keras.layers.ZeroPadding1D(padding=((59, 0)), name = 'Zer75352', )(Res46349)
Con11573 = keras.layers.Concatenate(axis=2, name = 'Con11573', )([Zer75352,in0Con11573])
Zer62768 = keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name = 'Zer62768', )(in0Zer62768)
Res54240 = keras.layers.Reshape((6, 10), name = 'Res54240', )(Zer62768)
Fla89916 = keras.layers.Flatten(name = 'Fla89916', )(Res54240)
GRU57578 = keras.layers.GRU(3,reset_after=False, recurrent_activation='sigmoid', name = 'GRU57578', )(in0GRU57578)
Con63075 = keras.layers.Concatenate(axis=1, name = 'Con63075', )([GRU57578,in0Con63075])
Sub28514 = keras.layers.Subtract(name = 'Sub28514', )([Fla89916,Con63075])
Lay70591 = keras.layers.LayerNormalization(axis=1, epsilon=2.732498290547623, name = 'Lay70591', )(Sub28514)
Res31919 = keras.layers.Reshape((60, 1), name = 'Res31919', )(Lay70591)
Con30538 = keras.layers.Concatenate(axis=2, name = 'Con30538', )([Res31919,in0Con30538])
Sub80913 = keras.layers.Subtract(name = 'Sub80913', )([in0Sub80913,in1Sub80913])
Dot8770 = keras.layers.Dot(axes=(2, 2), name = 'Dot8770', )([Con30538,Sub80913])
Sub58494 = keras.layers.Subtract(name = 'Sub58494', )([Con11573,Dot8770])
model = tf.keras.models.Model(inputs=[in0Glo55338,in0Con11573,in0Zer62768,in0GRU57578,in0Con63075,in0Con30538,in0Sub80913,in1Sub80913], outputs=Sub58494)
w = model.get_layer('GRU57578').get_weights() 
w[0] = np.array([[7, 8, 5, 8, 2, 3, 10, 1, 8], [5, 9, 6, 8, 6, 3, 10, 8, 3]])
w[1] = np.array([[10, 5, 4, 1, 10, 10, 3, 9, 7], [10, 2, 2, 2, 6, 9, 5, 10, 2], [3, 8, 4, 5, 6, 1, 3, 2, 10]])
w[2] = np.array([7, 3, 10, 8, 5, 9, 10, 1, 2])
model.get_layer('GRU57578').set_weights(w) 
in0Glo55338 = tf.constant([[[[[1.3362]]]]])
in0Con11573 = tf.constant([[[0.3988, 0.336], [0.678, 0.1316], [0.5233, 0.6645], [0.6894, 0.934], [0.4379, 0.3402], [0.9653, 0.7215], [0.9827, 0.0496], [0.9716, 0.2509], [0.6717, 0.2361], [0.1469, 0.8115], [0.6461, 0.556], [0.5616, 0.7406], [0.3259, 0.9371], [0.6194, 0.5364], [0.9207, 0.1102], [0.1781, 0.5053], [0.2459, 0.0337], [0.082, 0.8805], [0.4843, 0.3275], [0.1197, 0.0004], [0.6301, 0.6915], [0.8442, 0.4456], [0.3576, 0.2953], [0.5306, 0.9986], [0.9694, 0.2942], [0.7805, 0.9132], [0.894, 0.9544], [0.932, 0.258], [0.9283, 0.3487], [0.4831, 0.0331], [0.0496, 0.2222], [0.1957, 0.3514], [0.1572, 0.4248], [0.4122, 0.22], [0.5475, 0.2519], [0.3845, 0.3638], [0.2741, 0.1463], [0.0961, 0.0905], [0.7989, 0.4735], [0.1366, 0.414], [0.5037, 0.5041], [0.6809, 0.5223], [0.6947, 0.3097], [0.5184, 0.2092], [0.7123, 0.0122], [0.3807, 0.0676], [0.6309, 0.713], [0.5229, 0.0884], [0.8271, 0.4732], [0.6299, 0.803], [0.3809, 0.9158], [0.6377, 0.2614], [0.8773, 0.3759], [0.9871, 0.948], [0.6781, 0.0416], [0.1605, 0.202], [0.1464, 0.1919], [0.0922, 0.8333], [0.6222, 0.4681], [0.1859, 0.4]]])
in0Zer62768 = tf.constant([[[[1.4464, 1.6245], [1.2475, 1.45], [1.2977, 1.082]], [[1.7798, 1.4198], [1.8485, 1.4964], [1.4723, 1.5424]], [[1.799, 1.7184], [1.1008, 1.9464], [1.9774, 1.5234]], [[1.2668, 1.6364], [1.4631, 1.466], [1.6506, 1.1677]]]])
in0GRU57578 = tf.constant([[[10, 3], [10, 4]]])
in0Con63075 = tf.constant([[0.0973, 0.8874, 0.1523, 0.6083, 0.2863, 0.1479, 0.0148, 0.7283, 0.7314, 0.9866, 0.723, 0.6164, 0.271, 0.895, 0.915, 0.4837, 0.8295, 0.6032, 0.9434, 0.5016, 0.6843, 0.4497, 0.9048, 0.9314, 0.82, 0.2936, 0.4132, 0.6507, 0.332, 0.022, 0.4571, 0.4237, 0.0764, 0.3252, 0.501, 0.5814, 0.4128, 0.6924, 0.7119, 0.2638, 0.935, 0.5154, 0.8234, 0.0092, 0.5443, 0.7775, 0.6858, 0.2758, 0.0855, 0.0521, 0.9928, 0.4245, 0.0315, 0.4398, 0.0242, 0.8023, 0.3865]])
in0Con30538 = tf.constant([[[0.311], [0.5093], [0.2766], [0.9287], [0.5193], [0.1317], [0.3087], [0.3323], [0.0947], [0.8497], [0.8884], [0.7322], [0.9931], [0.6927], [0.4961], [0.9527], [0.7246], [0.8355], [0.6788], [0.8554], [0.4891], [0.9547], [0.4926], [0.9874], [0.1983], [0.5409], [0.4002], [0.4148], [0.0313], [0.201], [0.1197], [0.2879], [0.8423], [0.5433], [0.1727], [0.943], [0.8296], [0.4577], [0.0459], [0.7692], [0.3572], [0.4695], [0.9433], [0.6399], [0.7213], [0.3795], [0.0821], [0.443], [0.9511], [0.5841], [0.3653], [0.1301], [0.4459], [0.3109], [0.0487], [0.7489], [0.3609], [0.5021], [0.7132], [0.1236]]])
in0Sub80913 = tf.constant([[[0.1447, 0.4251], [0.7505, 0.0259], [0.0956, 0.4505]]])
in1Sub80913 = tf.constant([[[0.428, 0.3093], [0.6173, 0.3828], [0.0162, 0.8151]]])
print (np.array2string(model.predict([in0Glo55338,in0Con11573,in0Zer62768,in0GRU57578,in0Con63075,in0Con30538,in0Sub80913,in1Sub80913],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub58494.png')

LGlo55338 = global_average_pooling3D_layer([[[[[1.3362]]]]], Glo55338), 
LELU48115 = elu_layer(Glo55338, 1.0053358735745572, ELU48115), 
LRes46349 = reshape_layer(ELU48115, [1, 1], Res46349), 
LZer75352 = zero_padding1D_layer(Res46349, 59, 0, Zer75352), 
LCon11573 = concatenate_layer([Zer75352,[[[0.3988, 0.336], [0.678, 0.1316], [0.5233, 0.6645], [0.6894, 0.934], [0.4379, 0.3402], [0.9653, 0.7215], [0.9827, 0.0496], [0.9716, 0.2509], [0.6717, 0.2361], [0.1469, 0.8115], [0.6461, 0.556], [0.5616, 0.7406], [0.3259, 0.9371], [0.6194, 0.5364], [0.9207, 0.1102], [0.1781, 0.5053], [0.2459, 0.0337], [0.082, 0.8805], [0.4843, 0.3275], [0.1197, 0.0004], [0.6301, 0.6915], [0.8442, 0.4456], [0.3576, 0.2953], [0.5306, 0.9986], [0.9694, 0.2942], [0.7805, 0.9132], [0.894, 0.9544], [0.932, 0.258], [0.9283, 0.3487], [0.4831, 0.0331], [0.0496, 0.2222], [0.1957, 0.3514], [0.1572, 0.4248], [0.4122, 0.22], [0.5475, 0.2519], [0.3845, 0.3638], [0.2741, 0.1463], [0.0961, 0.0905], [0.7989, 0.4735], [0.1366, 0.414], [0.5037, 0.5041], [0.6809, 0.5223], [0.6947, 0.3097], [0.5184, 0.2092], [0.7123, 0.0122], [0.3807, 0.0676], [0.6309, 0.713], [0.5229, 0.0884], [0.8271, 0.4732], [0.6299, 0.803], [0.3809, 0.9158], [0.6377, 0.2614], [0.8773, 0.3759], [0.9871, 0.948], [0.6781, 0.0416], [0.1605, 0.202], [0.1464, 0.1919], [0.0922, 0.8333], [0.6222, 0.4681], [0.1859, 0.4]]]], 2, Con11573), 
LZer62768 = zero_padding2D_layer([[[[1.4464, 1.6245], [1.2475, 1.45], [1.2977, 1.082]], [[1.7798, 1.4198], [1.8485, 1.4964], [1.4723, 1.5424]], [[1.799, 1.7184], [1.1008, 1.9464], [1.9774, 1.5234]], [[1.2668, 1.6364], [1.4631, 1.466], [1.6506, 1.1677]]]], 1, 1, 1, 1, Zer62768), 
LRes54240 = reshape_layer(Zer62768, [6, 10], Res54240), 
LFla89916 = flatten_layer(Res54240, Fla89916), 
LGRU57578 = gru_layer([[[10, 3], [10, 4]]],[[7, 8, 5, 8, 2, 3, 10, 1, 8], [5, 9, 6, 8, 6, 3, 10, 8, 3]],[[10, 5, 4, 1, 10, 10, 3, 9, 7], [10, 2, 2, 2, 6, 9, 5, 10, 2], [3, 8, 4, 5, 6, 1, 3, 2, 10]],[7, 3, 10, 8, 5, 9, 10, 1, 2], false, GRU57578), 
LCon63075 = concatenate_layer([GRU57578,[[0.0973, 0.8874, 0.1523, 0.6083, 0.2863, 0.1479, 0.0148, 0.7283, 0.7314, 0.9866, 0.723, 0.6164, 0.271, 0.895, 0.915, 0.4837, 0.8295, 0.6032, 0.9434, 0.5016, 0.6843, 0.4497, 0.9048, 0.9314, 0.82, 0.2936, 0.4132, 0.6507, 0.332, 0.022, 0.4571, 0.4237, 0.0764, 0.3252, 0.501, 0.5814, 0.4128, 0.6924, 0.7119, 0.2638, 0.935, 0.5154, 0.8234, 0.0092, 0.5443, 0.7775, 0.6858, 0.2758, 0.0855, 0.0521, 0.9928, 0.4245, 0.0315, 0.4398, 0.0242, 0.8023, 0.3865]]], 1, Con63075), 
LSub28514 = subtract_layer(Fla89916,Con63075, Sub28514), 
LLay70591 = layer_normalization_layer(Sub28514, 1, 2.732498290547623, Lay70591), 
LRes31919 = reshape_layer(Lay70591, [60, 1], Res31919), 
LCon30538 = concatenate_layer([Res31919,[[[0.311], [0.5093], [0.2766], [0.9287], [0.5193], [0.1317], [0.3087], [0.3323], [0.0947], [0.8497], [0.8884], [0.7322], [0.9931], [0.6927], [0.4961], [0.9527], [0.7246], [0.8355], [0.6788], [0.8554], [0.4891], [0.9547], [0.4926], [0.9874], [0.1983], [0.5409], [0.4002], [0.4148], [0.0313], [0.201], [0.1197], [0.2879], [0.8423], [0.5433], [0.1727], [0.943], [0.8296], [0.4577], [0.0459], [0.7692], [0.3572], [0.4695], [0.9433], [0.6399], [0.7213], [0.3795], [0.0821], [0.443], [0.9511], [0.5841], [0.3653], [0.1301], [0.4459], [0.3109], [0.0487], [0.7489], [0.3609], [0.5021], [0.7132], [0.1236]]]], 2, Con30538), 
LSub80913 = subtract_layer([[[0.1447, 0.4251], [0.7505, 0.0259], [0.0956, 0.4505]]], [[[0.428, 0.3093], [0.6173, 0.3828], [0.0162, 0.8151]]], Sub80913), 
LDot8770 = dot_layer(Con30538,Sub80913, 2, 2, Dot8770), 
LSub58494 = subtract_layer(Con11573,Dot8770, Sub58494), 
exec_layers([LGlo55338,LELU48115,LRes46349,LZer75352,LCon11573,LZer62768,LRes54240,LFla89916,LGRU57578,LCon63075,LSub28514,LLay70591,LRes31919,LCon30538,LSub80913,LDot8770,LSub58494],["Glo55338","ELU48115","Res46349","Zer75352","Con11573","Zer62768","Res54240","Fla89916","GRU57578","Con63075","Sub28514","Lay70591","Res31919","Con30538","Sub80913","Dot8770","Sub58494"],Sub58494,"Sub58494")

Actual (Unparsed): [[[-0.0547637, 0.5186116, 0.4546456], [-0.0777269, 0.8685849, 0.3225458], [-0.0507802, 0.6308342, 0.7706034], [-0.1413960, 1.0367696, 1.2820918], [-0.2166242, 0.6968152, 0.5733957], [-0.0576403, 1.0322341, 0.7813982], [-0.1489157, 1.1460837, 0.1938695], [-0.1016688, 1.1199074, 0.3897663], [-0.0526727, 0.7251077, 0.2823166], [-0.1194424, 0.4600537, 1.1271995], [-0.2346710, 1.0251361, 0.9168484], [-0.2170642, 0.8851146, 1.0446327], [-0.0623822, 0.6555975, 1.2844369], [0.0409633, 0.8096501, 0.7549961], [0.0217590, 1.0605170, 0.2688788], [0.0539279, 0.4408924, 0.8066202], [-0.0401528, 0.4839369, 0.2856258], [-0.0895796, 0.3768182, 1.1831134], [-0.1724333, 0.7706792, 0.6012875], [-0.2465575, 0.4943438, 0.3536190], [-0.1690144, 0.8574963, 0.9013215], [-0.2757356, 1.2625963, 0.8399787], [0.1226050, 0.4489432, 0.4245523], [-0.0189289, 0.8381429, 1.3318651], [0.1754041, 0.9469063, 0.3109041], [0.0104401, 0.9391887, 1.0899312], [0.0188636, 1.0061729, 1.0820375], [0.0453448, 1.0361380, 0.3830650], [-0.0679461, 0.9697133, 0.3781393], [-0.1061613, 0.5938074, 0.1296148], [-0.1336107, 0.1486239, 0.2994046], [-0.1036207, 0.3314962, 0.4760661], [0.1595318, 0.3369494, 0.6598540], [0.1141108, 0.5228714, 0.3684727], [0.0663487, 0.5685385, 0.2906660], [0.1623059, 0.5934022, 0.6315235], [0.1416314, 0.4584245, 0.3821526], [0.0869420, 0.1936554, 0.2181557], [-0.1143081, 0.8665273, 0.5207824], [-0.1718967, 0.4500688, 0.7176631], [-0.1675857, 0.6905309, 0.6697112], [-0.1836168, 0.9092338, 0.7297040], [0.0276983, 0.9669818, 0.6152494], [0.0160187, 0.7044088, 0.4172500], [0.0448224, 0.9093858, 0.2392138], [0.0370462, 0.4780631, 0.1832661], [0.2265156, 0.5492299, 0.6767840], [0.0267128, 0.6443275, 0.2280535], [-0.2495683, 1.2321042, 0.8590491], [-0.1928363, 0.8972298, 1.0510517], [-0.1038604, 0.5402188, 1.0662413], [-0.0470865, 0.6991881, 0.3178089], [-0.0784719, 1.0490596, 0.5459966], [-0.2088513, 1.1793292, 1.1097983], [-0.0902789, 0.7352762, 0.0830778], [-0.1103619, 0.4388970, 0.4816743], [-0.1288064, 0.3161170, 0.3478715], [-0.0806493, 0.2819813, 1.0226734], [-0.2258688, 0.9441076, 0.7682896], [1.2431459, 0.2670348, 0.4671332]]]

Expected (Unparsed): [[[-0.05476371967523726,0.51861160526206,0.4546456074910478],[-0.07772685967523725,0.8685848752620601,0.3225457874910478],[-0.05078019967523725,0.63083424526206,0.7706033674910477],[-0.14139596539855503,1.0367695627182758,1.28209180301675],[-0.21662416667289633,0.6968151731515347,0.57339574434108],[-0.057640284358292805,1.0322340911878736,0.7813982304978767],[-0.1489157033699364,1.146083678135812,0.19386948743230834],[-0.10166880327838104,1.1199073769138028,0.3897663010882579],[-0.05267273084151379,0.7251076849103057,0.28231662029938653],[-0.11944238695894849,0.4600537200138791,1.12719946179506],[-0.2346709683730005,1.0251360520694799,0.9168483855729483],[-0.21706418016891302,0.8851145060377663,1.0446327227582481],[-0.06238225717182994,0.6555974892562222,1.2844369017488293],[0.04096328291028191,0.8096500377103792,0.7549960879594904],[0.021758964970044092,1.0605169380409112,0.26887875470306566],[0.05392791947986761,0.4408924486137721,0.8066201947592606],[-0.04015283121912126,0.4839369229946592,0.285625784097417],[-0.08957962937930634,0.3768182124543721,1.1831134204119906],[-0.17243328150842152,0.7706792221846868,0.6012875586296106],[-0.24655749925891793,0.49434379645354,0.35361902013822133],[-0.16901441815730617,0.8574962467686311,0.9013214656113311],[-0.2757356223409929,1.2625962403205797,0.8399787141400454],[0.12260499694906732,0.44894327162860653,0.4245523048296649],[-0.01892895067729014,0.83814293181862,1.331865092720709],[0.17540407197714672,0.9469063704752703,0.3109041452983218],[0.010440064989868797,0.9391887166690769,1.089931176257693],[0.018863637876074216,1.0061729067310516,1.0820375237721134],[0.04534479044320869,1.0361380127813788,0.38306501308439544],[-0.0679460852494008,0.9697132214197677,0.37813926800848013],[-0.10616126356912134,0.5938074038736567,0.1296147652219846],[-0.1336106918043524,0.14862387499237464,0.2994045857086678],[-0.10362068685038128,0.33149614347854145,0.4760661170134849],[0.15953183107847044,0.3369494263443267,0.6598539686917384],[0.11411077457780244,0.5228714416492648,0.36847271400113835],[0.066348653554552,0.5685384578663384,0.29066600808248705],[0.16230592495584517,0.5934022372957339,0.6315234731327424],[0.1416314458752838,0.45842453803534133,0.3821526379580038],[0.086941982950869,0.19365541294720878,0.21815565773279566],[-0.1143081339150829,0.8665272311206814,0.5207823950824482],[-0.17189673688577778,0.45006879239387787,0.7176630842948492],[-0.1675857285429172,0.6905308367593244,0.6697111323625402],[-0.18361679435591508,0.9092337913985453,0.7297040075603941],[0.02769829880870693,0.9669818397164851,0.6152493626988658],[0.016018659567672483,0.7044087554697707,0.4172500217590075],[0.04482241483646157,0.9093857617959171,0.23921384087534403],[0.03704623711617104,0.47806314299726793,0.183266118047921],[0.22651560542500798,0.5492299579893715,0.6767839629906613],[0.02671277631568078,0.6443274840266549,0.2280534625504234],[-0.24956829042425677,1.2321042340822839,0.8590491196106107],[-0.1928363182677486,0.8972297873429725,1.051051757064805],[-0.10386042784061293,0.5402188005696069,1.0662413267509518],[-0.04708652823992044,0.6991880740647985,0.31780891566625374],[-0.07847193018073426,1.0490596055032608,0.5459966182504423],[-0.20885128773392098,1.1793291680732731,1.1097982486412754],[-0.09027887237357655,0.7352761931774106,0.08307776141356152],[-0.11036186598854157,0.4388969442946479,0.4816742705029658],[-0.12880644801146723,0.3161169472789532,0.3478714668764931],[-0.08064934401752184,0.28198127978868304,1.0226734235827435],[-0.22586884479155672,0.9441075958285752,0.7682896370930096],[1.2431459425440605,0.26703481259841566,0.46713321333569224]]]

Actual:   [[[-0.0547, 0.5187, 0.4547], [-0.0777, 0.8686, 0.3226], [-0.0507, 0.6309, 0.7707], [-0.1413, 1.0368, 1.2821], [-0.2166, 0.6969, 0.5734], [-0.0576, 1.0323, 0.7814], [-0.1489, 1.1461, 0.1939], [-0.1016, 1.12, 0.3898], [-0.0526, 0.7252, 0.2824], [-0.1194, 0.4601, 1.1272], [-0.2346, 1.0252, 0.9169], [-0.217, 0.8852, 1.0447], [-0.0623, 0.6556, 1.2845], [0.041, 0.8097, 0.755], [0.0218, 1.0606, 0.2689], [0.054, 0.4409, 0.8067], [-0.0401, 0.484, 0.2857], [-0.0895, 0.3769, 1.1832], [-0.1724, 0.7707, 0.6013], [-0.2465, 0.4944, 0.3537], [-0.169, 0.8575, 0.9014], [-0.2757, 1.2626, 0.84], [0.1227, 0.449, 0.4246], [-0.0189, 0.8382, 1.3319], [0.1755, 0.947, 0.311], [0.0105, 0.9392, 1.09], [0.0189, 1.0062, 1.0821], [0.0454, 1.0362, 0.3831], [-0.0679, 0.9698, 0.3782], [-0.1061, 0.5939, 0.1297], [-0.1336, 0.1487, 0.2995], [-0.1036, 0.3315, 0.4761], [0.1596, 0.337, 0.6599], [0.1142, 0.5229, 0.3685], [0.0664, 0.5686, 0.2907], [0.1624, 0.5935, 0.6316], [0.1417, 0.4585, 0.3822], [0.087, 0.1937, 0.2182], [-0.1143, 0.8666, 0.5208], [-0.1718, 0.4501, 0.7177], [-0.1675, 0.6906, 0.6698], [-0.1836, 0.9093, 0.7298], [0.0277, 0.967, 0.6153], [0.0161, 0.7045, 0.4173], [0.0449, 0.9094, 0.2393], [0.0371, 0.4781, 0.1833], [0.2266, 0.5493, 0.6768], [0.0268, 0.6444, 0.2281], [-0.2495, 1.2322, 0.8591], [-0.1928, 0.8973, 1.0511], [-0.1038, 0.5403, 1.0663], [-0.047, 0.6992, 0.3179], [-0.0784, 1.0491, 0.546], [-0.2088, 1.1794, 1.1098], [-0.0902, 0.7353, 0.0831], [-0.1103, 0.4389, 0.4817], [-0.1288, 0.3162, 0.3479], [-0.0806, 0.282, 1.0227], [-0.2258, 0.9442, 0.7683], [1.2432, 0.2671, 0.4672]]]

Expected: [[[-0.0547, 0.5187, 0.4547], [-0.0777, 0.8686, 0.3226], [-0.0507, 0.6309, 0.7707], [-0.1413, 1.0368, 1.2821], [-0.2166, 0.6969, 0.5734], [-0.0576, 1.0323, 0.7814], [-0.1489, 1.1461, 0.1939], [-0.1016, 1.12, 0.3898], [-0.0526, 0.7252, 0.2824], [-0.1194, 0.4601, 1.1272], [-0.2346, 1.0252, 0.9169], [-0.217, 0.8852, 1.0447], [-0.0623, 0.6556, 1.2845], [0.041, 0.8097, 0.755], [0.0218, 1.0606, 0.2689], [0.054, 0.4409, 0.8067], [-0.0401, 0.484, 0.2857], [-0.0895, 0.3769, 1.1832], [-0.1724, 0.7707, 0.6013], [-0.2465, 0.4944, 0.3537], [-0.169, 0.8575, 0.9014], [-0.2757, 1.2626, 0.84], [0.1227, 0.449, 0.4246], [-0.0189, 0.8382, 1.3319], [0.1755, 0.947, 0.311], [0.0105, 0.9392, 1.09], [0.0189, 1.0062, 1.0821], [0.0454, 1.0362, 0.3831], [-0.0679, 0.9698, 0.3782], [-0.1061, 0.5939, 0.1297], [-0.1336, 0.1487, 0.2995], [-0.1036, 0.3315, 0.4761], [0.1596, 0.337, 0.6599], [0.1142, 0.5229, 0.3685], [0.0664, 0.5686, 0.2907], [0.1624, 0.5935, 0.6316], [0.1417, 0.4585, 0.3822], [0.087, 0.1937, 0.2182], [-0.1143, 0.8666, 0.5208], [-0.1718, 0.4501, 0.7177], [-0.1675, 0.6906, 0.6698], [-0.1836, 0.9093, 0.7298], [0.0277, 0.967, 0.6153], [0.0161, 0.7045, 0.4173], [0.0449, 0.9094, 0.2393], [0.0371, 0.4781, 0.1833], [0.2266, 0.5493, 0.6768], [0.0268, 0.6444, 0.2281], [-0.2495, 1.2322, 0.8591], [-0.1928, 0.8973, 1.0511], [-0.1038, 0.5403, 1.0663], [-0.047, 0.6992, 0.3179], [-0.0784, 1.0491, 0.546], [-0.2088, 1.1794, 1.1098], [-0.0902, 0.7353, 0.0831], [-0.1103, 0.4389, 0.4817], [-0.1288, 0.3162, 0.3479], [-0.0806, 0.282, 1.0227], [-0.2258, 0.9442, 0.7683], [1.2432, 0.2671, 0.4672]]]