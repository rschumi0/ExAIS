import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add23431 = tf.keras.layers.Input(shape=([2, 2, 2]))
in1Add23431 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Mas37670 = tf.keras.layers.Input(shape=([2]))
in0Con54569 = tf.keras.layers.Input(shape=([7]))

Add23431 = keras.layers.Add(name = 'Add23431', )([in0Add23431,in1Add23431])
Res80313 = keras.layers.Reshape((2, 4), name = 'Res80313', )(Add23431)
Fla53682 = keras.layers.Flatten(name = 'Fla53682', )(Res80313)
Mas37670 = keras.layers.Masking(mask_value=2, name = 'Mas37670', )(in0Mas37670)
Res21697 = keras.layers.Reshape((2, 1), name = 'Res21697', )(Mas37670)
Glo41101 = keras.layers.GlobalAveragePooling1D(name = 'Glo41101', )(Res21697)
ReL97564 = keras.layers.ReLU(max_value=4.698584245238283, negative_slope=1.1517175044903454, threshold=9.015191274895418, name = 'ReL97564', )(Glo41101)
Thr91530 = keras.layers.ThresholdedReLU(theta=6.690172125750781, name = 'Thr91530', )(ReL97564)
Con54569 = keras.layers.Concatenate(axis=1, name = 'Con54569', )([Thr91530,in0Con54569])
Sub99024 = keras.layers.Subtract(name = 'Sub99024', )([Fla53682,Con54569])
model = tf.keras.models.Model(inputs=[in0Add23431,in1Add23431,in0Mas37670,in0Con54569], outputs=Sub99024)
in0Add23431 = tf.constant([[[[0.0045, 0.3206], [0.7543, 0.3726]], [[0.3153, 0.1465], [0.1825, 0.4255]]]])
in1Add23431 = tf.constant([[[[0.3975, 0.8389], [0.2367, 0.1047]], [[0.2419, 0.6174], [0.7831, 0.4536]]]])
in0Mas37670 = tf.constant([[1.3037, 1.3242]])
in0Con54569 = tf.constant([[0.4782, 0.9898, 0.3521, 0.6448, 0.2553, 0.9426, 0.7558]])
print (np.array2string(model.predict([in0Add23431,in1Add23431,in0Mas37670,in0Con54569],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Sub99024.png')

LAdd23431 = add_layer([[[[[0.0045, 0.3206], [0.7543, 0.3726]], [[0.3153, 0.1465], [0.1825, 0.4255]]]], [[[[0.3975, 0.8389], [0.2367, 0.1047]], [[0.2419, 0.6174], [0.7831, 0.4536]]]]], Add23431), 
LRes80313 = reshape_layer(Add23431, [2, 4], Res80313), 
LFla53682 = flatten_layer(Res80313, Fla53682), 
LMas37670 = masking_layer([[1.3037, 1.3242]], 2, Mas37670), 
LRes21697 = reshape_layer(Mas37670, [2, 1], Res21697), 
LGlo41101 = global_average_pooling1D_layer(Res21697, Glo41101), 
LReL97564 = relu_layer(Glo41101, 4.698584245238283, 1.1517175044903454, 9.015191274895418, ReL97564), 
LThr91530 = thresholded_relu_layer(ReL97564, 6.690172125750781, Thr91530), 
LCon54569 = concatenate_layer([Thr91530,[[0.4782, 0.9898, 0.3521, 0.6448, 0.2553, 0.9426, 0.7558]]], 1, Con54569), 
LSub99024 = subtract_layer(Fla53682,Con54569, Sub99024), 
exec_layers([LAdd23431,LRes80313,LFla53682,LMas37670,LRes21697,LGlo41101,LReL97564,LThr91530,LCon54569,LSub99024],["Add23431","Res80313","Fla53682","Mas37670","Res21697","Glo41101","ReL97564","Thr91530","Con54569","Sub99024"],Sub99024,"Sub99024")

Actual (Unparsed): [[0.4020000, 0.6813000, 0.0012000, 0.1252000, -0.0876000, 0.5086000, 0.0230000, 0.1233000]]

Expected (Unparsed): [[0.402,0.6813,0.0011999999999999789,0.12519999999999998,-0.08760000000000001,0.5085999999999999,0.02300000000000002,0.12329999999999997]]

Actual:   [[0.402, 0.6813, 0.0012, 0.1252, -0.0876, 0.5086, 0.023, 0.1233]]

Expected: [[0.402, 0.6813, 0.0012, 0.1252, -0.0876, 0.5086, 0.0231, 0.1233]]