import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo8372 = tf.keras.layers.Input(shape=([1, 2, 1]))
in0Con81240 = tf.keras.layers.Input(shape=([2, 1]))
in0Dot13286 = tf.keras.layers.Input(shape=([3]))
in1Dot13286 = tf.keras.layers.Input(shape=([3]))
in0Con34300 = tf.keras.layers.Input(shape=([2, 1]))
in0Min70502 = tf.keras.layers.Input(shape=([2, 2]))
in1Min70502 = tf.keras.layers.Input(shape=([2, 2]))

Glo8372 = keras.layers.GlobalMaxPool2D(name = 'Glo8372', )(in0Glo8372)
Lea30835 = keras.layers.LeakyReLU(alpha=7.317660024082695, name = 'Lea30835', )(Glo8372)
Res3919 = keras.layers.Reshape((1, 1), name = 'Res3919', )(Lea30835)
PRe94921 = keras.layers.PReLU(name = 'PRe94921', )(Res3919)
Zer83683 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer83683', )(PRe94921)
Con81240 = keras.layers.Concatenate(axis=2, name = 'Con81240', )([Zer83683,in0Con81240])
Dot13286 = keras.layers.Dot(axes=(1, 1), name = 'Dot13286', )([in0Dot13286,in1Dot13286])
Res85517 = keras.layers.Reshape((1, 1), name = 'Res85517', )(Dot13286)
Zer72484 = keras.layers.ZeroPadding1D(padding=((1, 0)), name = 'Zer72484', )(Res85517)
Con34300 = keras.layers.Concatenate(axis=2, name = 'Con34300', )([Zer72484,in0Con34300])
Min70502 = keras.layers.Minimum(name = 'Min70502', )([in0Min70502,in1Min70502])
Sub47121 = keras.layers.Subtract(name = 'Sub47121', )([Con34300,Min70502])
Add68212 = keras.layers.Add(name = 'Add68212', )([Con81240,Sub47121])
model = tf.keras.models.Model(inputs=[in0Glo8372,in0Con81240,in0Dot13286,in1Dot13286,in0Con34300,in0Min70502,in1Min70502], outputs=Add68212)
w = model.get_layer('PRe94921').get_weights() 
w[0] = np.array([[0.1865]])
model.get_layer('PRe94921').set_weights(w) 
in0Glo8372 = tf.constant([[[[1.8534], [1.9149]]]])
in0Con81240 = tf.constant([[[0.0601], [0.69]]])
in0Dot13286 = tf.constant([[0.4576, 0.3304, 0.4814]])
in1Dot13286 = tf.constant([[0.2828, 0.3, 0.4242]])
in0Con34300 = tf.constant([[[0.4646], [0.5862]]])
in0Min70502 = tf.constant([[[0.6146, 0.3797], [0.7363, 0.8792]]])
in1Min70502 = tf.constant([[[0.7849, 0.1051], [0.0834, 0.3492]]])
print (np.array2string(model.predict([in0Glo8372,in0Con81240,in0Dot13286,in1Dot13286,in0Con34300,in0Min70502,in1Min70502],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add68212.png')

LGlo8372 = global_max_pool2D_layer([[[[1.8534], [1.9149]]]], Glo8372), 
LLea30835 = leaky_relu_layer(Glo8372, 7.317660024082695, Lea30835), 
LRes3919 = reshape_layer(Lea30835, [1, 1], Res3919), 
LPRe94921 = prelu_layer(Res3919, [[0.1865]], PRe94921), 
LZer83683 = zero_padding1D_layer(PRe94921, 1, 0, Zer83683), 
LCon81240 = concatenate_layer([Zer83683,[[[0.0601], [0.69]]]], 2, Con81240), 
LDot13286 = dot_layer([[0.4576, 0.3304, 0.4814]], [[0.2828, 0.3, 0.4242]], 1, 1, Dot13286), 
LRes85517 = reshape_layer(Dot13286, [1, 1], Res85517), 
LZer72484 = zero_padding1D_layer(Res85517, 1, 0, Zer72484), 
LCon34300 = concatenate_layer([Zer72484,[[[0.4646], [0.5862]]]], 2, Con34300), 
LMin70502 = minimum_layer([[[[0.6146, 0.3797], [0.7363, 0.8792]]], [[[0.7849, 0.1051], [0.0834, 0.3492]]]], Min70502), 
LSub47121 = subtract_layer(Con34300,Min70502, Sub47121), 
LAdd68212 = add_layer([Con81240,Sub47121], Add68212), 
exec_layers([LGlo8372,LLea30835,LRes3919,LPRe94921,LZer83683,LCon81240,LDot13286,LRes85517,LZer72484,LCon34300,LMin70502,LSub47121,LAdd68212],["Glo8372","Lea30835","Res3919","PRe94921","Zer83683","Con81240","Dot13286","Res85517","Zer72484","Con34300","Min70502","Sub47121","Add68212"],Add68212,"Add68212")

Actual (Unparsed): [[[-0.6146000, 0.4196000], [2.2642391, 0.9270000]]]

Expected (Unparsed): [[[-0.6146,0.41960000000000003],[2.26423916,0.927]]]

Actual:   [[[-0.6146, 0.4196], [2.2643, 0.927]]]

Expected: [[[-0.6146, 0.4197], [2.2643, 0.927]]]