import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Sub28903 = tf.keras.layers.Input(shape=([3, 3, 3]))
in1Sub28903 = tf.keras.layers.Input(shape=([3, 3, 3]))
in0Glo11997 = tf.keras.layers.Input(shape=([2, 2, 2]))
in0Con42403 = tf.keras.layers.Input(shape=([26]))

Sub28903 = keras.layers.Subtract(name = 'Sub28903', )([in0Sub28903,in1Sub28903])
Sof35494 = keras.layers.Softmax(axis=1, name = 'Sof35494', )(Sub28903)
Res76975 = keras.layers.Reshape((3, 9), name = 'Res76975', )(Sof35494)
Fla81814 = keras.layers.Flatten(name = 'Fla81814', )(Res76975)
Glo11997 = keras.layers.GlobalMaxPool2D(name = 'Glo11997', )(in0Glo11997)
Res56933 = keras.layers.Reshape((2, 1), name = 'Res56933', )(Glo11997)
Res8429 = keras.layers.Reshape((2, 1, 1), name = 'Res8429', )(Res56933)
Res20711 = keras.layers.Reshape((2, 1, 1, 1), name = 'Res20711', )(Res8429)
Glo6285 = keras.layers.GlobalMaxPool3D(name = 'Glo6285', )(Res20711)
Con42403 = keras.layers.Concatenate(axis=1, name = 'Con42403', )([Glo6285,in0Con42403])
Mul59026 = keras.layers.Multiply(name = 'Mul59026', )([Fla81814,Con42403])
model = tf.keras.models.Model(inputs=[in0Sub28903,in1Sub28903,in0Glo11997,in0Con42403], outputs=Mul59026)
in0Sub28903 = tf.constant([[[[0.555, 0.9368, 0.6172], [0.3016, 0.8219, 0.9316], [0.3038, 0.6166, 0.0019]], [[0.6287, 0.8155, 0.3892], [0.1589, 0.0551, 0.2319], [0.1619, 0.2734, 0.3771]], [[0.0398, 0.5654, 0.2137], [0.9446, 0.8613, 0.9145], [0.1595, 0.9157, 0.6571]]]])
in1Sub28903 = tf.constant([[[[0.2359, 0.3307, 0.307], [0.685, 0.5815, 0.4192], [0.3384, 0.5522, 0.6433]], [[0.9535, 0.4973, 0.5493], [0.8863, 0.9329, 0.8339], [0.0768, 0.6399, 0.4637]], [[0.6179, 0.383, 0.8499], [0.7982, 0.6351, 0.0215], [0.4804, 0.1362, 0.0851]]]])
in0Glo11997 = tf.constant([[[[1.4048, 1.8783], [1.7789, 1.2506]], [[1.5826, 1.7656], [1.747, 1.8547]]]])
in0Con42403 = tf.constant([[0.8676, 0.1576, 0.6483, 0.9675, 0.1206, 0.1545, 0.9698, 0.8103, 0.5729, 0.9266, 0.4013, 0.5467, 0.7736, 0.9431, 0.1755, 0.1311, 0.005, 0.1906, 0.1817, 0.6506, 0.5636, 0.6102, 0.386, 0.2917, 0.8888, 0.5109]])
print (np.array2string(model.predict([in0Sub28903,in1Sub28903,in0Glo11997,in0Con42403],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Mul59026.png')

LSub28903 = subtract_layer([[[[0.555, 0.9368, 0.6172], [0.3016, 0.8219, 0.9316], [0.3038, 0.6166, 0.0019]], [[0.6287, 0.8155, 0.3892], [0.1589, 0.0551, 0.2319], [0.1619, 0.2734, 0.3771]], [[0.0398, 0.5654, 0.2137], [0.9446, 0.8613, 0.9145], [0.1595, 0.9157, 0.6571]]]], [[[[0.2359, 0.3307, 0.307], [0.685, 0.5815, 0.4192], [0.3384, 0.5522, 0.6433]], [[0.9535, 0.4973, 0.5493], [0.8863, 0.9329, 0.8339], [0.0768, 0.6399, 0.4637]], [[0.6179, 0.383, 0.8499], [0.7982, 0.6351, 0.0215], [0.4804, 0.1362, 0.0851]]]], Sub28903), 
LSof35494 = softmax_layer(Sub28903, 1, Sof35494), 
LRes76975 = reshape_layer(Sof35494, [3, 9], Res76975), 
LFla81814 = flatten_layer(Res76975, Fla81814), 
LGlo11997 = global_max_pool2D_layer([[[[1.4048, 1.8783], [1.7789, 1.2506]], [[1.5826, 1.7656], [1.747, 1.8547]]]], Glo11997), 
LRes56933 = reshape_layer(Glo11997, [2, 1], Res56933), 
LRes8429 = reshape_layer(Res56933, [2, 1, 1], Res8429), 
LRes20711 = reshape_layer(Res8429, [2, 1, 1, 1], Res20711), 
LGlo6285 = global_max_pool3D_layer(Res20711, Glo6285), 
LCon42403 = concatenate_layer([Glo6285,[[0.8676, 0.1576, 0.6483, 0.9675, 0.1206, 0.1545, 0.9698, 0.8103, 0.5729, 0.9266, 0.4013, 0.5467, 0.7736, 0.9431, 0.1755, 0.1311, 0.005, 0.1906, 0.1817, 0.6506, 0.5636, 0.6102, 0.386, 0.2917, 0.8888, 0.5109]]], 1, Con42403), 
LMul59026 = multiply_layer([Fla81814,Con42403], Mul59026), 
exec_layers([LSub28903,LSof35494,LRes76975,LFla81814,LGlo11997,LRes56933,LRes8429,LRes20711,LGlo6285,LCon42403,LMul59026],["Sub28903","Sof35494","Res76975","Fla81814","Glo11997","Res56933","Res8429","Res20711","Glo6285","Con42403","Mul59026"],Mul59026,"Mul59026")

Actual (Unparsed): [[0.9717273, 0.3608299, 0.0782930, 0.1902556, 0.4183299, 0.0432061, 0.0536795, 0.2625114, 0.1326947, 0.1556740, 0.2889628, 0.1245625, 0.1137400, 0.1093343, 0.1108607, 0.0687293, 0.0230638, 0.0014260, 0.0402025, 0.0494683, 0.1254483, 0.2809452, 0.2601196, 0.2023379, 0.0761163, 0.4918516, 0.2815248]]

Expected (Unparsed): [[0.971727334545085,0.3608299372020277,0.07829302930567358,0.19025558694474157,0.4183299024687322,0.04320607241787353,0.053679458962397536,0.2625114526226812,0.1326947014074255,0.15567399345986455,0.2889627980288917,0.12456250939693422,0.11373998572385383,0.10933426935239357,0.11086065893887082,0.0687292835007231,0.023063821851608473,0.0014260157608219331,0.0402025266199607,0.04946834428970242,0.12544826094467781,0.28094518819043846,0.2601196477904393,0.20233791287250175,0.07611628176420518,0.4918516190814528,0.28152474232602503]]

Actual:   [[0.9718, 0.3609, 0.0783, 0.1903, 0.4184, 0.0433, 0.0537, 0.2626, 0.1327, 0.1557, 0.289, 0.1246, 0.1138, 0.1094, 0.1109, 0.0688, 0.0231, 0.0015, 0.0403, 0.0495, 0.1255, 0.281, 0.2602, 0.2024, 0.0762, 0.4919, 0.2816]]

Expected: [[0.9718, 0.3609, 0.0783, 0.1903, 0.4184, 0.0433, 0.0537, 0.2626, 0.1327, 0.1557, 0.289, 0.1246, 0.1138, 0.1094, 0.1109, 0.0688, 0.0231, 0.0015, 0.0403, 0.0495, 0.1255, 0.281, 0.2602, 0.2024, 0.0762, 0.4919, 0.2816]]