import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Add62707 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in1Add62707 = tf.keras.layers.Input(shape=([1, 2, 2, 2]))
in0Mul38402 = tf.keras.layers.Input(shape=([2, 1, 1]))
in1Mul38402 = tf.keras.layers.Input(shape=([2, 1, 1]))
in0Con45323 = tf.keras.layers.Input(shape=([2, 3, 3]))
in0Per1254 = tf.keras.layers.Input(shape=([4, 1]))
in0Con95395 = tf.keras.layers.Input(shape=([4, 11]))

Add62707 = keras.layers.Add(name = 'Add62707', )([in0Add62707,in1Add62707])
Res98290 = keras.layers.Reshape((1, 2, 4), name = 'Res98290', )(Add62707)
Zer45454 = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)), name = 'Zer45454', )(Res98290)
Mul38402 = keras.layers.Multiply(name = 'Mul38402', )([in0Mul38402,in1Mul38402])
Zer19968 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer19968', )(Mul38402)
Con45323 = keras.layers.Concatenate(axis=3, name = 'Con45323', )([Zer19968,in0Con45323])
Sub90115 = keras.layers.Subtract(name = 'Sub90115', )([Zer45454,Con45323])
Res48164 = keras.layers.Reshape((2, 12), name = 'Res48164', )(Sub90115)
Zer11413 = keras.layers.ZeroPadding1D(padding=((2, 0)), name = 'Zer11413', )(Res48164)
Per1254 = keras.layers.Permute((1,2), name = 'Per1254',)(in0Per1254)
Con95395 = keras.layers.Concatenate(axis=2, name = 'Con95395', )([Per1254,in0Con95395])
Add57716 = keras.layers.Add(name = 'Add57716', )([Zer11413,Con95395])
model = tf.keras.models.Model(inputs=[in0Add62707,in1Add62707,in0Mul38402,in1Mul38402,in0Con45323,in0Per1254,in0Con95395], outputs=Add57716)
in0Add62707 = tf.constant([[[[[0.7253, 0.9632], [0.3982, 0.5481]], [[0.9338, 0.8168], [0.4037, 0.421]]]]])
in1Add62707 = tf.constant([[[[[0.9667, 0.4582], [0.2331, 0.0849]], [[0.5274, 0.9576], [0.4918, 0.0766]]]]])
in0Mul38402 = tf.constant([[[[0.9779]], [[0.5572]]]])
in1Mul38402 = tf.constant([[[[0.2733]], [[0.403]]]])
in0Con45323 = tf.constant([[[[0.301, 0.6221, 0.9821], [0.5896, 0.4928, 0.5723], [0.2337, 0.3067, 0.4175]], [[0.6646, 0.7106, 0.9399], [0.9755, 0.7197, 0.9394], [0.785, 0.3054, 0.5607]]]])
in0Per1254 = tf.constant([[[1.7409], [1.3839], [1.3815], [1.2735]]])
in0Con95395 = tf.constant([[[0.0261, 0.3968, 0.8018, 0.6213, 0.0933, 0.113, 0.7913, 0.0107, 0.4597, 0.1054, 0.0021], [0.9541, 0.7581, 0.6477, 0.6016, 0.2735, 0.4993, 0.7441, 0.1459, 0.4358, 0.1327, 0.0168], [0.0868, 0.1869, 0.1609, 0.4683, 0.5126, 0.0835, 0.2236, 0.6602, 0.7333, 0.5667, 0.9326], [0.0936, 0.7622, 0.1714, 0.5089, 0.4828, 0.0975, 0.5734, 0.9515, 0.1727, 0.4584, 0.4358]]])
print (np.array2string(model.predict([in0Add62707,in1Add62707,in0Mul38402,in1Mul38402,in0Con45323,in0Per1254,in0Con95395],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add57716.png')

LAdd62707 = add_layer([[[[[[0.7253, 0.9632], [0.3982, 0.5481]], [[0.9338, 0.8168], [0.4037, 0.421]]]]], [[[[[0.9667, 0.4582], [0.2331, 0.0849]], [[0.5274, 0.9576], [0.4918, 0.0766]]]]]], Add62707), 
LRes98290 = reshape_layer(Add62707, [1, 2, 4], Res98290), 
LZer45454 = zero_padding2D_layer(Res98290, 1, 0, 1, 0, Zer45454), 
LMul38402 = multiply_layer([[[[[0.9779]], [[0.5572]]]], [[[[0.2733]], [[0.403]]]]], Mul38402), 
LZer19968 = zero_padding2D_layer(Mul38402, 0, 0, 2, 0, Zer19968), 
LCon45323 = concatenate_layer([Zer19968,[[[[0.301, 0.6221, 0.9821], [0.5896, 0.4928, 0.5723], [0.2337, 0.3067, 0.4175]], [[0.6646, 0.7106, 0.9399], [0.9755, 0.7197, 0.9394], [0.785, 0.3054, 0.5607]]]]], 3, Con45323), 
LSub90115 = subtract_layer(Zer45454,Con45323, Sub90115), 
LRes48164 = reshape_layer(Sub90115, [2, 12], Res48164), 
LZer11413 = zero_padding1D_layer(Res48164, 2, 0, Zer11413), 
LPer1254 = permute_layer([[[1.7409], [1.3839], [1.3815], [1.2735]]], 1,2, Per1254), 
LCon95395 = concatenate_layer([Per1254,[[[0.0261, 0.3968, 0.8018, 0.6213, 0.0933, 0.113, 0.7913, 0.0107, 0.4597, 0.1054, 0.0021], [0.9541, 0.7581, 0.6477, 0.6016, 0.2735, 0.4993, 0.7441, 0.1459, 0.4358, 0.1327, 0.0168], [0.0868, 0.1869, 0.1609, 0.4683, 0.5126, 0.0835, 0.2236, 0.6602, 0.7333, 0.5667, 0.9326], [0.0936, 0.7622, 0.1714, 0.5089, 0.4828, 0.0975, 0.5734, 0.9515, 0.1727, 0.4584, 0.4358]]]], 2, Con95395), 
LAdd57716 = add_layer([Zer11413,Con95395], Add57716), 
exec_layers([LAdd62707,LRes98290,LZer45454,LMul38402,LZer19968,LCon45323,LSub90115,LRes48164,LZer11413,LPer1254,LCon95395,LAdd57716],["Add62707","Res98290","Zer45454","Mul38402","Zer19968","Con45323","Sub90115","Res48164","Zer11413","Per1254","Con95395","Add57716"],Add57716,"Add57716")

Actual (Unparsed): [[[1.7409000, 0.0261000, 0.3968000, 0.8018000, 0.6213000, 0.0933000, 0.1130000, 0.7913000, 0.0107000, 0.4597000, 0.1054000, 0.0021000], [1.3839000, 0.9541000, 0.7581000, 0.6477000, 0.6016000, 0.2735000, 0.4993000, 0.7441000, 0.1459000, 0.4358000, 0.1327000, 0.0168000], [1.3815000, -0.2142000, -0.4352000, -0.8212000, 0.4683000, -0.0770000, -0.4093000, -0.3487000, 0.3929399, 0.4996000, 0.2600000, 0.5151000], [1.2735000, -0.5710000, 0.0516000, -0.7685000, 2.2009000, 0.9287000, 0.0091000, 0.2670000, 2.1881484, 1.1621000, 1.0485000, 0.3727000]]]

Expected (Unparsed): [[[1.7409,0.0261,0.3968,0.8018,0.6213,0.0933,0.113,0.7913,0.0107,0.4597,0.1054,0.0021],[1.3839,0.9541,0.7581,0.6477,0.6016,0.2735,0.4993,0.7441,0.1459,0.4358,0.1327,0.0168],[1.3815,-0.2142,-0.4352,-0.8211999999999999,0.4683,-0.07700000000000007,-0.4093,-0.3487,0.39293993000000005,0.49959999999999993,0.26,0.5151],[1.2735,-0.571,0.05159999999999998,-0.7685,2.2009,0.9287,0.00909999999999997,0.267,2.1881483999999998,1.1621,1.0485,0.37270000000000003]]]

Actual:   [[[1.7409, 0.0261, 0.3968, 0.8018, 0.6213, 0.0933, 0.113, 0.7913, 0.0107, 0.4597, 0.1054, 0.0021], [1.3839, 0.9541, 0.7581, 0.6477, 0.6016, 0.2735, 0.4993, 0.7441, 0.1459, 0.4358, 0.1327, 0.0168], [1.3815, -0.2142, -0.4352, -0.8212, 0.4683, -0.077, -0.4093, -0.3487, 0.393, 0.4996, 0.26, 0.5151], [1.2735, -0.571, 0.0516, -0.7685, 2.2009, 0.9287, 0.0091, 0.267, 2.1882, 1.1621, 1.0485, 0.3727]]]

Expected: [[[1.7409, 0.0261, 0.3968, 0.8018, 0.6213, 0.0933, 0.113, 0.7913, 0.0107, 0.4597, 0.1054, 0.0021], [1.3839, 0.9541, 0.7581, 0.6477, 0.6016, 0.2735, 0.4993, 0.7441, 0.1459, 0.4358, 0.1327, 0.0168], [1.3815, -0.2142, -0.4352, -0.8211, 0.4683, -0.077, -0.4093, -0.3487, 0.393, 0.4996, 0.26, 0.5151], [1.2735, -0.571, 0.0516, -0.7685, 2.2009, 0.9287, 0.0091, 0.267, 2.1882, 1.1621, 1.0485, 0.3728]]]