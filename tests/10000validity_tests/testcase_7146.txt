import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave83185 = tf.keras.layers.Input(shape=([1, 2, 2]))
in1Ave83185 = tf.keras.layers.Input(shape=([1, 2, 2]))
in0Add15578 = tf.keras.layers.Input(shape=([1, 1, 1]))
in1Add15578 = tf.keras.layers.Input(shape=([1, 1, 1]))
in0Dot92680 = tf.keras.layers.Input(shape=([2]))
in1Dot92680 = tf.keras.layers.Input(shape=([2]))
in0Con90442 = tf.keras.layers.Input(shape=([3]))

Ave83185 = keras.layers.Average(name = 'Ave83185', )([in0Ave83185,in1Ave83185])
Res14091 = keras.layers.Reshape((1, 4), name = 'Res14091', )(Ave83185)
Fla46669 = keras.layers.Flatten(name = 'Fla46669', )(Res14091)
Add15578 = keras.layers.Add(name = 'Add15578', )([in0Add15578,in1Add15578])
Res47952 = keras.layers.Reshape((1, 1), name = 'Res47952', )(Add15578)
Fla2185 = keras.layers.Flatten(name = 'Fla2185', )(Res47952)
Dot92680 = keras.layers.Dot(axes=(1, 1), name = 'Dot92680', )([in0Dot92680,in1Dot92680])
Dot74280 = keras.layers.Dot(axes=(1, 1), name = 'Dot74280', )([Fla2185,Dot92680])
Con90442 = keras.layers.Concatenate(axis=1, name = 'Con90442', )([Dot74280,in0Con90442])
Add10113 = keras.layers.Add(name = 'Add10113', )([Fla46669,Con90442])
Lea28993 = keras.layers.LeakyReLU(alpha=0.5089964021363844, name = 'Lea28993', )(Add10113)
model = tf.keras.models.Model(inputs=[in0Ave83185,in1Ave83185,in0Add15578,in1Add15578,in0Dot92680,in1Dot92680,in0Con90442], outputs=Lea28993)
in0Ave83185 = tf.constant([[[[0.9073, 0.5423], [0.7044, 0.6761]]]])
in1Ave83185 = tf.constant([[[[0.1928, 0.8347], [0.093, 0.5773]]]])
in0Add15578 = tf.constant([[[[0.212]]]])
in1Add15578 = tf.constant([[[[0.6143]]]])
in0Dot92680 = tf.constant([[0.274, 0.746]])
in1Dot92680 = tf.constant([[0.342, 0.0141]])
in0Con90442 = tf.constant([[0.879, 0.46, 0.5255]])
print (np.array2string(model.predict([in0Ave83185,in1Ave83185,in0Add15578,in1Add15578,in0Dot92680,in1Dot92680,in0Con90442],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Lea28993.png')

LAve83185 = average_layer([[[[[0.9073, 0.5423], [0.7044, 0.6761]]]], [[[[0.1928, 0.8347], [0.093, 0.5773]]]]], Ave83185), 
LRes14091 = reshape_layer(Ave83185, [1, 4], Res14091), 
LFla46669 = flatten_layer(Res14091, Fla46669), 
LAdd15578 = add_layer([[[[[0.212]]]], [[[[0.6143]]]]], Add15578), 
LRes47952 = reshape_layer(Add15578, [1, 1], Res47952), 
LFla2185 = flatten_layer(Res47952, Fla2185), 
LDot92680 = dot_layer([[0.274, 0.746]], [[0.342, 0.0141]], 1, 1, Dot92680), 
LDot74280 = dot_layer(Fla2185,Dot92680, 1, 1, Dot74280), 
LCon90442 = concatenate_layer([Dot74280,[[0.879, 0.46, 0.5255]]], 1, Con90442), 
LAdd10113 = add_layer([Fla46669,Con90442], Add10113), 
LLea28993 = leaky_relu_layer(Add10113, 0.5089964021363844, Lea28993), 
exec_layers([LAve83185,LRes14091,LFla46669,LAdd15578,LRes47952,LFla2185,LDot92680,LDot74280,LCon90442,LAdd10113,LLea28993],["Ave83185","Res14091","Fla46669","Add15578","Res47952","Fla2185","Dot92680","Dot74280","Con90442","Add10113","Lea28993"],Lea28993,"Lea28993")

Actual (Unparsed): [[0.6361724, 1.5675000, 0.8587000, 1.1522000]]

Expected (Unparsed): [[0.63617243958,1.5675,0.8587,1.1522000000000001]]

Actual:   [[0.6362, 1.5675, 0.8587, 1.1522]]

Expected: [[0.6362, 1.5675, 0.8587, 1.1523]]