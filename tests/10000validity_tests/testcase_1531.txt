import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Con64534 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0Dot5699 = tf.keras.layers.Input(shape=([3]))
in1Dot5699 = tf.keras.layers.Input(shape=([3]))
in0Con51029 = tf.keras.layers.Input(shape=([7]))
in0Max32691 = tf.keras.layers.Input(shape=([2, 1]))
in0Con98597 = tf.keras.layers.Input(shape=([8, 3, 2]))
in0Add51148 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))
in1Add51148 = tf.keras.layers.Input(shape=([2, 2, 2, 1]))

Con64534 = keras.layers.Conv3D(4, (1, 1, 1),strides=(1, 1, 1), padding='same', dilation_rate=(1, 1, 1), name = 'Con64534', )(in0Con64534)
Res51019 = keras.layers.Reshape((1, 2, 4), name = 'Res51019', )(Con64534)
Res15422 = keras.layers.Reshape((1, 8), name = 'Res15422', )(Res51019)
Fla31052 = keras.layers.Flatten(name = 'Fla31052', )(Res15422)
Dot5699 = keras.layers.Dot(axes=(1, 1), name = 'Dot5699', )([in0Dot5699,in1Dot5699])
Con51029 = keras.layers.Concatenate(axis=1, name = 'Con51029', )([Dot5699,in0Con51029])
Sub33673 = keras.layers.Subtract(name = 'Sub33673', )([Fla31052,Con51029])
Res78564 = keras.layers.Reshape((8, 1), name = 'Res78564', )(Sub33673)
Max32691 = keras.layers.MaxPool1D(pool_size=(2), name = 'Max32691', )(in0Max32691)
Zer10528 = keras.layers.ZeroPadding1D(padding=((7, 0)), name = 'Zer10528', )(Max32691)
Ave43026 = keras.layers.Average(name = 'Ave43026', )([Res78564,Zer10528])
Res80663 = keras.layers.Reshape((8, 1, 1), name = 'Res80663', )(Ave43026)
Zer70389 = keras.layers.ZeroPadding2D(padding=((0, 0), (2, 0)), name = 'Zer70389', )(Res80663)
Con98597 = keras.layers.Concatenate(axis=3, name = 'Con98597', )([Zer70389,in0Con98597])
Add51148 = keras.layers.Add(name = 'Add51148', )([in0Add51148,in1Add51148])
Res62682 = keras.layers.Reshape((2, 2, 2), name = 'Res62682', )(Add51148)
Sep98465 = keras.layers.SeparableConv2D(3, (1, 2),strides=(1, 1), padding='same', name = 'Sep98465', )(Res62682)
Zer89435 = keras.layers.ZeroPadding2D(padding=((6, 0), (1, 0)), name = 'Zer89435', )(Sep98465)
Add72018 = keras.layers.Add(name = 'Add72018', )([Con98597,Zer89435])
model = tf.keras.models.Model(inputs=[in0Con64534,in0Dot5699,in1Dot5699,in0Con51029,in0Max32691,in0Con98597,in0Add51148,in1Add51148], outputs=Add72018)
w = model.get_layer('Con64534').get_weights() 
w[0] = np.array([[[[[0.0451, 0.1182, 0.4165, 0.5502]]]]])
w[1] = np.array([0, 0, 0, 0])
model.get_layer('Con64534').set_weights(w) 
w = model.get_layer('Sep98465').get_weights() 
w[0] = np.array([[[[0.609], [0.0359]], [[0.4677], [0.0771]]]])
w[1] = np.array([[[[0.38, 0.6024, 0.4897], [0.7883, 0.6337, 0.8725]]]])
w[2] = np.array([0, 0, 0])
model.get_layer('Sep98465').set_weights(w) 
in0Con64534 = tf.constant([[[[[0.1284]], [[0.9745]]]]])
in0Dot5699 = tf.constant([[0.5746, 0.3511, 0.8404]])
in1Dot5699 = tf.constant([[0.2482, 0.802, 0.1442]])
in0Con51029 = tf.constant([[0.6444, 0.8612, 0.9908, 0.3474, 0.1218, 0.6413, 0.0642]])
in0Max32691 = tf.constant([[[1.2589], [1.1562]]])
in0Con98597 = tf.constant([[[[0.216, 0.6722], [0.111, 0.0377], [0.5878, 0.3533]], [[0.5098, 0.0707], [0.0847, 0.9626], [0.7463, 0.3403]], [[0.8491, 0.5748], [0.757, 0.1496], [0.8081, 0.6494]], [[0.1607, 0.1846], [0.1836, 0.0246], [0.9663, 0.2392]], [[0.7251, 0.9667], [0.531, 0.3827], [0.4393, 0.3749]], [[0.9574, 0.4485], [0.9323, 0.1159], [0.601, 0.3622]], [[0.3432, 0.1241], [0.8619, 0.7526], [0.2526, 0.3361]], [[0.9817, 0.4902], [0.8757, 0.7534], [0.1308, 0.2868]]]])
in0Add51148 = tf.constant([[[[[0.732], [0.9849]], [[0.8166], [0.0555]]], [[[0.4986], [0.8253]], [[0.1039], [0.4722]]]]])
in1Add51148 = tf.constant([[[[[0.7397], [0.6765]], [[0.3131], [0.8817]]], [[[0.2374], [0.4274]], [[0.4143], [0.991]]]]])
print (np.array2string(model.predict([in0Con64534,in0Dot5699,in1Dot5699,in0Con51029,in0Max32691,in0Con98597,in0Add51148,in1Add51148],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Add72018.png')

LCon64534 = conv3D_layer([[[[[0.1284]], [[0.9745]]]]], 1, 1, 1,[[[[[0.0451, 0.1182, 0.4165, 0.5502]]]]],[0, 0, 0, 0], 1, 1, 1, true, 1, 1, 1, Con64534), 
LRes51019 = reshape_layer(Con64534, [1, 2, 4], Res51019), 
LRes15422 = reshape_layer(Res51019, [1, 8], Res15422), 
LFla31052 = flatten_layer(Res15422, Fla31052), 
LDot5699 = dot_layer([[0.5746, 0.3511, 0.8404]], [[0.2482, 0.802, 0.1442]], 1, 1, Dot5699), 
LCon51029 = concatenate_layer([Dot5699,[[0.6444, 0.8612, 0.9908, 0.3474, 0.1218, 0.6413, 0.0642]]], 1, Con51029), 
LSub33673 = subtract_layer(Fla31052,Con51029, Sub33673), 
LRes78564 = reshape_layer(Sub33673, [8, 1], Res78564), 
LMax32691 = max_pool1D_layer([[[1.2589], [1.1562]]], 2, Max32691), 
LZer10528 = zero_padding1D_layer(Max32691, 7, 0, Zer10528), 
LAve43026 = average_layer([Res78564,Zer10528], Ave43026), 
LRes80663 = reshape_layer(Ave43026, [8, 1, 1], Res80663), 
LZer70389 = zero_padding2D_layer(Res80663, 0, 0, 2, 0, Zer70389), 
LCon98597 = concatenate_layer([Zer70389,[[[[0.216, 0.6722], [0.111, 0.0377], [0.5878, 0.3533]], [[0.5098, 0.0707], [0.0847, 0.9626], [0.7463, 0.3403]], [[0.8491, 0.5748], [0.757, 0.1496], [0.8081, 0.6494]], [[0.1607, 0.1846], [0.1836, 0.0246], [0.9663, 0.2392]], [[0.7251, 0.9667], [0.531, 0.3827], [0.4393, 0.3749]], [[0.9574, 0.4485], [0.9323, 0.1159], [0.601, 0.3622]], [[0.3432, 0.1241], [0.8619, 0.7526], [0.2526, 0.3361]], [[0.9817, 0.4902], [0.8757, 0.7534], [0.1308, 0.2868]]]]], 3, Con98597), 
LAdd51148 = add_layer([[[[[[0.732], [0.9849]], [[0.8166], [0.0555]]], [[[0.4986], [0.8253]], [[0.1039], [0.4722]]]]], [[[[[0.7397], [0.6765]], [[0.3131], [0.8817]]], [[[0.2374], [0.4274]], [[0.4143], [0.991]]]]]], Add51148), 
LRes62682 = reshape_layer(Add51148, [2, 2, 2], Res62682), 
LSep98465 = separable_conv2D_layer(Res62682, 1, 2,[[[[[0.609], [0.0359]], [[0.4677], [0.0771]]]],[[[[0.38, 0.6024, 0.4897], [0.7883, 0.6337, 0.8725]]]]],[0, 0, 0], 1, 1, true, Sep98465), 
LZer89435 = zero_padding2D_layer(Sep98465, 6, 0, 1, 0, Zer89435), 
LAdd72018 = add_layer([Con98597,Zer89435], Add72018), 
exec_layers([LCon64534,LRes51019,LRes15422,LFla31052,LDot5699,LCon51029,LSub33673,LRes78564,LMax32691,LZer10528,LAve43026,LRes80663,LZer70389,LCon98597,LAdd51148,LRes62682,LSep98465,LZer89435,LAdd72018],["Con64534","Res51019","Res15422","Fla31052","Dot5699","Con51029","Sub33673","Res78564","Max32691","Zer10528","Ave43026","Res80663","Zer70389","Con98597","Add51148","Res62682","Sep98465","Zer89435","Add72018"],Add72018,"Add72018")

Actual (Unparsed): [[[[0.0000000, 0.2160000, 0.6722000], [0.0000000, 0.1110000, 0.0377000], [-0.2697964, 0.5878000, 0.3533000]], [[0.0000000, 0.5098000, 0.0707000], [0.0000000, 0.0847000, 0.9626000], [-0.3146116, 0.7463000, 0.3403000]], [[0.0000000, 0.8491000, 0.5748000], [0.0000000, 0.7570000, 0.1496000], [-0.4038607, 0.8081000, 0.6494000]], [[0.0000000, 0.1607000, 0.1846000], [0.0000000, 0.1836000, 0.0246000], [-0.4600772, 0.9663000, 0.2392000]], [[0.0000000, 0.7251000, 0.9667000], [0.0000000, 0.5310000, 0.3827000], [-0.1517250, 0.4393000, 0.3749000]], [[0.0000000, 0.9574000, 0.4485000], [0.0000000, 0.9323000, 0.1159000], [-0.0033070, 0.6010000, 0.3622000]], [[0.0000000, 0.3432000, 0.1241000], [0.6453365, 1.8036812, 1.5653242], [0.1702475, 0.6883647, 0.7023631]], [[0.0000000, 0.9817000, 0.4902000], [0.3868044, 1.3916972, 1.2292472], [1.0267653, 0.3541952, 0.4871728]]]]

Expected (Unparsed): [[[[0,0.216,0.6722],[0,0.111,0.0377],[-0.26979638000000006,0.5878,0.3533]],[[0,0.5098,0.0707],[0,0.0847,0.9626],[-0.31461156,0.7463,0.3403]],[[0,0.8491,0.5748],[0,0.757,0.1496],[-0.40386069999999996,0.8081,0.6494]],[[0,0.1607,0.1846],[0,0.1836,0.0246],[-0.46007716,0.9663,0.2392]],[[0,0.7251,0.9667],[0,0.531,0.3827],[-0.15172502499999999,0.4393,0.3749]],[[0,0.9574,0.4485],[0,0.9323,0.1159],[-0.003307049999999999,0.601,0.3622]],[[0,0.3432,0.1241],[0.645336522354,1.803681234582,1.5653241738530002],[0.170247530884,0.688364690196,0.70236306211]],[[0,0.9817,0.4902],[0.38680437279499996,1.391697223441,1.229247139883],[1.026765310104,0.354195232376,0.48717283466]]]]

Actual:   [[[[0, 0.216, 0.6722], [0, 0.111, 0.0377], [-0.2697, 0.5878, 0.3533]], [[0, 0.5098, 0.0707], [0, 0.0847, 0.9626], [-0.3146, 0.7463, 0.3403]], [[0, 0.8491, 0.5748], [0, 0.757, 0.1496], [-0.4038, 0.8081, 0.6494]], [[0, 0.1607, 0.1846], [0, 0.1836, 0.0246], [-0.46, 0.9663, 0.2392]], [[0, 0.7251, 0.9667], [0, 0.531, 0.3827], [-0.1517, 0.4393, 0.3749]], [[0, 0.9574, 0.4485], [0, 0.9323, 0.1159], [-0.0033, 0.601, 0.3622]], [[0, 0.3432, 0.1241], [0.6454, 1.8037, 1.5654], [0.1703, 0.6884, 0.7024]], [[0, 0.9817, 0.4902], [0.3869, 1.3917, 1.2293], [1.0268, 0.3542, 0.4872]]]]

Expected: [[[[0, 0.216, 0.6722], [0, 0.111, 0.0377], [-0.2697, 0.5878, 0.3533]], [[0, 0.5098, 0.0707], [0, 0.0847, 0.9626], [-0.3146, 0.7463, 0.3403]], [[0, 0.8491, 0.5748], [0, 0.757, 0.1496], [-0.4038, 0.8081, 0.6494]], [[0, 0.1607, 0.1846], [0, 0.1836, 0.0246], [-0.46, 0.9663, 0.2392]], [[0, 0.7251, 0.9667], [0, 0.531, 0.3827], [-0.1517, 0.4393, 0.3749]], [[0, 0.9574, 0.4485], [0, 0.9323, 0.1159], [-0.0033, 0.601, 0.3622]], [[0, 0.3432, 0.1241], [0.6454, 1.8037, 1.5654], [0.1703, 0.6884, 0.7024]], [[0, 0.9817, 0.4902], [0.3869, 1.3917, 1.2293], [1.0268, 0.3542, 0.4872]]]]