import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Ave45347 = tf.keras.layers.Input(shape=([2, 2, 1]))
in0Con23018 = tf.keras.layers.Input(shape=([1, 2, 1, 1]))
in0Mul66795 = tf.keras.layers.Input(shape=([1, 2, 1, 2]))
in1Mul66795 = tf.keras.layers.Input(shape=([1, 2, 1, 2]))

Ave45347 = keras.layers.AveragePooling2D(pool_size=(2, 1), name = 'Ave45347', )(in0Ave45347)
Res10916 = keras.layers.Reshape((1, 2, 1, 1), name = 'Res10916', )(Ave45347)
Con23018 = keras.layers.Concatenate(axis=4, name = 'Con23018', )([Res10916,in0Con23018])
Mul66795 = keras.layers.Multiply(name = 'Mul66795', )([in0Mul66795,in1Mul66795])
Sub48256 = keras.layers.Subtract(name = 'Sub48256', )([Con23018,Mul66795])
Bat15654 = keras.layers.BatchNormalization(axis=1, epsilon=0.1584606095152289,  name = 'Bat15654', )(Sub48256)
model = tf.keras.models.Model(inputs=[in0Ave45347,in0Con23018,in0Mul66795,in1Mul66795], outputs=Bat15654)
w = model.get_layer('Bat15654').get_weights() 
w[0] = np.array([0.6493])
w[1] = np.array([0.4679])
w[2] = np.array([0.4174])
w[3] = np.array([0.8119])
model.get_layer('Bat15654').set_weights(w) 
in0Ave45347 = tf.constant([[[[1.5795], [1.2952]], [[1.6317], [1.3684]]]])
in0Con23018 = tf.constant([[[[[0.1223]], [[0.587]]]]])
in0Mul66795 = tf.constant([[[[[0.7724, 0.0081]], [[0.6319, 0.9027]]]]])
in1Mul66795 = tf.constant([[[[[0.5317, 0.1634]], [[0.2325, 0.7578]]]]])
print (np.array2string(model.predict([in0Ave45347,in0Con23018,in0Mul66795,in1Mul66795],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat15654.png')

LAve45347 = average_pooling2D_layer([[[[1.5795], [1.2952]], [[1.6317], [1.3684]]]], 2, 1, Ave45347), 
LRes10916 = reshape_layer(Ave45347, [1, 2, 1, 1], Res10916), 
LCon23018 = concatenate_layer([Res10916,[[[[[0.1223]], [[0.587]]]]]], 4, Con23018), 
LMul66795 = multiply_layer([[[[[[0.7724, 0.0081]], [[0.6319, 0.9027]]]]], [[[[[0.5317, 0.1634]], [[0.2325, 0.7578]]]]]], Mul66795), 
LSub48256 = subtract_layer(Con23018,Mul66795, Sub48256), 
LBat15654 = batch_normalization_layer(Sub48256, 1, 0.1584606095152289, [0.6493], [0.4679], [0.4174], [0.8119], Bat15654), 
exec_layers([LAve45347,LRes10916,LCon23018,LMul66795,LSub48256,LBat15654],["Ave45347","Res10916","Con23018","Mul66795","Sub48256","Bat15654"],Bat15654,"Bat15654")

Actual (Unparsed): [[[[[0.9803925, 0.2725149]], [[0.9737802, 0.1287940]]]]]

Expected (Unparsed): [[[[[0.9803925484024778,0.27251486781361856]],[[0.9737802558396126,0.12879393865781752]]]]]

Actual:   [[[[[0.9804, 0.2726]], [[0.9738, 0.1288]]]]]

Expected: [[[[[0.9804, 0.2726]], [[0.9738, 0.1288]]]]]