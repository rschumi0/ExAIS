import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Min50184 = tf.keras.layers.Input(shape=([1, 1]))
in1Min50184 = tf.keras.layers.Input(shape=([1, 1]))

Min50184 = keras.layers.Minimum(name = 'Min50184', )([in0Min50184,in1Min50184])
Glo57255 = keras.layers.GlobalMaxPool1D(name = 'Glo57255', )(Min50184)
ReL84995 = keras.layers.ReLU(max_value=7.4670243925352064, negative_slope=2.763435615166967, threshold=5.05535137317663, name = 'ReL84995', )(Glo57255)
model = tf.keras.models.Model(inputs=[in0Min50184,in1Min50184], outputs=ReL84995)
in0Min50184 = tf.constant([[[0.2623]]])
in1Min50184 = tf.constant([[[0.3706]]])
print (np.array2string(model.predict([in0Min50184,in1Min50184],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='ReL84995.png')

LMin50184 = minimum_layer([[[[0.2623]]], [[[0.3706]]]], Min50184), 
LGlo57255 = global_max_pool1D_layer(Min50184, Glo57255), 
LReL84995 = relu_layer(Glo57255, 7.4670243925352064, 2.763435615166967, 5.05535137317663, ReL84995), 
exec_layers([LMin50184,LGlo57255,LReL84995],["Min50184","Glo57255","ReL84995"],ReL84995,"ReL84995")

Actual (Unparsed): [[-13.2452888]]

Expected (Unparsed): [[-13.245288869961238]]

Actual:   [[-13.2452]]

Expected: [[-13.2452]]