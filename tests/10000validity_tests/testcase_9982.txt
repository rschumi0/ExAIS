import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
np.set_printoptions(suppress=True,threshold=np.inf,formatter={'float_kind':'{:16.7f}'.format})
tf.keras.backend.set_floatx('float64')
in0Glo67382 = tf.keras.layers.Input(shape=([2, 2, 1, 1]))

Glo67382 = keras.layers.GlobalAveragePooling3D(name = 'Glo67382', )(in0Glo67382)
Bat84132 = keras.layers.BatchNormalization(axis=1, epsilon=0.5973642934269454,  name = 'Bat84132', )(Glo67382)
model = tf.keras.models.Model(inputs=[in0Glo67382], outputs=Bat84132)
w = model.get_layer('Bat84132').get_weights() 
w[0] = np.array([0.4931])
w[1] = np.array([0.2052])
w[2] = np.array([0.8206])
w[3] = np.array([0.1245])
model.get_layer('Bat84132').set_weights(w) 
in0Glo67382 = tf.constant([[[[[1.9833]], [[1.2807]]], [[[1.674]], [[1.7231]]]]])
print (np.array2string(model.predict([in0Glo67382],steps=1), separator=', '))
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='Bat84132.png')

LGlo67382 = global_average_pooling3D_layer([[[[[1.9833]], [[1.2807]]], [[[1.674]], [[1.7231]]]]], Glo67382), 
LBat84132 = batch_normalization_layer(Glo67382, 1, 0.5973642934269454, [0.4931], [0.2052], [0.8206], [0.1245], Bat84132), 
exec_layers([LGlo67382,LBat84132],["Glo67382","Bat84132"],Bat84132,"Bat84132")

Actual (Unparsed): [[0.6954266]]

Expected (Unparsed): [[0.6954265889936802]]

Actual:   [[0.6955]]

Expected: [[0.6955]]