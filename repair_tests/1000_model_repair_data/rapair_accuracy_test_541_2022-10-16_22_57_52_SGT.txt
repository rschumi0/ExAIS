origninal model:
LELU8613 = elu_layer([[[[[0.5010591234522161], [0.5788814936859175]]]]], -0.25789218425347116, ELU8613), 
LFla7305 = flatten_layer(ELU8613, Fla7305), 
LSim63054 = simple_rnn_layer([[[2, 10, 10]]],[[5, 2, 5], [6, 3, 10], [5, 6, 6]],[[5, 3, 5], [8, 2, 6], [1, 7, 4]],[5, 2, 2], Sim63054), 
LThr1387 = thresholded_relu_layer(Sim63054, 1.9720298161889995, Thr1387), 
LAdd21780 = add_layer([Fla7305,Thr1387], Add21780), 
exec_layers([LELU8613,LFla7305,LSim63054,LThr1387,LAdd21780],["ELU8613","Fla7305","Sim63054","Thr1387","Add21780"],Add21780,"Add21780")
-------------------------------------------------------------------------------------
json model:
{"layers":[{"inputs":["Fla7305","Thr1387"],"name":"Add21780","type":"add"},{"input_shape":"[1, 1, 1, 2, 1]","inputs":["[[[[[0.5010591234522161], [0.5788814936859175]]]]]"],"alpha":"-0.25789218425347116","name":"ELU8613","alphas":"","type":"elu"},{"inputs":["ELU8613"],"name":"Fla7305","type":"flatten"},{"nodes":"3","input_shape":"[1, 1, 3]","inputs":["[[[2, 10, 10]]]"],"bias":"[5, 2, 2]","name":"Sim63054","type":"simplernn","weights":"[[5, 2, 5], [6, 3, 10], [5, 6, 6]]","recurrent_weights":"[[5, 3, 5], [8, 2, 6], [1, 7, 4]]"},{"inputs":["Sim63054"],"name":"Thr1387","alphas":"","type":"thresholdedrelu","theta":"1.9720298161889995"}]}
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
repaired model:
LELU8613 = elu_layer([[[[[0.7931280235719929], [0.8404008049965779]]]]], -0.25789218425347116, ELU8613), 
LFla7305 = flatten_layer(ELU8613, Fla7305), 
LCon95476 = concatenate_layer([Fla7305,[[0.4825219670161248]]], 1, Con95476), 
LSim63054 = simple_rnn_layer([[[3, 9, 9]]],[[5, 2, 5], [6, 3, 10], [5, 6, 6]],[[5, 3, 5], [8, 2, 6], [1, 7, 4]],[5, 2, 2], Sim63054), 
LThr1387 = thresholded_relu_layer(Sim63054, 1.9720298161889995, Thr1387), 
LAdd21780 = add_layer([Con95476,Thr1387], Add21780), 
exec_layers([LELU8613,LFla7305,LCon95476,LSim63054,LThr1387,LAdd21780],["ELU8613","Fla7305","Con95476","Sim63054","Thr1387","Add21780"],Add21780,"Add21780")
-------------------------------------------------------------------------------------
origin size: 5 repaired size: 6
origin input size: 8 repaired input size: 4
number of issues: 1 total repair duration: 11576.219s repair duration: 4.761s